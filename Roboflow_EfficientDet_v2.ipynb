{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mearan/Eficiendet/blob/main/Roboflow_EfficientDet_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dA0CmSKv-7y-"
      },
      "source": [
        "For the most up to date version of this notebook, please copy from this link\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1ZmbeTro4SqT7h_TfW63MLdqbrCUk_1br#scrollTo=KwDS9qqBbMQa)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAs6vn4Rukct"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# Overview\n",
        "\n",
        "üí° Recommendation: Open this blog post on [how to train EfficientDet](https://towardsdatascience.com/training-efficientdet-object-detection-model-with-a-custom-dataset-25fb0f190555) to continue.\n",
        "\n",
        "In this notebook we show an example of how to train EfficientDet using a pytorch implementation on a custom dataset that has been uploaded through RoboFlow. The example provides a flexible framework, so you can apply it to your own dataset with a custom number of classes and a different objective. We we tackle chess here. \n",
        "\n",
        "![Chess Example](https://i.imgur.com/nkjobw1.png)\n",
        "\n",
        "### **Our Data and Roboflow**\n",
        "\n",
        "Our dataset of 289 chess images (and 2894 annotations!) is hosted publicly on Roboflow [here](https://public.roboflow.ai/object-detection/chess-full). Roboflow also hosts many other public datasets and you can easily upload your own custom dataset for your use case, augment, and export in flexible formats. Our tutorial uses Coco Json, but you might have another format (say tfrecord). No problem! Upload your dataset and we will export it in the required format.\n",
        "\n",
        "### **Model and Training**\n",
        "\n",
        "For a deep dive on the EfficientDet model please see [the paper](https://arxiv.org/abs/1911.09070). For a shorter look, here is a great [blog post](https://towardsdatascience.com/efficientdet-scalable-and-efficient-object-detection-review-4472ffc34fd9)! \n",
        "\n",
        "We use a pytorch implementation of EfficientDet using the [image detection library](https://github.com/roboflow-ai/Monk_Object_Detection) from Tessellate-Imaging for object detection. Our implementation uses the base version of EfficientDet-d0.  We train from the EfficientNet base backbone, without using a pretrained checkpoint for the detector.\n",
        "\n",
        "### **Inference**\n",
        "\n",
        "We witness some fast inference on a few basic examples from our test set to see that our approach is heading in the right direction.\n",
        "\n",
        "### **Export**\n",
        "\n",
        "We export our model weights to google drive for future utilization.\n",
        "\n",
        "### **Next Steps**\n",
        "\n",
        "We will be exploring evaluation on custom RoboFlow datasets and objectives compared to yoloV3, including training time, inference time, model size, and performance. \n",
        "\n",
        "We will also explore comparing performance from the Coco pretrained checkpoint!\n",
        "\n",
        "## **Stay in touch!**\n",
        "\n",
        "If you run into any hurdles on your own data set or just want to share some cool results in your own domain, [reach out to us](roboflow.ai)! \n",
        "\n",
        "#### ![Roboflow Workmark](https://i.imgur.com/WHFqYSJ.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SJBVVCyvObX"
      },
      "source": [
        "# Setting up our envionment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2EDGrtsba1E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b153cbc-30da-4657-f8f3-e42955f3ef6b"
      },
      "source": [
        "#our fork of the Tessellate-Imaging image detection library\n",
        "#!rm -rf Monk_Object_Detection\n",
        "! git clone https://github.com/roboflow-ai/Monk_Object_Detection.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Monk_Object_Detection'...\n",
            "remote: Enumerating objects: 3794, done.\u001b[K\n",
            "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 3794 (delta 28), reused 30 (delta 16), pack-reused 3747\u001b[K\n",
            "Receiving objects: 100% (3794/3794), 132.21 MiB | 21.94 MiB/s, done.\n",
            "Resolving deltas: 100% (828/828), done.\n",
            "Updating files: 100% (4032/4032), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIu1PTPlcAuU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ede7f4b-e56a-44e7-9458-c3f08ab327d6"
      },
      "source": [
        "# For colab use the command below\n",
        "# Set up library requirments\n",
        "! cd Monk_Object_Detection/3_mxrcnn/installation && cat requirements_colab.txt | xargs -n 1 -L 1 pip install"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mxnet-cu100\n",
            "  Downloading mxnet_cu100-1.9.0-py3-none-manylinux2014_x86_64.whl (354.0 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m354.0/354.0 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.10/dist-packages (from mxnet-cu100) (1.22.4)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet-cu100) (2.27.1)\n",
            "Collecting graphviz<0.9.0,>=0.8.1 (from mxnet-cu100)\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet-cu100) (3.4)\n",
            "Installing collected packages: graphviz, mxnet-cu100\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.20.1\n",
            "    Uninstalling graphviz-0.20.1:\n",
            "      Successfully uninstalled graphviz-0.20.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-cu100-1.9.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dicttoxml\n",
            "  Downloading dicttoxml-1.7.16-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: dicttoxml\n",
            "Successfully installed dicttoxml-1.7.16\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xmltodict\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: xmltodict\n",
            "Successfully installed xmltodict-0.13.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pycocotools\n",
            "  Cloning https://github.com/abhi-kumar/cocoapi.git to /tmp/pip-install-4rqqa0gi/pycocotools_4b812fcd2eea4a459a208cc6765af935\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/abhi-kumar/cocoapi.git /tmp/pip-install-4rqqa0gi/pycocotools_4b812fcd2eea4a459a208cc6765af935\n",
            "  Resolved https://github.com/abhi-kumar/cocoapi.git to commit 1d6d019f8938f47a9b5af28685011898b25ff93a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools) (67.7.2)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.10/dist-packages (from pycocotools) (0.29.34)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\n",
            "Building wheels for collected packages: pycocotools\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp310-cp310-linux_x86_64.whl size=386162 sha256=08546b88862b120364af5e672908cac4b55b7590f00fbd5b2b7d49cb1b3a44b2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-si3omiz8/wheels/3a/99/72/80011e7ed3f3a7ce5e34de816a6d6016008c29f8f89605823a\n",
            "Successfully built pycocotools\n",
            "Installing collected packages: pycocotools\n",
            "  Attempting uninstall: pycocotools\n",
            "    Found existing installation: pycocotools 2.0.6\n",
            "    Uninstalling pycocotools-2.0.6:\n",
            "      Successfully uninstalled pycocotools-2.0.6\n",
            "Successfully installed pycocotools-2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2YxNg_6ftEC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d0fa91d-a936-4d82-b69f-547f7c22c579"
      },
      "source": [
        "#fixed version of tqdm output for Colab\n",
        "!pip install --force https://github.com/chengs/tqdm/archive/colab.zip\n",
        "#IGNORE restart runtime warning, it is indeed installed\n",
        "#missing a few extra packages that we will need later! \n",
        "!pip install efficientnet_pytorch\n",
        "!pip install tensorboardX"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting https://github.com/chengs/tqdm/archive/colab.zip\n",
            "  Downloading https://github.com/chengs/tqdm/archive/colab.zip\n",
            "\u001b[2K     \u001b[32m-\u001b[0m \u001b[32m91.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: tqdm\n",
            "  Building wheel for tqdm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tqdm: filename=tqdm-4.28.1-py2.py3-none-any.whl size=47876 sha256=b66d2e20b9839e27d3a1343300347fc729ff861af0ae9bcfa9d928f2d3a745cf\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dnx6o1ey/wheels/65/77/d5/d5ddeac9924f01d101ed3d2bf420c627eba535f8b8d93f27ee\n",
            "Successfully built tqdm\n",
            "Installing collected packages: tqdm\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.65.0\n",
            "    Uninstalling tqdm-4.65.0:\n",
            "      Successfully uninstalled tqdm-4.65.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "panel 0.14.4 requires tqdm>=4.48.0, but you have tqdm 4.28.1 which is incompatible.\n",
            "prophet 1.1.2 requires tqdm>=4.36.1, but you have tqdm 4.28.1 which is incompatible.\n",
            "spacy 3.5.2 requires tqdm<5.0.0,>=4.38.0, but you have tqdm 4.28.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tqdm-4.28.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet_pytorch) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->efficientnet_pytorch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->efficientnet_pytorch) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet_pytorch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\n",
            "Building wheels for collected packages: efficientnet_pytorch\n",
            "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16427 sha256=f04f624a0103f85be36eab3370d461240a63e1acad4af3f855e6ab3bf8e9741f\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "Successfully built efficientnet_pytorch\n",
            "Installing collected packages: efficientnet_pytorch\n",
            "Successfully installed efficientnet_pytorch-0.7.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.1)\n",
            "Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PdgWcjbc0hj"
      },
      "source": [
        "# Let's get some data! \n",
        "\n",
        "The best part about Roboflow is the efficient management of your datasets. [Upload you dataset](roboflow.ai) and you will recieve a fresh curl code to ouput it in whatever augmented and annotated format you need. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -L \"https://app.roboflow.com/ds/CEUgj3HBPt?key=4NvpPvx249\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n"
      ],
      "metadata": {
        "id": "4MftjLDtJ4-F",
        "outputId": "9d73b2d3-bc75-4e95-a7de-57094c27c6c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            " extracting: train/2010-mitsubishi-fuso-26-ft-box-truck_jpg.rf.61f5c54cdbd4130986dca6211ad29956.jpg  \n",
            " extracting: train/2010-mitsubishi-fuso-26-ft-box-truck_jpg.rf.ad87da9c93b2c74fb0ea8fa893f8055d.jpg  \n",
            " extracting: train/2010-mitsubishi-fuso-fe145-12ft-box-_jpg.rf.45421b6754ea04223df4c22a75140490.jpg  \n",
            " extracting: train/2010-mitsubishi-fuso-fe145-12ft-box-_jpg.rf.a4b78d6af27baebd48e2e7b3df92f9c9.jpg  \n",
            " extracting: train/2010-mitsubishi-fuso-fe145-12ft-box-_jpg.rf.b2672a85bcd8512d6b2c960db59e0572.jpg  \n",
            " extracting: train/2010-mitsubishi-fuso-fe145-12ft-box-_jpg.rf.dbf8827d740d345375d6d525c0bd6b08.jpg  \n",
            " extracting: train/2012-mitsubishi-fuso-canter-fe160-du-1_jpg.rf.0fdef5168f9bf62c805932e31a13fc4b.jpg  \n",
            " extracting: train/2012-mitsubishi-fuso-canter-fe160-du-1_jpg.rf.221f67b1c1d2d34498253f1f2c7fdafc.jpg  \n",
            " extracting: train/2012-mitsubishi-fuso-canter-fe160-du-1_jpg.rf.5f6727824f063ce642c7d5e098e307cf.jpg  \n",
            " extracting: train/2012-mitsubishi-fuso-canter-fe160-du-1_jpg.rf.6c3dfe19c11e1f6f3424dcdc32a906bd.jpg  \n",
            " extracting: train/2012-mitsubishi-fuso-canter-fe160-du_jpg.rf.c3b4ccd6c8d7282326a711bc61e65209.jpg  \n",
            " extracting: train/2012-mitsubishi-fuso-fe160-16ft-dump-1_jpg.rf.99107357f51c14a6b8860f8de41c22af.jpg  \n",
            " extracting: train/2012-mitsubishi-fuso-fe160-16ft-dump-1_jpg.rf.ce7d0caf45ee6a62d4aad50b05223543.jpg  \n",
            " extracting: train/2012-mitsubishi-fuso-fe160-16ft-dump-1_jpg.rf.f38b9fa9f3f76fbf3e49fdf88d14e0a1.jpg  \n",
            " extracting: train/2012-mitsubishi-fuso-fe160-16ft-dump-2_jpg.rf.b1dee9eb360b98cbf155e3a333687e3b.jpg  \n",
            " extracting: train/2012-mitsubishi-fuso-fe160-16ft-dump-2_jpg.rf.df7bfb772b760b4c1976d0ff7eb62f73.jpg  \n",
            " extracting: train/2012-mitsubishi-fuso-fe160-16ft-dump-2_jpg.rf.f7ea5d4c994cb2109cab076a98089338.jpg  \n",
            " extracting: train/2012-mitsubishi-fuso-fe160-16ft-dump_jpg.rf.19ff455c0461e8b6c302e5bf6a3650e8.jpg  \n",
            " extracting: train/2012-mitsubishi-fuso-fe160-16ft-dump_jpg.rf.3104527037abfc5ff8bb2efe900566c4.jpg  \n",
            " extracting: train/2012-mitsubishi-fuso-fe160-16ft-dump_jpg.rf.b13f0318c32efdf433669d9546321fa9.jpg  \n",
            " extracting: train/2012-mitsubishi-fuso-fe160-16ft-dump_jpg.rf.cddac9a6e72dfb590e0500bc96fb32ac.jpg  \n",
            " extracting: train/2012-mitsubishi-fuso-fe160-16ft-dump_jpg.rf.d045223f85a1c7b5684a1c124c601976.jpg  \n",
            " extracting: train/2012-mitsubishi-fuso-fe160-16ft-dump_jpg.rf.e7b0efa540c07df0b83bd3240d4a2032.jpg  \n",
            " extracting: train/20121009_123807_jpg.rf.681fde8e386537cad362145a03349058.jpg  \n",
            " extracting: train/20121009_123807_jpg.rf.ce475f42cc2f953490ef17da2184b996.jpg  \n",
            " extracting: train/20121009_123807_jpg.rf.f5074949cd8e7c9676c1cc348f6c8891.jpg  \n",
            " extracting: train/2013-Fuso-Canter-4x4-1-1_jpg.rf.0139dc00ddd0b3af8ff527ad14504b0f.jpg  \n",
            " extracting: train/2013-Fuso-Canter-4x4-1-1_jpg.rf.182ce5f62a405c4ef5b797b62a5eb1bc.jpg  \n",
            " extracting: train/2013-Fuso-Canter-4x4-1-1_jpg.rf.6027f9c96155f5ef9c47d73cac4b9b4e.jpg  \n",
            " extracting: train/2013-Fuso-Canter-4x4-1-1_jpg.rf.c65ddc24df5f610017fba167e3590615.jpg  \n",
            " extracting: train/2013-Mitsubishi-18ft-Refrigerated-Va_jpg.rf.c49b3b38047446f88acab4aa943c17d5.jpg  \n",
            " extracting: train/2013-Mitsubishi-Fuso-Canter-7C15-PBU_jpg.rf.25f44e379cf7dc2afce8372d55b3e295.jpg  \n",
            " extracting: train/2013-Mitsubishi-Fuso-Canter-7C15-PBU_jpg.rf.687c010e22c70c15b9d4c15c4785ff9a.jpg  \n",
            " extracting: train/2013-Mitsubishi-Fuso-Canter-7C15-PBU_jpg.rf.e9a0a2e61d65c676a92c625c3df84401.jpg  \n",
            " extracting: train/2013-mitsubishi-fuso-fe160-20-box-tr_jpg.rf.01ccf09f83402954001cedc6fc70a2f5.jpg  \n",
            " extracting: train/2013-mitsubishi-fuso-fe160-20-box-tr_jpg.rf.0bf406e3239d7ec71ed39ce7ca09f6b5.jpg  \n",
            " extracting: train/2013-mitsubishi-fuso-fe160-20-box-tr_jpg.rf.691da95ac1222fdc8fdcc843214474e5.jpg  \n",
            " extracting: train/2013-mitsubishi-fuso-fe160-20-box-tr_jpg.rf.6c818267e4f6cd3482266373c42ee1ae.jpg  \n",
            " extracting: train/2013-mitsubishi-fuso-fe160-20-box-tr_jpg.rf.7829adee1c574116702d6867d16c0174.jpg  \n",
            " extracting: train/2014-mitsubishi-canter-truck-7mnuxba_jpg.rf.44193493ad76a1aa0825643fa5aab7f5.jpg  \n",
            " extracting: train/2014-mitsubishi-canter-truck-7mnuxba_jpg.rf.86e3d3d5edc91843942bcf938b20ad4b.jpg  \n",
            " extracting: train/2014-mitsubishi-canter-truck-7mnuxba_jpg.rf.97c7ba6e4728f55177072f2fae71754a.jpg  \n",
            " extracting: train/2014-mitsubishi-canter-truck-7mnuxba_jpg.rf.bc1bfc5f3ff5f7b31302733044f0133d.jpg  \n",
            " extracting: train/2014-mitsubishi-canter-truck-ugikpwq_jpg.rf.379a1afa8c853fa0c219a86a0aa9a765.jpg  \n",
            " extracting: train/2014-mitsubishi-canter-truck-ugikpwq_jpg.rf.cc2b0e4a953861f103adecd6216ed4b2.jpg  \n",
            " extracting: train/2014-mitsubishi-fuso-fe160-14-feet-b_jpg.rf.49dd8d97ea730e70fe2599d2b4d64ab4.jpg  \n",
            " extracting: train/2014-mitsubishi-fuso-fe160-14-feet-b_jpg.rf.d0e2c0b9b5b1d2070e010333509d9889.jpg  \n",
            " extracting: train/2014-mitsubishi-fuso-fe160-14-feet-b_jpg.rf.f8c1ef3543d17c90b21a76eed730c8a1.jpg  \n",
            " extracting: train/2015-Mitsubishi-Fuso-Canter-7C15-4x2-1_jpg.rf.852c7cac588e76924e69f8e2e6787d23.jpg  \n",
            " extracting: train/2015-Mitsubishi-Fuso-Canter-7C15-4x2_jpg.rf.5badbb18bbdbb88456dbdde157b761f7.jpg  \n",
            " extracting: train/2015-Mitsubishi-Fuso-Canter-7C15-4x2_jpg.rf.6a4e5da1c08923f188ed258f00078372.jpg  \n",
            " extracting: train/2015-mitsubishi-fuso-fe180-dual-tech_jpg.rf.b1011c8d723b55df729194cae5382195.jpg  \n",
            " extracting: train/2015-mitsubishi-fuso-fe180-dual-tech_jpg.rf.cbb10037e85621630235b20c75d2cd2a.jpg  \n",
            " extracting: train/2015-mitsubishi-fuso-fe180-dual-tech_jpg.rf.d4bfe89dfc2d76b482b9389295ce4e74.jpg  \n",
            " extracting: train/2015-mitsubishi-fuso-fe180-dual-tech_jpg.rf.dd121a7700fa0c5881c5b22f9a995333.jpg  \n",
            " extracting: train/2017-Mitsubishi-Super-Great-Cargo-Du_jpg.rf.2407cbbcd07d4e99e4daa0698e9df319.jpg  \n",
            " extracting: train/2017-Mitsubishi-Super-Great-Cargo-Du_jpg.rf.d71dd43f704ee3f3334cd8f279b16f51.jpg  \n",
            " extracting: train/20170325_115955_HDRw_1u_jpg.rf.786dcdb36c240532e4a762b7ec016ee6.jpg  \n",
            " extracting: train/20170325_115955_HDRw_1u_jpg.rf.99965881331d32b9a39195e0ea058908.jpg  \n",
            " extracting: train/201707170712_fuso-1024x512_jpg.rf.033e1320c6e0aa3dc1e87053b25d890d.jpg  \n",
            " extracting: train/201707170712_fuso-1024x512_jpg.rf.0bb1dd12c64ef92bafb78823560499af.jpg  \n",
            " extracting: train/201707170712_fuso-1024x512_jpg.rf.deef60b2d02b20070a778ff08965481b.jpg  \n",
            " extracting: train/201707170712_fuso-1024x512_jpg.rf.f9422f414df631b8ccda41330c0df272.jpg  \n",
            " extracting: train/201707170712_fuso_jpg.rf.6b6b929011adb7bb857ff4eb40b51854.jpg  \n",
            " extracting: train/201707170712_fuso_jpg.rf.ada21acb98997ed4dedaf3b7f410f493.jpg  \n",
            " extracting: train/20170820170831fuso-1-1024x674_jpg.rf.c484baba3f5edcc9a8ebf944a56125b9.jpg  \n",
            " extracting: train/20170820170831fuso-1-1024x674_jpg.rf.d2303a5c7fb7e0757818c2b064f2171f.jpg  \n",
            " extracting: train/20171210_212912_jpg.rf.03615682c2f9059638b4c28945a2b492.jpg  \n",
            " extracting: train/20171211_084300_jpg.rf.e5a64783bb6a242f5bdf5b5d1d8124c5.jpg  \n",
            " extracting: train/20171211_110642_jpg.rf.bdd3d666db9b4c82a92f3169c7b7cd92.jpg  \n",
            " extracting: train/20171211_110651_jpg.rf.ea56c6d50955a4b4bc508951800d0d9e.jpg  \n",
            " extracting: train/20171211_110659_jpg.rf.7ba33c09a5a3664c00202eb4fdbc2c95.jpg  \n",
            " extracting: train/20171211_110711_jpg.rf.feb4554a78c57904b5f501b6593dc14c.jpg  \n",
            " extracting: train/20171211_154917_jpg.rf.6cc1d4a04d37593c59ab8fb5750e96e0.jpg  \n",
            " extracting: train/20171211_154939_jpg.rf.b000e6d375a4eb9a2fbb02f1803a15a8.jpg  \n",
            " extracting: train/20171211_160434_jpg.rf.398d463a83a44558b27a78fc19a47392.jpg  \n",
            " extracting: train/20171212_073402_jpg.rf.1e44a49a19ea334dd9bdc852659b8fa1.jpg  \n",
            " extracting: train/20171212_073415_jpg.rf.4835aea07c1106a48fc078bad7775ff0.jpg  \n",
            " extracting: train/20171212_073435_jpg.rf.d824cfb527dc96b5594f387c1d082c65.jpg  \n",
            " extracting: train/20171212_100546_jpg.rf.42b716f428e0bcbd8dc8cb85976f9bee.jpg  \n",
            " extracting: train/20171212_100708_jpg.rf.ebefb49bd73fd0022940c86f9f48b3e7.jpg  \n",
            " extracting: train/20171212_124357_jpg.rf.4347819a00c8394b05b915635c8cb29d.jpg  \n",
            " extracting: train/20171212_124415_jpg.rf.2ad1beb1cf57cfcc1d64a0881c1a8ea4.jpg  \n",
            " extracting: train/20171212_124449_jpg.rf.5fb92abb46bd88db73dfea8cbbf1e062.jpg  \n",
            " extracting: train/20171212_141155_jpg.rf.2e6bc22d92623862d4a56cbc0a9315a3.jpg  \n",
            " extracting: train/20171212_141203_jpg.rf.f841665e245831a73cc551e278fbe667.jpg  \n",
            " extracting: train/20171212_142228_jpg.rf.45862eff32b58985cd48a8f0fcecb1cb.jpg  \n",
            " extracting: train/20171212_142243_jpg.rf.9ef012ab1af4937913cace7050885ebe.jpg  \n",
            " extracting: train/20171212_142342_jpg.rf.4281cdbeccb2b7ea8f0e6ae661f3e7ee.jpg  \n",
            " extracting: train/20171214_091545_jpg.rf.766f6caf471f9bc34d6846501b8065ce.jpg  \n",
            " extracting: train/20171214_121617_jpg.rf.a889caa2c45d06c476509a491290b8da.jpg  \n",
            " extracting: train/20171214_121636_jpg.rf.78097f208066d2ab19639cdddfc429da.jpg  \n",
            " extracting: train/20180925_133619_jpg.rf.129d2673f3f0c11d337b687c6fa826b4.jpg  \n",
            " extracting: train/20180925_133619_jpg.rf.7e0f99a7b0761c2f46faa900af4bbfca.jpg  \n",
            " extracting: train/20180925_133619_jpg.rf.c158407cfad350cc7b758369512a4f51.jpg  \n",
            " extracting: train/2020-09-19-16-41-50-1100x674_jpg.rf.25bc60f9155c5c775c709ce32be809e9.jpg  \n",
            " extracting: train/2020-09-19-16-41-50-1100x674_jpg.rf.6bbe7dfe12f740e5fafe89da4ff10e3a.jpg  \n",
            " extracting: train/2020-09-19-16-41-50-1100x674_jpg.rf.d62a8e219e51ff4acff547ea4b1d3f43.jpg  \n",
            " extracting: train/2021-fuso-fe180-steel-dumptruck-oran_jpg.rf.becc739cadfee4c9f6b8b533cebd2857.jpg  \n",
            " extracting: train/2021-fuso-fe180-steel-dumptruck-oran_jpg.rf.fcf9c9d98148b7e9308169ac4be1f5d8.jpg  \n",
            " extracting: train/2021-fuso-fe180-steel-dumptruck-west_jpg.rf.387fe1b6510aed371b62dc3712399ac3.jpg  \n",
            " extracting: train/2021-fuso-fe180-steel-dumptruck-west_jpg.rf.d06f04e246e4459620d0cd9befda2d8a.jpg  \n",
            " extracting: train/2021-fuso-fe180-steel-dumptruck-west_jpg.rf.e87be9e6b3b16c9faa9abe56a9d14d3a.jpg  \n",
            " extracting: train/20211122_114011_jpg.rf.f5f36253300b956c159ea71f1ea74d2c.jpg  \n",
            " extracting: train/20211122_114029_jpg.rf.e0359cd04f2b569cabc380758d933f96.jpg  \n",
            " extracting: train/20211122_114037_jpg.rf.0ebd650b9fca3743078b4068ef7ce8bc.jpg  \n",
            " extracting: train/20211122_114133_jpg.rf.6841dc4facb5d628d4966ae7ab776d52.jpg  \n",
            " extracting: train/20211122_114142_jpg.rf.a186c9cc6f9c19e2490ac2bc8517a4e0.jpg  \n",
            " extracting: train/20211122_114201_jpg.rf.aabdaec0c8afddadf0abfab81b1acd01.jpg  \n",
            " extracting: train/20211122_114210_jpg.rf.e473bd0a28b3fe78748b4f3f1dce57ff.jpg  \n",
            " extracting: train/20211122_114224_jpg.rf.8005d4006d0c86ef96f9995627d4c915.jpg  \n",
            " extracting: train/20211122_114233_jpg.rf.f9106108a9ad61b408e6986036079707.jpg  \n",
            " extracting: train/20211122_114245_jpg.rf.200d8bb466800a008f1b1519cf5da7df.jpg  \n",
            " extracting: train/20211122_114305_jpg.rf.155433ec16245bf4d3d1e7d75aca60fd.jpg  \n",
            " extracting: train/20211122_114320_jpg.rf.87a9cd5171aa1191cdb19d19d38a1887.jpg  \n",
            " extracting: train/20211122_114325_jpg.rf.1e474afe70974940d6018017c15df494.jpg  \n",
            " extracting: train/20211122_114332_jpg.rf.3da83ca087bda54bc71c40bbada63135.jpg  \n",
            " extracting: train/20211122_114344_jpg.rf.b685162c1d20e13d14ead937b514e229.jpg  \n",
            " extracting: train/20211122_114352_jpg.rf.1d9857e809cfdb417233c788f66d1e41.jpg  \n",
            " extracting: train/20211122_114406_jpg.rf.96060c57f9390a729fd7fe8efa0a28a6.jpg  \n",
            " extracting: train/20211122_114415_jpg.rf.028aaf2892390f7ba6cb904f25012899.jpg  \n",
            " extracting: train/20211122_114429_jpg.rf.8d51e3c322bfef55a301d0bb27910238.jpg  \n",
            " extracting: train/20211122_114435_jpg.rf.0633c4553b0cd794331c1bc6a705b029.jpg  \n",
            " extracting: train/20211122_114453_jpg.rf.2479bf2af97361b8c89083d8451b2b20.jpg  \n",
            " extracting: train/20211122_114501_jpg.rf.758d8d331331eb70330b69ef597b92b4.jpg  \n",
            " extracting: train/20211122_114507_jpg.rf.d79e0c61552eb1067d67d92fd7aa3078.jpg  \n",
            " extracting: train/20211122_114513_jpg.rf.c2209c42aff92cff36f2382b4b49b354.jpg  \n",
            " extracting: train/20211122_114527_jpg.rf.8a7511ec75dac7f216961f00e006c2bc.jpg  \n",
            " extracting: train/20211122_114541_jpg.rf.fc23879083b4f25cde435d86effaaebf.jpg  \n",
            " extracting: train/20211122_114604_jpg.rf.18ceadd799c6769a534966acd253f58b.jpg  \n",
            " extracting: train/20211122_114618_jpg.rf.ffea546ab58176813d4cc92a5b9299e2.jpg  \n",
            " extracting: train/20211122_114638_jpg.rf.374974e0caec8ed675ef032372fd063f.jpg  \n",
            " extracting: train/20211122_114649_jpg.rf.85bc1afcb49b21badf21927fe249fcf0.jpg  \n",
            " extracting: train/2022-05-15-09_46_24-20220514_111222-mp4-VLC-media-player_jpg.rf.c2ba27d69b3df631d02e6fe6d6a246f0.jpg  \n",
            " extracting: train/2022-05-15-09_48_38-20220514_111222-mp4-VLC-media-player_jpg.rf.77c44b0a565aedacffc5649f0fbc53b0.jpg  \n",
            " extracting: train/2022-05-15-09_48_38-20220514_111222-mp4-VLC-media-player_jpg.rf.eb759da72c113b4a1c70e01f05646f3e.jpg  \n",
            " extracting: train/2022-05-15-09_50_17-20220514_111222-mp4-VLC-media-player_jpg.rf.0ea7967ec2d245a389fd79c50cdbf978.jpg  \n",
            " extracting: train/2022-05-15-09_52_11-20220514_111222-mp4-VLC-media-player_jpg.rf.06c94a5f3fb3fe05def7f8be0aa2f293.jpg  \n",
            " extracting: train/2022-05-15-09_52_11-20220514_111222-mp4-VLC-media-player_jpg.rf.531f72ba7719153186d34948c4254697.jpg  \n",
            " extracting: train/2022-05-15-09_53_43-20220514_111222-mp4-VLC-media-player_jpg.rf.2670fa5ffcf5c064f3e13a5322858cd8.jpg  \n",
            " extracting: train/2022-05-15-09_53_43-20220514_111222-mp4-VLC-media-player_jpg.rf.c4215931818dc3e4db09ad48f6145013.jpg  \n",
            " extracting: train/2022-05-15-09_54_24-20220514_111222-mp4-VLC-media-player_jpg.rf.5bb8c6d2f8c72b4920ca176ae47b7e3d.jpg  \n",
            " extracting: train/2022-05-15-09_54_44-20220514_111222-mp4-VLC-media-player_jpg.rf.ba05033693e9810edba5af0c48831003.jpg  \n",
            " extracting: train/2022-05-15-09_54_44-20220514_111222-mp4-VLC-media-player_jpg.rf.e495bccab64604ff1c6635b11604c3d7.jpg  \n",
            " extracting: train/2022-05-15-09_57_15-20220514_111222-mp4-VLC-media-player_jpg.rf.1897f32c64b0964ad08f8f54819a3545.jpg  \n",
            " extracting: train/2022-05-15-09_59_08-20220514_111444-mp4-VLC-media-player_jpg.rf.c7f51f120f0749c0e1113f489cfc6203.jpg  \n",
            " extracting: train/2022-05-15-09_59_25-20220514_111444-mp4-VLC-media-player_jpg.rf.0a4efd38601c2c5cacc3ffcd2e037d3c.jpg  \n",
            " extracting: train/2022-05-15-09_59_25-20220514_111444-mp4-VLC-media-player_jpg.rf.f5d97a399a24f8d9515950b4bb77e767.jpg  \n",
            " extracting: train/2022-05-15-09_59_54-20220514_111444-mp4-VLC-media-player_jpg.rf.cde9991fdc01d75eacd198e928c5e367.jpg  \n",
            " extracting: train/2022-05-15-10_00_02-20220514_111444-mp4-VLC-media-player_jpg.rf.882ea3c328854f2e7385cdc6d882c9e6.jpg  \n",
            " extracting: train/2022-05-15-10_01_25-20220514_111444-mp4-VLC-media-player_jpg.rf.3406ad3ae429814b7ee59968f07598ed.jpg  \n",
            " extracting: train/2022-05-15-10_02_30-20220514_112722-mp4-VLC-media-player_jpg.rf.eee64784d77e1b8647e8f0469303632c.jpg  \n",
            " extracting: train/2022-05-15-10_02_45-20220514_112722-mp4-VLC-media-player_jpg.rf.41c7b7e9d5235b36ee67e9bbac8a1dba.jpg  \n",
            " extracting: train/2022-05-15-10_02_50-20220514_112722-mp4-VLC-media-player_jpg.rf.c51ea26de3a35ab3838de0ca4cb881d4.jpg  \n",
            " extracting: train/2022-05-15-10_03_02-20220514_112722-mp4-VLC-media-player_jpg.rf.28ac2d1b4327ee4dbf20bb81486f0800.jpg  \n",
            " extracting: train/2022-05-15-10_03_02-20220514_112722-mp4-VLC-media-player_jpg.rf.aaa26219a8e6b8324c24dc3e00144709.jpg  \n",
            " extracting: train/2022-05-15-10_03_23-20220514_112722-mp4-VLC-media-player_jpg.rf.4029051356e708b714e52d565e36fb47.jpg  \n",
            " extracting: train/2022-05-15-10_03_33-20220514_112722-mp4-VLC-media-player_jpg.rf.760f48dfe607af620ae0dc990a4bc217.jpg  \n",
            " extracting: train/2022-05-15-10_03_33-20220514_112722-mp4-VLC-media-player_jpg.rf.a42a2a05c1fb7a0470823bb2c1f527d7.jpg  \n",
            " extracting: train/2022-05-15-10_03_50-20220514_112722-mp4-VLC-media-player_jpg.rf.6829eafe47ccbd186b505e219efdba80.jpg  \n",
            " extracting: train/2022-05-15-10_03_50-20220514_112722-mp4-VLC-media-player_jpg.rf.898dc71fc7309d72a9f8e6b662d5ec09.jpg  \n",
            " extracting: train/2022-05-15-10_03_58-20220514_112722-mp4-VLC-media-player_jpg.rf.4194b23444fd6c71bdb65b85ad6cedd3.jpg  \n",
            " extracting: train/2022-05-15-10_03_58-20220514_112722-mp4-VLC-media-player_jpg.rf.6836685da3cb36cff2f51827577f3d34.jpg  \n",
            " extracting: train/2022-05-15-10_04_08-20220514_112722-mp4-VLC-media-player_jpg.rf.0a3b46ea3bf8028c24583213b6dd6da5.jpg  \n",
            " extracting: train/2022-05-15-10_04_08-20220514_112722-mp4-VLC-media-player_jpg.rf.d5dafefeadbf2b53560161e066bc1521.jpg  \n",
            " extracting: train/2022-05-15-10_04_52-20220514_112722-mp4-VLC-media-player_jpg.rf.dd1d344251f306c11ee148b6e0e5302b.jpg  \n",
            " extracting: train/2022-05-15-10_06_45-20220514_112722-mp4-VLC-media-player_jpg.rf.627c5d20a023ee181c2af1a0ae675867.jpg  \n",
            " extracting: train/2022-05-15-10_06_59-20220514_112722-mp4-VLC-media-player_jpg.rf.6890f9251221941003c41c2daa9bbad1.jpg  \n",
            " extracting: train/2022-05-15-10_07_49-20220514_112722-mp4-VLC-media-player_jpg.rf.acaf9d54ee29fcb889fef21d7e15a9a5.jpg  \n",
            " extracting: train/2022-05-15-10_07_59-20220514_112722-mp4-VLC-media-player_jpg.rf.da6ec858fb9647011bdc345223a76ae6.jpg  \n",
            " extracting: train/2022-05-15-10_08_10-20220514_112722-mp4-VLC-media-player_jpg.rf.47ae9b3d69f5c3ac0927dfa4dfdf5c62.jpg  \n",
            " extracting: train/2022-05-15-10_09_03-20220514_112722-mp4-VLC-media-player_jpg.rf.d7b0deb6756fd6667a0b6c2a79665f71.jpg  \n",
            " extracting: train/2022-05-15-10_09_46-20220514_112722-mp4-VLC-media-player_jpg.rf.420186e77eb6f2c1c14db25810940e58.jpg  \n",
            " extracting: train/2022-05-15-10_09_57-20220514_112722-mp4-VLC-media-player_jpg.rf.9f0502e04f7e1c9a4f54f191944ce77c.jpg  \n",
            " extracting: train/2022-05-15-10_11_17-20220514_112722-mp4-VLC-media-player_jpg.rf.46b0e32f19a9e4a75b2157dcf94a61a7.jpg  \n",
            " extracting: train/2022-05-15-10_11_38-20220514_112722-mp4-VLC-media-player_jpg.rf.3c7d4aed18cbe5ae66f22de20662a627.jpg  \n",
            " extracting: train/2022-05-15-10_12_01-20220514_112722-mp4-VLC-media-player_jpg.rf.3a30700ba3b3fa9768d7a237d43461cd.jpg  \n",
            " extracting: train/2022-05-15-10_12_18-20220514_112722-mp4-VLC-media-player_jpg.rf.dc6c94a4bbcd0262233fabaabcd21896.jpg  \n",
            " extracting: train/2022-05-15-10_13_49-20220514_112722-mp4-VLC-media-player_jpg.rf.47eb0f1d2c000e764d7792c57d2d17c4.jpg  \n",
            " extracting: train/20220515_135912_jpg.rf.47ce77cf6cfeedaa49ae3a7fd857185c.jpg  \n",
            " extracting: train/20220515_140122_jpg.rf.bbe39defb55e032b10b080a3599e3d48.jpg  \n",
            " extracting: train/20220515_151534_jpg.rf.14700259fb1fce57b9705ce1d44cfcb5.jpg  \n",
            " extracting: train/20220515_151534_jpg.rf.7d0a311993c91d3fdfa73311491f023a.jpg  \n",
            " extracting: train/20220515_151751_jpg.rf.bcd9ceea602abce0e7cffb80e87150b6.jpg  \n",
            " extracting: train/20220515_152005_jpg.rf.df228556d49041186eb39a7457d20d56.jpg  \n",
            " extracting: train/20220515_152659_jpg.rf.12c893390f235ca7ee41c70b3945bced.jpg  \n",
            " extracting: train/20220515_153146_jpg.rf.6b5a8b71c26abfd0977e2fcd2eea50b3.jpg  \n",
            " extracting: train/20220515_202107-1-_jpg.rf.02b8cd2cff23b97d2ea289ec30bf0e03.jpg  \n",
            " extracting: train/20220515_202107-1-_jpg.rf.b4ec2424a393b759530589b2323936b5.jpg  \n",
            " extracting: train/20220515_202120-1-_jpg.rf.370519b6eaf37c1d18a6541748f60325.jpg  \n",
            " extracting: train/20220516_095815_jpg.rf.58f404f7af49b2f05ce3501df3f9436a.jpg  \n",
            " extracting: train/20220516_102400_jpg.rf.3a6e4fc3d2676804029b22ba710827f1.jpg  \n",
            " extracting: train/20220516_102424_jpg.rf.7bc052dbe5f1300815c5bb8129c5b794.jpg  \n",
            " extracting: train/20220516_103850_jpg.rf.224e7a74877261a524cefacc94f2e2f4.jpg  \n",
            " extracting: train/20220516_104623_jpg.rf.9595eec1f2c0c00cb8f50ade1cc9bbf6.jpg  \n",
            " extracting: train/20220516_120444_jpg.rf.4c77ac31d596eb6ffd8ec80f1fb78f0d.jpg  \n",
            " extracting: train/20220516_143612_jpg.rf.5c864280df2f08d6c58e71c83cb10020.jpg  \n",
            " extracting: train/20220516_143723_jpg.rf.2085689b1b5600bc5dc8680551d8aeb3.jpg  \n",
            " extracting: train/20220516_144206_jpg.rf.49a09ec1acb5ba8fd5cc5ae7a3420ab7.jpg  \n",
            " extracting: train/20220516_144302_jpg.rf.36b0d0739d72283b183a6ccb44bfce7c.jpg  \n",
            " extracting: train/20220516_144322_jpg.rf.31cf61e91151a9f041f236852cb699a5.jpg  \n",
            " extracting: train/20220516_144322_jpg.rf.7917c7e91ac647379264e489c5a91069.jpg  \n",
            " extracting: train/20220516_144343_jpg.rf.0db9d9db7970c66c3a4d2663694e78f0.jpg  \n",
            " extracting: train/20220516_144343_jpg.rf.1bfc76d76411cb5a1e8fe75a430faacb.jpg  \n",
            " extracting: train/20220516_144602_jpg.rf.5eb0310b56ebbf05f1eee92d419a45ea.jpg  \n",
            " extracting: train/20220516_144602_jpg.rf.76f597107f01ff770788c83172b0a84b.jpg  \n",
            " extracting: train/20220516_144604_jpg.rf.0f6b6190171fd38e945ed94ddd64c370.jpg  \n",
            " extracting: train/20220516_144654_jpg.rf.52bc46218b22bbe0addebf76499c2eb3.jpg  \n",
            " extracting: train/20220516_144744_jpg.rf.1f695a46b36593ddc83c5a922a98aed4.jpg  \n",
            " extracting: train/20220516_144744_jpg.rf.a4575382a3d97161a604097ea713a1f1.jpg  \n",
            " extracting: train/20220516_144755_jpg.rf.25e970c73013254d372439d89994e21e.jpg  \n",
            " extracting: train/20220516_144755_jpg.rf.beb54a05fd088a4fe4fcc64464643337.jpg  \n",
            " extracting: train/20220516_144848_jpg.rf.23eac6be27e861491d0bfb974feb0551.jpg  \n",
            " extracting: train/20220516_144852_jpg.rf.5128a077df4f9ad9bb6d1e87c1a96a26.jpg  \n",
            " extracting: train/20220516_145103_jpg.rf.a0010bae4f69d6d9861e99becd9eae63.jpg  \n",
            " extracting: train/20220516_145103_jpg.rf.b0e9ae3d35aa5e06af490b88792f4588.jpg  \n",
            " extracting: train/20220516_145147_jpg.rf.ca63fbc248e8c40b29c2c76ecaa8b547.jpg  \n",
            " extracting: train/20220516_145209_jpg.rf.53581a5c8eac57e0f0ba950056403405.jpg  \n",
            " extracting: train/20220516_145209_jpg.rf.70f189bf832020ea62119416d688eb3d.jpg  \n",
            " extracting: train/20220516_145254_jpg.rf.26df6d7e70e34e6adef700da39ada576.jpg  \n",
            " extracting: train/20220516_145254_jpg.rf.657bec559d65e464e5a844ae8ba0ffd4.jpg  \n",
            " extracting: train/20220516_145440_jpg.rf.d6557d3b2d49c6c2ac1e085d3ca95469.jpg  \n",
            " extracting: train/20220516_145507_jpg.rf.f57e3604824142d7d3ca60961bf35c64.jpg  \n",
            " extracting: train/20220516_145536_jpg.rf.4b5fda0fc39fc48bb02ed9b9e86170eb.jpg  \n",
            " extracting: train/20220516_145613_jpg.rf.037884b042eca7d1e927913ed3971cfa.jpg  \n",
            " extracting: train/20220516_145800_jpg.rf.a4f5639495ed8d5de8a27e7f4c98e31f.jpg  \n",
            " extracting: train/20220516_145800_jpg.rf.ef591b97a880957124e02e50656b0337.jpg  \n",
            " extracting: train/20220516_145804_jpg.rf.43874b32374fbde1204ce802120bb14d.jpg  \n",
            " extracting: train/20220516_145804_jpg.rf.4ea1fa08c5ceff81400218cc897dc1d6.jpg  \n",
            " extracting: train/20220516_145849_jpg.rf.665f9e1099e263cf1a30797c08e9c01d.jpg  \n",
            " extracting: train/20220516_145849_jpg.rf.99b0f92815f83e7c3aaf7d0164ef64dd.jpg  \n",
            " extracting: train/20220516_145908_jpg.rf.cefb3dcbeaf6ab7ec415bd1b9e01c711.jpg  \n",
            " extracting: train/20220517_123134_jpg.rf.8bb1835006123a42db681a6e10c1c357.jpg  \n",
            " extracting: train/20220517_123234_jpg.rf.e137cd70d90556bc92b6b12a24ae3674.jpg  \n",
            " extracting: train/20220517_123409_jpg.rf.6c1489aaef795671a783300bacab2bad.jpg  \n",
            " extracting: train/20220517_123417_jpg.rf.7f2fd6f32032f331301ccf03ab37d7c3.jpg  \n",
            " extracting: train/20220517_123427_jpg.rf.6b98c17ca186c84fbcd24144d8fdc852.jpg  \n",
            " extracting: train/20220517_123452_jpg.rf.310fa31332c6dc2877a0a79a03cfe8b9.jpg  \n",
            " extracting: train/20220517_123452_jpg.rf.aaa29bac9a091c8c45a18f8bf806e21d.jpg  \n",
            " extracting: train/20220517_123506_jpg.rf.697fd32a5abe4816434ddf83a8f78cab.jpg  \n",
            " extracting: train/20220517_123506_jpg.rf.ec0e3ed5553e49c95b906c7d1a4bb8c8.jpg  \n",
            " extracting: train/20220517_123511_jpg.rf.21755ae0532d817cad195bde6520f03a.jpg  \n",
            " extracting: train/20220517_123511_jpg.rf.c9720f76c97a450390e677d505d58b12.jpg  \n",
            " extracting: train/20220517_123527_jpg.rf.2626affc643f44849217724975cab914.jpg  \n",
            " extracting: train/20220517_123527_jpg.rf.6737519d2f4d91a9e286f75e42fb222d.jpg  \n",
            " extracting: train/20220517_123534_jpg.rf.1ca67f62f1c4ed1a266bb880bd28a529.jpg  \n",
            " extracting: train/20220517_123546_jpg.rf.5d345dd752501be784504928497b6b6e.jpg  \n",
            " extracting: train/20220517_123558_jpg.rf.8bb611f7e6ba881d63bd59227faa5744.jpg  \n",
            " extracting: train/20220517_123601_jpg.rf.cf951e605c92aaa8ad61d7af5d78ba4a.jpg  \n",
            " extracting: train/20220517_123608_jpg.rf.74e3584000abbaeed20bd2416d4b9a06.jpg  \n",
            " extracting: train/20220517_123612_jpg.rf.80517c7b4908b9c97ebf7063a8353b0d.jpg  \n",
            " extracting: train/20220517_123619_jpg.rf.256b521df13ad27652e145b0236945c5.jpg  \n",
            " extracting: train/20220517_123904_jpg.rf.c6d0eb7e4e336015db498b53fd1eff36.jpg  \n",
            " extracting: train/20220517_123913_jpg.rf.0f7ee762674a34319ccf544759b0916f.jpg  \n",
            " extracting: train/20220517_124020_jpg.rf.1d5088ebb6ea8c376091c770ce14d6e6.jpg  \n",
            " extracting: train/20220517_124032_jpg.rf.849c266563d5e424a4c6598187735d12.jpg  \n",
            " extracting: train/20220517_124111_jpg.rf.e7696664127285e00e7335da33c46c6c.jpg  \n",
            " extracting: train/20220517_124127_jpg.rf.cda5b09a36c2a91c78b721e2a9fa1c75.jpg  \n",
            " extracting: train/20220517_124132_jpg.rf.7d4f5645b1bd4a7a363f1f8f7fadb845.jpg  \n",
            " extracting: train/20220517_124140_jpg.rf.aa60d3989f41b32ec1199382c90dc1e3.jpg  \n",
            " extracting: train/20220517_124145_jpg.rf.2b17b9a5306cb609f734f77e913c9678.jpg  \n",
            " extracting: train/20220517_124604_jpg.rf.ddb5d990fa4f4eaf7fe1d8a4db5d620d.jpg  \n",
            " extracting: train/20220517_124614_jpg.rf.6be8140249a3c2a0e88d9cd2a634441c.jpg  \n",
            " extracting: train/20220517_124627_jpg.rf.182398aea79871223df93d076845c449.jpg  \n",
            " extracting: train/20220517_124640_jpg.rf.81472f500697d5f739a5dae1c061ac9e.jpg  \n",
            " extracting: train/20220517_124655_jpg.rf.6211caa17af486a05b6b9baef186438a.jpg  \n",
            " extracting: train/20220517_124658_jpg.rf.5ed16f551d7dd881daa7d566e29391d9.jpg  \n",
            " extracting: train/20220517_124708_jpg.rf.f4389845a64a38697ac73b0f53bc912e.jpg  \n",
            " extracting: train/20220517_124711_jpg.rf.5a7234ed5bc3d28e6af1e940a2c6d374.jpg  \n",
            " extracting: train/20220517_124930_jpg.rf.a9878087141ff39bc9141e22140df578.jpg  \n",
            " extracting: train/20220517_124933_jpg.rf.60cbefff338bb6f835bfade0adc7019c.jpg  \n",
            " extracting: train/20220517_124937_jpg.rf.4d00df1933bedf9097731bb7b3be8e19.jpg  \n",
            " extracting: train/20220517_124959_jpg.rf.93777442b36ae139fbae61853fb38bf9.jpg  \n",
            " extracting: train/20220517_125005_jpg.rf.38941645ef4bd648bfc30456017e628d.jpg  \n",
            " extracting: train/20220517_125005_jpg.rf.a0f0259d68996fcc5f3a988340bff862.jpg  \n",
            " extracting: train/20220517_132137_jpg.rf.9cc7ea8846c701b1a0da93487581d824.jpg  \n",
            " extracting: train/20220517_132137_jpg.rf.bfa62f0a1beabfca232dc311a36ab7ac.jpg  \n",
            " extracting: train/20220517_132148_jpg.rf.adae64cac94b477f1d7c3cb625a8e0ac.jpg  \n",
            " extracting: train/20220517_132153_jpg.rf.ea52d25068ec1c74996e78980406796b.jpg  \n",
            " extracting: train/20220912_15_1159286_L_jpg.rf.1a24e3672b9830e2d6e77903ef3aa58b.jpg  \n",
            " extracting: train/203-E-3071-TC-10-21_jpg.rf.3b8a5be9adee3cba5045e4b5a8cb4541.jpg  \n",
            " extracting: train/204_jpg.rf.7cee5168f68598aa1f37d46eaaa1051f.jpg  \n",
            " extracting: train/205_jpg.rf.cf42521632b147aae2942c077a9bfef3.jpg  \n",
            " extracting: train/206_jpg.rf.ec3182170ee08bf9266f8d76de00fd98.jpg  \n",
            " extracting: train/207_jpg.rf.0bd05634e7cea5788c43a5d95705a1b1.jpg  \n",
            " extracting: train/208696_jpg.rf.ec4b2941cf2929b5dd808bd8c68bf861.jpg  \n",
            " extracting: train/209491_jpg.rf.6d5bc89016963c81f2df05476b900644.jpg  \n",
            " extracting: train/209_jpg.rf.51f3b0d722571e283115b7ce15a110ea.jpg  \n",
            " extracting: train/20_jpeg_jpg.rf.276ae6e1c80e29f2a2b8bf399c96e983.jpg  \n",
            " extracting: train/210_jpg.rf.048de7928e11f4cb7629e1d0e86a2ed8.jpg  \n",
            " extracting: train/211_jpg.rf.d8e67ad96284c0f058c85e3ffffb6821.jpg  \n",
            " extracting: train/212390_jpg.rf.246d576a1ee7efa431e3809b846ce07b.jpg  \n",
            " extracting: train/212_jpg.rf.4188aece6e5a4dd3587f9ea56fdda8c2.jpg  \n",
            " extracting: train/213_jpg.rf.12dd7161f808e900406653c971a3bf89.jpg  \n",
            " extracting: train/21452_NT130964_2-1_jpg.rf.1059e81689b01064d8b5e4b47d2c7d8a.jpg  \n",
            " extracting: train/21452_NT130964_2-1_jpg.rf.1e27d1dc40ea2e41f4f0c64a8b8bb2e0.jpg  \n",
            " extracting: train/21452_NT130964_2-1_jpg.rf.481bc1132976203e2a9585baa402e19d.jpg  \n",
            " extracting: train/21452_NT130964_2-1_jpg.rf.93577aa8aebdae15a767e2520f269ade.jpg  \n",
            " extracting: train/21452_NT789-1_19-1_jpg.rf.2feb6fa3290b05bbe8033ec42307c68a.jpg  \n",
            " extracting: train/21452_NT789-1_19-1_jpg.rf.9edd3d9c62921866459191e77c26a636.jpg  \n",
            " extracting: train/21452_NT789-1_19-1_jpg.rf.abd66884627442169bb9568ca4a134d3.jpg  \n",
            " extracting: train/21452_NT789-1_19-1_jpg.rf.afec65ea5572453ec96dcc8adafdf807.jpg  \n",
            " extracting: train/215_jpg.rf.41d9dacc26ba685335a352b6e55a2d05.jpg  \n",
            " extracting: train/216_jpg.rf.75e999e27db3d460dfe90503a650b1b9.jpg  \n",
            " extracting: train/218014_jpg.rf.b00c4696bf469ca175d063d5e71276c6.jpg  \n",
            " extracting: train/2182_jpg.rf.b0e9c5e71955d208e3b60586052c8a10.jpg  \n",
            " extracting: train/219222_jpg.rf.049768c8885830d6675342c300df65e0.jpg  \n",
            " extracting: train/219_jpg.rf.dc33b699c1b37213bd7dce98918da55a.jpg  \n",
            " extracting: train/21_jpeg_jpg.rf.95a6ab316ad6e043b890542baf5634d0.jpg  \n",
            " extracting: train/221_jpg.rf.3e2d10b7d61751159e4fd353028b0cd4.jpg  \n",
            " extracting: train/222_jpg.rf.3b9b28afdf24619fcaf3e6b2ef0224f9.jpg  \n",
            " extracting: train/2234_jpg.rf.5249bbd34b4c910a3495c3a087ff47e0.jpg  \n",
            " extracting: train/2234_jpg.rf.7658531f55c9bffd787d1595235e1c3b.jpg  \n",
            " extracting: train/223_jpg.rf.ef741e355e12eb7965cc6c799c3e2bc0.jpg  \n",
            " extracting: train/224_jpg.rf.9971ec5770caf72f5ea3a2807d76653f.jpg  \n",
            " extracting: train/225_jpg.rf.1cb520c565a9ce934885d0787fd99a3e.jpg  \n",
            " extracting: train/226-E-5148-OI-06-13_jpg.rf.5e298cf37bb27c6a68515afcd193d93a.jpg  \n",
            " extracting: train/228_jpg.rf.8454407f093c3787341715f9a0bc4572.jpg  \n",
            " extracting: train/229_jpg.rf.c036fc58808769bb62d4614dff5ae2f3.jpg  \n",
            " extracting: train/22_jpeg_jpg.rf.7805ffe3a5a806fa1d08f662ee6a4924.jpg  \n",
            " extracting: train/22_jpg.rf.ac72d48230134c6630a21b980418956f.jpg  \n",
            " extracting: train/23-E-2694-SI-09-19_jpg.rf.847a425cccbe9aa45e8c931b5710baf9.jpg  \n",
            " extracting: train/23-Kode-Plat-Kendaraan-Kota-Yogyakarta-_jpg.rf.51f8901c6c22d92a859b1af375d2b011.jpg  \n",
            " extracting: train/231_jpg.rf.3393800a7f4789cb7452e47cbdcafdca.jpg  \n",
            " extracting: train/232_jpg.rf.3613056773a83b612753e03fabccc4d0.jpg  \n",
            " extracting: train/233-E-3407-PAB-03-21_jpg.rf.33410342166a623ea52caca093443ff1.jpg  \n",
            " extracting: train/233916005_6a02c11c_9248_4e5b_8386_34007ee612e8_823_1266_jpg.rf.b524c1efa62e087d836f65eabd4f3e3b.jpg  \n",
            " extracting: train/233_jpg.rf.71b31ef034240fd7f856b0e1f2a574c4.jpg  \n",
            " extracting: train/235_jpg.rf.1921fccc6968d1d2abbc21f8670f92f3.jpg  \n",
            " extracting: train/239_jpg.rf.59c3e79ef5da446eaa5149fe87c6a4c3.jpg  \n",
            " extracting: train/23_jpg.rf.56c528d88e41d02c4eb3297d7418058c.jpg  \n",
            " extracting: train/24-E-6520-PAC-05-21_jpeg_jpg.rf.dad4711665dc69f509829df2ed4bd40b.jpg  \n",
            " extracting: train/240_jpg.rf.01a600aabf36de3a88b646a2587cb4ca.jpg  \n",
            " extracting: train/241_jpg.rf.410a661fe245581e048c6cd27dc278fe.jpg  \n",
            " extracting: train/242150_jpg.rf.a3e4c15bc45a94130f921381efe69f5f.jpg  \n",
            " extracting: train/243_jpg.rf.0754fb2aa62471e1927b01c81bd98611.jpg  \n",
            " extracting: train/244_jpg.rf.1c50ab95e0d0a801666a1f68f133cccf.jpg  \n",
            " extracting: train/245-E-6941-PAP-08-22_jpeg_jpg.rf.fdb9d8ef7d7f023f55b731c110b9eaf1.jpg  \n",
            " extracting: train/245_jpg.rf.7d523b7a0d5713d14a4bb036dec6135a.jpg  \n",
            " extracting: train/2465_da8fe53a59ef60c6eb3ea78b89ee30c_jpg.rf.61f5bb87ec6ac06b815f3469a81943d1.jpg  \n",
            " extracting: train/2465_da8fe53a59ef60c6eb3ea78b89ee30c_jpg.rf.8466404ff243b5c089e0bfcd0a982cad.jpg  \n",
            " extracting: train/2465_da8fe53a59ef60c6eb3ea78b89ee30c_jpg.rf.b550bf6ec76bf12cdbd5921f8bbaf24a.jpg  \n",
            " extracting: train/2465_da8fe53a59ef60c6eb3ea78b89ee30c_jpg.rf.f3b6b14b5dd1c2793fcd525023ff59aa.jpg  \n",
            " extracting: train/246_jpg.rf.d1bbdb6874bf251f1d99891d61dc5e5f.jpg  \n",
            " extracting: train/248-E-4212-SS-01-21_jpeg_jpg.rf.eca98b68171099555b21a29642165373.jpg  \n",
            " extracting: train/248526_jpg.rf.cbfa076e5690802b8d2e218219833a8f.jpg  \n",
            " extracting: train/24_jpg.rf.644c4b1cabd8b3597779a2c1d5bf4f01.jpg  \n",
            " extracting: train/25-E-2101-PAD-06-21_jpeg_jpg.rf.0ac4d17ed4756c0a0c14562f9dfa0d86.jpg  \n",
            " extracting: train/250-E-6031-ST-03-21_jpeg_jpg.rf.d0f424c4502dd9eec2a0a82bd496e46f.jpg  \n",
            " extracting: train/250150_jpg.rf.dd0ea6652a8130314ffbdf091d7a0f09.jpg  \n",
            " extracting: train/251-E-3008-SM-05-20_jpeg_jpg.rf.83e8c5416a3b6ce0077a3ff404117ae5.jpg  \n",
            " extracting: train/251327_jpg.rf.00e98209d426acf987ef53461dcba68a.jpg  \n",
            " extracting: train/25195-ets2-fuso-fu-v1-5-ets2-1-40_jpg.rf.00b28cc850f5e79b4d8748bab99428fe.jpg  \n",
            " extracting: train/25195-ets2-fuso-fu-v1-5-ets2-1-40_jpg.rf.4c0afe4106d49bf45e63ec11fb94e2ad.jpg  \n",
            " extracting: train/25195-ets2-fuso-fu-v1-5-ets2-1-40_jpg.rf.4ca0184c0dee13f7496b35f0a9091678.jpg  \n",
            " extracting: train/25195-ets2-fuso-fu-v1-5-ets2-1-40_jpg.rf.92628638fc5f449ea792c61867388eb0.jpg  \n",
            " extracting: train/25195-ets2-fuso-fu-v1-5-ets2-1-40_jpg.rf.d92c3feee72c83833cb759b113edfb82.jpg  \n",
            " extracting: train/251_jpg.rf.420793729b63348d7bcdfc2be2b3c40e.jpg  \n",
            " extracting: train/253-E-2212-TZ-07-18_jpeg_jpg.rf.4fb5ab224de6f74dcc09ba6174927bdf.jpg  \n",
            " extracting: train/2530355363_287ac9442d_b_jpg.rf.f02155870f75b7fe6c14c05b4caae2fb.jpg  \n",
            " extracting: train/25397-colt-fe-truk-mitsubishi-colt-d_jpg.rf.0262cdc38cc79b423ed7754af29fab7e.jpg  \n",
            " extracting: train/25397-colt-fe-truk-mitsubishi-colt-d_jpg.rf.9ed615cf682f1310febd61dac8879aa7.jpg  \n",
            " extracting: train/25397-colt-fe-truk-mitsubishi-colt-d_jpg.rf.e16027d4aa9603646a3610f82ef762c9.jpg  \n",
            " extracting: train/253_jpg.rf.79c50d0ef8694d44eb664be91438f2e1.jpg  \n",
            " extracting: train/255-E-6527-OD-02-20_jpeg_jpg.rf.8dd2351aa32b58d8f5f8252a9541e6e5.jpg  \n",
            " extracting: train/257-E-4553-QT-06-20_jpg.rf.019d80f91317d61dc75f5bdaf0b8ca25.jpg  \n",
            " extracting: train/257927_jpg.rf.ab7e76ddb4f75aea2663dfe92e403f34.jpg  \n",
            " extracting: train/257_jpg.rf.5604c2570bf825aacc345ffa33f030ef.jpg  \n",
            " extracting: train/258-E-2895-NB-10-13_jpg.rf.9d52b2e2927da5be404a2c32ff0d767d.jpg  \n",
            " extracting: train/258179_jpg.rf.e11d3211196c831fa8149884337cc370.jpg  \n",
            " extracting: train/259-E-3154-QO-11-19_jpeg_jpg.rf.fb5ac8baf50f1601265474c39b6a317f.jpg  \n",
            " extracting: train/25994-colt-fe-jual-truk-engkel-fe-71_jpg.rf.550578cd2d5be4675bed5470dcd9bb88.jpg  \n",
            " extracting: train/25994-colt-fe-jual-truk-engkel-fe-71_jpg.rf.939ff6d74545a81a37176aafea56b6c7.jpg  \n",
            " extracting: train/25994-colt-fe-jual-truk-engkel-fe-71_jpg.rf.f9155faeb8fe8cbca07a03f8f2b53e6a.jpg  \n",
            " extracting: train/259_jpg.rf.ad49299eaaf3cc23b5ebcaca257bb1bd.jpg  \n",
            " extracting: train/260-E-4250-SU-04-21_jpeg_jpg.rf.a20e29b07dc57816b519d7bcc4c88c00.jpg  \n",
            " extracting: train/260_jpg.rf.b37f1c6047792eb091068d8ea43ce270.jpg  \n",
            " extracting: train/261-E-4991-TP-09-17_jpg.rf.6b0c1a94dcbba2dbc5988980f22d27b1.jpg  \n",
            " extracting: train/26135_jpg.rf.17aa0f23a20a3adc0c1c89abd8facc9b.jpg  \n",
            " extracting: train/262-E-3465-SL-02-20_jpg.rf.6c7a3abf7e9575df4178a631d0fd139f.jpg  \n",
            " extracting: train/262_jpg.rf.e279fad8c298cc4c973f938369b96530.jpg  \n",
            " extracting: train/263-E-6631-TO-08-21_jpg.rf.2d27cbd5f654b98cd9f0ded143c1ad98.jpg  \n",
            " extracting: train/263_jpg.rf.c0009ef3f77f4e0ac0b25f9609d2d469.jpg  \n",
            " extracting: train/264-E-2458-SV-05-16_jpeg_jpg.rf.15ec620af85ca3768daf24ca9f72a6ff.jpg  \n",
            " extracting: train/264441_jpg.rf.c12720ed857a68091a4598eae7369553.jpg  \n",
            " extracting: train/264675_jpg.rf.c1e65ed16d430345c6fee6f82d040923.jpg  \n",
            " extracting: train/265-E-3984-TZ-07-21_jpg.rf.03ed8990e911e33eede07b6eb88466bd.jpg  \n",
            " extracting: train/265_jpg.rf.3866750c19d947dccd20fda183cb6a6a.jpg  \n",
            " extracting: train/266-E-4299-SZ-09-21_jpeg_jpg.rf.42533122b6b8223d51250c40c6e2f7c7.jpg  \n",
            " extracting: train/266_jpg.rf.6ca580da529394d0c39714d32ccf61f5.jpg  \n",
            " extracting: train/267-E-2747-TS-12-17_jpg.rf.7f30924a1a928d1f71010e08b549d8a7.jpg  \n",
            " extracting: train/267_jpg.rf.9a88aa5afe1b6161f6b8dc876a2a730d.jpg  \n",
            " extracting: train/268-E-6752-SN-04-18_jpeg_jpg.rf.0484a39d7bd54edd3b9174b2903bbebd.jpg  \n",
            " extracting: train/269-E-2101-TJ-02-22_jpg.rf.603603040ec0996b4b116ad27a2118c3.jpg  \n",
            " extracting: train/269660_jpg.rf.9bfae51d9ad4c0b96cb82d1ed2cbb3ae.jpg  \n",
            " extracting: train/269_jpg.rf.6a71e0a35d7d050a516bde586679913c.jpg  \n",
            " extracting: train/26_jpg.rf.af68ffd953d7e245f270784b3a3b06ee.jpg  \n",
            " extracting: train/27-E-3524-PAG-09-21_jpeg_jpg.rf.5ce83cbf7eefbd219aea06a047832dd8.jpg  \n",
            " extracting: train/27-E-3524-PAG-09-21_jpeg_jpg.rf.a0179ab1914d80c3fecb174a22c89006.jpg  \n",
            " extracting: train/270672_jpg.rf.228e81132aaf2a81ae59e0eadbf0a304.jpg  \n",
            " extracting: train/270_jpg.rf.caab8d0688b47485459306bc0c15fd0e.jpg  \n",
            " extracting: train/271-E-2381-PAH-10-21_jpeg_jpg.rf.488c4f95a9e291f93d241f290f69cd77.jpg  \n",
            " extracting: train/272-E-1677-PE-02-21_jpeg_jpg.rf.2ed816f36afe98f0ad521fa4d1dcb218.jpg  \n",
            " extracting: train/273-E-6078-RM-09-22_jpeg_jpg.rf.a6839a7a290e28edb0d29f0c64cec915.jpg  \n",
            " extracting: train/273_jpg.rf.6b36a27ca8890f01e7a696c7302497bc.jpg  \n",
            " extracting: train/274-E-4558-SH-08-18_jpeg_jpg.rf.fd906ca35974e73fe3ca756ebbe36ac6.jpg  \n",
            " extracting: train/274_jpg.rf.28b71d84f2834c552b8481d8a6ceeea8.jpg  \n",
            " extracting: train/275-E-4986-SO-10-20_jpg.rf.86cbe345e3de6c9a107a8949ebe3cdfb.jpg  \n",
            " extracting: train/275__flip_jpg.rf.a6f020af5e4170c4006aa1fd158f51e8.jpg  \n",
            " extracting: train/275__flip_jpg.rf.e33de4c09983b225b8aa0a67a1a797a6.jpg  \n",
            " extracting: train/276-E-2810-PAD-05-21_jpeg_jpg.rf.d96246a6cae5aefedaaceef78ffdbc13.jpg  \n",
            " extracting: train/276086_jpg.rf.852aa943294c2df157989d8792d8be8d.jpg  \n",
            " extracting: train/276520_jpg.rf.23aebd2157326d2cde7d09006a96e640.jpg  \n",
            " extracting: train/276__flip_jpg.rf.a2ed6b49cd003f2d7874a0c2500d56d9.jpg  \n",
            " extracting: train/277-E-6802-PAH-11-21_jpg.rf.83fe067d6e9404458eb241e1e9f2f65a.jpg  \n",
            " extracting: train/277_jpg.rf.0629d6b3662673085f868d2e3e2910ae.jpg  \n",
            " extracting: train/278-E-4568-TCK-12-17_jpeg_jpg.rf.5b0efc3e130061ade4819d1c06bfdc8b.jpg  \n",
            " extracting: train/2788_1807600_1_jpg.rf.7c442cb4b590cfd8692b016c0cdf0da8.jpg  \n",
            " extracting: train/2788_1807600_1_jpg.rf.dd57e72adec4651f3f546053bd4eea27.jpg  \n",
            " extracting: train/278__flip_jpg.rf.58dc39560cde20d98f716aad913fb99d.jpg  \n",
            " extracting: train/278_jpg.rf.120f979f2c19f4249b618c196071dd5b.jpg  \n",
            " extracting: train/279_jpg.rf.4a07ea16f9faf3f3b2be2b9aed9f31c0.jpg  \n",
            " extracting: train/27_jpg.rf.2d4ccde4ea046fca8003750050435619.jpg  \n",
            " extracting: train/28-E-2393-TT-01-18_jpeg_jpg.rf.2905c2320fb0b1c116261d60eb87849f.jpg  \n",
            " extracting: train/280-E-4813-PL-04-20_jpeg_jpg.rf.89b79d275a8ed0f8553d3b2989a17397.jpg  \n",
            " extracting: train/280708_jpg.rf.3f16bbd0f8a7a70444d5addd8d877491.jpg  \n",
            " extracting: train/280933_jpg.rf.1ad0a439fdee1d133889b8e763ef49f5.jpg  \n",
            " extracting: train/280_jpg.rf.fc71d2ad85a21e8a89d6168cbaab8b7a.jpg  \n",
            " extracting: train/281-E-5503-TI-02-20_jpeg_jpg.rf.7a737820ab7c896da9834346e4d9ebc7.jpg  \n",
            " extracting: train/281__flip_jpg.rf.0a41f8420c57420076d18f40b1ee0349.jpg  \n",
            " extracting: train/281_jpg.rf.a7673a3d75c552dfb6c8b66c5c256b5c.jpg  \n",
            " extracting: train/281_jpg.rf.d24ab90829d3aa8264b50e14763a5e9b.jpg  \n",
            " extracting: train/282474_jpg.rf.5388278143664ccd2a5a0553eabbfa06.jpg  \n",
            " extracting: train/282948_jpg.rf.b7659d354d1bdd80887722f073fe9ac8.jpg  \n",
            " extracting: train/282__flip_jpg.rf.5e1b66f870c9e4141b357aa828d38306.jpg  \n",
            " extracting: train/282_jpg.rf.514b2281f02b51472c7888794f393e72.jpg  \n",
            " extracting: train/282_jpg.rf.ed49393d349f5a539e86b58fe0adbfa6.jpg  \n",
            " extracting: train/283040_jpg.rf.fe2b2651fcb2a9f607f6338f732d872c.jpg  \n",
            " extracting: train/283794_jpg.rf.e6381acc012996f41f236102cdc8e5ec.jpg  \n",
            " extracting: train/283_jpg.rf.a39d254565ebedd41eae7b9bb0d38f0c.jpg  \n",
            " extracting: train/283_jpg.rf.f632e2d2bb4f6424313ffdb5bbabda5c.jpg  \n",
            " extracting: train/285-E-5515-QT-06-20_jpeg_jpg.rf.9b633c730eb6b255c9f6a49ce91fcc5b.jpg  \n",
            " extracting: train/285152_jpg.rf.c45844858cb78f3fc841cd853a264c79.jpg  \n",
            " extracting: train/286973_jpg.rf.b58f1bf0ed379323a7662bb7ba690bd9.jpg  \n",
            " extracting: train/287-E-6272-PAJ-02-22_jpeg_jpg.rf.f58448c287b4c8fa8e85b3f1e4e0a8a1.jpg  \n",
            " extracting: train/288-E-2747-QQ-01-20_jpeg_jpg.rf.8f2fd889e0f02c6415279547072fac94.jpg  \n",
            " extracting: train/288__flip_jpg.rf.fa510a6c3b0cba3b25dfefe7aa413955.jpg  \n",
            " extracting: train/289-E-6810-TX-06-18_jpeg_jpg.rf.7393fbc50fec7f81d5418702ce74de7d.jpg  \n",
            " extracting: train/289_jpg.rf.2f07d752c4f5c8b0c2a684fdf80fcf28.jpg  \n",
            " extracting: train/289_jpg.rf.40b533b2463665e487d9447ac0ac2d13.jpg  \n",
            " extracting: train/289_jpg.rf.9e0c2ed286657ae50725c90364fce370.jpg  \n",
            " extracting: train/29-E-3978-SC-12-21_jpeg_jpg.rf.07a5ee06c408946fca629a8261e94345.jpg  \n",
            " extracting: train/290_jpg.rf.957a7274de9a978eea32c0310d029dad.jpg  \n",
            " extracting: train/291-E-3496-RW-04-19_jpeg_jpg.rf.278b686b763e9afb3c166bc3e6222493.jpg  \n",
            " extracting: train/29174_jpg.rf.7961248d9edeba3f1f5c6f60ab103ece.jpg  \n",
            " extracting: train/291_jpg.rf.78a351a11b7137ce803f185dac3e7b1c.jpg  \n",
            " extracting: train/291_jpg.rf.f1d7fa39216e8ac420c99c88e47d4efd.jpg  \n",
            " extracting: train/292-E-4890-QE-01-19_jpeg_jpg.rf.018bd1763add838137693d183b8cb8c3.jpg  \n",
            " extracting: train/292846_jpg.rf.f91653444e183f27e2c3d1d80f011ff2.jpg  \n",
            " extracting: train/292_jpg.rf.56792d17c1785f745abb5dd44312604a.jpg  \n",
            " extracting: train/293-E-2509-OW-09-20_jpg.rf.816f6e1b9f9f32f5314a177496396151.jpg  \n",
            " extracting: train/293__flip_jpg.rf.73fabc7ed7e54525a6a962fdfac8b231.jpg  \n",
            " extracting: train/294-E-2381-QAA-10-22_jpeg_jpg.rf.10c9775fc3b838bcc55ea431ba16ef04.jpg  \n",
            " extracting: train/294__flip_jpg.rf.dad4d81e0e0fe7b59bb8bc8a1ce6c483.jpg  \n",
            " extracting: train/295-E-6919-TM-06-17_jpg.rf.f9ae43d8e4def59aa07e68b53fef1f30.jpg  \n",
            " extracting: train/295_jpg.rf.e981fe1521a3690d1201f569c2899faf.jpg  \n",
            " extracting: train/297_jpg.rf.d8f0e3a509f2fc483454a5a7bbf5f6fb.jpg  \n",
            " extracting: train/298-E-5944-TK-04-22_jpeg_jpg.rf.08d15e2cf2a592abb44fdd99e3b287f7.jpg  \n",
            " extracting: train/298_jpg.rf.c78231d4d300671f9484c15093b2571a.jpg  \n",
            " extracting: train/299-E-5051-SD-03-18_jpeg_jpg.rf.0127cc54956d3be999ac345813a8d19c.jpg  \n",
            " extracting: train/299__flip_jpg.rf.67e510a4bb17d9ad4a9b506ac32fff14.jpg  \n",
            " extracting: train/299__flip_jpg.rf.7a828349ef9057f202f7cbd7e5dc5c8a.jpg  \n",
            " extracting: train/2_57_jpg.rf.99dd06878fd6ef80ea87d99463189906.jpg  \n",
            " extracting: train/2e1asdasd_PNG_jpg.rf.0631020da8512ec6896b8141b3d943d2.jpg  \n",
            " extracting: train/2e1dasdas_PNG_jpg.rf.680b581e3da372df09d6b2da27c9ebc7.jpg  \n",
            " extracting: train/3-1650482375-Yamaha-Motor-Fino-Premium-Tahun-2016-Plat-T-Karawang-Pajak-Jalan-Motor-Siap-Paka_jpg.rf.fbee5189a84c511e12bc3b08c7dc3074.jpg  \n",
            " extracting: train/3-655x370-1-655x370_jpg.rf.5f35c0238a8b1b78e5faad3b8dde4575.jpg  \n",
            " extracting: train/300-E-5105-OD-12-21_jpg.rf.91c59dba9380c14bdb9015a835473a11.jpg  \n",
            " extracting: train/300__flip_jpg.rf.b4a28b8315bc9ea3b3ac6d79e74688e1.jpg  \n",
            " extracting: train/300_jpg.rf.2c45faab3d223fa8b8cc2f248928f5fe.jpg  \n",
            " extracting: train/300_jpg.rf.3db0d48c04b7ca70c46ba034561e0ec6.jpg  \n",
            " extracting: train/301-E-6893-PAD-06-21_jpeg_jpg.rf.ff1303149a6effb352ec6dc8bdee9594.jpg  \n",
            " extracting: train/301_jpg.rf.007e7e1c257fcea0483f6a0d034ffb86.jpg  \n",
            " extracting: train/302-E-3922-OI-05-19_jpg.rf.884871d0d82eaaaa2bb5f2df6a1e438c.jpg  \n",
            " extracting: train/302_jpg.rf.c9054fa032c6b2297dadc0f795a48db9.jpg  \n",
            " extracting: train/303-E-6888-SC-11-21_jpg.rf.9122b8168ef5c3f7c053fc6fc0453da5.jpg  \n",
            " extracting: train/30364-1_jpg.rf.2147f01957d5d0aeab15d5c2f2b36a2a.jpg  \n",
            " extracting: train/30364-1_jpg.rf.37dee55403818a6a9b063b69e754d005.jpg  \n",
            " extracting: train/30364-1_jpg.rf.48d4e034edcd92ccdfbfcef2e3b71e4c.jpg  \n",
            " extracting: train/303_jpg.rf.326065010c77de49d7e691b89af83bc7.jpg  \n",
            " extracting: train/303_jpg.rf.c00476a63e3a858c9c908fa7f201f343.jpg  \n",
            " extracting: train/304-E-5381-PAB-03-21_jpeg_jpg.rf.ede30c21c6a605dfc05f2207ee72bc62.jpg  \n",
            " extracting: train/3040974006_jpg.rf.00b08731018f55d58a8be792ceac7870.jpg  \n",
            " extracting: train/3040974006_jpg.rf.10e3636a4b362a9fdba26e0ee90b3a08.jpg  \n",
            " extracting: train/3040974006_jpg.rf.955002bec719ca09633a5c6bb7d22df8.jpg  \n",
            " extracting: train/304__flip_jpg.rf.9bf8f5f49e84af01641e3cb941a3b36b.jpg  \n",
            " extracting: train/304_jpg.rf.588e0977b9fe6a96defd2f408a31ecaa.jpg  \n",
            " extracting: train/304_jpg.rf.89e84f14f93f1d9fde5b2179eb6f4c07.jpg  \n",
            " extracting: train/3059_en_43493_17596_fuso_canter_fg4x_jpg.rf.1eef2b4206e99f22d2e416a30b7ee83c.jpg  \n",
            " extracting: train/3059_en_43493_17596_fuso_canter_fg4x_jpg.rf.c725a99a722ee3ae508941dfaff11862.jpg  \n",
            " extracting: train/3059_en_43493_17596_fuso_canter_fg4x_jpg.rf.ea8dde60998cbac2acd047234b1e42a5.jpg  \n",
            " extracting: train/305_jpg.rf.659453c28356f3728b0343f2001bd775.jpg  \n",
            " extracting: train/305_jpg.rf.fa2f29ae096805dab6f146c4be946e19.jpg  \n",
            " extracting: train/306-E-3270-SJ-08-22_jpeg_jpg.rf.42a6f0310d58dfb4f7ac03d13e919367.jpg  \n",
            " extracting: train/306616_jpg.rf.9f4afe7bbf13b558dd8c152aa95e41be.jpg  \n",
            " extracting: train/306_jpg.rf.e7529764f9c7385d1b5e33a29832d323.jpg  \n",
            " extracting: train/306_jpg.rf.ee87338eb81feb8716cbf56a3618ed1e.jpg  \n",
            " extracting: train/307-E-4238-QC-11-18_jpeg_jpg.rf.9b75af32c28550cdfa53bd28c9b75a74.jpg  \n",
            " extracting: train/307__flip_jpg.rf.c0ede904b5511523d662c2acdf674edf.jpg  \n",
            " extracting: train/307_jpg.rf.1c497f990e201e6151a879aef1769eee.jpg  \n",
            " extracting: train/307_jpg.rf.aab5e6c1a67d0832e6a861507fa80687.jpg  \n",
            " extracting: train/309-E-6140-OX-11-20_jpg.rf.72c3eee8ab5aa482ec4e74f82a9f3a9b.jpg  \n",
            " extracting: train/309098_jpg.rf.2613d221b84c94dcee33fbf1903db5e7.jpg  \n",
            " extracting: train/309_jpg.rf.2dd748abde9bb298ab586acc301c10b2.jpg  \n",
            " extracting: train/31-E-5235-RO-11-16_jpg.rf.440da1266e457f17f5d2c057dca254f3.jpg  \n",
            " extracting: train/310__flip_jpg.rf.a936700492f417271c8f979da8f59f85.jpg  \n",
            " extracting: train/310_jpg.rf.8ff4f41cf36670e97a302fb00b16f7c0.jpg  \n",
            " extracting: train/311-E-3593-TF-10-19_jpg.rf.4bed425b8f02a52935e00f831072b02a.jpg  \n",
            " extracting: train/311_jpg.rf.0bba914f74c9f8edf79f374582ce5c4b.jpg  \n",
            " extracting: train/311_jpg.rf.a32c95c54a8eec8e0e62ccf991d7cd07.jpg  \n",
            " extracting: train/311_jpg.rf.e9c22b8e7ecd7eb58db1af4d15de4344.jpg  \n",
            " extracting: train/312250_jpg.rf.9dbabb27fe3a18969f46aeefd7859544.jpg  \n",
            " extracting: train/312__flip_jpg.rf.625128038c345f5e63c1e025090fa07b.jpg  \n",
            " extracting: train/312_jpg.rf.cc9d2481795e7ba939fb75d7cde4cdbd.jpg  \n",
            " extracting: train/312_jpg.rf.d92b0eaa38656b40299d1810b6ee220f.jpg  \n",
            " extracting: train/312easda_PNG_jpg.rf.ca40efd6750596ae78bfbdf50be7bdb7.jpg  \n",
            " extracting: train/313-E-5971-TO-08-22_jpg.rf.52b7f4fbc2836653530c24bed53bd390.jpg  \n",
            " extracting: train/313_jpg.rf.475c0f5d33527571319607228839f7f7.jpg  \n",
            " extracting: train/314-E-3016-SB-10-18_jpeg_jpg.rf.3e57eb0322d4830e444325b7b444f98e.jpg  \n",
            " extracting: train/314__flip_jpg.rf.7e7f00ccc0601a8d4d5c6c1cf05bc7e5.jpg  \n",
            " extracting: train/315947_jpg.rf.40560dd79d78e1db0da59467e3190544.jpg  \n",
            " extracting: train/315_jpg.rf.513aa0a6328ec01fb7655d550d760172.jpg  \n",
            " extracting: train/316_jpg.rf.736eccaed3847037b1b8e5640bea555a.jpg  \n",
            " extracting: train/317-E-5064-SE-05-19_jpeg_jpg.rf.280773696efce96a11a3dc884a232787.jpg  \n",
            " extracting: train/317185_jpg.rf.4b50377223498301de7c08ceda1eca16.jpg  \n",
            " extracting: train/3173ec56-a792-47ff-9b18-79fc37729b95_jpg.rf.41fdac473b573448454abec7ea056b6b.jpg  \n",
            " extracting: train/3173ec56-a792-47ff-9b18-79fc37729b95_jpg.rf.ea358523dec0b3e0d7c209e7cdd80428.jpg  \n",
            " extracting: train/317__flip_jpg.rf.33a2fed8ee39ac861e3ee704dc001f0b.jpg  \n",
            " extracting: train/317_jpg.rf.2552e8014a6ac1d511119746a19863c1.jpg  \n",
            " extracting: train/317_jpg.rf.e623d351c8e6e866427043cb79636c77.jpg  \n",
            " extracting: train/318__flip_jpg.rf.acee03aa63fd73c49f6257d4f3d858b3.jpg  \n",
            " extracting: train/318_jpg.rf.8891a22072a11366db71472419f2238e.jpg  \n",
            " extracting: train/318_jpg.rf.f3aefd5123720d4f301264a03a89d25c.jpg  \n",
            " extracting: train/319-E-3547-RR-06-12_jpg.rf.c8cf3bd5ac47553f20a9b74d3e429110.jpg  \n",
            " extracting: train/319_jpg.rf.606f7dda1988164c4daf0da1352380b4.jpg  \n",
            " extracting: train/319_jpg.rf.9f6e7b4335902252407cb95a70dd9e7f.jpg  \n",
            " extracting: train/31_jpg.rf.45b1318d9fd10983d3beec3e4c989f6d.jpg  \n",
            " extracting: train/320-E-3796-PY-05-20_jpg.rf.96a0ae346e40de076413d9779944fc38.jpg  \n",
            " extracting: train/320__flip_jpg.rf.d847db1005a1fa278cf503a2fecb8ff0.jpg  \n",
            " extracting: train/320_jpg.rf.43b6fc24b7d2a5f5b742332cb76c193f.jpg  \n",
            " extracting: train/321-E-3255-TN-12-20_jpg.rf.64bd27b2f5171abd0dc8b266800dcd57.jpg  \n",
            " extracting: train/321_jpg.rf.39537770e88e5a49c436c106790ccd15.jpg  \n",
            " extracting: train/322-E-8767-TG-11-22_jpg.rf.669117853717596c5d59808126bd17c9.jpg  \n",
            " extracting: train/322_jpg.rf.5a8677dee8a3d90684af99f59c5d682b.jpg  \n",
            " extracting: train/322_jpg.rf.cf0e8a854c884b23fb1f3f6dec1bc4f5.jpg  \n",
            " extracting: train/323-E-4886-TM-06-22_jpeg_jpg.rf.8d3339013e722ed01aea597542ed95a1.jpg  \n",
            " extracting: train/323_jpg.rf.87eeca1170bb66e716a446a0e3b45ba1.jpg  \n",
            " extracting: train/323_jpg.rf.9a70a1d0b23b269bc1c4f85c6cc8a441.jpg  \n",
            " extracting: train/324-E-5854-PAP-08-22_jpeg_jpg.rf.52a0d97e4113251550bcb5020ebb26f7.jpg  \n",
            " extracting: train/32455_44329_230732_jpg.rf.8bd96c47c552ee84b868382af637b6a5.jpg  \n",
            " extracting: train/32455_44329_230732_jpg.rf.a9c0819da80944cc17457c46692fc1cc.jpg  \n",
            " extracting: train/324_jpg.rf.a4ee3cb9070157c5bf1807c754d51d95.jpg  \n",
            " extracting: train/325-E-2634-QG-03-19_jpeg_jpg.rf.01d94b9977d6356f14dc6b5d3088477c.jpg  \n",
            " extracting: train/325841_jpg.rf.98f84dd119fd79646b86553047a273af.jpg  \n",
            " extracting: train/325_jpg.rf.152bddf0f63f4e7089d41148790b1301.jpg  \n",
            " extracting: train/326-E-3758-RW-04-18_jpeg_jpg.rf.19761559c2bd4606faed41a665ef5ead.jpg  \n",
            " extracting: train/326__flip_jpg.rf.d4d995d401735da0a8c4f021a6938815.jpg  \n",
            " extracting: train/327-E-5071-SS-01-21_jpg.rf.15c7c20849c20a5f12342c7ce7c1ef1d.jpg  \n",
            " extracting: train/327_jpg.rf.2691980234d5f55b936410c9e8bd2eba.jpg  \n",
            " extracting: train/328789_jpg.rf.22094f644205c85b4707e4ddd2b3b6cc.jpg  \n",
            " extracting: train/328_jpg.rf.187059b84bc5d185b9fbb6acb686edc7.jpg  \n",
            " extracting: train/328_jpg.rf.b70e97e1dfaaca7dce3e93022cd2e617.jpg  \n",
            " extracting: train/328_jpg.rf.bea1faa1bea708089f3c07242aa2c0a5.jpg  \n",
            " extracting: train/329-E-5078-QF-02-19_jpeg_jpg.rf.457342a9a171acb6cbed4ec23cd486fb.jpg  \n",
            " extracting: train/329220_jpg.rf.64e3ae09d56fb377a65661cd7f081b69.jpg  \n",
            " extracting: train/329_jpg.rf.e0103ee597ea82a548ebe3122bdb1899.jpg  \n",
            " extracting: train/32_jpg.rf.5fb8291c870957fa2388c16876b25e3e.jpg  \n",
            " extracting: train/33-E-5216-TI-11-21_jpeg_jpg.rf.4b02d42400228a30ed0e8b7d3d9a57b7.jpg  \n",
            " extracting: train/330-E-5869-PAA-02-21_jpg.rf.7c453f01684a73339570026a7571f683.jpg  \n",
            " extracting: train/330__flip_jpg.rf.c1c44d4b5b00ee934dfdf624ca2bba29.jpg  \n",
            " extracting: train/330_jpg.rf.68ab31634e491b64b4c240fcb0c80379.jpg  \n",
            " extracting: train/331-E-2843-HB-08-21_jpeg_jpg.rf.60650b1b434c3d888c9c297ce2ed6072.jpg  \n",
            " extracting: train/331995_jpg.rf.88b7bb5358a51b31d1ffdc8b41f55f64.jpg  \n",
            " extracting: train/331_jpg.rf.320c0a8f34bc850b81080af4177d8f62.jpg  \n",
            " extracting: train/332-E-4876-Q-08-18_jpg.rf.6a34c98fe3ea1deb46d3927a38813273.jpg  \n",
            " extracting: train/332__flip_jpg.rf.fdbd63f67038d830dddd8e2b2ab31408.jpg  \n",
            " extracting: train/332_jpg.rf.23fccba9796eee56e1117c7340339cda.jpg  \n",
            " extracting: train/333847_jpg.rf.1a7ea8008bac87cff4c6edc69e4196d7.jpg  \n",
            " extracting: train/333879_jpg.rf.0a85be2a67ecbd7834ba8ddef387b70a.jpg  \n",
            " extracting: train/333991_jpg.rf.911939cad41e6bef9875618792fcde13.jpg  \n",
            " extracting: train/333__flip_jpg.rf.f409574c4754c4921fb86841ac2fc29f.jpg  \n",
            " extracting: train/333_jpg.rf.4690fc681ff719c17936201845c6fe85.jpg  \n",
            " extracting: train/333_jpg.rf.5975acf04e328e1f012181231c1f53eb.jpg  \n",
            " extracting: train/334-E-5195-PL-04-20_jpeg_jpg.rf.0fb6ea95d6abf419b2ed28963c1df4a2.jpg  \n",
            " extracting: train/335-E-3405-PAH-10-21_jpeg_jpg.rf.176ae5c35751c1742a06e097f938f749.jpg  \n",
            " extracting: train/33564bdf916af91988b51c38883f1841_jpg.rf.46e0fddbbd4bcbc98d70815fa67d3af7.jpg  \n",
            " extracting: train/33564bdf916af91988b51c38883f1841_jpg.rf.d12a5f745ff3cba6086a0ee3804327a3.jpg  \n",
            " extracting: train/33564bdf916af91988b51c38883f1841_jpg.rf.d889b26e92aeafabf89d072c077a282d.jpg  \n",
            " extracting: train/33564bdf916af91988b51c38883f1841_jpg.rf.dad1e76ac90f26eace814ae77827906e.jpg  \n",
            " extracting: train/33564bdf916af91988b51c38883f1841_jpg.rf.f816a4e2b4e75ac8668700293e7e9f68.jpg  \n",
            " extracting: train/335_jpg.rf.f63e06e248b0f5853ac052319cfc94d9.jpg  \n",
            " extracting: train/336-E-2909-TP-12-21_jpeg_jpg.rf.572998bfdfae2bc13f830b3ece0288bc.jpg  \n",
            " extracting: train/338-E-3851-PAI-12-21_jpeg_jpg.rf.06bab7bab0ef5db087731bcaa78fa254.jpg  \n",
            " extracting: train/339664_jpg.rf.0852f592ee168bf304bb6f889efd9586.jpg  \n",
            " extracting: train/339_jpg.rf.fc1e3178e30b4d4d641fa1764bc32f63.jpg  \n",
            " extracting: train/340-E-4235-RP-01-22_jpeg_jpg.rf.a728490bb7935924c91db3eb6addc982.jpg  \n",
            " extracting: train/3403092507_jpg.rf.e176c4dd0236748491ff64e63551df5f.jpg  \n",
            " extracting: train/340_jpg.rf.92ff725c6a6e52a9cab2c20443b79196.jpg  \n",
            " extracting: train/342-E-2544-QD-11-18_jpeg_jpg.rf.55b5a022941e9caf3da5862f4805aa62.jpg  \n",
            " extracting: train/343-E-6894-SB-11-19_jpeg_jpg.rf.52e932a58350ff75570239f73e90b4be.jpg  \n",
            " extracting: train/344-E-6393-TZ-07-18_jpeg_jpg.rf.cc252fef998dcad5540e0878491bd93d.jpg  \n",
            " extracting: train/344339_jpg.rf.eee2b1e9cfaa750292ac02bbaa7b2f17.jpg  \n",
            " extracting: train/34456_jpg.rf.bab7c5c3477e55f16f2cef690bbd4de9.jpg  \n",
            " extracting: train/345-E-2047-SF-05-19_jpeg_jpg.rf.f009585a6b232ad6f2a59da3d289ffc6.jpg  \n",
            " extracting: train/345_jpg.rf.c36e1f93ad21d712cf7227964e01b749.jpg  \n",
            " extracting: train/346_jpg.rf.e60f28c9ae6b3747b20e6d4d8b582c6c.jpg  \n",
            " extracting: train/347-E-6765-PAD-06-21_jpeg_jpg.rf.b3e3b8d2af6d798beab43053bbfa8372.jpg  \n",
            " extracting: train/347_jpg.rf.9607da75870b83f99ea7f59b0b8b1b5c.jpg  \n",
            " extracting: train/348157_jpg.rf.baaac7537651ec871be47b94a53fbc21.jpg  \n",
            " extracting: train/348_jpg.rf.afb8a6e9a4addc8932ecb89a9dcefc8b.jpg  \n",
            " extracting: train/349172_jpg.rf.c00b9d9c477086007fd7d8f01dec7c53.jpg  \n",
            " extracting: train/34_jpg.rf.7ba71ad43b43f6068db00710c78f72e9.jpg  \n",
            " extracting: train/350_jpg.rf.d694e08d58a40fc19309db5a42aa1ed4.jpg  \n",
            " extracting: train/352-E-5053-RG-09-20_jpeg_jpg.rf.75464c899bb8bcb2bda6fc84e56f4b2b.jpg  \n",
            " extracting: train/352_jpg.rf.3f16aca9fd524faacab1c911ecc61477.jpg  \n",
            " extracting: train/353-E-6270-SM-06-20_jpeg_jpg.rf.cac16cba33b40d02ec808f615512bfd0.jpg  \n",
            " extracting: train/3534274-foto-camion_jpg.rf.0b5fa7ebd3b9db08122cce67f6be4150.jpg  \n",
            " extracting: train/354-E-6250-PAJ-02-22_jpeg_jpg.rf.aea9a0c0e4d73954dc00ef7e0e71e61c.jpg  \n",
            " extracting: train/354_jpg.rf.a8e112762be7f160d694727cafc30ccb.jpg  \n",
            " extracting: train/355-E-6547-PAF-09-21_jpeg_jpg.rf.9fecf9e84169a75023b8760dc38f54b6.jpg  \n",
            " extracting: train/355833_jpg.rf.921ef114aeebee52640866f210839b87.jpg  \n",
            " extracting: train/355_jpg.rf.d75739c408daa9ae0cd075caf7022ffc.jpg  \n",
            " extracting: train/356-E-6225-SJ-11-19_jpeg_jpg.rf.8432bb2ff5d6a02d3047010bfb7d1882.jpg  \n",
            " extracting: train/359-E-6270-OZ-01-21_jpg.rf.8a0af35739a46feeb3d98168ad697ee7.jpg  \n",
            " extracting: train/35_jpg.rf.d397d989f3d6419c6316af8161a3cef2.jpg  \n",
            " extracting: train/360-E-4690-PAL-04-22_jpg.rf.70780d968c3488d1887658ad4e944924.jpg  \n",
            " extracting: train/360006_jpg.rf.a8bc4197e97da4be85b2664a12430b3b.jpg  \n",
            " extracting: train/36038_47874_245202_jpg.rf.650cba0cbf5c5146752f07e49e701cf8.jpg  \n",
            " extracting: train/36038_47874_245202_jpg.rf.adaeaf32e58e6dad9186001c27bdfe28.jpg  \n",
            " extracting: train/36038_47874_245202_jpg.rf.b36b7c1caff0a953db40b9f10da9cca0.jpg  \n",
            " extracting: train/360_jpg.rf.63e1b6be882c8b9c83f596e811f278a9.jpg  \n",
            " extracting: train/361-E-3193-PS-08-17_jpeg_jpg.rf.0a73e7e8aa29edcf0670c23d5be6f049.jpg  \n",
            " extracting: train/361936_jpg.rf.9c0ab779748af1647348728216063b64.jpg  \n",
            " extracting: train/362-E-6525-SF-09-21_jpeg_jpg.rf.ba7774d6ed6f080dff92f5ff348fc1d1.jpg  \n",
            " extracting: train/362394__flip_jpg.rf.bf4c39cd0b2fc0620c7c45f300f43409.jpg  \n",
            " extracting: train/3626_2211076_1_jpg.rf.0128699f2171dcefa60e9b27ac38e9cd.jpg  \n",
            " extracting: train/3626_2211076_1_jpg.rf.27a27a3543c6b5592b2a75e728730763.jpg  \n",
            " extracting: train/3626_2211076_1_jpg.rf.577503b4765163bb4b5f4733d33c5706.jpg  \n",
            " extracting: train/3626_2211076_1_jpg.rf.7aeb98f642dcfcf8fc4b1f60c5a62540.jpg  \n",
            " extracting: train/362_jpg.rf.d8d8946e9f1be1b50a49c36cbfc9b8f2.jpg  \n",
            " extracting: train/363-E-6263-RU-07-20_jpg.rf.8c6f74fc6281b233e7fc325fc7b333ea.jpg  \n",
            " extracting: train/364-E-6528-P-11-18_jpeg_jpg.rf.c2da374c42f977327f484a599de7ff5d.jpg  \n",
            " extracting: train/36481_48360_248248_jpg.rf.0c9a2b9acad1f41a4649c1170df7d321.jpg  \n",
            " extracting: train/36481_48360_248248_jpg.rf.33e989386cca16239bb4c07993c71749.jpg  \n",
            " extracting: train/36481_48360_248248_jpg.rf.b7e772da8eada9a0741476cb84736331.jpg  \n",
            " extracting: train/36481_48360_248248_jpg.rf.f06e2061c8d22bf5eb77c1df5d29b206.jpg  \n",
            " extracting: train/36484_48363_248254_jpg.rf.39cd8e1f8a345c5abeb84af29d66f048.jpg  \n",
            " extracting: train/36484_48363_248254_jpg.rf.533885b70a52d521b16032285fd15b13.jpg  \n",
            " extracting: train/36484_48363_248254_jpg.rf.80ad7c9eeba3a075746ed1a200c14988.jpg  \n",
            " extracting: train/36484_48363_248254_jpg.rf.d3b10f4d7e302a5a11e75545324ff082.jpg  \n",
            " extracting: train/36486_48365_248258_jpg.rf.6606f48e7e3d6d2af938c95d68beb392.jpg  \n",
            " extracting: train/36486_48365_248258_jpg.rf.c0388131d5a12418da9276c8601ea4d5.jpg  \n",
            " extracting: train/36486_48365_248258_jpg.rf.ce2db18d72a1b92786e8a8d2e3396ec5.jpg  \n",
            " extracting: train/364_jpg.rf.5b3cb94d90859bb83131bfbb3c577e96.jpg  \n",
            " extracting: train/366_jpg.rf.cdd265a8004dfc2b4920990e30f8b83d.jpg  \n",
            " extracting: train/3671090417_jpg.rf.3a3167d6cdc8533d6c0c620b853e671a.jpg  \n",
            " extracting: train/367_jpg.rf.9d959f41c3bcaaa51d0960d561047f0e.jpg  \n",
            " extracting: train/368_jpg.rf.87803fcf32bf0ffe88042d975b1c90f6.jpg  \n",
            " extracting: train/369_jpg.rf.e159f859d329c6baa6cc84f91b6765d6.jpg  \n",
            " extracting: train/37-E-4127-QI-05-19_jpg.rf.a77c2d69c404928cfd0cbc233fe96dc4.jpg  \n",
            " extracting: train/370_jpg.rf.85de763c2834b80c3c26d2bbc887677c.jpg  \n",
            " extracting: train/373_jpg.rf.9024d3a0e86e24042739fa464577bb05.jpg  \n",
            " extracting: train/374_jpg.rf.1e3afe414879c10809fd0a114d3ff038.jpg  \n",
            " extracting: train/375_jpg.rf.a3e0beaf39ade369198c1a5dc1d1ca03.jpg  \n",
            " extracting: train/378100_jpg.rf.b702a566d2910806ac3df953d6fa109f.jpg  \n",
            " extracting: train/378950_jpg.rf.4fb33732c59232f0b18116222cf0744c.jpg  \n",
            " extracting: train/378_jpg.rf.1b566dc2880165e4f5356a7cc6bc6232.jpg  \n",
            " extracting: train/379_jpg.rf.de5f899008b515e065a7d373c08f6d59.jpg  \n",
            " extracting: train/37_jpg.rf.e417f8a8d96cebf5cb1704f458a04d4f.jpg  \n",
            " extracting: train/38-E-3747-RE-08-15_jpeg_jpg.rf.387983e9f03998b562b124a070551b24.jpg  \n",
            " extracting: train/380_jpg.rf.cb9c79d94b59a20e55ec8676fde52131.jpg  \n",
            " extracting: train/381_jpg.rf.bd1833804d5c891c67943a4c9dc5c7c2.jpg  \n",
            " extracting: train/38263_50139_258320_jpg.rf.9c6c5b161e7dbbfdb09f10503986008b.jpg  \n",
            " extracting: train/387_jpg.rf.8eab2bee6c07c66be964b28098c0157c.jpg  \n",
            " extracting: train/389_jpg.rf.6fed82f5b1704eded3f13e1da484347d.jpg  \n",
            " extracting: train/38_jpg.rf.e6d3f1bcaa8d02341df7a9fe1185e2ed.jpg  \n",
            " extracting: train/39-E-6716-QR-04-20_jpeg_jpg.rf.4f99585f4883618dd05f420cf5699459.jpg  \n",
            " extracting: train/390_jpg.rf.b1df27877574a4bca8ee22ed4b2e1340.jpg  \n",
            " extracting: train/391_jpg.rf.0f9234b24ab9e2a02d81f855e9adbed1.jpg  \n",
            " extracting: train/393_jpg.rf.3aca41788cbe9ac2c00f6240e2f43964.jpg  \n",
            " extracting: train/39489_jpg.rf.6ff5790a4e5e886f1e18936c7623c63d.jpg  \n",
            " extracting: train/394_jpg.rf.34044d2211610f387d7144ba0f81b6c6.jpg  \n",
            " extracting: train/396_jpg.rf.03e9f0b68d664c91b62d56988a264854.jpg  \n",
            " extracting: train/398674_jpg.rf.244146c7325e4daab0198b3dfc726870.jpg  \n",
            " extracting: train/39878_jpg.rf.d0c4f6bb86666285405e3f4ad6ea7d71.jpg  \n",
            " extracting: train/39_jpg.rf.86c58d88afc8fc7e554b2679e69276f1.jpg  \n",
            " extracting: train/3_58_jpg.rf.c99481226912e5f2e3f75d5cae3514b5.jpg  \n",
            " extracting: train/3_jpeg_jpg.rf.1d81209535bd155e85e04591adde3eb2.jpg  \n",
            " extracting: train/3_jpg.rf.19bb0f63e1e0365f30340548ede5b87e.jpg  \n",
            " extracting: train/3asdad_PNG_jpg.rf.ebd21825064b43332508836671dc417a.jpg  \n",
            " extracting: train/3asdf1ewq_PNG_jpg.rf.0f9dcc76115929dde47333875482a841.jpg  \n",
            " extracting: train/40-E-2324-OM-09-19_jpg.rf.34213dd61a4d3c6e5c8699e3a69257ab.jpg  \n",
            " extracting: train/401_jpg.rf.56641981f7c694da609113eb0cc271e5.jpg  \n",
            " extracting: train/402313_jpg.rf.25d92c48883f9fb07191ceb411bef756.jpg  \n",
            " extracting: train/4026_a15903860165ecb5d607e7b1_jpg.rf.492062e2d781e434d396d0e67e1ceadc.jpg  \n",
            " extracting: train/4026_a15903860165ecb5d607e7b1_jpg.rf.7e03f85975f919443683079e9e9f267f.jpg  \n",
            " extracting: train/4026_a15903860165ecb5d607e7b1_jpg.rf.85d47aa391f14bdf23b621cd75b765ea.jpg  \n",
            " extracting: train/4026_a15903860165ecb5d607e7b1_jpg.rf.e10f92973d297e49bd14ed1e59a6dbd9.jpg  \n",
            " extracting: train/4026_a15903860165ecb5d607e7b1_jpg.rf.fff28da883221cd257ebabbcaded6fab.jpg  \n",
            " extracting: train/403_jpg.rf.1f96cb18b21aec7c08c748f3d67056a1.jpg  \n",
            " extracting: train/404887_jpg.rf.2069f536c366440a94eb5333a5b6068a.jpg  \n",
            " extracting: train/404_jpg.rf.d39281efbe734d6f44bbeaf0cf5f7982.jpg  \n",
            " extracting: train/405_jpg.rf.898a565bb07f6aa5d508bf3f22081c6f.jpg  \n",
            " extracting: train/406716_fuso2nd_jpg43571b893bc1565318_jpg.rf.04c7565a19f40afdda593f9efd4a0a90.jpg  \n",
            " extracting: train/406716_fuso2nd_jpg43571b893bc1565318_jpg.rf.2dad7aa5f877e24ba8452bc66ed04475.jpg  \n",
            " extracting: train/406716_fuso2nd_jpg43571b893bc1565318_jpg.rf.e4b5a8ca8c774a6af90fe2eafb121e8a.jpg  \n",
            " extracting: train/406716_fuso2nd_jpg43571b893bc1565318_jpg.rf.e7a16e95b147af1e2eacab0ade5a2978.jpg  \n",
            " extracting: train/406_jpg.rf.d0ee617aed47d19ca273b37e0ff3ab06.jpg  \n",
            " extracting: train/407_jpg.rf.36d9afc8e8a9277dcb701e8b00c99c8a.jpg  \n",
            " extracting: train/408218_jpg.rf.d1e70d0986d8798ccd1eb68f6113b408.jpg  \n",
            " extracting: train/409_jpg.rf.449488f8b16ad2a68f44800eb2ef5c4a.jpg  \n",
            " extracting: train/40_jpg.rf.6ddaa50068f0f804f680afad8dad09b8.jpg  \n",
            " extracting: train/41-E-2648-QI-05-19_jpg.rf.b32c54c7978bd8643b64a7415e72acf7.jpg  \n",
            " extracting: train/410_jpg.rf.3d313c2a3275f8f3a72aabe6e55415ec.jpg  \n",
            " extracting: train/411_jpg.rf.c06a132e9ca4422800abbb8f18b92ead.jpg  \n",
            " extracting: train/412_jpg.rf.745bec9f6443e6dd9192ab5ab8ba0bbb.jpg  \n",
            " extracting: train/414_jpg.rf.dda68fba04cb1f19ed575b92fe69b475.jpg  \n",
            " extracting: train/415_jpg.rf.41758c4a9da14bd05da576ae5b6337c4.jpg  \n",
            " extracting: train/41728_53604_276708_jpg.rf.370eaf6a420adaec8d639574274cd760.jpg  \n",
            " extracting: train/41728_53604_276708_jpg.rf.4759a4ec16551e32b1fa33ecb971989e.jpg  \n",
            " extracting: train/41728_53604_276708_jpg.rf.7617ee34b5e9ddb9e1d88844c08a91fb.jpg  \n",
            " extracting: train/41728_53604_276708_jpg.rf.d13212cde8e95e3a5763d8e28db4d85e.jpg  \n",
            " extracting: train/418663_jpg.rf.12cdebadc58b578b338ab16034d8701d.jpg  \n",
            " extracting: train/419825_jpg.rf.a403b60337ba72efec3dc22768f4615e.jpg  \n",
            " extracting: train/42-E-3690-SE-09-21_jpg.rf.15598866268b41f1a687dfe5c022d73a.jpg  \n",
            " extracting: train/4209015271_jpg.rf.3196b676e1ca3eea8517032d35edb3b7.jpg  \n",
            " extracting: train/4209015271_jpg.rf.442f97322fc4cde4d45aa5919268e1ff.jpg  \n",
            " extracting: train/4209015271_jpg.rf.44c8034815aa2277ff1dedc91a1cf8c4.jpg  \n",
            " extracting: train/4209015271_jpg.rf.4abd9c64f10a0beaa3fcfb145f0825f7.jpg  \n",
            " extracting: train/4209015271_jpg.rf.9c0138a9e75423f9f899991637cf78cd.jpg  \n",
            " extracting: train/420924_jpg.rf.51e5e4a86e887f04e2a1562be45c62ec.jpg  \n",
            " extracting: train/420_jpg.rf.945f586f5496fd0afda5bc5c28da5c36.jpg  \n",
            " extracting: train/4261621862-1_jpg.rf.c638eb9ae3291c53e2c61a43f3de8d41.jpg  \n",
            " extracting: train/4261621862_jpg.rf.0e48eb77e6b35fbb4877934ec7f60b4b.jpg  \n",
            " extracting: train/4261621862_jpg.rf.4273812fe6c088d3aaf6cedcf9c4e33b.jpg  \n",
            " extracting: train/4261621862_jpg.rf.684ef6ecd6dc4212575380a568261c9c.jpg  \n",
            " extracting: train/4261621862_jpg.rf.827722c515f09d81f324ada31db28c3e.jpg  \n",
            " extracting: train/4261621862_jpg.rf.97837a18e0185c524ba2cfa823995254.jpg  \n",
            " extracting: train/4261621862_jpg.rf.b5e13debde2ad4bbcaf1a0450709f4dd.jpg  \n",
            " extracting: train/42618_jpg.rf.388ad05daa7c238ac5f587e3b6437526.jpg  \n",
            " extracting: train/426822_jpg.rf.80c96fe142fba0ab8522f71f37a191fa.jpg  \n",
            " extracting: train/426_jpg.rf.369f47b58329e05004d5a6070278ada2.jpg  \n",
            " extracting: train/427_jpg.rf.e728a81b44b66412d15d0d85fa50b41b.jpg  \n",
            " extracting: train/428_jpg.rf.29629466e60e14bcab8a4f29d7891ed1.jpg  \n",
            " extracting: train/42_jpg.rf.896458dbf89e32c3c9e208f8ddae67c5.jpg  \n",
            " extracting: train/43-E-5736-PAQ-09-22_jpeg_jpg.rf.743c99a2d444cce83f3601e4f08ddd9e.jpg  \n",
            " extracting: train/430_jpg.rf.e04796e810d85637a3d219c8e6eb6af0.jpg  \n",
            " extracting: train/431_jpg.rf.2832321f9a83f17e24ea420a1e579526.jpg  \n",
            " extracting: train/432_jpg.rf.271bf68aedf1dda64737d3d801959bcb.jpg  \n",
            " extracting: train/433_jpg.rf.d1df69364c0a9331cc676f5f85ab6b9f.jpg  \n",
            " extracting: train/434586_jpg.rf.b3cac37bbf06dd9c2cf8963a16cc37b7.jpg  \n",
            " extracting: train/434_jpg.rf.178be56f47c28f91f20bdeefd7c72e4d.jpg  \n",
            " extracting: train/437_jpg.rf.d3cb54c2ea9acae97c92d80d3693d6f9.jpg  \n",
            " extracting: train/438154_jpg.rf.69b78cbfd291b30059fde5ed749fc52a.jpg  \n",
            " extracting: train/439_jpg.rf.11fdd7b1d453f688987b67864f0fbd98.jpg  \n",
            " extracting: train/440_jpg.rf.d9fe9b2e0fc413fa2d0820fae1c554da.jpg  \n",
            " extracting: train/441_jpg.rf.223d93e55b8d1572fa1da6d32420d840.jpg  \n",
            " extracting: train/442_jpg.rf.3353cfc1cb906ef8ed585c6589fc4067.jpg  \n",
            " extracting: train/443971_jpg.rf.c8790487544d241d2d3e94454d1ba0b4.jpg  \n",
            " extracting: train/444238_jpg.rf.499d246b42215a43aad6802e71b3174e.jpg  \n",
            " extracting: train/445310_jpg.rf.61beae2755a49a1e8a4faf294e131c71.jpg  \n",
            " extracting: train/445_jpg.rf.10cb10b050041585e3710ed8903e0882.jpg  \n",
            " extracting: train/446_jpg.rf.247b6748a728101ae35c2acfcdf356fc.jpg  \n",
            " extracting: train/448_jpg.rf.8269075acd360166cd3b1077cd0b068e.jpg  \n",
            " extracting: train/449_jpg.rf.02e2b6b4b7554a93543bcff6a1c92c8c.jpg  \n",
            " extracting: train/44_jpg.rf.2f65600f682569136d70d41f79d16f69.jpg  \n",
            " extracting: train/45-E-4836-QM-10-19_jpeg_jpg.rf.d97ca30605f940f782e45649a2767204.jpg  \n",
            " extracting: train/451_jpg.rf.f75d6d1feb40d402ded03e674577d07f.jpg  \n",
            " extracting: train/452_jpg.rf.9f64ef41811649f3e48ed21e38c2e865.jpg  \n",
            " extracting: train/453_jpg.rf.934bf18bcc5a9e2d9c6f2ad72e3f956e.jpg  \n",
            " extracting: train/45490_57349_308284_jpg.rf.4f53a2aa20d5c20babd18471aad5f665.jpg  \n",
            " extracting: train/45490_57349_308284_jpg.rf.5e7d2b8d89c234b57ed1a6fd89d276d5.jpg  \n",
            " extracting: train/45490_57349_308284_jpg.rf.a81ec1702c99f89a4d5293699bf815c0.jpg  \n",
            " extracting: train/454_jpg.rf.62675a4a8ddd9d7db3d4ced514d77590.jpg  \n",
            " extracting: train/455_jpg.rf.d9f1f856ea686c1541283ce807d83adb.jpg  \n",
            " extracting: train/4560_jpg.rf.c4493f48849b7e55e598b7d1685d4400.jpg  \n",
            " extracting: train/456_jpg.rf.e7aaa6b36a2c38e189373217677c0502.jpg  \n",
            " extracting: train/457_jpg.rf.43b25c9e572eed29c648602fc3f3a684.jpg  \n",
            " extracting: train/458_jpg.rf.f5c5b72419c1246e0e0411b6e81cca3a.jpg  \n",
            " extracting: train/459_jpg.rf.bcc4c84dfedb25e7066c25a6ec0d0899.jpg  \n",
            " extracting: train/45_jpg.rf.b61a4fdce90fb422273af8dd123c47fc.jpg  \n",
            " extracting: train/46-E-4531-TV-04-18_jpeg_jpg.rf.ccdf9ee4762eae293ab6f11db6d5f9eb.jpg  \n",
            " extracting: train/460_jpg.rf.178b6067a77587d42137e2fc4dc68a73.jpg  \n",
            " extracting: train/461_jpg.rf.8e35b8cdbd9196be3c93668c258b9f8d.jpg  \n",
            " extracting: train/465_jpg.rf.cb30a266a68bebcae42b64b458ece7b9.jpg  \n",
            " extracting: train/466_jpg.rf.ffe1ebce624dc6a3ef808dbbc62fcbf1.jpg  \n",
            " extracting: train/468811_jpg.rf.36141d880310a9ef032855c1834c8553.jpg  \n",
            " extracting: train/468_jpg.rf.7d66647152fb49a89927b91a4abb7f4a.jpg  \n",
            " extracting: train/469775_jpg.rf.5341f187893acb38168903546d20dbbf.jpg  \n",
            " extracting: train/46_jpg.rf.b982306037916550ffb50b0d762a71f1.jpg  \n",
            " extracting: train/47-E-4240-RY-06-19_jpeg_jpg.rf.f05ce30b2046bb91643e700a378bdd99.jpg  \n",
            " extracting: train/470_jpg.rf.fefe00c2a36d88d7265952f2caf33765.jpg  \n",
            " extracting: train/47133a8d-f-968a_jpg.rf.1a520f5a87a5c5e1583cdaaea84ad010.jpg  \n",
            " extracting: train/471_jpg.rf.db6b4c85ec4344175618f5ec65907452.jpg  \n",
            " extracting: train/473_jpg.rf.ffdea983bc3d0a3892c31b78ee43c5f2.jpg  \n",
            " extracting: train/47585156_303828156906029_21693398286_jpg.rf.09319b90d6a72e23887a061ff21a33b6.jpg  \n",
            " extracting: train/47585156_303828156906029_21693398286_jpg.rf.322fd9ed62752bd8e7bf1b85027f658f.jpg  \n",
            " extracting: train/47585156_303828156906029_21693398286_jpg.rf.b7ad774ce70145e46449ab3d0e9cc8db.jpg  \n",
            " extracting: train/479_jpg.rf.28c592bcb92962345cdf17f045ee8f8d.jpg  \n",
            " extracting: train/48-E-6073-OL-09-19_jpg.rf.1f5dc3cffbb8b9b6be6f117c854528e8.jpg  \n",
            " extracting: train/481_jpg.rf.ee7116699359836d5c2202e88fda4c86.jpg  \n",
            " extracting: train/482830_jpg.rf.6345be999c0000f361cff78cc777988e.jpg  \n",
            " extracting: train/482_jpg.rf.7ac30c316d6e5646aa18a939437ba274.jpg  \n",
            " extracting: train/484_jpg.rf.eafe85fb613c9c678bc22703f1e8ea6e.jpg  \n",
            " extracting: train/485014_jpg.rf.a7e76ca78f4930a4302c45d6dc070198.jpg  \n",
            " extracting: train/488_jpg.rf.cd5869af8e127896f496b0705f84e9db.jpg  \n",
            " extracting: train/490_jpg.rf.a59fa5110c165e09183ee396e3ae1dfd.jpg  \n",
            " extracting: train/492659_jpg.rf.898b470490098b5d2537b24eac297d9c.jpg  \n",
            " extracting: train/492_jpg.rf.02f0b3f6196d2f9721f5b25da9a2aa72.jpg  \n",
            " extracting: train/494_jpg.rf.b3e0ffa726edaff6096d75887a2a1c44.jpg  \n",
            " extracting: train/496_jpg.rf.baa33a240202466f6be0058d9992cda6.jpg  \n",
            " extracting: train/497_jpg.rf.d05a70c7ee1c49ea952274ea3d0fa519.jpg  \n",
            " extracting: train/498_jpg.rf.4dece179d9a06cd77a4204f30e73dc5d.jpg  \n",
            " extracting: train/499_jpg.rf.d167a34530288db6eb2675a154de71df.jpg  \n",
            " extracting: train/4_jpeg_jpg.rf.e3a22af099fb324c945ba408f3833bbb.jpg  \n",
            " extracting: train/4_jpg.rf.54d59ae63df639b6a5d27bacba01acff.jpg  \n",
            " extracting: train/5-E-6862-QT-06-20_jpg.rf.647077fd077e0d353040a5f03faca51e.jpg  \n",
            " extracting: train/501_jpg.rf.efdde9ce5a938407dd45c7484651153f.jpg  \n",
            " extracting: train/503437_jpg.rf.9c86b27889441df83a553eacaf55b1a9.jpg  \n",
            " extracting: train/50483_jpg.rf.c0676cf7531afc00bb5bcf1e22f96a97.jpg  \n",
            " extracting: train/509950_jpg.rf.af05cb7aebcef014538f11de75955eea.jpg  \n",
            " extracting: train/50_jpg.rf.8c21b9f1719e1c11b4b621066f239f9b.jpg  \n",
            " extracting: train/51-E-3083-PAH-10-21_jpeg_jpg.rf.ced12c85a2db00ed1a07046b84be3438.jpg  \n",
            " extracting: train/510_jpg.rf.090d40d72432a3a037f9f7c5e089989d.jpg  \n",
            " extracting: train/511_jpg.rf.235f759c4e45f74cdcabfee89222c971.jpg  \n",
            " extracting: train/515_jpg.rf.3fdd325cd2209ff2c9514cafc3d2d50f.jpg  \n",
            " extracting: train/516_jpg.rf.ac8dcedae7a136e36254d0f7566977f0.jpg  \n",
            " extracting: train/519_jpg.rf.85f35994b590d3c1472c98f3e5958b00.jpg  \n",
            " extracting: train/52-E-3765-QO-12-19_jpg.rf.eb19e671e152f5c921ec1f8bec96161a.jpg  \n",
            " extracting: train/522730_jpg.rf.1ae3116e836bc3256d2a698f25fc8906.jpg  \n",
            " extracting: train/523324_jpg.rf.8718a3187ed88ddddb4e6f619a48dd06.jpg  \n",
            " extracting: train/525392_jpg.rf.e007498e943793f019acf37d9308d1f9.jpg  \n",
            " extracting: train/525_jpg.rf.d83ce7d11dda3c01bb5a50650d8314fc.jpg  \n",
            " extracting: train/526_jpg.rf.a6e36ca2466cefbf8c42ed8a21718584.jpg  \n",
            " extracting: train/527214_jpg.rf.89c27b6b8f3c73634ac04ad0cf8e8819.jpg  \n",
            " extracting: train/527_jpg.rf.0cfaa469a0034c4f0718b8b4b9019d75.jpg  \n",
            " extracting: train/528_jpg.rf.6f6a3ee32b47a95364032e19dec1272c.jpg  \n",
            " extracting: train/52_jpg.rf.8dfad20aaeacc130b9d7a2667f22b4dc.jpg  \n",
            " extracting: train/53-E-3288-QU-06-20_jpg.rf.fea80fa143a3862c3aad8bd432751a73.jpg  \n",
            " extracting: train/530948_jpg.rf.f6153a9c1daf50b86b9ab74357903631.jpg  \n",
            " extracting: train/531_jpg.rf.7f317af4f53a2213747283af68726cee.jpg  \n",
            " extracting: train/53241f12843e709981c8804a647fcc41_jpg.rf.5f297c77f94273a18cac8a834cec4e67.jpg  \n",
            " extracting: train/532742_jpg.rf.7402dfe047e726564eaf5dde83d337a3.jpg  \n",
            " extracting: train/532_jpg.rf.1d9dd841781e0026df6c2c5b3e8e6326.jpg  \n",
            " extracting: train/534_jpg.rf.8b9cbb6ad494071709c65c0b63a64028.jpg  \n",
            " extracting: train/535_jpg.rf.40880289fa78433df4225405cc398928.jpg  \n",
            " extracting: train/537_jpg.rf.81a7d232b772f5b3d02b8dfc18554d47.jpg  \n",
            " extracting: train/539_jpg.rf.eab02ccd1a648288bb94c5299c56f2a8.jpg  \n",
            " extracting: train/53_jpg.rf.e5d6496348a4b6ab78de7e22b782bfc1.jpg  \n",
            " extracting: train/54-E-5627-SF-06-19_jpg.rf.e76454e83b1f216c620a143a68b3bc3d.jpg  \n",
            " extracting: train/540709_jpg.rf.ccd9b60e5c4bef2c7db3dd9d1427d542.jpg  \n",
            " extracting: train/540_jpg.rf.2e3937d19db3cbc3e64772085dbf8372.jpg  \n",
            " extracting: train/542108_jpg.rf.0e7d04c7c1d150f13d8f35271b6d23d7.jpg  \n",
            " extracting: train/542_jpg.rf.7b51db61a51b380e35ca27d1730b472a.jpg  \n",
            " extracting: train/544_jpg.rf.2f48e567b83be76b4c406632f527fed7.jpg  \n",
            " extracting: train/545887_jpg.rf.bd9b5baad16358614db93adc5262f5d9.jpg  \n",
            " extracting: train/546_jpg.rf.4b50402e195be2efe4babcc9dc3737b4.jpg  \n",
            " extracting: train/549_jpg.rf.2c912fbe4e479a5bad19e8b8d49227cb.jpg  \n",
            " extracting: train/550_jpg.rf.3b416d2c74e94a0b8b074f22976bb36b.jpg  \n",
            " extracting: train/552_jpg.rf.8edc5d04e6cbd24a274c344c237fae9e.jpg  \n",
            " extracting: train/553_jpg.rf.d7c636317c8981ed3183821f0492231d.jpg  \n",
            " extracting: train/55450_jpg.rf.4b5c7e8ea31dcee90ef7a265ee4ae316.jpg  \n",
            " extracting: train/554_jpg.rf.830c161de312dec3d70184e14c0f5dd4.jpg  \n",
            " extracting: train/556_jpg.rf.29ba14aece70f4e41a232640e4dd3803.jpg  \n",
            " extracting: train/557_jpg.rf.3250a1150717a41eac5a257c842446eb.jpg  \n",
            " extracting: train/558_jpg.rf.02326be24843c0523601faa5eceb1925.jpg  \n",
            " extracting: train/55_jpg.rf.794946242ada7549524d5faecec0c990.jpg  \n",
            " extracting: train/56-E-5056-QD-12-18_jpeg_jpg.rf.9ae15fa99406d04069e13821a16d77ad.jpg  \n",
            " extracting: train/560_jpg.rf.a432885e6788e161f8956f32151343cf.jpg  \n",
            " extracting: train/562_jpg.rf.67f4fa5bbb702aca11ec2ebe9b8d2fe8.jpg  \n",
            " extracting: train/563_jpg.rf.0c8549fcac755e24581cb545836e4522.jpg  \n",
            " extracting: train/564579_jpg.rf.4ccaa8686c382382b9eba5081bb206fa.jpg  \n",
            " extracting: train/564_jpg.rf.6ed57ce932ebe990ac0b034581bd0ebd.jpg  \n",
            " extracting: train/566_jpg.rf.59d845ac479a86ec9b269cde019e0196.jpg  \n",
            " extracting: train/567049_jpg.rf.a8f41ec696572916f077c6288152d512.jpg  \n",
            " extracting: train/568568_jpg.rf.d98d4d400fb21916f5f9a3d8de0b858e.jpg  \n",
            " extracting: train/56_jpg.rf.0bc854b4dd41e82eccde484ab210eb88.jpg  \n",
            " extracting: train/57-E-5893-SH-05-20_jpg.rf.ee12ffc6eee75bfb1ba3995798ef8d7c.jpg  \n",
            " extracting: train/570761_v3_jpg.rf.685fb0c185162f3f8294d5bd352f2f61.jpg  \n",
            " extracting: train/572512_jpg.rf.74949435435717a618e19fdb3577fe74.jpg  \n",
            " extracting: train/572_jpg.rf.b9ca91164ddc07177d7d67d1af11568b.jpg  \n",
            " extracting: train/57368a_jpg.rf.f64509567a0af17fed0a2a291f07c2ae.jpg  \n",
            " extracting: train/573_jpg.rf.1ef7001f811997298de3a1e5142e8f44.jpg  \n",
            " extracting: train/575820_jpg.rf.b2fc45b324462dafea5be8b25916a17a.jpg  \n",
            " extracting: train/577_jpg.rf.0c990a766fcb825d570f8623bb94eb60.jpg  \n",
            " extracting: train/57877d_jpg.rf.6b3d65f0d517d40d5e9b9c56a2e2657c.jpg  \n",
            " extracting: train/579_jpg.rf.bdf8f8ad527e7a99e6d8dba3161c77bf.jpg  \n",
            " extracting: train/58-E-5158-TP-09-17_jpg.rf.958c62bc113380037518259b3f2e1aaf.jpg  \n",
            " extracting: train/580327_jpg.rf.b14f18ad2bdf32f539aae34f34fe5eba.jpg  \n",
            " extracting: train/580_jpg.rf.90cbdcbbc2297ce068905d50060917cc.jpg  \n",
            " extracting: train/581156_jpg.rf.eadb98d395ed34274a26cd8e30be1fa5.jpg  \n",
            " extracting: train/581_jpg.rf.a2b627bba820700dea450b868d9d7700.jpg  \n",
            " extracting: train/582171_jpg.rf.060de0ed2277e8888a097ee3bfc69922.jpg  \n",
            " extracting: train/583_jpg.rf.bcb245fd4a899623763811ef9e79c9ed.jpg  \n",
            " extracting: train/585_jpg.rf.5d2ad9d80fde1c5faaee1daf104b5b84.jpg  \n",
            " extracting: train/589_jpg.rf.2a04d7a7e732d1f999c4b8177c2d3076.jpg  \n",
            " extracting: train/58_jpg.rf.2faa32c04d02f3c63f07339765684942.jpg  \n",
            " extracting: train/59-E-2153-SP-08-20_jpeg_jpg.rf.b0613871da323fa8757df8fe75404b89.jpg  \n",
            " extracting: train/590_jpg.rf.fa38010a44d98270aa05bec79e61e520.jpg  \n",
            " extracting: train/591090_jpg.rf.46e5917680594370446dff85cc334183.jpg  \n",
            " extracting: train/592_jpg.rf.39ec46a104b7a3e4e5ec75cb9024fa87.jpg  \n",
            " extracting: train/593_jpg.rf.33f1ca2934ef0724296c9c18b2c425d0.jpg  \n",
            " extracting: train/594_jpg.rf.b66fe13f272851eb81fa9338b12a803f.jpg  \n",
            " extracting: train/595347_jpg.rf.dd7c42aba7cdd100c75dd9787ea8496d.jpg  \n",
            " extracting: train/595_jpg.rf.26e3f37fdf208b9b6fedeeb470d6348f.jpg  \n",
            " extracting: train/597672_jpg.rf.adaf6229fd04e3f05fa904c385ba034d.jpg  \n",
            " extracting: train/598_jpg.rf.681e49ade8d35467aa1e55409838d13d.jpg  \n",
            " extracting: train/599_jpg.rf.e83d8387e5ea349edab3db7a7556ade6.jpg  \n",
            " extracting: train/5_jpeg_jpg.rf.bb54e37f2005474b10f3da0ab0d2d6c7.jpg  \n",
            " extracting: train/5a1e37db78f66_jpg.rf.3675cf36f7a8e042116a0da69275ea7e.jpg  \n",
            " extracting: train/5f630068e794c-jpg_jpg.rf.c990fecc6e5e11ceb5342e5d6329a128.jpg  \n",
            " extracting: train/60-E-1707-PH-03-15_jpeg_jpg.rf.798a2d47f585835fb6bbedf9b912c81c.jpg  \n",
            " extracting: train/600109_jpg.rf.34402417b3baaf1fd69cefd1e35eec7c.jpg  \n",
            " extracting: train/6007931417_jpg.rf.2db4f8596080d7094a8c4cca677501ee.jpg  \n",
            " extracting: train/6007931417_jpg.rf.f5561e2e6a475e4fc7ed27c301da0cf6.jpg  \n",
            " extracting: train/6007950747_jpg.rf.b31fcaa3d63f092c50f5614ae9ab9cc5.jpg  \n",
            " extracting: train/6007950747_jpg.rf.d7183131e8e644f34a74cc51b6738ceb.jpg  \n",
            " extracting: train/601054_jpg.rf.7f2c14744f0adddd1dfd85b211c6ec8e.jpg  \n",
            " extracting: train/601_jpg.rf.14788cef49597f394ff0cafa48ef53e0.jpg  \n",
            " extracting: train/60251_jpg.rf.0a4317453036e11678e7cf590a1ca826.jpg  \n",
            " extracting: train/6046f688f6314789_jpg.rf.993a8dfc47c08b2cd31adecd12fa49d7.jpg  \n",
            " extracting: train/604996_jpg.rf.3858fd4371c6a779456e86507c81cad2.jpg  \n",
            " extracting: train/605_jpg.rf.2563fc3417753e72e0c757edc400f92d.jpg  \n",
            " extracting: train/606_jpg.rf.763b11f320d2900371a8a58513075847.jpg  \n",
            " extracting: train/609_jpg.rf.df834e57fe681d52d17c618e9c647ab2.jpg  \n",
            " extracting: train/60_jpg.rf.86d3705c338aadadb2f56391b35bdc25.jpg  \n",
            " extracting: train/610_jpg.rf.8d219bfe3f58bb124dfbda0d3304cac3.jpg  \n",
            " extracting: train/612_jpg.rf.16b8f702809552efd44618f56f173128.jpg  \n",
            " extracting: train/613827_jpg.rf.51cd4906dff98a6008929af5454a5e1e.jpg  \n",
            " extracting: train/613_jpg.rf.45639c594d0f39a63f416762448e84ce.jpg  \n",
            " extracting: train/614_jpg.rf.b837fa811b9f83cd62e87e3aa8b11347.jpg  \n",
            " extracting: train/615_jpg.rf.e302c5125cd98f6820069f8a03b950d7.jpg  \n",
            " extracting: train/616269383_jpg.rf.0d8236770ec4068026270e6b537f8504.jpg  \n",
            " extracting: train/616269383_jpg.rf.916c94af3e479d1670b304fd53b0cc7c.jpg  \n",
            " extracting: train/6171fa966192f1f1_jpg.rf.bba0f0c99f899e8e87b5158f7da22634.jpg  \n",
            " extracting: train/618513_jpg.rf.3938182d4d740fdd09564373c7d45f70.jpg  \n",
            " extracting: train/618_jpg.rf.538170d23aa48b11518908c8d5d807ae.jpg  \n",
            " extracting: train/619286_jpg.rf.5f60643d938156b109bab2f9b5c2fd01.jpg  \n",
            " extracting: train/619_jpg.rf.7390c2ddeb695602ee084136b7161455.jpg  \n",
            " extracting: train/62-E-3977-TH-12-18_jpg.rf.92569212f5816254e9f635cd0e960070.jpg  \n",
            " extracting: train/620_jpg.rf.486fa690af935573062448063577a871.jpg  \n",
            " extracting: train/621102_jpg.rf.a64cc3a63e3770f0ab316c2690e8a10a.jpg  \n",
            " extracting: train/62134520-mature-lady-on-yellow-scooter-scooter-driver-on-street-background-parking-for-a-few-minutes-near-the__flip_jpg.rf.1c805eb4a0176b1d68a72e2dab274217.jpg  \n",
            " extracting: train/62134520-mature-lady-on-yellow-scooter-scooter-driver-on-street-background-parking-for-a-few-minutes-near-the_jpg.rf.831379c3dcc7b41a5bcd934607b54e38.jpg  \n",
            " extracting: train/6221ece66a3b3354_jpg.rf.d0eea1e5c85fef3db3b1f17188760232.jpg  \n",
            " extracting: train/622_jpg.rf.943420e71404a7a667b13494535cb226.jpg  \n",
            " extracting: train/6247ff1c389c8997_jpg.rf.32c04955d41aba5514887eabb87d7eb5.jpg  \n",
            " extracting: train/625_jpg.rf.b8083a9b96de5e6e4134739768a5ccb3.jpg  \n",
            " extracting: train/627071_jpg.rf.633b7447af2cb4fb6fb3f0c6d45a5a4f.jpg  \n",
            " extracting: train/627_jpg.rf.f24aa2bd11011b7603ff8d3c95c0bc4d.jpg  \n",
            " extracting: train/628_jpg.rf.21ed3d7179719290e98516691d8f4696.jpg  \n",
            " extracting: train/629525_jpg.rf.b32485820241a9a42972a9b6553804ad.jpg  \n",
            " extracting: train/629_jpg.rf.9d7ead2c852fdf555699189aa3cdf1a5.jpg  \n",
            " extracting: train/62_jpg.rf.9439ba55ae91617209ab6d228edc71cf.jpg  \n",
            " extracting: train/63-E-2536-SA-09-18_jpg.rf.5996eff6f99333ca5fcfaa2e51da3594.jpg  \n",
            " extracting: train/630385_jpg.rf.5dda13412f6082ef53597e6e96744812.jpg  \n",
            " extracting: train/630_jpg.rf.f436a0e52bf3ccc628eaac2d74a80233.jpg  \n",
            " extracting: train/631183_jpg.rf.7747e8cbba80e6afecdd8ab409f9da8d.jpg  \n",
            " extracting: train/631_jpg.rf.6a35b8dc87836b7cafa4ba4f3d3ca912.jpg  \n",
            " extracting: train/6320646c88aca-generasi-terbaru-dari-_jpg.rf.99ce069568ccb5a25a74b15d6b943f8a.jpg  \n",
            " extracting: train/633_jpg.rf.c68a284b6ff66bc8422dd62b44859142.jpg  \n",
            " extracting: train/634_jpg.rf.bf2380a50f7e362847c6a34b910f0600.jpg  \n",
            " extracting: train/635188_jpg.rf.8ee066f1f08f878f28e047f1a7d41dd0.jpg  \n",
            " extracting: train/636308_jpg.rf.6c3d2005ffc88061703c34248bc37d3d.jpg  \n",
            " extracting: train/636534_jpg.rf.2af14e7dad428fff98ded681edfa9a64.jpg  \n",
            " extracting: train/638_jpg.rf.119a5f688d4e9ca4f1df165c3a4c6ecf.jpg  \n",
            " extracting: train/640699_jpg.rf.5183c2c2268b4cc6811192720e723e2a.jpg  \n",
            " extracting: train/640806_jpg.rf.b63bfb33b1a6aab092473ae8a887bce7.jpg  \n",
            " extracting: train/642_jpg.rf.d991894ea2b7f85a31ff854843246654.jpg  \n",
            " extracting: train/644_jpg.rf.4092d837c7ea9a5fe4b889efe224b12d.jpg  \n",
            " extracting: train/645_jpg.rf.b176cffb9a2f1269712d66fd4849f440.jpg  \n",
            " extracting: train/646657_jpg.rf.32a9e39d3c723e0ec5985b73da1b01dc.jpg  \n",
            " extracting: train/648_jpg.rf.0ba834224c51ebbb0e1a28868c067879.jpg  \n",
            " extracting: train/64_jpg.rf.e000e4d26b4c5447885b5c8fe0410c19.jpg  \n",
            " extracting: train/65-E-4235-PAL-04-22_jpeg_jpg.rf.c3202c0a595ca7b772a9706d02324829.jpg  \n",
            " extracting: train/652_jpg.rf.a84d3e1e9ee05f3fbc0966c8bf26459f.jpg  \n",
            " extracting: train/654787_jpg.rf.93fba4d39d97e3b516b6148d14096132.jpg  \n",
            " extracting: train/65497_jpg.rf.cf358bae7183db199e4693fa485f7096.jpg  \n",
            " extracting: train/654_jpg.rf.28bb0ed22efc03612f2258382fefef40.jpg  \n",
            " extracting: train/656_jpg.rf.7009a04cd43b12bdc1ee93b3edf846b7.jpg  \n",
            " extracting: train/658128_jpg.rf.cc3d2e2a54310ccdcf3d58a93d10f2ac.jpg  \n",
            " extracting: train/65_jpg.rf.b058831109c1276aeb78ee0b319cafaf.jpg  \n",
            " extracting: train/66-E-1477-RB-02-21_jpg.rf.db77e6ec051d1e1e71cd24263ecaf475.jpg  \n",
            " extracting: train/661_jpg.rf.24b028bf06857dabd85cdbce79ac0996.jpg  \n",
            " extracting: train/662_jpg.rf.fb99de70902a0a706449aeb4c342e5ff.jpg  \n",
            " extracting: train/663_jpg.rf.a2f3cd2198f279210b4b55414c1adb80.jpg  \n",
            " extracting: train/667_jpg.rf.bfde60b9ca457819d5750aa13b9c5945.jpg  \n",
            " extracting: train/668_jpg.rf.fe55da8448e6f163b63152363e65c533.jpg  \n",
            " extracting: train/669_jpg.rf.c2d0cf63000f6cbbcaffb01306e8ca18.jpg  \n",
            " extracting: train/66_jpg.rf.afd716b85514a2e9f121bd230164dead.jpg  \n",
            " extracting: train/670_jpg.rf.cd98b65d4c3691f7581af7be608b6f42.jpg  \n",
            " extracting: train/671_jpg.rf.0a622a0209d6d8c8a9684f3ef960cd09.jpg  \n",
            " extracting: train/67369_jpg.rf.c6ed44b5fa0e1a3c6893f17eaeeca0b8.jpg  \n",
            " extracting: train/673838_jpg.rf.7002b2aab7846e34bdf6394b4d6e76a2.jpg  \n",
            " extracting: train/67697v_jpg.rf.0c8c81c5840992716b924aef4ff8d27c.jpg  \n",
            " extracting: train/67697v_jpg.rf.282749b27b63f2209d43c0446e0714fe.jpg  \n",
            " extracting: train/67697v_jpg.rf.6462f81759c1383ff05b929bcdecc21d.jpg  \n",
            " extracting: train/677_jpg.rf.1563ba577cf59f64b17f9a10e2ed2062.jpg  \n",
            " extracting: train/678_jpg.rf.8901fb0005ed251123c6bcdf18ff4af6.jpg  \n",
            " extracting: train/67_jpg.rf.fc805e1a36e90b05b1433b1777bd5c1c.jpg  \n",
            " extracting: train/68-E-1267-RB-01-21_jpg.rf.9f16e712476948301072aff67c2f9103.jpg  \n",
            " extracting: train/680_jpg.rf.b577c97283181f8fdea28f39b644a556.jpg  \n",
            " extracting: train/682403_jpg.rf.ec76dd2d5b112b145a53f4761f341723.jpg  \n",
            " extracting: train/682974_jpg.rf.009bc8186bbbf26bffd363c8fec99240.jpg  \n",
            " extracting: train/682_jpg.rf.5d29e6950c923863308a10d5f0886b98.jpg  \n",
            " extracting: train/6833_jpg.rf.f8bc52e73e34808b3a875625987d2866.jpg  \n",
            " extracting: train/686_jpg.rf.8ae0c5cfc29acd57fe4dbe61039cd0f7.jpg  \n",
            " extracting: train/688_jpg.rf.70a4204d01cb84a6f5fbe787995c81aa.jpg  \n",
            " extracting: train/689402_jpg.rf.cf6b876832b05dd64e348772693160a2.jpg  \n",
            " extracting: train/689_jpg.rf.803a28829d2cf139b5fe5239acb565b4.jpg  \n",
            " extracting: train/690_jpg.rf.cfc7d74090304c840bda89e13aff0ca9.jpg  \n",
            " extracting: train/691077_jpg.rf.9709afa7d703695d36f6957f20aabf8d.jpg  \n",
            " extracting: train/691_jpg.rf.575e1f5c39e81b746e7d5c7057167807.jpg  \n",
            " extracting: train/692_jpg.rf.f784c569914a789e276eada9d758ca8b.jpg  \n",
            " extracting: train/694_jpg.rf.c98621b2cfa5a9eced18f390f15ff802.jpg  \n",
            " extracting: train/696278_jpg.rf.d5e5a825580e655803079cf93b74edfc.jpg  \n",
            " extracting: train/696_jpg.rf.6aa4de7f394f9ec7225723d7f541c91b.jpg  \n",
            " extracting: train/698335_jpg.rf.f47cbec17156b4191eff64c80a1d1752.jpg  \n",
            " extracting: train/6_jpg.rf.68c77d2e8bb855fed7a200e076679417.jpg  \n",
            " extracting: train/6ed4bc32-ec4f-475a-996d-64ad159da3ea_jpg.rf.6d07137e1302d69632e222defa67979c.jpg  \n",
            " extracting: train/7-E-4594-Q-08-18_jpeg_jpg.rf.5fd329ea75df7fe4f0a89ab099b68df1.jpg  \n",
            " extracting: train/70-E-4310-OR-03-20_jpeg_jpg.rf.22a61505efccc4e55251042eb80b07bc.jpg  \n",
            " extracting: train/7002574__flip_jpg.rf.addfa753cade8a98c82031d38b28267a.jpg  \n",
            " extracting: train/7002574_jpg.rf.067275215aab8a8a5c26082a0d02bbc3.jpg  \n",
            " extracting: train/7003032861_jpg.rf.1f5ad73929c25f498da60840a44cc259.jpg  \n",
            " extracting: train/7003032861_jpg.rf.5e0d6e04b9c092a4a585f38602cf7356.jpg  \n",
            " extracting: train/7003032861_jpg.rf.8efd2abbbeeaaa43339b8367d8291ab4.jpg  \n",
            " extracting: train/700_jpg.rf.bc9e9ad3f74693a27ba9f293dc417edc.jpg  \n",
            " extracting: train/701_jpg.rf.923089d591f2c00811636d0dd0bd4292.jpg  \n",
            " extracting: train/702_jpg.rf.c864593d2cc24dc6d6e58fd3ccbc7f1f.jpg  \n",
            " extracting: train/703_jpg.rf.c7e2094dca9e9af512dee2cb436fff60.jpg  \n",
            " extracting: train/706_jpg.rf.ba3b45ceb005f5336da3ec96d924439e.jpg  \n",
            " extracting: train/707_jpg.rf.4611171065b755ade654ace40efd524c.jpg  \n",
            " extracting: train/709_jpg.rf.6eb27a146616df36caa3cb21fc5840a6.jpg  \n",
            " extracting: train/71-E-2478-QK-07-19_jpeg_jpg.rf.7f3b3ffe64bccb8d40310abc91fe8751.jpg  \n",
            " extracting: train/710_jpg.rf.11ec3ad8d5fe7ec5fe23c8598ca068c1.jpg  \n",
            " extracting: train/714_jpg.rf.7fccb087203bc017772ed9d7793456c5.jpg  \n",
            " extracting: train/717_jpg.rf.f5f60f9b890ef4a41f636a315335daf1.jpg  \n",
            " extracting: train/719_jpg.rf.436be3c98b0a4ae1febbeb80af98fb67.jpg  \n",
            " extracting: train/720175_jpg.rf.b3922a6c4af1a0aad26dfd37c2cfe5c2.jpg  \n",
            " extracting: train/721_jpg.rf.4b87db5b10b05f91cad042a9fbc579b6.jpg  \n",
            " extracting: train/722785_jpg.rf.ff398905462cd277101847a9fcf46d60.jpg  \n",
            " extracting: train/723_jpg.rf.ec94ea36829c2a6735aeeef23e58d917.jpg  \n",
            " extracting: train/724_jpg.rf.b29e161554750f6d709539f7872f63cd.jpg  \n",
            " extracting: train/725_jpg.rf.5eabf25636d1478e92104cbfbda269e7.jpg  \n",
            " extracting: train/726559_jpg.rf.dd7b9933885b0f2f77ba5619c3fccd66.jpg  \n",
            " extracting: train/726_jpg.rf.0f2c65e3c7827a06e988e85329620cf8.jpg  \n",
            " extracting: train/727447_jpg.rf.113f064f8252daa9de15ef62c0890743.jpg  \n",
            " extracting: train/727_jpg.rf.e279821d412e19b7a2a36bf88ea6b5ef.jpg  \n",
            " extracting: train/729_jpg.rf.ffc47209383c4f2351c46e8d501f837e.jpg  \n",
            " extracting: train/730_jpg.rf.bf12cad017892a6fda1ea6b60ac6c609.jpg  \n",
            " extracting: train/733_jpg.rf.298e1040db866b61acff2aa4077931dc.jpg  \n",
            " extracting: train/734_jpg.rf.34b6d8fd1aa14f5fa96b77f7196f68dd.jpg  \n",
            " extracting: train/737_jpg.rf.cc8105a18a2a68137a5067d9d0d4dd54.jpg  \n",
            " extracting: train/73812_jpg.rf.302fcf6174a9de2a4fcf46b265b21ec1.jpg  \n",
            " extracting: train/738_jpg.rf.e53ca71ad8ee576daa49508fd8d1ad98.jpg  \n",
            " extracting: train/73_jpg.rf.ce6cd84b33c1e4a55d1387e91cb31b8c.jpg  \n",
            " extracting: train/74-E-2393-TT-01-18_jpg.rf.8b6ef70e014968784ef3a4cc24fa5cf6.jpg  \n",
            " extracting: train/740_jpg.rf.ea113e9d782366274eabf6e2c012bf61.jpg  \n",
            " extracting: train/741_jpg.rf.ba4f6cc752250c325489cf561fc18e2a.jpg  \n",
            " extracting: train/742221_jpg.rf.9c702bf9565e49ba380085cabe68a546.jpg  \n",
            " extracting: train/743_jpg.rf.da88e9a65c95bf26fd7df1067f735854.jpg  \n",
            " extracting: train/745988_jpg.rf.20147691926a94e5159d140e458b0fae.jpg  \n",
            " extracting: train/745_jpg.rf.47d620022d1ec838d1f43d691aa5b230.jpg  \n",
            " extracting: train/747753_jpg.rf.8f44f81bbec1ec4c135da52a606b673f.jpg  \n",
            " extracting: train/748_jpg.rf.b4353c050120f932c1d21fa24b9eaf25.jpg  \n",
            " extracting: train/749_jpg.rf.37a006e25e0adf85f93dbf965f7a497b.jpg  \n",
            " extracting: train/75-E-2956-RP-03-22_jpeg_jpg.rf.8756c9bcdb13b64f32956006448d59be.jpg  \n",
            " extracting: train/750110_jpg.rf.8072354f69345d0ad1b50e7eb6dd1656.jpg  \n",
            " extracting: train/750982_jpg.rf.995712c7e10c24e98631b89be38b6f58.jpg  \n",
            " extracting: train/754_jpg.rf.ca60114d7fdc8edcfd1cb144f403e817.jpg  \n",
            " extracting: train/755_jpg.rf.2bd27ef2874d64f6b7ab3feb024ac261.jpg  \n",
            " extracting: train/756_jpg.rf.2be1c0b0c5ec521431e812121c4e3bf9.jpg  \n",
            " extracting: train/757_jpg.rf.152d8817352c674c65a4ef9318e2aadb.jpg  \n",
            " extracting: train/759821_jpg.rf.142a0b29912706fc307be980fec1fe86.jpg  \n",
            " extracting: train/759_jpg.rf.474c60ec580227e22eb4b24c5b4ab8d6.jpg  \n",
            " extracting: train/760_jpg.rf.8e3d35d3bf436aa43768e6caa821b11d.jpg  \n",
            " extracting: train/762961_jpg.rf.0761e51848e19cc4f6e272d8a8ece8dd.jpg  \n",
            " extracting: train/762_jpg.rf.3318c4770b13d99a34ebe455824afec7.jpg  \n",
            " extracting: train/763_jpg.rf.0b43cc2df8124a1002cd642972d5a6f0.jpg  \n",
            " extracting: train/764_jpg.rf.1f5cb6a6cb51b8b029e911eda75f781e.jpg  \n",
            " extracting: train/765_jpg.rf.cc0bb467b93d05eb3e9d19460b436953.jpg  \n",
            " extracting: train/766170_jpg.rf.07f00fe12a0ca8e32b4888da969388a0.jpg  \n",
            " extracting: train/768_jpg.rf.2f7d02b1756a0e114f01bcc7008d8237.jpg  \n",
            " extracting: train/769_jpg.rf.2de49e45fa517ff2aaea043b7af8d2b0.jpg  \n",
            " extracting: train/77-E-6295-QL-09-19_jpeg_jpg.rf.c08df15ba9620de1917406c35b3f79af.jpg  \n",
            " extracting: train/77-E-6295-QL-09-19_jpeg_jpg.rf.e628a4bb5b2d07fb652825206741f4aa.jpg  \n",
            " extracting: train/770_jpg.rf.9f0e355d669833f5649d30b60979cd2a.jpg  \n",
            " extracting: train/771_jpg.rf.7dbc1a6bdfce709b59292d73366c9890.jpg  \n",
            " extracting: train/772_jpg.rf.94df66978cec1155491c25de7aaa9e37.jpg  \n",
            " extracting: train/773514_jpg.rf.6e6f30cb616075284575a4178551d5eb.jpg  \n",
            " extracting: train/773_jpg.rf.6b3eb304953460668e5f778c1f449fbe.jpg  \n",
            " extracting: train/774_jpg.rf.92d5f51311cf7a2564a692762d673045.jpg  \n",
            " extracting: train/775_jpg.rf.d2d67a93ccd0367783aa601cdf878c3a.jpg  \n",
            " extracting: train/778_jpg.rf.496061f83168b118c1d99d245ad728ce.jpg  \n",
            " extracting: train/779_jpg.rf.bab8d7b60f755e06c8d91313a72e22ba.jpg  \n",
            " extracting: train/78-E-1245-RG-02-20_jpg.rf.336e426d901bd516b18bb5fd2f6dd3c1.jpg  \n",
            " extracting: train/780_jpg.rf.6b4ddc168b6d2edb77be3d359b588c9d.jpg  \n",
            " extracting: train/781_jpg.rf.89976aaef2bdb1b695e9577b921feab5.jpg  \n",
            " extracting: train/782_jpg.rf.4821002c127d2c09530b9efdab857777.jpg  \n",
            " extracting: train/783_jpg.rf.8aad48cf63616a616cdb0290f1e74f98.jpg  \n",
            " extracting: train/787982_jpg.rf.fae7cb0791185cf87bd18b711f59367f.jpg  \n",
            " extracting: train/788_jpg.rf.2b79173558bc8f32d26c39e050e5f4fc.jpg  \n",
            " extracting: train/789_jpg.rf.bae9d2d322a789bc93aeb970761f74d9.jpg  \n",
            " extracting: train/78_jpg.rf.68a40f6971c3a1698069663950a5ba60.jpg  \n",
            " extracting: train/79-E-4564-SZ-09-21_jpeg_jpg.rf.7ca124e3c974a4726d2e8386989e7b03.jpg  \n",
            " extracting: train/790_jpg.rf.400820954fa0004354b4071748af209c.jpg  \n",
            " extracting: train/792_jpg.rf.038a32d74cbc4ac2ce48e98dfa24ca3b.jpg  \n",
            " extracting: train/794_jpg.rf.d910796b5e6a78109d66116dee1be7f2.jpg  \n",
            " extracting: train/7_jpg.rf.3c1addcfe0e07f0209f39f4eb96fb3da.jpg  \n",
            " extracting: train/8-E-3396-TO-08-22_jpeg_jpg.rf.ca55a9c63f50d247b775e173532f3d0a.jpg  \n",
            " extracting: train/80-E-5142-TW-05-18_jpeg_jpg.rf.b5f0241f328a457866e5a90b0a1c35bb.jpg  \n",
            " extracting: train/800_jpg.rf.5b7e8b84f2080bafcd5960fc5fa1a11e.jpg  \n",
            " extracting: train/803054_jpg.rf.33d7c63627a1bb6c37ef41e23383083e.jpg  \n",
            " extracting: train/805065_jpg.rf.5d22f3e7817fa7628943a88538ef6667.jpg  \n",
            " extracting: train/806114_jpg.rf.618702dbdfe803d40b7cce6eea7ac4f5.jpg  \n",
            " extracting: train/80_jpg.rf.cba45b7c938363c21405a97735fc1510.jpg  \n",
            " extracting: train/81-E-3115-SN-06-20_jpg.rf.29e9a731c0f996d3e14232088de2fefa.jpg  \n",
            " extracting: train/811212_jpg.rf.0c88a195366060f84cb1a559dde06e88.jpg  \n",
            " extracting: train/81_jpg.rf.34b92aa5cc37879f612ff371ccf019ca.jpg  \n",
            " extracting: train/82-E-4993-TI-01-22_jpg.rf.0b4a118045007b12109ff277e6a3f0a9.jpg  \n",
            " extracting: train/821596_jpg.rf.5bbea13bbfa84c1eecd020921579f06d.jpg  \n",
            " extracting: train/828179_jpg.rf.f78316e37129226969c892514205f72e.jpg  \n",
            " extracting: train/82_jpg.rf.09ddf7b383f32fc170140abeb39d2f25.jpg  \n",
            " extracting: train/83-E-4147-QJ-06-19_jpeg_jpg.rf.874d9ffb88dd6e310414596e554d8fd5.jpg  \n",
            " extracting: train/830005_1_original_jpg.rf.bd7b6cd12bcfaa793c06a07b76d8e5b8.jpg  \n",
            " extracting: train/830005_2_original_jpg.rf.3b9ad6d923726ed1e614e29cd56093d5.jpg  \n",
            " extracting: train/830005_2_original_jpg.rf.5bff7f51ae6fdb03d011f6b718be2e4b.jpg  \n",
            " extracting: train/83736_jpg.rf.38e65e4a0a1a1647a31eae8443bb3aa9.jpg  \n",
            " extracting: train/838467_jpg.rf.c321f44772a2c7e0a68b5f663573e4ba.jpg  \n",
            " extracting: train/839402_jpg.rf.97af72f514271d57ea40d48dc9fd3c38.jpg  \n",
            " extracting: train/839615_jpg.rf.be4a76f56659ae116629f23e0d1576c9.jpg  \n",
            " extracting: train/83_jpg.rf.fc34d8153b7b4972901c3e8813d4fa24.jpg  \n",
            " extracting: train/84-E-6545-SN-06-21_jpeg_jpg.rf.1325e83ae2e85e98daf01ef7d9a6f3de.jpg  \n",
            " extracting: train/840206_jpg.rf.e3d18169149968a5dfd0e326ba389c9b.jpg  \n",
            " extracting: train/840255_jpg.rf.0cb55bcbcd06c637625affe865c7b847.jpg  \n",
            " extracting: train/847209_jpg.rf.02c52928ec819993c2c1ac816109ca6e.jpg  \n",
            " extracting: train/847666-2012-mitsubishi-fuso-super-gr_jpg.rf.21e56d4f9571d169d6ce07e5062d3ec0.jpg  \n",
            " extracting: train/847666-2012-mitsubishi-fuso-super-gr_jpg.rf.ee09c1405462f9c01f29a971a51630df.jpg  \n",
            " extracting: train/847668-2012-mitsubishi-fuso-super-gr_jpg.rf.702b83eeb634b5c0a89e1513d7f70f44.jpg  \n",
            " extracting: train/847668-2012-mitsubishi-fuso-super-gr_jpg.rf.d0254bc230c5cb762bc83dafd759d15f.jpg  \n",
            " extracting: train/847673-2012-mitsubishi-fuso-super-gr_jpg.rf.d9fe3d5d17c76899788151a8356158f4.jpg  \n",
            " extracting: train/847675-2012-mitsubishi-fuso-super-gr_jpg.rf.5645092fe1ebe2fcca0fa21ed67a330c.jpg  \n",
            " extracting: train/848105_jpg.rf.ece60e80c792e4198d283111c274b9eb.jpg  \n",
            " extracting: train/84_jpg.rf.63a78efdf39d36e98507047e3f1824a0.jpg  \n",
            " extracting: train/85-E-2686-QH-04-19_jpeg_jpg.rf.9aa68c366e821b7d9b95b41216774699.jpg  \n",
            " extracting: train/850082_jpg.rf.4bc480730ba8c6b882f785c1c6357c92.jpg  \n",
            " extracting: train/852641_jpg.rf.a255f35c910a0a0b7e8e412c3d77b459.jpg  \n",
            " extracting: train/85267e_jpg.rf.6729413ad0909c0ab80b7f1c64d5476c.jpg  \n",
            " extracting: train/85267e_jpg.rf.707a1e812e80b22b60e1fc3dc77ff7cf.jpg  \n",
            " extracting: train/85267e_jpg.rf.97be33dba949f2e597681bc73994dc32.jpg  \n",
            " extracting: train/854534_SAM_0695_JPG5bb2899218b4c7a1a_jpg.rf.0bf59afb7866f14809dc3149073b8b15.jpg  \n",
            " extracting: train/854534_SAM_0695_JPG5bb2899218b4c7a1a_jpg.rf.1635c6d75790a827069a342023e5b7d1.jpg  \n",
            " extracting: train/854534_SAM_0695_JPG5bb2899218b4c7a1a_jpg.rf.465751f17830f0861433f5a910046d49.jpg  \n",
            " extracting: train/854534_SAM_0695_JPG5bb2899218b4c7a1a_jpg.rf.910e282cf5d8805aa128b53396f6c2d4.jpg  \n",
            " extracting: train/854534_SAM_0695_JPG5bb2899218b4c7a1a_jpg.rf.f1d0c6873e677c9e96cb0186f7bae876.jpg  \n",
            " extracting: train/854815_jpg.rf.81e1e49479c338b6d57b3bcd4ed5167c.jpg  \n",
            " extracting: train/858073_jpg.rf.44cc4c41328ad4c970250c754c62f60c.jpg  \n",
            " extracting: train/865166_jpg.rf.69c1ce6cc466bc076d06f9f4bc7837bf.jpg  \n",
            " extracting: train/86_jpg.rf.aa7caeff6c54e93f12f56f1b89c4a551.jpg  \n",
            " extracting: train/876470_jpg.rf.04414c47c0616e5d8dd1f72798ca8410.jpg  \n",
            " extracting: train/876850_jpg.rf.d05ec6da5e4c868ee3d82fc0d4031e4d.jpg  \n",
            " extracting: train/877171_jpg.rf.ceee4634566452f064c6f02bdd247d39.jpg  \n",
            " extracting: train/87_jpg.rf.c502499790e37b2cf4cc098f3cf87e3c.jpg  \n",
            " extracting: train/88-E-3118-QP-01-20_jpeg_jpg.rf.49ae4b919e49e93e7843ff2062e9f8c0.jpg  \n",
            " extracting: train/880050_jpg.rf.ab5f520cf5bd5d43d67d4842e96ec4dd.jpg  \n",
            " extracting: train/884374_jpg.rf.e0ca4ab834594b97bbd53eba28985caf.jpg  \n",
            " extracting: train/89-E-6099-QS-05-20_jpeg_jpg.rf.665361adb0e503ce5b076c0fb3b4a8fc.jpg  \n",
            " extracting: train/894838_jpg.rf.ae0fdc05a39e771823604b7f8028c2b6.jpg  \n",
            " extracting: train/89_jpg.rf.1160a7d2563b5a07d6a32bfb294073cb.jpg  \n",
            " extracting: train/8__flip_jpg.rf.61c9e6045e522caea45e040b5f63460a.jpg  \n",
            " extracting: train/8_jpg.rf.7a5790432d87d17865d8562cc62be370.jpg  \n",
            " extracting: train/8e122b9b28dc5f426486-1296x954_jpg.rf.411cb937ac6629edf302979c197af480.jpg  \n",
            " extracting: train/9-E-2633-RO-11-16_jpg.rf.a15888bd7dd5773325a3308d342354d2.jpg  \n",
            " extracting: train/90-E-5811-RO-10-18_jpeg_jpg.rf.d0bee9183491546f9b99b7854e822627.jpg  \n",
            " extracting: train/9041_1413578135698_jpg.rf.bf3eef8206a3bd85fa9a5512598a689e.jpg  \n",
            " extracting: train/907365_jpg.rf.37acf9fa6f45e3f8c2cacbc275ce4025.jpg  \n",
            " extracting: train/908898_jpg.rf.5016d1910309d8a5c3bd549e4e4307c9.jpg  \n",
            " extracting: train/90_jpg.rf.e13d8ff62d42c848d4b0be7136c92b3b.jpg  \n",
            " extracting: train/910715-725x490_jpg.rf.1a6d5202e4c3bae093a50146f8272dac.jpg  \n",
            " extracting: train/912422_jpg.rf.a1599ecc63ebc20d42b6b2fbba08ead6.jpg  \n",
            " extracting: train/91247a_jpg.rf.1b1d26c0a16797349ee71a7dd3601252.jpg  \n",
            " extracting: train/91247a_jpg.rf.b38060ea432e1877f9ded2e27dc39f3b.jpg  \n",
            " extracting: train/91247a_jpg.rf.fc4f125e5524268fe51b4f3868b17239.jpg  \n",
            " extracting: train/916007_jpg.rf.19ef6557f414b5b49c0016613bade805.jpg  \n",
            " extracting: train/92-E-3912-P-05-21_jpg.rf.17643a56b039de7fe43a36b70774adb6.jpg  \n",
            " extracting: train/92182b_jpg.rf.71bec081ad9faee7eb92be5555a72212.jpg  \n",
            " extracting: train/93-E-5277-PW-09-18_jpg.rf.1e0221a36beb57509a77a42c93667cad.jpg  \n",
            " extracting: train/93_jpg.rf.f7517870ca540e1909700bc1c5af62e3.jpg  \n",
            " extracting: train/94-E-2118-ST-01-21_jpeg_jpg.rf.46125dd293c67f3c76cc758fe03903df.jpg  \n",
            " extracting: train/94_jpg.rf.f265dbbd8867890b50442ec113e4503f.jpg  \n",
            " extracting: train/95-E-6686-SK-01-20_jpeg_jpg.rf.ea4f0b3a50dde70068548ea775699982.jpg  \n",
            " extracting: train/95945044-man-riding-motorcycle-on-the-road-in-hanoi-vietnam-__flip_jpg.rf.8eaec5c6e146edf29f7964c8af32617d.jpg  \n",
            " extracting: train/95945044-man-riding-motorcycle-on-the-road-in-hanoi-vietnam-_jpg.rf.75db8b685b04088246af6b648aad3a0d.jpg  \n",
            " extracting: train/95945046-woman-riding-motorcycle-on-the-road-in-hanoi-vietnam-_jpg.rf.eb4e9cdd8bf0e96646ddf5d3eb763ec4.jpg  \n",
            " extracting: train/96-E-5942-TM-06-17_jpeg_jpg.rf.5d50abb39a9a3cbb39b0da9510bbe21c.jpg  \n",
            " extracting: train/9688017_201706150418340410_png_jpg.rf.5eec0565081d243a3441da81d4223eff.jpg  \n",
            " extracting: train/9688017_201706150418340410_png_jpg.rf.9580a0fd5a6d4ffc530e93d0d1bd6aa7.jpg  \n",
            " extracting: train/97_jpg.rf.e1db3adf08493745c0dfb38f9d95fd62.jpg  \n",
            " extracting: train/98-E-2521-RQ-04-19_jpg.rf.c2e757c3facbe204096b2e1eafd7988b.jpg  \n",
            " extracting: train/982197058_jpg.rf.b5e1b74f26bef993cc29fd1f9e656488.jpg  \n",
            " extracting: train/99841576-people-riding-motorcycles-on-the-road-at-hanoi-vietnam-__flip_jpg.rf.282d939bddb1550a09c182929c0baaef.jpg  \n",
            " extracting: train/999589157_7_jpg.rf.081f3381788c1f5c4c8964b1a1bed612.jpg  \n",
            " extracting: train/999589157_7_jpg.rf.2478997350d40bd2819900d000f80e37.jpg  \n",
            " extracting: train/999589157_7_jpg.rf.656cbc3465cb2d995511aa64fc0836d8.jpg  \n",
            " extracting: train/999589157_7_jpg.rf.de18faf3c4ba472886623116923f0f74.jpg  \n",
            " extracting: train/99_jpg.rf.c899295cf111b16c345e25b19fac0365.jpg  \n",
            " extracting: train/9_jpeg_jpg.rf.883382a9a1e450405702344d922308ca.jpg  \n",
            " extracting: train/9_jpg.rf.06ace4961a07f574c9ef4dde97b5de16.jpg  \n",
            " extracting: train/A10_png_jpg.rf.5b0ad0fa6ac653229d5406f765986110.jpg  \n",
            " extracting: train/A10_png_jpg.rf.78854230f976acf45a24ed73f1a6f97c.jpg  \n",
            " extracting: train/A10_png_jpg.rf.8ec0ae63abbfc9869138377fb381bac3.jpg  \n",
            " extracting: train/A11_png_jpg.rf.29d4c57cbfe9ae175d6d8eb49cc23194.jpg  \n",
            " extracting: train/A11_png_jpg.rf.6460b3a7f1df9db5eca9ceaed24e2920.jpg  \n",
            " extracting: train/A11_png_jpg.rf.a7dc71e8254faba874207c59a88a55b2.jpg  \n",
            " extracting: train/A11_png_jpg.rf.ea988067bee8402e99983a746bfafa47.jpg  \n",
            " extracting: train/A12_png_jpg.rf.5c34dab72e4e0092d6058801380255dd.jpg  \n",
            " extracting: train/A12_png_jpg.rf.683b835876c2e0a0a8fd9053b8984d2e.jpg  \n",
            " extracting: train/A12_png_jpg.rf.c55bd2dc5755859387c7352d91465b9d.jpg  \n",
            " extracting: train/A14_png_jpg.rf.96b8cb960ab1704fa6c0146f7881cbd5.jpg  \n",
            " extracting: train/A15_png_jpg.rf.740d0213ce759fdedaf18bdbaf71268b.jpg  \n",
            " extracting: train/A17_png_jpg.rf.6b43e30cea3e537af8f350387764c1d0.jpg  \n",
            " extracting: train/A17_png_jpg.rf.834e8eaa37e9dfb934c77f41faf04024.jpg  \n",
            " extracting: train/A17_png_jpg.rf.e0d55e58a072a88ef7b75cb167a0aa31.jpg  \n",
            " extracting: train/A17_png_jpg.rf.e882abfb02abbf2f62ef877cb816d72f.jpg  \n",
            " extracting: train/A17_png_jpg.rf.ea00b06095a5cb0cbdb71974377b7132.jpg  \n",
            " extracting: train/A17_png_jpg.rf.eacaab0946873e31522d3e77e5139d82.jpg  \n",
            " extracting: train/A18_png_jpg.rf.1d399be0480112822420a579bb4221b7.jpg  \n",
            " extracting: train/A18_png_jpg.rf.3853458ebb4e18a51a61761edc77e1ab.jpg  \n",
            " extracting: train/A18_png_jpg.rf.483115efc7fbe29d3d21243ed60b78cf.jpg  \n",
            " extracting: train/A18_png_jpg.rf.7f32f397ade8a63de498227a9db42095.jpg  \n",
            " extracting: train/A18_png_jpg.rf.d32e81f9a9c4e75fe809f3fd4cab9b45.jpg  \n",
            " extracting: train/A19_png_jpg.rf.cb2605fe096b8ebd7546322ad635af62.jpg  \n",
            " extracting: train/A19_png_jpg.rf.d07fabc678d82136e44538b352ca5be3.jpg  \n",
            " extracting: train/A19_png_jpg.rf.dbe9d255434bb6a493934be3b33ba1d6.jpg  \n",
            " extracting: train/A19_png_jpg.rf.ea35cba966581476a2e918307fc868ba.jpg  \n",
            " extracting: train/A1_png_jpg.rf.28846779b56d3efe3e985daf586ba6d3.jpg  \n",
            " extracting: train/A20_png_jpg.rf.0d51fc6be0c66d757d9dd20e9b11d11d.jpg  \n",
            " extracting: train/A20_png_jpg.rf.23b6079a9bf39663a510932264f80881.jpg  \n",
            " extracting: train/A20_png_jpg.rf.326ba5b160e84a6cfc70a88e1aa49b64.jpg  \n",
            " extracting: train/A20_png_jpg.rf.4ea8d84c6d6220f075b0659573e4a688.jpg  \n",
            " extracting: train/A20_png_jpg.rf.7d2351232796f6fc2f846625eeab3082.jpg  \n",
            " extracting: train/A21_png_jpg.rf.79573c27abe2b0823fd1ad017108dc42.jpg  \n",
            " extracting: train/A21_png_jpg.rf.aa02d76f6a8a054aa35e9199bf9e7955.jpg  \n",
            " extracting: train/A21_png_jpg.rf.c629e35d7591672570866d267d136654.jpg  \n",
            " extracting: train/A21_png_jpg.rf.d7bc320ca8987c8a0833b1c97f2c1c27.jpg  \n",
            " extracting: train/A21_png_jpg.rf.ddbe06303b8982d473f67f5607a709c9.jpg  \n",
            " extracting: train/A22_png_jpg.rf.238819da6da9baeeb5e12330621e5713.jpg  \n",
            " extracting: train/A25_png_jpg.rf.007100f2726c2bbbfbc5df9bf502132c.jpg  \n",
            " extracting: train/A25_png_jpg.rf.856fe6280c7019d7e9aac084f800a14c.jpg  \n",
            " extracting: train/A25_png_jpg.rf.ba89775c2e259ca7823beb88e5adcd3f.jpg  \n",
            " extracting: train/A26_png_jpg.rf.4f430d63d4d3119a8f4842f7a2becd60.jpg  \n",
            " extracting: train/A26_png_jpg.rf.dc57a71d3a34aa35aa9ee261e26d3c1b.jpg  \n",
            " extracting: train/A27_png_jpg.rf.003f30701756811874fd5253825b7d70.jpg  \n",
            " extracting: train/A27_png_jpg.rf.4191f2ca15da7a81695369831d54a5ec.jpg  \n",
            " extracting: train/A27_png_jpg.rf.6a747326b33ce6c5972f1c403eef8b5f.jpg  \n",
            " extracting: train/A28_png_jpg.rf.dbd951f9a630401093f0274d1bc64316.jpg  \n",
            " extracting: train/A2_png_jpg.rf.49189777749b27e8b346fda61d530faf.jpg  \n",
            " extracting: train/A2_png_jpg.rf.6a44e7168b142e2e4695db33029c9d5b.jpg  \n",
            " extracting: train/A2_png_jpg.rf.97eb34b53dc67fbc95642a76fbc73e00.jpg  \n",
            " extracting: train/A2_png_jpg.rf.a1db9efc8d7737bb1cbc0c8a1953a6ad.jpg  \n",
            " extracting: train/A2_png_jpg.rf.ebf1083fbf0b17eaeebf3233174b2357.jpg  \n",
            " extracting: train/A30_png_jpg.rf.2577688ecc4188bf69af78a511e6b69e.jpg  \n",
            " extracting: train/A30_png_jpg.rf.cceea794ac9604766892cd92898f6a53.jpg  \n",
            " extracting: train/A31_png_jpg.rf.d174c1b8d5f401d3e8b3e684b3febc9e.jpg  \n",
            " extracting: train/A32_png_jpg.rf.ef77531aff7ec7b769743523ca6ce7dc.jpg  \n",
            " extracting: train/A33_png_jpg.rf.7dfabc445e94b77b6f1d7cde207886e8.jpg  \n",
            " extracting: train/A33_png_jpg.rf.bd273e29d88f013c6360fae511f46b26.jpg  \n",
            " extracting: train/A33_png_jpg.rf.d6d29605abddca04a3096f505b0829e0.jpg  \n",
            " extracting: train/A34_png_jpg.rf.4318b8333f45145651e88e8453b2879d.jpg  \n",
            " extracting: train/A34_png_jpg.rf.ca4739b5150ef93d59ed62db4e90688f.jpg  \n",
            " extracting: train/A34_png_jpg.rf.d4bd08d8315157674565e177f6674815.jpg  \n",
            " extracting: train/A34_png_jpg.rf.ef5edbb653d5d304ea11a3b4252435f7.jpg  \n",
            " extracting: train/A35_png_jpg.rf.2af273bc50605a4ff5909daa90ce8212.jpg  \n",
            " extracting: train/A35_png_jpg.rf.452e24941262aa1bf8118943562bca19.jpg  \n",
            " extracting: train/A35_png_jpg.rf.5256edf2c7fb06dd1a8756eff4e65036.jpg  \n",
            " extracting: train/A36_png_jpg.rf.d31b1f366e2e0836a23e1b84116b9134.jpg  \n",
            " extracting: train/A37_png_jpg.rf.7545161c445d4bb25d0209ccb90a3dc7.jpg  \n",
            " extracting: train/A38_png_jpg.rf.afc8d286c672447e4fc6362274901c52.jpg  \n",
            " extracting: train/A38_png_jpg.rf.c94167c0f91497a15ad612d0aa881706.jpg  \n",
            " extracting: train/A39_png_jpg.rf.2816e7f6619ca92284a953649cda3b8d.jpg  \n",
            " extracting: train/A3_png_jpg.rf.dcebccb1cbb935a38b9faa3a59e3d18c.jpg  \n",
            " extracting: train/A4_png_jpg.rf.221303d45a4194d52fb2fdfdf8ee8599.jpg  \n",
            " extracting: train/A4_png_jpg.rf.afa7be7e4efbd1e36d3439a71876a35e.jpg  \n",
            " extracting: train/A4_png_jpg.rf.c4b14dfa80965b90a8e8033dc80ebb7b.jpg  \n",
            " extracting: train/A5_png_jpg.rf.7a5a7bcac04bedbc9e133f3fdb425d5f.jpg  \n",
            " extracting: train/A5_png_jpg.rf.f514e84649845fdf58fc4b2a80a9290b.jpg  \n",
            " extracting: train/A6_png_jpg.rf.3d591a621d257556a791e765d46565e9.jpg  \n",
            " extracting: train/A6_png_jpg.rf.667b0a5a47d2a7112d9ee336b74eaf8f.jpg  \n",
            " extracting: train/A6_png_jpg.rf.a1a4d8c16b037c3842a78ef35fb04910.jpg  \n",
            " extracting: train/A6_png_jpg.rf.ab580deadcf3bd4e0b52cd9010e888d2.jpg  \n",
            " extracting: train/A7_png_jpg.rf.4be476459a2bdae81accee715aee98aa.jpg  \n",
            " extracting: train/A7_png_jpg.rf.aa8fa50fe7571e0c548e04f22dea5c82.jpg  \n",
            " extracting: train/A7_png_jpg.rf.e1673afe7c2ddce3b32e0d45923741b8.jpg  \n",
            " extracting: train/A8_png_jpg.rf.9e853711805fbb5909e13956461d1f8c.jpg  \n",
            " extracting: train/A9_png_jpg.rf.2562c2ad0c4744becd40884edf0213b9.jpg  \n",
            " extracting: train/A9_png_jpg.rf.6ef32b12ec82d7da7659e8ca80aaf613.jpg  \n",
            " extracting: train/A9_png_jpg.rf.7d9aeab4620eb2576b6bd72479a4a43b.jpg  \n",
            " extracting: train/AB1140W_jpg.rf.1af46ccf21368c2543f20ae32335fe0f.jpg  \n",
            " extracting: train/AB1291WY_jpg.rf.fa677265105c9e59042f362481e7e710.jpg  \n",
            " extracting: train/AB1359EV_jpg.rf.d374625f57b16bea176d770539a40f54.jpg  \n",
            " extracting: train/AB1801LY_jpg.rf.ba64a9c188c6795a926abaa9c08db3bc.jpg  \n",
            " extracting: train/AB5592EG_jpg.rf.5688a0767d09b17b7a078a2cd02b8376.jpg  \n",
            " extracting: train/AD1A_jpg.rf.8742e46f06a09d31dd8d6f1e0e5fd683.jpg  \n",
            " extracting: train/AD2914JG_jpg.rf.845fe6fa22be8384f7416fd8194ce59b.jpg  \n",
            " extracting: train/AD9501GA_jpg.rf.6c71f00b11ad510faecb1779516f91cc.jpg  \n",
            " extracting: train/B1015SEA_jpg.rf.0ba7436295658552f26e09d5e8afbbc6.jpg  \n",
            " extracting: train/B1040TYQ_jpg.rf.66b499f70a5ff1438a97b217c2a85dc6.jpg  \n",
            " extracting: train/B1044SAJ_jpg.rf.cf9e9a1919de69d7572c5e26078ec616.jpg  \n",
            " extracting: train/B1050BIZ_jpg.rf.97c687e25ef12d1f24ad712d3b8ffab9.jpg  \n",
            " extracting: train/B1063SJV_jpg.rf.a72aa6bb80acc224f8ddf7f7caedbbd6.jpg  \n",
            " extracting: train/B1080UYF_jpg.rf.0f12765e4dbfa59882626a50cc7b75e0.jpg  \n",
            " extracting: train/B1114TID_jpg.rf.dbcac12b97ece671bd5ad8bb9b86b53c.jpg  \n",
            " extracting: train/B1114TIZ_jpg.rf.84df4e56d407e1a8148002894c47cfae.jpg  \n",
            " extracting: train/B1125TZM_jpg.rf.d6fa412fed20a867573db59bd58e6ece.jpg  \n",
            " extracting: train/B1134UVL_jpg.rf.c9b196257142432ef3bced416e6b4877.jpg  \n",
            " extracting: train/B1145ERE-1-_jpg.rf.5aa8f20752d1f33a42970315df0aa0b5.jpg  \n",
            " extracting: train/B1145ERE_jpg.rf.220ff13b153b458acca3b2202a8ff9c2.jpg  \n",
            " extracting: train/B1163PU_jpg.rf.50ed950f4b283ad2f52fba47107b5952.jpg  \n",
            " extracting: train/B1192FJE_jpg.rf.02bf5ccd2fde4dcb65e81883ef09d256.jpg  \n",
            " extracting: train/B1204UIU_jpg.rf.56d16753c79d2122137becf501fa8040.jpg  \n",
            " extracting: train/B1215WZE_jpg.rf.779874a0068cd6bba2787418d9c80323.jpg  \n",
            " extracting: train/B1269VOE_jpg.rf.1596a64daf8f3e02b0ec93d73f4d67ad.jpg  \n",
            " extracting: train/B1302ZMC-1-_jpg.rf.29aaa0720b2bec525c4ce4f4014a277c.jpg  \n",
            " extracting: train/B1302ZMC_jpg.rf.caf12e7840d654be77ea163d8d6cdc38.jpg  \n",
            " extracting: train/B1335UZH_jpg.rf.4e3352812ea247cc44f90a8d2fdf29d1.jpg  \n",
            " extracting: train/B1342PIK_jpg.rf.d2b05587c3a6e379ab83001963eba630.jpg  \n",
            " extracting: train/B1400EYL_jpg.rf.c4b019c71d672d9eea314cd879939305.jpg  \n",
            " extracting: train/B1410BLQ_jpg.rf.307cc387e126787ba0219592d81a1984.jpg  \n",
            " extracting: train/B1422RK_jpg.rf.fe6351012b5a16555f54ed420ea4bd48.jpg  \n",
            " extracting: train/B1440BJS_jpg.rf.6625bd79f1fb94b8d8d9d90e61dbca9b.jpg  \n",
            " extracting: train/B1491BVB_jpg.rf.acf9a667532fb313e3c2b73eadd79ad9.jpg  \n",
            " extracting: train/B1512WFL_jpg.rf.6e756c4abe1bcdddf912d7696e454166.jpg  \n",
            " extracting: train/B1518GZ-1-_jpg.rf.8f65cebbfb93412fd92a5a65cd7e37a9.jpg  \n",
            " extracting: train/B1518GZ_jpg.rf.d621d0fdbc8239a8d7c42cf8787db345.jpg  \n",
            " extracting: train/B1523KBL-1-_jpg.rf.1d79aa8b9a4972803f29cab87b0d2143.jpg  \n",
            " extracting: train/B1523KBL-2-_jpg.rf.8900e0cc14d9827a8046b31eb928a4bf.jpg  \n",
            " extracting: train/B1528SZC_jpg.rf.11a7fdcc593346e49cc366ff2fe7a122.jpg  \n",
            " extracting: train/B1579KML_jpg.rf.b9c4a844e3f9d89478c12151517423db.jpg  \n",
            " extracting: train/B1595SGR-2-_jpg.rf.0f945274486fb37ce16324850e164c21.jpg  \n",
            " extracting: train/B1595SGR_jpg.rf.e8109f5f156fb839143218ef3aa602c2.jpg  \n",
            " extracting: train/B1635NOZ_jpg.rf.cd112a827f8ec59cc54afdd80aaae318.jpg  \n",
            " extracting: train/B1636BRW_jpg.rf.71b2dd8b39b7d5542f9d485a919aabee.jpg  \n",
            " extracting: train/B1665GKC_jpg.rf.bfc99a33a1a07420640620fc588a9bf2.jpg  \n",
            " extracting: train/B1669OG_jpg.rf.ca2508cc24f742fd613daeba2f9b6c59.jpg  \n",
            " extracting: train/B1700TYZ_jpg.rf.15324ca514ae371273cdba437298a967.jpg  \n",
            " extracting: train/B1767NJ_jpg.rf.bf01c822dff6f46a85b53e8142d4f903.jpg  \n",
            " extracting: train/B1864PYH_jpg.rf.5939f6e304a4358178e9e1093d2ea0ab.jpg  \n",
            " extracting: train/B1864PYH_jpg.rf.d86cf786cd5f161ca9c78f119bb74b36.jpg  \n",
            " extracting: train/B1869ERN_jpg.rf.3602cd831c051184a3185a55a273969b.jpg  \n",
            " extracting: train/B1870WZP_jpg.rf.c637d2b1c9e3647225c14ef1757315b3.jpg  \n",
            " extracting: train/B1879CMA_jpg.rf.15c5e7bec8de4f0ad617be432db7cf0b.jpg  \n",
            " extracting: train/B1879CMA_jpg.rf.9feb7f8eafbde5a337cc3079b2de1395.jpg  \n",
            " extracting: train/B1896WOP_jpg.rf.67ff64b35717efa61810b668eca32bd2.jpg  \n",
            " extracting: train/B1925BOF-1-_jpg.rf.bb922a87b49b8e75b913587fcc236c96.jpg  \n",
            " extracting: train/B1925BOF_jpg.rf.1a86bda07c8dbf806cbc627185f520c9.jpg  \n",
            " extracting: train/B1973CFZ_jpg.rf.0418c03997f30721c3a9b080c3847316.jpg  \n",
            " extracting: train/B1989KIB_jpg.rf.1e7cd6a6569f8d2d2a0a5f61230f1857.jpg  \n",
            " extracting: train/B2113SOY_jpg.rf.48bbd6a58d213fd23009de4a44bd36d0.jpg  \n",
            " extracting: train/B2127BKW-1-_jpg.rf.ebed18caa498c2ec2b4ffa46b9ef665a.jpg  \n",
            " extracting: train/B2130BOH_jpg.rf.462aeb4ec8b4497adc8e766c2f1b17a2.jpg  \n",
            " extracting: train/B2130BOH_jpg.rf.cd61e788f67561d578f7976855421502.jpg  \n",
            " extracting: train/B234LOG_jpg.rf.6b2a14dcf10946632becd5579bdbfc3f.jpg  \n",
            " extracting: train/B2573SOG_jpg.rf.4ec91990b9f49af7f68f7d2b7631dad6.jpg  \n",
            " extracting: train/B2594TYM_jpg.rf.8cf505d7251e84766bc1c4b91ad319f6.jpg  \n",
            " extracting: train/B2652SRY_jpg.rf.2ec314a5b3eb8eadf69ae3563260379d.jpg  \n",
            " extracting: train/B3023KEZ_jpg.rf.544996420fb0084ea3687e2ee5590916.jpg  \n",
            " extracting: train/B7124HG-1-_jpg.rf.ed4a71141aa2e302db4f8f99245a568b.jpg  \n",
            " extracting: train/B777DEF_jpg.rf.be8e67b6f77ffe012de463a7aaccfb53.jpg  \n",
            " extracting: train/B868DSY_jpg.rf.e518ee836c49fef1d88193c56f43ee3e.jpg  \n",
            " extracting: train/B9080SRO_jpg.rf.8de910fb71a3bdecca1f3ad4a417750f.jpg  \n",
            " extracting: train/B9507NCG_jpg.rf.4340b942c2c7bef811493469bdab269f.jpg  \n",
            " extracting: train/BG1733RP_jpg.rf.0eb01a0a2a19044609d1af6651a42142.jpg  \n",
            " extracting: train/BL1439JD-1-_jpg.rf.5cea1d12a4e10d182a514d8f4564bc6e.jpg  \n",
            " extracting: train/BM1762VP_jpg.rf.e8270d30ee0e4df307042417980d17c4.jpg  \n",
            " extracting: train/Bc9FWNbIQAAldsS_jpg.rf.e4791382f0478536e7cb7b1d212e7ea9.jpg  \n",
            " extracting: train/Bus-10-_jpg.rf.78edce04b324ed765b7805c4d1c4fe50.jpg  \n",
            " extracting: train/Bus-100-_jpg.rf.730fa8f1061e41e7ef68c6a6151ec242.jpg  \n",
            " extracting: train/Bus-101-_jpg.rf.8e6434afa146c35b8da35882b20b3b68.jpg  \n",
            " extracting: train/Bus-102-_jpg.rf.6e6ccc9dd02fa3a2854fb6ba45ea1553.jpg  \n",
            " extracting: train/Bus-103-_jpg.rf.a383f008b3cfa21ec67081c6fcb05860.jpg  \n",
            " extracting: train/Bus-104-_jpg.rf.548b966a0999fc83445a90ea34b439ca.jpg  \n",
            " extracting: train/Bus-105-_jpg.rf.2d0d755d2522992f872e013dc4ee2d70.jpg  \n",
            " extracting: train/Bus-106-_jpg.rf.9b738de34b5f5d44f16db041d5f62535.jpg  \n",
            " extracting: train/Bus-109-_jpg.rf.df2c38fc35e6b644b805cb1add951454.jpg  \n",
            " extracting: train/Bus-11-_jpg.rf.d24b244d540a779997e1cc01b3494bbe.jpg  \n",
            " extracting: train/Bus-110-_jpg.rf.bff0b0531978c1ebbbaa2c6d598b6fec.jpg  \n",
            " extracting: train/Bus-111-_jpg.rf.a73141964b673c9300a11212aa9680b8.jpg  \n",
            " extracting: train/Bus-113-_jpg.rf.657962c3ba08a722df33e7b52b63700f.jpg  \n",
            " extracting: train/Bus-115-_jpg.rf.189e92bda09ed458b05f5b9e769f60bb.jpg  \n",
            " extracting: train/Bus-116-_jpg.rf.d2be0dd7a79d5e66e94f39674122d973.jpg  \n",
            " extracting: train/Bus-117-_jpg.rf.f3ba8676716161984ea0061b86ab5bf4.jpg  \n",
            " extracting: train/Bus-12-_jpg.rf.0e46f1dcd31d17eb18a484a446f2b58e.jpg  \n",
            " extracting: train/Bus-121-_jpg.rf.36c2c02af30f5504caddb179d03c889a.jpg  \n",
            " extracting: train/Bus-122-_jpg.rf.0605ca93f14fd56a80806a7c0e4cc43c.jpg  \n",
            " extracting: train/Bus-124-_jpg.rf.473c87af003cead6e79e54b1a06aa9e5.jpg  \n",
            " extracting: train/Bus-126-_jpg.rf.9064ccc8e8ef1b8fd02f56df61ba0a77.jpg  \n",
            " extracting: train/Bus-127-_jpg.rf.50e300fa9d5d38c19fb0e4fc0c30686f.jpg  \n",
            " extracting: train/Bus-128-_jpg.rf.9573ee35c777fdf0e32dbf051b85561f.jpg  \n",
            " extracting: train/Bus-131-_jpg.rf.c59247f179b363568436dee93bf62152.jpg  \n",
            " extracting: train/Bus-133-_jpg.rf.b7b76cc445d6bfaabc81a08e7130d915.jpg  \n",
            " extracting: train/Bus-134-_jpg.rf.7e744204886032091b24f004accf8257.jpg  \n",
            " extracting: train/Bus-135-_jpg.rf.111bb5ca3694cbc148813cb20f7b54e3.jpg  \n",
            " extracting: train/Bus-136-_jpg.rf.42b945dd62dad0fc09cdda56e29471c2.jpg  \n",
            " extracting: train/Bus-138-_jpg.rf.fd3a79f48868fbbe0078b75fd6bc5cf1.jpg  \n",
            " extracting: train/Bus-139-_jpg.rf.51797607e069622f3d6398eac1dba8e7.jpg  \n",
            " extracting: train/Bus-14-_jpg.rf.a63f8f88113858964c4d86cd9ff88e60.jpg  \n",
            " extracting: train/Bus-141-_jpg.rf.850e87fd8e7b985871c7862329fe761f.jpg  \n",
            " extracting: train/Bus-142-_jpg.rf.a4e466713be0c48d8a40dbaeb9433be5.jpg  \n",
            " extracting: train/Bus-143-_jpg.rf.27e75b46c5f9f3225acdd7e49e2fe6ad.jpg  \n",
            " extracting: train/Bus-145-_jpg.rf.a2d8c7aeee9e5f58c0cc4ffec0345dba.jpg  \n",
            " extracting: train/Bus-146-_jpg.rf.fdbdb4d40040343e8bc53efd636cb4b3.jpg  \n",
            " extracting: train/Bus-148-_jpg.rf.d77d3fa5e6d93fede5cea9d54c718ad0.jpg  \n",
            " extracting: train/Bus-149-_jpg.rf.c9812aacf398480eed72e64b7fc7c944.jpg  \n",
            " extracting: train/Bus-15-_jpg.rf.a1ce513998929e33e711dfa3f80e4e42.jpg  \n",
            " extracting: train/Bus-150-_jpg.rf.547f24675f7655b1a30067e7a5550f75.jpg  \n",
            " extracting: train/Bus-151-_jpg.rf.10bd63fd2c7627bfe1d570b29d544a83.jpg  \n",
            " extracting: train/Bus-155-_jpg.rf.4bebfa4e3bfa3d4fb2d7f590d499193e.jpg  \n",
            " extracting: train/Bus-156-_jpg.rf.e405312c1bd595963c342660e2941423.jpg  \n",
            " extracting: train/Bus-159-_jpg.rf.90509a688455d7bad42cc975250f261d.jpg  \n",
            " extracting: train/Bus-16-_jpg.rf.96432c1f2c01c23ee324e492c0f275ab.jpg  \n",
            " extracting: train/Bus-160-_jpg.rf.6ae8d53c468a3d58eee000f9436582f1.jpg  \n",
            " extracting: train/Bus-161-_jpg.rf.f8eee131b868be3432cc5963a68b4a83.jpg  \n",
            " extracting: train/Bus-163-_jpg.rf.444212f11f0f7318d3e4295afbb3921d.jpg  \n",
            " extracting: train/Bus-165-_jpg.rf.b045b73184232822863b332baebdea54.jpg  \n",
            " extracting: train/Bus-166-_jpg.rf.725337cc1137c448a698510207be2c40.jpg  \n",
            " extracting: train/Bus-168-_jpg.rf.e19efe99f2195e8cf8f655ea237d2a21.jpg  \n",
            " extracting: train/Bus-169-_jpg.rf.3e8af120008a855e71ec0d0d76e80f56.jpg  \n",
            " extracting: train/Bus-170-_jpg.rf.5d4d3b31729eaaab44d11475994cf918.jpg  \n",
            " extracting: train/Bus-171-_jpg.rf.ada0fe54e3abda70f40bce8ad2dcb7ea.jpg  \n",
            " extracting: train/Bus-172-_jpg.rf.04e247cf0e30a35ecf6776ee08896e22.jpg  \n",
            " extracting: train/Bus-173-_jpg.rf.b56d9f3994ee7f7daa40937b596f9e02.jpg  \n",
            " extracting: train/Bus-174-_jpg.rf.5f314717f453bfae7c8d9befe335572c.jpg  \n",
            " extracting: train/Bus-176-_jpg.rf.e4051097b3151841103727883ff9e5fa.jpg  \n",
            " extracting: train/Bus-177-_jpg.rf.77dc429a88c9baf41b351c03932094cf.jpg  \n",
            " extracting: train/Bus-178-_jpg.rf.1d608b59dc190d4ce7fd246d76d4bf31.jpg  \n",
            " extracting: train/Bus-179-_jpg.rf.0da59790a70c132b1facee48ccfc0e1b.jpg  \n",
            " extracting: train/Bus-18-_jpg.rf.69920a8a81423be9366c6a6090a1c65d.jpg  \n",
            " extracting: train/Bus-180-_jpg.rf.347baef9770776e7fd26b8cfa064cf7a.jpg  \n",
            " extracting: train/Bus-181-_jpg.rf.3987c63a10f473e45383cf3d70a30a46.jpg  \n",
            " extracting: train/Bus-182-_jpg.rf.7578ea8c9281abee646df2353eb412f4.jpg  \n",
            " extracting: train/Bus-184-_jpg.rf.ad12a64f70fa5a48fa5af3bde7077236.jpg  \n",
            " extracting: train/Bus-185-_jpg.rf.5336f8d8aee76ee00df304eda0b6fde8.jpg  \n",
            " extracting: train/Bus-187-_jpg.rf.9a96f30247aec8d921e71e08c6ac4716.jpg  \n",
            " extracting: train/Bus-188-_jpg.rf.26777ba096b09316334ce9aa4334663f.jpg  \n",
            " extracting: train/Bus-189-_jpg.rf.08b6582d7bf645dc3da958e544767bb8.jpg  \n",
            " extracting: train/Bus-19-_jpg.rf.300fa23d110a89ffe55f3b50fdfd6ce8.jpg  \n",
            " extracting: train/Bus-190-_jpg.rf.bdf3df1f068a3e622b89c34a8dde7c39.jpg  \n",
            " extracting: train/Bus-194-_jpg.rf.6d9a8a44670cef693f002ba25a1da431.jpg  \n",
            " extracting: train/Bus-195-_jpg.rf.881cbf5cac5eb46e8e9f3eb57a67eac6.jpg  \n",
            " extracting: train/Bus-197-_jpg.rf.c2afbc54412941cb58d22185e5626bba.jpg  \n",
            " extracting: train/Bus-198-_jpg.rf.7a6f5909a539d784c92f23ce0f531ee3.jpg  \n",
            " extracting: train/Bus-20-_jpg.rf.e241399b14ed9791b8b1adf051e6daa9.jpg  \n",
            " extracting: train/Bus-200-_jpg.rf.d1920ea28a557a7425b2bb225315df20.jpg  \n",
            " extracting: train/Bus-201-_jpg.rf.534d1b76bf58cb4edb30bd98a3357143.jpg  \n",
            " extracting: train/Bus-202-_jpg.rf.5cd788ace26dfd824b44de787b0b7433.jpg  \n",
            " extracting: train/Bus-203-_jpg.rf.80987226f4d55eb111caec6838c39095.jpg  \n",
            " extracting: train/Bus-204-_jpg.rf.29912c5c43c2a4b992de12fe12212c6a.jpg  \n",
            " extracting: train/Bus-205-_jpg.rf.91b289a33ac697442240d210600b2425.jpg  \n",
            " extracting: train/Bus-206-_jpg.rf.59c575a0aceccd89280b8d44c50b65dd.jpg  \n",
            " extracting: train/Bus-208-_jpg.rf.e2be7fe7086f5856f43a2ae65ede4317.jpg  \n",
            " extracting: train/Bus-209-_jpg.rf.45bcf0709de7043b92dd56b32b3dfe92.jpg  \n",
            " extracting: train/Bus-210-_jpg.rf.f61f21c357f4a962611fa7d611ca4960.jpg  \n",
            " extracting: train/Bus-211-_jpg.rf.96f9f6a262b48fd85dfd89f931c19c50.jpg  \n",
            " extracting: train/Bus-212-_jpg.rf.5b1a27e12fd28ec2f325b99eac649b3c.jpg  \n",
            " extracting: train/Bus-213-_jpg.rf.4a7b8cbf2edc9a5fc6cdad2509bdd3b5.jpg  \n",
            " extracting: train/Bus-214-_jpg.rf.9fe081d68d94d0269a2b3ce167571e41.jpg  \n",
            " extracting: train/Bus-215-_jpg.rf.26df08941eceff90753713389f4dba3b.jpg  \n",
            " extracting: train/Bus-218-_jpg.rf.3a43baac6815d5a965ed0c63cd848a43.jpg  \n",
            " extracting: train/Bus-219-_jpg.rf.badf36f730895e6da4f7bf5a150d8001.jpg  \n",
            " extracting: train/Bus-22-_jpg.rf.d045223a60720dd17c1938b9b3e00cb7.jpg  \n",
            " extracting: train/Bus-220-_jpg.rf.10bd67497c288921369c4683b6417226.jpg  \n",
            " extracting: train/Bus-221-_jpg.rf.4e4420a149ef7e3c22fbf9da990cbf5a.jpg  \n",
            " extracting: train/Bus-222-_jpg.rf.60c0fc289a816fbd66b070bf07b21576.jpg  \n",
            " extracting: train/Bus-223-_jpg.rf.1a73aac2b1c9fce538a23879b909a61d.jpg  \n",
            " extracting: train/Bus-224-_jpg.rf.230dd1a4c21c9dc1ddbba1ab14d68a9b.jpg  \n",
            " extracting: train/Bus-226-_jpg.rf.91e919794810185e7c982989d36baa73.jpg  \n",
            " extracting: train/Bus-227-_jpg.rf.db2fcae2ff1799d78ec79af85fce667e.jpg  \n",
            " extracting: train/Bus-228-_jpg.rf.f548ef84a2645c99da021d963564562d.jpg  \n",
            " extracting: train/Bus-229-_jpg.rf.8dc58f84019a54fc5fec4768b610d7ea.jpg  \n",
            " extracting: train/Bus-23-_jpg.rf.7634ce5e52d333cb8a463f4761619ab4.jpg  \n",
            " extracting: train/Bus-230-_jpg.rf.3768ea5d1693a698085082f5056cc42b.jpg  \n",
            " extracting: train/Bus-232-_jpg.rf.909d30d999bb0e6064e80c8724f02fe7.jpg  \n",
            " extracting: train/Bus-233-_jpg.rf.0b6a656304b9a61b8e267d126713d3ed.jpg  \n",
            " extracting: train/Bus-234-_jpg.rf.60f11c53dcb8044df718b01cfc36625d.jpg  \n",
            " extracting: train/Bus-236-_jpg.rf.535db95b553a3a94d414c69969980486.jpg  \n",
            " extracting: train/Bus-237-_jpg.rf.f6f392e523104ff08d24e7e87ab18b0c.jpg  \n",
            " extracting: train/Bus-238-_jpg.rf.c19dd7d31467e00577971f6648876d9a.jpg  \n",
            " extracting: train/Bus-24-_jpg.rf.1c7599068574fe592a62be4ffabda25d.jpg  \n",
            " extracting: train/Bus-240-_jpg.rf.5f576d0be0e591ee25cdfc51e425499a.jpg  \n",
            " extracting: train/Bus-241-_jpg.rf.0468687b879fd4d41688cec5c3efcbd9.jpg  \n",
            " extracting: train/Bus-242-_jpg.rf.cb5ea2708deb6768f18aa336d53eb9fd.jpg  \n",
            " extracting: train/Bus-243-_jpg.rf.f35586fa5f2f68d8b0dae9eadd3ff5eb.jpg  \n",
            " extracting: train/Bus-25-_jpg.rf.07747a5f262133270afb2fba36c7b33a.jpg  \n",
            " extracting: train/Bus-250-_jpg.rf.92ebaf47f0a48697cb43a69b9d625f8e.jpg  \n",
            " extracting: train/Bus-252-_jpg.rf.f30e9b6ecf5db78ed642af4df8a5cbdf.jpg  \n",
            " extracting: train/Bus-258-_jpg.rf.7d25d0ce9fe35dc6f8523f6793e8f341.jpg  \n",
            " extracting: train/Bus-26-_jpg.rf.f80673a30d64a82bdee86343a91dc9c1.jpg  \n",
            " extracting: train/Bus-260-_jpg.rf.ef2d294af6a1f074d9dbe44426406c94.jpg  \n",
            " extracting: train/Bus-261-_jpg.rf.c237522080b699d75bbf92f18f068fcb.jpg  \n",
            " extracting: train/Bus-262-_jpg.rf.e48a5bc08108b81630003cccb3731357.jpg  \n",
            " extracting: train/Bus-263-_jpg.rf.89cb218139ba5bc176135e98ed8ea8e9.jpg  \n",
            " extracting: train/Bus-264-_jpg.rf.d489fd4970a8ef645021801462086a93.jpg  \n",
            " extracting: train/Bus-265-_jpg.rf.87147d14894cfd0d1d9e5f1c7e644115.jpg  \n",
            " extracting: train/Bus-266-_jpg.rf.20d433542c1c29021320aed6174a9945.jpg  \n",
            " extracting: train/Bus-267-_jpg.rf.59c9481cd9e4c6c58f8a178a227499f3.jpg  \n",
            " extracting: train/Bus-268-_jpg.rf.a6857f99e47af07f09897db8caf825d7.jpg  \n",
            " extracting: train/Bus-270-_jpg.rf.55d086f81e00028c21a4e4f4ebd9e8a8.jpg  \n",
            " extracting: train/Bus-271-_jpg.rf.b27b8cb6a9f3d82828c3da025fd86797.jpg  \n",
            " extracting: train/Bus-272-_jpg.rf.9b019f80c96f8237c95263a1f075bd15.jpg  \n",
            " extracting: train/Bus-273-_jpg.rf.e33d26facda919824582fa7419bbb47b.jpg  \n",
            " extracting: train/Bus-274-_jpg.rf.8c781e517481ab41698d1614fada8e1b.jpg  \n",
            " extracting: train/Bus-275-_jpg.rf.036b2302cb0a33cec5314bddcfa5873e.jpg  \n",
            " extracting: train/Bus-277-_jpg.rf.aed770e946e1c40e16a2039773c7f575.jpg  \n",
            " extracting: train/Bus-278-_jpg.rf.5748eb9fff6d8ae1d7995b7bae3a5670.jpg  \n",
            " extracting: train/Bus-279-_jpg.rf.1ac726f17c427c8ee2921025d5e28099.jpg  \n",
            " extracting: train/Bus-28-_jpg.rf.2a88d29cbd1fef81f6502260c41add31.jpg  \n",
            " extracting: train/Bus-280-_jpg.rf.f1b558aa9c22ee20b5579a22eadaa3df.jpg  \n",
            " extracting: train/Bus-281-_jpg.rf.f45826b83defde3d9a59af538f01d9ac.jpg  \n",
            " extracting: train/Bus-283-_jpg.rf.ce85df07dec80fb2a1ffbf5a38917796.jpg  \n",
            " extracting: train/Bus-284-_jpg.rf.06786f1b8317d849d166671e414c9c71.jpg  \n",
            " extracting: train/Bus-286-_jpg.rf.d95691d641009b3e96432d33c3d76518.jpg  \n",
            " extracting: train/Bus-287-_jpg.rf.83853dddd9fdf3ca0cd84a55300b1b40.jpg  \n",
            " extracting: train/Bus-288-_jpg.rf.34db7f16b47c3b0666eab352f9f206a1.jpg  \n",
            " extracting: train/Bus-29-_jpg.rf.15307ae8cb27314cfb9d183382004d41.jpg  \n",
            " extracting: train/Bus-290-_jpg.rf.c3bc82f398b51d52109ae0018b8ff6db.jpg  \n",
            " extracting: train/Bus-291-_jpg.rf.9ca350a192494884f61bf9befee7aebe.jpg  \n",
            " extracting: train/Bus-292-_jpg.rf.c849b915ee4aca6ac56c59002c5ce7c0.jpg  \n",
            " extracting: train/Bus-293-_jpg.rf.890b2353259d64cb89cabdd2841abe2c.jpg  \n",
            " extracting: train/Bus-294-_jpg.rf.f5a6976f9b367c8ea2262c2f71b9bb47.jpg  \n",
            " extracting: train/Bus-295-_jpg.rf.9b094d5c7287861322bb80319877607b.jpg  \n",
            " extracting: train/Bus-298-_jpg.rf.31d1cc3b55b879c2bc8d320c2e8b3613.jpg  \n",
            " extracting: train/Bus-299-_jpg.rf.a18551210f7de5aeacebd2d0aa4d493c.jpg  \n",
            " extracting: train/Bus-3-_jpg.rf.a33671886a55e830f38606cfc043134f.jpg  \n",
            " extracting: train/Bus-30-_jpg.rf.1103fc2fb717e2934e4f8c6b6f4904b4.jpg  \n",
            " extracting: train/Bus-301-_jpg.rf.e00c6eef0c4cebba98b61c19c5a29701.jpg  \n",
            " extracting: train/Bus-302-_jpg.rf.ae7237739d53f199e7fc05b6fb49f2bd.jpg  \n",
            " extracting: train/Bus-303-_jpg.rf.c642f286e66e4b67e86197beb90d3a12.jpg  \n",
            " extracting: train/Bus-306-_jpg.rf.070273085e767dce6dd50cae1a8cc42b.jpg  \n",
            " extracting: train/Bus-307-_jpg.rf.86491c4cb55ffb211a3fca55fb3ef1e2.jpg  \n",
            " extracting: train/Bus-31-_jpg.rf.efc1679d47ae97d839ef89b28c029f8d.jpg  \n",
            " extracting: train/Bus-317-_jpg.rf.a7452249702772e5d78f827e17634953.jpg  \n",
            " extracting: train/Bus-318-_jpg.rf.57f83d6a01b8776cd9a653cf22e7c068.jpg  \n",
            " extracting: train/Bus-319-_jpg.rf.b3c7eb21863f5e4437aeaf6478c03d4c.jpg  \n",
            " extracting: train/Bus-321-_jpg.rf.27d6c6d19916f92ef1605f1cf3b0dcc9.jpg  \n",
            " extracting: train/Bus-322-_jpg.rf.af7e3cdbcbd6543e6dd128dc6bfffde2.jpg  \n",
            " extracting: train/Bus-324-_jpg.rf.3d80fe4e13cbec5bcc85013e48e84b6c.jpg  \n",
            " extracting: train/Bus-325-_jpg.rf.be46e16fbf0b3bb9aa55f08d1c61cc22.jpg  \n",
            " extracting: train/Bus-326-_jpg.rf.2ec91b597ae7716fcba5b0a3a15ae81c.jpg  \n",
            " extracting: train/Bus-331-_jpg.rf.1127cfa8710b6925affd72d16cbaa9eb.jpg  \n",
            " extracting: train/Bus-337-_jpg.rf.17db8c738d7b4385eac613407f3abdf7.jpg  \n",
            " extracting: train/Bus-338-_jpg.rf.c5fe842d692b5309882cfba649715f06.jpg  \n",
            " extracting: train/Bus-339-_jpg.rf.5f875a6edb4aebdc0b9439542145678a.jpg  \n",
            " extracting: train/Bus-343-_jpg.rf.b8953db667ce808851df3a35ea87ebee.jpg  \n",
            " extracting: train/Bus-344-_jpg.rf.1d8b78b902218bd825aa7d4d3f3dd67d.jpg  \n",
            " extracting: train/Bus-346-_jpg.rf.bc6a9ab112169ec1483e36e28d63b653.jpg  \n",
            " extracting: train/Bus-348-_jpg.rf.284931fae38b1903b6ddd65379d46cab.jpg  \n",
            " extracting: train/Bus-35-_jpg.rf.19224f764450e735bacaed0416cc3346.jpg  \n",
            " extracting: train/Bus-350-_jpg.rf.6601ffe38f18e9222cb3370b8eb51aab.jpg  \n",
            " extracting: train/Bus-351-_jpg.rf.9a751f975772f809346074738c6431c9.jpg  \n",
            " extracting: train/Bus-352-_jpg.rf.b3a8a06fa09eb6b663a155a56e131edd.jpg  \n",
            " extracting: train/Bus-353-_jpg.rf.1f9aeb769dbab71f3a5b5868b27723eb.jpg  \n",
            " extracting: train/Bus-355-_jpg.rf.8e3330a3a0c4aeda5851dfd3946e3678.jpg  \n",
            " extracting: train/Bus-356-_jpg.rf.92138af221760fe34c5c3cb4a325fdec.jpg  \n",
            " extracting: train/Bus-357-_jpg.rf.d5430c7052a8939b87a0b9d94843d8d8.jpg  \n",
            " extracting: train/Bus-358-_jpg.rf.55eb8d6c4df4bd39255994949cf79ad0.jpg  \n",
            " extracting: train/Bus-359-_jpg.rf.6f2624c0190e21476006f7c1a6d35fac.jpg  \n",
            " extracting: train/Bus-36-_jpg.rf.43ac3230a43f308c0496f8f4391192a9.jpg  \n",
            " extracting: train/Bus-360-_jpg.rf.7f164be67200eb08aaa698ed07c2b103.jpg  \n",
            " extracting: train/Bus-361-_jpg.rf.117dc14a242cc0dcd1734e6f2f62ffe4.jpg  \n",
            " extracting: train/Bus-363-_jpg.rf.2a3709560a0a02e8ec46c4a062384349.jpg  \n",
            " extracting: train/Bus-367-_jpg.rf.d8fea7a3642685effa4f7250f1848e42.jpg  \n",
            " extracting: train/Bus-368-_jpg.rf.37286c5dfcb8df013b54bf34cef54223.jpg  \n",
            " extracting: train/Bus-37-_jpg.rf.f15453a050e1a4d93128e29e47ff79d4.jpg  \n",
            " extracting: train/Bus-371-_jpg.rf.289c2e070a09b785e2afdf0b6ca00133.jpg  \n",
            " extracting: train/Bus-373-_jpg.rf.3a04fc350d91e8ecfae5974d78aef476.jpg  \n",
            " extracting: train/Bus-374-_jpg.rf.f8600de6e51b14de970519762f51afae.jpg  \n",
            " extracting: train/Bus-376-_jpg.rf.df04db6ebea152e59e38da524a570cf7.jpg  \n",
            " extracting: train/Bus-378-_jpg.rf.3d42a27045cbd6d7a9e6a906f0cfd64e.jpg  \n",
            " extracting: train/Bus-38-_jpg.rf.3f4cedf3ec96e20795573261bbb98115.jpg  \n",
            " extracting: train/Bus-380-_jpg.rf.d80883810a094a3303978beede7ebb25.jpg  \n",
            " extracting: train/Bus-382-_jpg.rf.90242bf659fbd89c55b95d5c5011e825.jpg  \n",
            " extracting: train/Bus-383-_jpg.rf.16fcfbd71ae8a72b53e58ada1ad5b167.jpg  \n",
            " extracting: train/Bus-385-_jpg.rf.0b595494a5ea76c9164e1dd87f88ea2e.jpg  \n",
            " extracting: train/Bus-387-_jpg.rf.18bfc566f5677f2ddf78b3a9f5687092.jpg  \n",
            " extracting: train/Bus-388-_jpg.rf.39fbfe225237eef6de4402f056ce79a3.jpg  \n",
            " extracting: train/Bus-389-_jpg.rf.0cf55244362c560726182ae408a18632.jpg  \n",
            " extracting: train/Bus-390-_jpg.rf.62408e08214b557c2eea91bf6b2c3a06.jpg  \n",
            " extracting: train/Bus-393-_jpg.rf.bf5c2c1fd08562025e06888bbba077c6.jpg  \n",
            " extracting: train/Bus-395-_jpg.rf.18cf9ae2190fe09804937c56883338a4.jpg  \n",
            " extracting: train/Bus-4-_jpg.rf.d8c730c87e84be4a93c6e6d0030cda23.jpg  \n",
            " extracting: train/Bus-40-_jpg.rf.48616d0b69dfc48117ac9c153c1a6fb4.jpg  \n",
            " extracting: train/Bus-42-_jpg.rf.664b72ec17c4ebe14b624c439ff3fe53.jpg  \n",
            " extracting: train/Bus-43-_jpg.rf.1f36657e9f672888c3fd7243be594434.jpg  \n",
            " extracting: train/Bus-44-_jpg.rf.eae11bcf92a7f980587243087ed9cf5c.jpg  \n",
            " extracting: train/Bus-45-_jpg.rf.b3b6c5d094a34a06110d85e9a01ac335.jpg  \n",
            " extracting: train/Bus-47-_jpg.rf.e4cbbb6a78b3098474e454f31da6d06e.jpg  \n",
            " extracting: train/Bus-5-_jpg.rf.5c76ffdb7483c56596d3653324cf6040.jpg  \n",
            " extracting: train/Bus-50-_jpg.rf.9545e1b387066e7113a258a825f33e2d.jpg  \n",
            " extracting: train/Bus-52-_jpg.rf.4a6f8c205af0bca59932a634a2f3dea5.jpg  \n",
            " extracting: train/Bus-53-_jpg.rf.993bb0188d76c369efe5256d6a1ae309.jpg  \n",
            " extracting: train/Bus-54-_jpg.rf.e2c6671adee99ee56839ce3920f27f39.jpg  \n",
            " extracting: train/Bus-55-_jpg.rf.9f4e85c43aac3dba355d99d4a7452a83.jpg  \n",
            " extracting: train/Bus-56-_jpg.rf.68ce6a1968f0404fdb690ac552ba2d81.jpg  \n",
            " extracting: train/Bus-57-_jpg.rf.48031d14d3f2abb5fc60cdad855a3b88.jpg  \n",
            " extracting: train/Bus-58-_jpg.rf.be7347c41d1114ac1deb7f1c91e81597.jpg  \n",
            " extracting: train/Bus-59-_jpg.rf.661fd2a985d0720463d387fc297712a3.jpg  \n",
            " extracting: train/Bus-6-_jpg.rf.3701b19d7bc8a8a4b5bb161259eda70c.jpg  \n",
            " extracting: train/Bus-62-_jpg.rf.67776d8d44205b31eca0cd075608dd2e.jpg  \n",
            " extracting: train/Bus-64-_jpg.rf.09fde61a0a46f2a68d967bab03773a34.jpg  \n",
            " extracting: train/Bus-67-_jpg.rf.dcfce2ad3d6c3e332c0177135bc4ae0a.jpg  \n",
            " extracting: train/Bus-68-_jpg.rf.75abe48ecbb8e30dc07558c21c30c4b7.jpg  \n",
            " extracting: train/Bus-69-_jpg.rf.2ae27f4906e30a40c055cbf33175457b.jpg  \n",
            " extracting: train/Bus-7-_jpg.rf.7f094b25167cff020cd916716615fa3a.jpg  \n",
            " extracting: train/Bus-70-_jpg.rf.4d0ecf52e5837b7f736f883d61f1c589.jpg  \n",
            " extracting: train/Bus-71-_jpg.rf.2172a4d976bca9bb9f84d44cdca17564.jpg  \n",
            " extracting: train/Bus-73-_jpg.rf.066296fbd30c2a9a0900af1098d7dd41.jpg  \n",
            " extracting: train/Bus-74-_jpg.rf.ce1bf7588289785bcaccf6c31fd16db6.jpg  \n",
            " extracting: train/Bus-76-_jpg.rf.d1fc9cba6031aec3161eada37a8e9c6c.jpg  \n",
            " extracting: train/Bus-77-_jpg.rf.cc2cd39555819ab48a41450a118d50b5.jpg  \n",
            " extracting: train/Bus-78-_jpg.rf.e78728725a9c5507c76cd2acfa078126.jpg  \n",
            " extracting: train/Bus-79-_jpg.rf.6fadb0f92ac25a4957bbf81a2d661f3d.jpg  \n",
            " extracting: train/Bus-80-_jpg.rf.3ed843b8c73625a7cd78667be881efd4.jpg  \n",
            " extracting: train/Bus-81-_jpg.rf.d1bb22bf6105a2a202c9a7e8d425df70.jpg  \n",
            " extracting: train/Bus-83-_jpg.rf.68e901fcc5483b3c0254e5323b3c87b4.jpg  \n",
            " extracting: train/Bus-85-_jpg.rf.dcaa5fa7f9c54c31ad28633fa4a85bc6.jpg  \n",
            " extracting: train/Bus-86-_jpg.rf.85185571cfaae43860667672437796d4.jpg  \n",
            " extracting: train/Bus-88-_jpg.rf.8da141051548f583a8f07208c6b337a0.jpg  \n",
            " extracting: train/Bus-89-_jpg.rf.9ef54f097889b84a286c4c188b5b4f5b.jpg  \n",
            " extracting: train/Bus-9-_jpg.rf.e0d427a3820ef950f7f788cbe02266d9.jpg  \n",
            " extracting: train/Bus-90-_jpg.rf.951540af2ad6f1ae7a546afafa915e4c.jpg  \n",
            " extracting: train/Bus-91-_jpg.rf.b734448da9deac94029de1986a216049.jpg  \n",
            " extracting: train/Bus-92-_jpg.rf.b6060202600363f453152dbf4f234703.jpg  \n",
            " extracting: train/Bus-93-_jpg.rf.348c2fab5f50412f4103282472b68c3a.jpg  \n",
            " extracting: train/Bus-95-_jpg.rf.7df84b3f51bd690b9c1e9cb802cf9528.jpg  \n",
            " extracting: train/Bus-97-_jpg.rf.a18763f06b037d3e096ff931a9c7321c.jpg  \n",
            " extracting: train/Bus-98-_jpg.rf.6b7a09eb8cce8e259e107eb8d000fe19.jpg  \n",
            " extracting: train/Bus-99-_jpg.rf.8854c8aeef380ef394e27f6e0e38db6d.jpg  \n",
            " extracting: train/Cars414_png_jpg.rf.0cc1a8004c82a6aa5a71e44ed1a456c3.jpg  \n",
            " extracting: train/Cars417_png_jpg.rf.ea394f282a8807a9ca8f7f6717108c20.jpg  \n",
            " extracting: train/Cars420_png_jpg.rf.bd275eb4f413c890409b2f0dbf7d448a.jpg  \n",
            " extracting: train/Cars423_png_jpg.rf.9d79417bf563e38e5f0d427be07c6544.jpg  \n",
            " extracting: train/Cars425_png_jpg.rf.ebd697e0f12d74cc0e7b962a9d7d007e.jpg  \n",
            " extracting: train/Chris-20Truck-20_jpg.rf.2f092fc7fcc60e1ec1ca778b099ac61f.jpg  \n",
            " extracting: train/Cutting-Sticker-Truck-Canter-Kuning-1_jpg.rf.4ed3f77e4769866a71febf6ba7aa22d9.jpg  \n",
            " extracting: train/D1129_17_316_1200__flip_jpg.rf.97118bd12a461bd817c1f980227bba59.jpg  \n",
            " extracting: train/D1129_17_316_1200_jpg.rf.165df740f22f5cd42eb296b487a8c59d.jpg  \n",
            " extracting: train/D1139WM_jpg.rf.e56031edbd6f7445b66b537b2b9b3d4e.jpg  \n",
            " extracting: train/D943_259_758_1200__flip_jpg.rf.28fff1c9fa1e0e8c42c3e1ade31a1091.jpg  \n",
            " extracting: train/DK27EW_jpg.rf.e046fd9d3db12b05a51a857b1e508f2d.jpg  \n",
            " extracting: train/DSC01700_JPG_jpg.rf.5de431a64c283fae3943fd483c05ec12.jpg  \n",
            " extracting: train/DSC01700_JPG_jpg.rf.6eb3ac3c6957322a2790cdce6f23ce92.jpg  \n",
            " extracting: train/DSC01701_JPG_jpg.rf.96a27a335110c36e96d052ffb1675404.jpg  \n",
            " extracting: train/DSC01702_JPG_jpg.rf.6fbabe81b0a439e85f5e3b459fda92fb.jpg  \n",
            " extracting: train/DSC01703_JPG_jpg.rf.a3656c49ec06941675cfc1cc48c6893b.jpg  \n",
            " extracting: train/DSC01705_JPG_jpg.rf.a2587067e34f9a841227c51267645f1a.jpg  \n",
            " extracting: train/DSC01710_JPG_jpg.rf.cba29fe8a76946412c88f314574e6422.jpg  \n",
            " extracting: train/DSC01710_JPG_jpg.rf.fe17f62ec172921d1e260da0476fafb9.jpg  \n",
            " extracting: train/DSC01711_JPG_jpg.rf.31d79981bfc5196cd6d9cd8007ac172a.jpg  \n",
            " extracting: train/DSC01714_JPG_jpg.rf.c9c864968e814a0adbd5cd21fab52fa9.jpg  \n",
            " extracting: train/DSC01717_JPG_jpg.rf.5f849c3078fa7f10d913314ea3d3225f.jpg  \n",
            " extracting: train/DSC01717_JPG_jpg.rf.d362e1228417fd72b90f04433e61750d.jpg  \n",
            " extracting: train/DSC01720_JPG_jpg.rf.3bd7892261dd6f6ae8b63284a601c9b8.jpg  \n",
            " extracting: train/DSC01721_JPG_jpg.rf.432eaddda1166530f936cd696c39d9cf.jpg  \n",
            " extracting: train/DSC01723_JPG_jpg.rf.8c1701b240f21a96abee60e6d13b486e.jpg  \n",
            " extracting: train/DSC01728_JPG_jpg.rf.6c8d1d670cedcd399dbabb387f393b5b.jpg  \n",
            " extracting: train/DSC01736_JPG_jpg.rf.ca3a38939a3ecab549d462ce96978524.jpg  \n",
            " extracting: train/DSC01739_JPG_jpg.rf.eb493e5fbf94a463e90a33a3e16ad049.jpg  \n",
            " extracting: train/DSC01757_JPG_jpg.rf.5e883c2c5b78bb2b35460f5ab404adae.jpg  \n",
            " extracting: train/DSC01918_JPG-Copy-Copy_jpg.rf.ae89429e34a5042942e2553c584342f7.jpg  \n",
            " extracting: train/DSC01920_JPG_jpg.rf.7967e3bf78ba7b024d2e76be055048c7.jpg  \n",
            " extracting: train/DSC01920_JPG_jpg.rf.7991b5d91da03478a662fb2292f4e201.jpg  \n",
            " extracting: train/DSC01920_JPG_jpg.rf.ec8fcce5dd2c5203b51aa8f20eea1251.jpg  \n",
            " extracting: train/DSC01928_JPG-Copy-Copy_jpg.rf.ebd9881569672a4b922a662f4248a64f.jpg  \n",
            " extracting: train/DSC01931_JPG_jpg.rf.0b96f52776069048ff0054b8d8e38f1a.jpg  \n",
            " extracting: train/DSC01933_JPG-Copy-Copy_jpg.rf.49830cceefab17f7d488343d83d33468.jpg  \n",
            " extracting: train/DSC01933_JPG_jpg.rf.6af1631cc5d8558f1e378b725c74d08b.jpg  \n",
            " extracting: train/DSC01939_JPG_jpg.rf.e1e0530fdd16c9873a7de94525a2643b.jpg  \n",
            " extracting: train/DSC01940_JPG_jpg.rf.49602b3863d05acbbf7280196bc950dd.jpg  \n",
            " extracting: train/DSC01941_JPG_jpg.rf.0a5d9639684c25a7dc9814d786dd0969.jpg  \n",
            " extracting: train/DSC01941_JPG_jpg.rf.9db6795d53d54a546396635ec763b32c.jpg  \n",
            " extracting: train/DSC01941_JPG_jpg.rf.c44a87eb4be727615678344f0297878c.jpg  \n",
            " extracting: train/DSC01943_JPG_jpg.rf.2f1e68e7501eb47bf794925a322fc80c.jpg  \n",
            " extracting: train/DSC01943_JPG_jpg.rf.ecc88b7041a49d414b637974faa0396a.jpg  \n",
            " extracting: train/DSC01946_JPG_jpg.rf.e0f8076033176fef68c5edd289650de9.jpg  \n",
            " extracting: train/DSC01946_JPG_jpg.rf.fadd11b6d9a87317c4cc17e8263aef7a.jpg  \n",
            " extracting: train/DSC01947_JPG_jpg.rf.4f5c6271f0651939b963083823226276.jpg  \n",
            " extracting: train/DSC01947_JPG_jpg.rf.68e0f86fff3b11ba4f0ad1e40e1a9879.jpg  \n",
            " extracting: train/DSC01950_JPG_jpg.rf.053ef98541c1395b0c397330c3e81714.jpg  \n",
            " extracting: train/DSC01950_JPG_jpg.rf.434e7f0c1cfb923b845585de088af7ed.jpg  \n",
            " extracting: train/DSC01950_JPG_jpg.rf.732e54357d39f8f59996f5878093568c.jpg  \n",
            " extracting: train/DSC01951_JPG_jpg.rf.29a0dd8958a1d6650d343791fe7457df.jpg  \n",
            " extracting: train/DSC01952_JPG_jpg.rf.489b48275931bf0fc5f9cd7941dcc50f.jpg  \n",
            " extracting: train/DSC01952_JPG_jpg.rf.c29c8cc4cae1184ec849f55e5ca4eb49.jpg  \n",
            " extracting: train/DSC01954_JPG_jpg.rf.99caa2695437e69173e0c33d915f212f.jpg  \n",
            " extracting: train/DSC01954_JPG_jpg.rf.e53ca85a47e0eb58afa4d44dcde88c06.jpg  \n",
            " extracting: train/DSC01955_JPG_jpg.rf.34525b2b7d57ef56ae85e845a4301fe8.jpg  \n",
            " extracting: train/DSC01955_JPG_jpg.rf.36d8274866999066a9b5b05796eecd1b.jpg  \n",
            " extracting: train/DSC01955_JPG_jpg.rf.bd6744a717eb7ac19b7a8a48a5e5191f.jpg  \n",
            " extracting: train/DSC01956_JPG_jpg.rf.9c0adb92ebb5789ae6ef9a2ff3aa2733.jpg  \n",
            " extracting: train/DSC01959_JPG_jpg.rf.76afe6550d83640f333daf94047b133b.jpg  \n",
            " extracting: train/DSC01960_JPG_jpg.rf.25450f02b87e40e7b9a7d0725e846605.jpg  \n",
            " extracting: train/DSC01961_JPG_jpg.rf.9b5c6b3d57682d8365b086b64f2b9011.jpg  \n",
            " extracting: train/DSC01961_JPG_jpg.rf.df73b3c2b9580b2b73c86cd49622d36c.jpg  \n",
            " extracting: train/DSC01963_JPG_jpg.rf.4976277bd3b29c444d0e5d7fbe9b2402.jpg  \n",
            " extracting: train/DSC01963_JPG_jpg.rf.bbe6391b1ac49378589241c1a6411e0b.jpg  \n",
            " extracting: train/DSC01963_JPG_jpg.rf.e3b5b6058723d667dc3c22335d56e178.jpg  \n",
            " extracting: train/DSC01964_JPG_jpg.rf.6648e9b0ad4c9ce28cb54ae16dc4bd79.jpg  \n",
            " extracting: train/DSC01964_JPG_jpg.rf.90ce4c10a339639879509b307b341ceb.jpg  \n",
            " extracting: train/DSC01965_JPG_jpg.rf.22f0394b00516f59a94c80b029cf1346.jpg  \n",
            " extracting: train/DSC01965_JPG_jpg.rf.b7d02c9fdfb99de8d41038afd08afe79.jpg  \n",
            " extracting: train/DSC01965_JPG_jpg.rf.e12904a85c53f059e2e3c11c27000494.jpg  \n",
            " extracting: train/DSC01966_JPG_jpg.rf.b072249ac19302b96c91ad1e198bc709.jpg  \n",
            " extracting: train/DSC01967_JPG_jpg.rf.ddb111754aeec3990af820c419236922.jpg  \n",
            " extracting: train/DSC01967_JPG_jpg.rf.edb5f9b2ec4cd3aa9bdcd42f967ab614.jpg  \n",
            " extracting: train/DSC01968_JPG_jpg.rf.b61548fc98a084daf77beaceab2a30a7.jpg  \n",
            " extracting: train/DSC01968_JPG_jpg.rf.ce0834f080532d843b22391bb81187e1.jpg  \n",
            " extracting: train/DSC01970_JPG_jpg.rf.15b3881845144521cb22474845ee0911.jpg  \n",
            " extracting: train/DSC01970_JPG_jpg.rf.3acceba9039baf837fb5a05cc06793a3.jpg  \n",
            " extracting: train/DSC01970_JPG_jpg.rf.3d692fd52791187815eaf99ebe4be884.jpg  \n",
            " extracting: train/DSC01970_JPG_jpg.rf.7d05775cef29e55fc959d12aee8931ea.jpg  \n",
            " extracting: train/DSC01972_JPG_jpg.rf.2da7cd896a444f2d6088168bbe9e7885.jpg  \n",
            " extracting: train/DSC01972_JPG_jpg.rf.8ff4090c8af5adf3701525d07b97d939.jpg  \n",
            " extracting: train/DSC01972_JPG_jpg.rf.d8f2eb25107c7404c467507ab0167c49.jpg  \n",
            " extracting: train/DSC01973_JPG_jpg.rf.c96d38a0f483613a042dce81d3e1e192.jpg  \n",
            " extracting: train/DSC01973_JPG_jpg.rf.efac0b901bef0eb466edf48d10c7ebea.jpg  \n",
            " extracting: train/DSC01975_JPG-Copy-Copy_jpg.rf.6aff362bf5434b7848b363cc11a52108.jpg  \n",
            " extracting: train/DSC01975_JPG_jpg.rf.77ef2c616a83f53681ef91039e5677fe.jpg  \n",
            " extracting: train/DSC01976_JPG_jpg.rf.86b10b8adf4b316764aa1d16cad1d44b.jpg  \n",
            " extracting: train/DSC01976_JPG_jpg.rf.9b9ad7dca542ffa9afbf3edaaa8f7f20.jpg  \n",
            " extracting: train/DSC01977_JPG_jpg.rf.8008d5f5def6ce565225e451daa62d45.jpg  \n",
            " extracting: train/DSC01977_JPG_jpg.rf.8740b1def711c34b08035a375b26563a.jpg  \n",
            " extracting: train/DSC01977_JPG_jpg.rf.a53585c03fa93e3ece7555848ac2abbd.jpg  \n",
            " extracting: train/DSC01977_JPG_jpg.rf.ae4321ceec3a31bc50ba57c4e6e95d30.jpg  \n",
            " extracting: train/DSC01977_JPG_jpg.rf.b6426b727b52d13fd492239230c569cd.jpg  \n",
            " extracting: train/DSC01981_JPG_jpg.rf.208ce25ea6ba990601eab38845cf35c1.jpg  \n",
            " extracting: train/DSC01981_JPG_jpg.rf.d94c50e1e4f74298a755e17a1a8ed6cd.jpg  \n",
            " extracting: train/DSC01983_JPG_jpg.rf.53d9e1d28df0911818ea74d0ef15ea72.jpg  \n",
            " extracting: train/DSC01983_JPG_jpg.rf.922e1de8759a5b077ee61b6783bbb6bf.jpg  \n",
            " extracting: train/DSC01983_JPG_jpg.rf.9ebbfaaec254810dc6bc114c4796cd6d.jpg  \n",
            " extracting: train/DSC01983_JPG_jpg.rf.afaa3e345bac0affdf0ea1600995cd2a.jpg  \n",
            " extracting: train/DSC01984_JPG_jpg.rf.7d8440b12f02c747a5e5ef8dd6fa8b8c.jpg  \n",
            " extracting: train/DSC01984_JPG_jpg.rf.e290bbb4b4c5b1ab427b83c1dc244a53.jpg  \n",
            " extracting: train/DSC01984_JPG_jpg.rf.e748882989a0ac47211b686d81478607.jpg  \n",
            " extracting: train/DSC01985_JPG_jpg.rf.a12cd614487bf54a14d90e2c7a6ba4a5.jpg  \n",
            " extracting: train/DSC01986_JPG_jpg.rf.4aa4ceb344f612ad7a03bc3ac5248ab2.jpg  \n",
            " extracting: train/DSC01986_JPG_jpg.rf.b378e63133e3212efa913bb483e4924c.jpg  \n",
            " extracting: train/DSC01989_JPG_jpg.rf.20e4a3f657d0ee0b4b83af99f05ef3c8.jpg  \n",
            " extracting: train/DSC01989_JPG_jpg.rf.6cb90470ed955a299a3de34f1573f254.jpg  \n",
            " extracting: train/DSC01989_JPG_jpg.rf.7392e96f11d2863ce8a903d7e9eda8af.jpg  \n",
            " extracting: train/DSC01989_JPG_jpg.rf.d35b8aece3a8dbacc9c73093dca2ee6e.jpg  \n",
            " extracting: train/DSC01990_JPG_jpg.rf.15ab3e5bf779be8631960a48c655b2ff.jpg  \n",
            " extracting: train/DSC01991_JPG_jpg.rf.0c426efc074d4ebeaa4a3bba245920ff.jpg  \n",
            " extracting: train/DSC01992_JPG_jpg.rf.5a7b457d75d33b9a74693a275977e514.jpg  \n",
            " extracting: train/DSC01992_JPG_jpg.rf.6759ba0aaa4f3f502778d663a6593f14.jpg  \n",
            " extracting: train/DSC01993_JPG_jpg.rf.46effce69a5d9e6aecfe26f9efeb616f.jpg  \n",
            " extracting: train/DSC01995_JPG_jpg.rf.1d0a345c796fba21d6e4350b7ef2aefc.jpg  \n",
            " extracting: train/DSC01995_JPG_jpg.rf.6086580d65052b36c41d1f6fc28999b2.jpg  \n",
            " extracting: train/DSC01996_JPG_jpg.rf.225ce415d4529b145345595dbc24e415.jpg  \n",
            " extracting: train/DSC01996_JPG_jpg.rf.9aaa7aefc3067dc6fc655e04587e0ee7.jpg  \n",
            " extracting: train/DSC01997_JPG_jpg.rf.51785dc3e62f79b42746c8b2b93689c0.jpg  \n",
            " extracting: train/DSC01997_JPG_jpg.rf.bece46f613907deca85f5e1576391cb8.jpg  \n",
            " extracting: train/DSC01998_JPG_jpg.rf.4607a7f53f329e7f8a3c91e94214b659.jpg  \n",
            " extracting: train/DSC01998_JPG_jpg.rf.697a1ae31d7b35015bc46d63e74a54a9.jpg  \n",
            " extracting: train/DSC01999_JPG_jpg.rf.90a2f1f60be6ad7afe2c1dec5ca8dbd7.jpg  \n",
            " extracting: train/DSC02000_JPG_jpg.rf.1640f5538cb149345d1707f251d3052f.jpg  \n",
            " extracting: train/DSC02000_JPG_jpg.rf.56ee0af28cf25904fd8500829313a58a.jpg  \n",
            " extracting: train/DSC02000_JPG_jpg.rf.8336ad47f42e7ffdf8bfb5454b96bf46.jpg  \n",
            " extracting: train/DSC02000_JPG_jpg.rf.d79e43cc6b5d3e5a571472ce5705e8bf.jpg  \n",
            " extracting: train/DSC02001_JPG_jpg.rf.83300c5eba0e7afb6dc08630dcdf88fd.jpg  \n",
            " extracting: train/DSC02001_JPG_jpg.rf.dee862ee3190897791fd1260b1d6dba5.jpg  \n",
            " extracting: train/DSC02004_JPG_jpg.rf.3fa451e0476272648a355aa606a313af.jpg  \n",
            " extracting: train/DSC02004_JPG_jpg.rf.a1950626596a2b117c50f7c47c39d665.jpg  \n",
            " extracting: train/DSC02005_JPG_jpg.rf.14300b430a3d3fd4afa6a1b92368cbe6.jpg  \n",
            " extracting: train/DSC02005_JPG_jpg.rf.527b6dd0871dd01895bc8021e6a6613d.jpg  \n",
            " extracting: train/DSC02005_JPG_jpg.rf.d05db680c2d763a4858135d30fcd5dfb.jpg  \n",
            " extracting: train/DSC02006_JPG_jpg.rf.86f5e50334078311e10eff3926563ffd.jpg  \n",
            " extracting: train/DSC02006_JPG_jpg.rf.8dab5733176fbcf78e40d00c50404d50.jpg  \n",
            " extracting: train/DSC02007_JPG_jpg.rf.067a6ab5d3f10551c2b1c58a2007f2eb.jpg  \n",
            " extracting: train/DSC02007_JPG_jpg.rf.a632604bf3e649df3f31fc5de3c3d2e8.jpg  \n",
            " extracting: train/DSC02008_JPG_jpg.rf.313b4693d88bf3ea9e4cf447737a86c9.jpg  \n",
            " extracting: train/DSC02011_JPG_jpg.rf.68cd97d8ea378854193435288307521a.jpg  \n",
            " extracting: train/DSC02012_JPG_jpg.rf.4b3592520fd8ea547c77dbc3dd625e11.jpg  \n",
            " extracting: train/DSC02012_JPG_jpg.rf.929617aec7b563637943e11bc37a3b50.jpg  \n",
            " extracting: train/DSC02012_JPG_jpg.rf.b1242b409859001fa5150716400037f0.jpg  \n",
            " extracting: train/DSC02013_JPG_jpg.rf.b03a346ce728e25e2dae2eb8dec832eb.jpg  \n",
            " extracting: train/DSC02013_JPG_jpg.rf.e49adc22d4ab9458014669e2cdb8fc93.jpg  \n",
            " extracting: train/DSC02013_JPG_jpg.rf.fc7151546bafd89be7eaffc86af3d63c.jpg  \n",
            " extracting: train/DSC02014_JPG_jpg.rf.7d6dd0ec2119b9e739bc5b55e1db0b38.jpg  \n",
            " extracting: train/DSC02014_JPG_jpg.rf.9a8ba35139785ecdf5385e8d99e59215.jpg  \n",
            " extracting: train/DSC02015_JPG_jpg.rf.8971124dd11d0e118ecce5fb0395ea89.jpg  \n",
            " extracting: train/DSC02015_JPG_jpg.rf.bce27d5345cba8e2d9b00b60d4a29be3.jpg  \n",
            " extracting: train/DSC02018_JPG_jpg.rf.ae98628c1564408bb812e1cec2bc30f0.jpg  \n",
            " extracting: train/DSC02018_JPG_jpg.rf.b17a55c04bcb2159da2db5919bfe435d.jpg  \n",
            " extracting: train/DSC02018_JPG_jpg.rf.feee3a0a1b0419e7947dcc4599509b2f.jpg  \n",
            " extracting: train/DSC02019_JPG_jpg.rf.4ce1a5730ef0a4bf87d8d66a58b15e71.jpg  \n",
            " extracting: train/DSC02019_JPG_jpg.rf.d477350e19757a5c36e9cc2f96cb8232.jpg  \n",
            " extracting: train/DSC02020_JPG_jpg.rf.5395e69813e7d67c16aca52e50f4344b.jpg  \n",
            " extracting: train/DSC02020_JPG_jpg.rf.75d07ca1f4931f89596d6d5b711f19cb.jpg  \n",
            " extracting: train/DSC02022_JPG_jpg.rf.93805fa90b030245811340b8c5463fc0.jpg  \n",
            " extracting: train/DSC02023_JPG_jpg.rf.7e9e72e7425150bae2b68d4254f2b60f.jpg  \n",
            " extracting: train/DSC02023_JPG_jpg.rf.89abd75181ce073efe29efb3f4f0c401.jpg  \n",
            " extracting: train/DSC02024_JPG_jpg.rf.cf4d83e9c87d1bba39f92ae5ceb422ba.jpg  \n",
            " extracting: train/DSC02024_JPG_jpg.rf.eb1b56aefdabe2dd71572f4daae56220.jpg  \n",
            " extracting: train/DSC02025_JPG_jpg.rf.2dcaef9fb34ed980d0f4292e0c10d048.jpg  \n",
            " extracting: train/DSC02025_JPG_jpg.rf.8d48cb2fc3e06986fe9d6e8efe0b4061.jpg  \n",
            " extracting: train/DSC02025_JPG_jpg.rf.f4d51b510ae31d785ae7085d2a608b6e.jpg  \n",
            " extracting: train/DSC02026_JPG_jpg.rf.2ac56fa5ec8479ac2b3276152d45b925.jpg  \n",
            " extracting: train/DSC02026_JPG_jpg.rf.5f907042986f06d836a72a8f0bf68764.jpg  \n",
            " extracting: train/DSC02028_JPG_jpg.rf.8ad9754f576f6d515ab5788be1a2fbf9.jpg  \n",
            " extracting: train/DSC02028_JPG_jpg.rf.bd366f4aa63479b5d5e3eb6d8f66e77a.jpg  \n",
            " extracting: train/DSC02028_JPG_jpg.rf.d2f37aeec98719a08368ec7e2ac9149c.jpg  \n",
            " extracting: train/DSC02029_JPG_jpg.rf.6c9cb8678bc590b3686027c887300b4a.jpg  \n",
            " extracting: train/DSC02030_JPG_jpg.rf.3caaebb6b3ac03e9bf5be18da1225634.jpg  \n",
            " extracting: train/DSC02030_JPG_jpg.rf.425426c4bc7cf79519c5a1c7abf9e0fd.jpg  \n",
            " extracting: train/DSC02031_JPG_jpg.rf.57a462f8f8f2ce7cdacafc68300521bf.jpg  \n",
            " extracting: train/DSC02032_JPG_jpg.rf.6c6d446d94a244f5a0e829a5235efc9f.jpg  \n",
            " extracting: train/DSC02036_JPG_jpg.rf.419534807b18044593687752c2b59a51.jpg  \n",
            " extracting: train/DSC02036_JPG_jpg.rf.839f1f83ec1145a748224b7e219f047b.jpg  \n",
            " extracting: train/DSC02037_JPG_jpg.rf.345f08de9a9ee15703f85241676b187f.jpg  \n",
            " extracting: train/DSC02037_JPG_jpg.rf.78b5e55ccf4c52a0281edb3abf7ae48b.jpg  \n",
            " extracting: train/DSC02038_JPG_jpg.rf.35d2d792b2cb4c035b12ee79656068f2.jpg  \n",
            " extracting: train/DSC02038_JPG_jpg.rf.cd4a39c97c45e768f779d805e8525bcf.jpg  \n",
            " extracting: train/DSC02039_JPG_jpg.rf.23f1e535cca8e345401860c2c45859de.jpg  \n",
            " extracting: train/DSC02039_JPG_jpg.rf.cb01e021d776a59eb184389fd69983d4.jpg  \n",
            " extracting: train/DSC02042_JPG_jpg.rf.61e3bf1e801702e781f1dbd442b95233.jpg  \n",
            " extracting: train/DSC02042_JPG_jpg.rf.8465b8486c458cdac3b2c2f4bec6ec79.jpg  \n",
            " extracting: train/DSC02043_JPG_jpg.rf.190b3a6653913926a47cc050baa64200.jpg  \n",
            " extracting: train/DSC02043_JPG_jpg.rf.85e606861fb709d54c6fee5eb6421e7c.jpg  \n",
            " extracting: train/DSC02043_JPG_jpg.rf.f68de67548a61d8eacf9af153244b5b8.jpg  \n",
            " extracting: train/DSC02044_JPG_jpg.rf.a6cc11f9305a4e56ece6a4de68912cec.jpg  \n",
            " extracting: train/DSC02044_JPG_jpg.rf.e1b8767d9cfec1ea2ffb03575a42b65a.jpg  \n",
            " extracting: train/DSC02045_JPG_jpg.rf.1caad18ddddd97a84b46b7e3a297acfa.jpg  \n",
            " extracting: train/DSC02045_JPG_jpg.rf.f710f5257b6333703a1d810d30f89aae.jpg  \n",
            " extracting: train/DSC02045_JPG_jpg.rf.fcb6eaa43fc3deafbe33da81d357ba72.jpg  \n",
            " extracting: train/DSC02047_JPG_jpg.rf.03592d61a16ac2a17f567091857bf620.jpg  \n",
            " extracting: train/DSC02047_JPG_jpg.rf.0d335087423571e27a759c86f2822c5b.jpg  \n",
            " extracting: train/DSC02047_JPG_jpg.rf.6c67298ce14beb2fc1c3bbba144aba02.jpg  \n",
            " extracting: train/DSC02048_JPG-Copy_jpg.rf.3a522c2dae30a9c9db9b87c2b4c65f6f.jpg  \n",
            " extracting: train/DSC02048_JPG-Copy_jpg.rf.9a5e8bcada507cc38eba703296ecb624.jpg  \n",
            " extracting: train/DSC02048_JPG-Copy_jpg.rf.f941d7f56cba8a16e983dc8b59dd04b5.jpg  \n",
            " extracting: train/DSC02049_JPG_jpg.rf.a05b26c703d6528f9925a6bdf73f7b43.jpg  \n",
            " extracting: train/DSC02050_JPG-Copy_jpg.rf.9d3fd077d44e748ae60bf42e41453187.jpg  \n",
            " extracting: train/DSC02050_JPG-Copy_jpg.rf.c89734c67cc125d067c8aa7c5e4dfb6a.jpg  \n",
            " extracting: train/DSC02051_JPG_jpg.rf.0c20220887d27467781468bdde351770.jpg  \n",
            " extracting: train/DSC02051_JPG_jpg.rf.5af420ecf59550c4b7031b5582b48661.jpg  \n",
            " extracting: train/DSC02051_JPG_jpg.rf.eb48f2b29a24d83ad11ecf16ee84870a.jpg  \n",
            " extracting: train/DSC02052_JPG_jpg.rf.021b77e2bf3cee49101f97c878f728ee.jpg  \n",
            " extracting: train/DSC02052_JPG_jpg.rf.0e7731be1ae34d7f3c22f4c36e12ca07.jpg  \n",
            " extracting: train/DSC02052_JPG_jpg.rf.b3188a6dee4a73aded0c5d7fc98ba32e.jpg  \n",
            " extracting: train/DSC02054_JPG_jpg.rf.0d843b9480cea491e0a2c87748751088.jpg  \n",
            " extracting: train/DSC02054_JPG_jpg.rf.22309ad1b5955392f1a061e78f200065.jpg  \n",
            " extracting: train/DSC02057_JPG_jpg.rf.e89da745867e85de0e3c0d5f5e1a0aee.jpg  \n",
            " extracting: train/DSC02059_JPG_jpg.rf.7e1e7674a045d482b9202a0968a55eb8.jpg  \n",
            " extracting: train/DSC02059_JPG_jpg.rf.aef547a5b2e8592518e27b71bcd53538.jpg  \n",
            " extracting: train/DSC02060_JPG_jpg.rf.a72d711d3d8e0fa597b030baf24c589c.jpg  \n",
            " extracting: train/DSC02060_JPG_jpg.rf.f9d2baf2491050a66c5e7494d906e8e6.jpg  \n",
            " extracting: train/DSC02061_JPG_jpg.rf.39effd28b7d0bce05ef8ddfeac92e0f9.jpg  \n",
            " extracting: train/DSC02063_JPG_jpg.rf.0ac6d559f45d5959f8fe547d32fbbc5e.jpg  \n",
            " extracting: train/DSC02063_JPG_jpg.rf.a2e4041cd67f1778905f90788ffdbe21.jpg  \n",
            " extracting: train/DSC02064_JPG_jpg.rf.45f0478b7236622c49f3b4bf6daeb2b6.jpg  \n",
            " extracting: train/DSC02064_JPG_jpg.rf.96fb4501dfd2f74ae243df5b62c98a9a.jpg  \n",
            " extracting: train/DSC02064_JPG_jpg.rf.9cf18565dd6102b2722f57846116bacd.jpg  \n",
            " extracting: train/DSC02065_JPG_jpg.rf.eb6223e07e883f49476ff5a2dff87141.jpg  \n",
            " extracting: train/DSC02067_JPG_jpg.rf.1c01541e10df68b7c08058925a8f0b99.jpg  \n",
            " extracting: train/DSC02067_JPG_jpg.rf.81eea2665235dcb76f67b66847ae419d.jpg  \n",
            " extracting: train/DSC02069_JPG_jpg.rf.da4bf26143ae1a6d719ab4c346961513.jpg  \n",
            " extracting: train/DSC02070_JPG_jpg.rf.b976fc488d8ffeab74980b9e79409cb0.jpg  \n",
            " extracting: train/DSC02071_JPG_jpg.rf.904e776a38db359df937861bbe9e2352.jpg  \n",
            " extracting: train/DSC02072_JPG-Copy_jpg.rf.0176fbb3c1a8bfcc74b61cea319415d0.jpg  \n",
            " extracting: train/DSC02072_JPG-Copy_jpg.rf.d3483b12d745b9ec26afc1c47e45f57d.jpg  \n",
            " extracting: train/DSC02073_JPG_jpg.rf.0df472399e6e744dc97fe45fa4cafb9a.jpg  \n",
            " extracting: train/DSC02075_JPG-Copy_jpg.rf.82b24020fd50b1065053d64eef1f36fa.jpg  \n",
            " extracting: train/DSC02075_JPG-Copy_jpg.rf.cb00d6d738a348e0f2497f026e6bbc65.jpg  \n",
            " extracting: train/DSC02076_JPG_jpg.rf.022fd8d2a2f3033c2addbfc8a675677a.jpg  \n",
            " extracting: train/DSC02076_JPG_jpg.rf.c34bf647c049aa3333caca473f5e5ecb.jpg  \n",
            " extracting: train/DSC02076_JPG_jpg.rf.f36a577ef259a6eb27ae3080d818d890.jpg  \n",
            " extracting: train/DSC02077_JPG_jpg.rf.03c389bd6a15071eaf89be29ad3021a8.jpg  \n",
            " extracting: train/DSC02077_JPG_jpg.rf.0fac8ab6ca9945df4ef43d95442e1f3e.jpg  \n",
            " extracting: train/DSC02077_JPG_jpg.rf.a75327024c0aae451a08fa506dc386e3.jpg  \n",
            " extracting: train/DSC02078_JPG_jpg.rf.4ef7b9d0df56047c7cad12db0cb0c3dd.jpg  \n",
            " extracting: train/DSC02078_JPG_jpg.rf.560926e9c4a1139e6ff005ac48e723b4.jpg  \n",
            " extracting: train/DSC02078_JPG_jpg.rf.f1a69d83bd5016d6be84dae47c8771e5.jpg  \n",
            " extracting: train/DSC02079_JPG_jpg.rf.5fc97f99749ba169e2eba537013a1c43.jpg  \n",
            " extracting: train/DSC02079_JPG_jpg.rf.7e7d18728f5a479b9b39a872aa152b52.jpg  \n",
            " extracting: train/DSC02080_JPG_jpg.rf.467955337a4139f30b5cd67ae01132c5.jpg  \n",
            " extracting: train/DSC02080_JPG_jpg.rf.b07c71a3f25c5d92c4d3ff820423ced4.jpg  \n",
            " extracting: train/DSC02080_JPG_jpg.rf.bffee79923608828f81424c79687573e.jpg  \n",
            " extracting: train/DSC02081_JPG_jpg.rf.064dae378b2577f0ac6b34f999bd73c2.jpg  \n",
            " extracting: train/DSC02081_JPG_jpg.rf.d209023e44c8404fd58c3918aaac3934.jpg  \n",
            " extracting: train/DSC02081_JPG_jpg.rf.ebd77ca45ddae7c3f76ad2e81edb8482.jpg  \n",
            " extracting: train/DSC02082_JPG_jpg.rf.7c8f0ed88d2ee7a4292ca30d84f27a0a.jpg  \n",
            " extracting: train/DSC02082_JPG_jpg.rf.7eceb15f6fe54477960276605f7a702f.jpg  \n",
            " extracting: train/DSC02082_JPG_jpg.rf.9e6d06649ea3cd0175f34c92b2fc8c40.jpg  \n",
            " extracting: train/DSC02083_JPG_jpg.rf.4970f1e3cecfb205a6589df1eae4edfa.jpg  \n",
            " extracting: train/DSC02083_JPG_jpg.rf.5ef6d197d921c47e2ab5355e2bc8ac0b.jpg  \n",
            " extracting: train/DSC02083_JPG_jpg.rf.f67b6c5f0b7a1008d79e296ec67ad36d.jpg  \n",
            " extracting: train/DSC02084_JPG_jpg.rf.8a3066a372ef8a7f725e063239e9903a.jpg  \n",
            " extracting: train/DSC02084_JPG_jpg.rf.8ec47933f3f63a00c57010dc812eb60f.jpg  \n",
            " extracting: train/DSC02084_JPG_jpg.rf.e849e301c0f78c1618821885e5b2be92.jpg  \n",
            " extracting: train/DSC02085_JPG_jpg.rf.5d59b142f28f08fc0ac1556959e13017.jpg  \n",
            " extracting: train/DSC02085_JPG_jpg.rf.d3f4a69106f088222de62560c4f19677.jpg  \n",
            " extracting: train/DSC02085_JPG_jpg.rf.f0eb9bb5bb9d1bdd5c60b6181fd24f31.jpg  \n",
            " extracting: train/DSC02086_JPG-Copy_jpg.rf.83fc75d1b057c765d46d5355a98f3736.jpg  \n",
            " extracting: train/DSC02086_JPG-Copy_jpg.rf.af8964f921d6aeae769c257b6bc2b643.jpg  \n",
            " extracting: train/DSC02087_JPG_jpg.rf.0b4e4356db61515a9ebaa4f3eaa522c6.jpg  \n",
            " extracting: train/DSC02087_JPG_jpg.rf.421fd5a532f61ab33012b89d47ae348c.jpg  \n",
            " extracting: train/DSC02087_JPG_jpg.rf.f95ff9471171941dbe8e965aa0478ff8.jpg  \n",
            " extracting: train/DSC02088_JPG_jpg.rf.3fba4038b5dd87422f7c0e4241b7aee6.jpg  \n",
            " extracting: train/DSC02088_JPG_jpg.rf.dcd0346fe78f99c4718ff81b4b9ed614.jpg  \n",
            " extracting: train/DSC02089_JPG_jpg.rf.58c3942bbaba105e24f36709d63ac607.jpg  \n",
            " extracting: train/DSC02089_JPG_jpg.rf.f5ed068e10e214234f985ade8c0380f0.jpg  \n",
            " extracting: train/DSC02092_JPG_jpg.rf.1d2b13ac3289b5f9c2c6f1fbd203c745.jpg  \n",
            " extracting: train/DSC02095_JPG_jpg.rf.5198f7838ed1fc4dbe6a96eb744032d3.jpg  \n",
            " extracting: train/DSC02095_JPG_jpg.rf.72e2237320898bc74b24937a5eaf0bce.jpg  \n",
            " extracting: train/DSC02096_JPG_jpg.rf.38a7548b48d535a97f08250b1199c8b2.jpg  \n",
            " extracting: train/DSC02096_JPG_jpg.rf.c33bdf49e6d0c66e58f6f747fd166628.jpg  \n",
            " extracting: train/DSC02097_JPG_jpg.rf.1bb60fd177ab3ac483a87d7f9352f214.jpg  \n",
            " extracting: train/DSC02097_JPG_jpg.rf.ff0c9d915e4f9bbfe7b8c0f8b36a0f60.jpg  \n",
            " extracting: train/DSC02098_JPG_jpg.rf.5cbc2125476ce669cdd04b23e38acf3b.jpg  \n",
            " extracting: train/DSC02100_JPG_jpg.rf.03c87b472bd2579dc1cc0a33ed233fc1.jpg  \n",
            " extracting: train/DSC02100_JPG_jpg.rf.5e22841b32db0f01aaf50c4cb6b32b7b.jpg  \n",
            " extracting: train/DSC02101_JPG_jpg.rf.0795c7280302fa19df04823cf2d649eb.jpg  \n",
            " extracting: train/DSC02101_JPG_jpg.rf.d4f00c2101dee2ab8afc1672a9a86f8f.jpg  \n",
            " extracting: train/DSC02101_JPG_jpg.rf.e796156abaa2fa83c5ef16cea374d51e.jpg  \n",
            " extracting: train/DSC02104_JPG_jpg.rf.27d209d01dde5bbbfac6593e16e9cdb7.jpg  \n",
            " extracting: train/DSC02104_JPG_jpg.rf.74cb9c88e8195164fa42aa486c4fa95e.jpg  \n",
            " extracting: train/DSC02104_JPG_jpg.rf.9a350279ead9dce33a19d45286d50317.jpg  \n",
            " extracting: train/DSC02105_JPG_jpg.rf.178fb4a1c8bb75b34188111b323f1ce0.jpg  \n",
            " extracting: train/DSC02105_JPG_jpg.rf.4eda98afbc064bf6bbfa925ec04388ac.jpg  \n",
            " extracting: train/DSC02105_JPG_jpg.rf.689447005654f528712aa4880f639cb3.jpg  \n",
            " extracting: train/DSC02106_JPG_jpg.rf.86b6c86cbb4c905b3435a185f7f7d81b.jpg  \n",
            " extracting: train/DSC02111_JPG_jpg.rf.ab8e2a76a3319a911920106b4e91f47d.jpg  \n",
            " extracting: train/DSC02111_JPG_jpg.rf.eb54e9dfa9132b5ebf0327ed2065e689.jpg  \n",
            " extracting: train/DSC02111_JPG_jpg.rf.f56d36b092a220eb7022e4955e73df31.jpg  \n",
            " extracting: train/DSC02112_JPG_jpg.rf.8f5226da9328cbf7bfcca2f32af8d949.jpg  \n",
            " extracting: train/DSC02112_JPG_jpg.rf.b2c68d5c9bbbea12834f65ad40322f51.jpg  \n",
            " extracting: train/DSC02113_JPG_jpg.rf.073a965db6910f7c47112195edfcf53d.jpg  \n",
            " extracting: train/DSC02113_JPG_jpg.rf.214dab0d3e0c9b42b2b1f890836b7807.jpg  \n",
            " extracting: train/DSC02113_JPG_jpg.rf.c448af3beaf09a360581b075a7b7fbd2.jpg  \n",
            " extracting: train/DSC02117_JPG_jpg.rf.15cec393cbdc0159ec909f419ee902db.jpg  \n",
            " extracting: train/DSC02118_JPG_jpg.rf.148a0721f99c9c4593f946d3bee13d8b.jpg  \n",
            " extracting: train/DSC02118_JPG_jpg.rf.d6ea62055c1e33086abe27d48c8a83ea.jpg  \n",
            " extracting: train/DSC02120_JPG_jpg.rf.770c8413782dc252862a25221bea61f3.jpg  \n",
            " extracting: train/DSC02122_JPG_jpg.rf.2f3b209d749cbbe18349c4d4f06de1c7.jpg  \n",
            " extracting: train/DSC02122_JPG_jpg.rf.ca90b91c2bd5e45f5194fca41382dc29.jpg  \n",
            " extracting: train/DSC02123_JPG_jpg.rf.2c1ad8c1372796cf5c4d7a4dd0294296.jpg  \n",
            " extracting: train/DSC02123_JPG_jpg.rf.84251c42ea77815da425b6282624b609.jpg  \n",
            " extracting: train/DSC02124_JPG_jpg.rf.87053534c44eacef654e76d3777f5fc0.jpg  \n",
            " extracting: train/DSC02125_JPG_jpg.rf.13659f689851b2fa378cc4781e04ab7e.jpg  \n",
            " extracting: train/DSC02125_JPG_jpg.rf.692034252c3bd10607aef3be51021b9a.jpg  \n",
            " extracting: train/DSC02125_JPG_jpg.rf.f5a8f74b2e0e7c32b3c9284dc4dd45c0.jpg  \n",
            " extracting: train/DSC02126_JPG_jpg.rf.4420d93f93388c5321b38b57040b9e86.jpg  \n",
            " extracting: train/DSC02126_JPG_jpg.rf.7a0e3e7b2528b31d36de056df8d4c21a.jpg  \n",
            " extracting: train/DSC02126_JPG_jpg.rf.c0947b9d5fd8f9001ab2cd1f4b0ce04d.jpg  \n",
            " extracting: train/DSC02127_JPG_jpg.rf.18b04484d16bf2d308d5097dd9c9f243.jpg  \n",
            " extracting: train/DSC02128_JPG_jpg.rf.780fd4301b4a8b6680f14364ec75ff42.jpg  \n",
            " extracting: train/DSC02129_JPG_jpg.rf.b5abb715cddc67caac29612083b347fc.jpg  \n",
            " extracting: train/DSC02129_JPG_jpg.rf.fe8525e7e4f2c506b5e3e0881ffa50e3.jpg  \n",
            " extracting: train/DSC02130_JPG_jpg.rf.ad125069f20b618227d30008824ce9f8.jpg  \n",
            " extracting: train/DSC02130_JPG_jpg.rf.c3dfd7f10bc5ac1f999365d2d4bcd1d4.jpg  \n",
            " extracting: train/DSC02130_JPG_jpg.rf.e49b4ed1c8fa0a33b9ba6aa29953f2e5.jpg  \n",
            " extracting: train/DSC02131_JPG_jpg.rf.70abb010ec4cd54b6f0b5c200c32f682.jpg  \n",
            " extracting: train/DSC02132_JPG_jpg.rf.58d8d421035f258ade7314832d1de88b.jpg  \n",
            " extracting: train/DSC02132_JPG_jpg.rf.7873c3a23966acfabbf1501e346f6586.jpg  \n",
            " extracting: train/DSC02133_JPG_jpg.rf.28a1884c17b9bf71ee07618749bcd749.jpg  \n",
            " extracting: train/DSC02135_JPG_jpg.rf.3761bfb24f50cb5a8da86215a0a1d82c.jpg  \n",
            " extracting: train/DSC02136_JPG_jpg.rf.7cc413329e24f6ccff39d5e400903fee.jpg  \n",
            " extracting: train/DSC02136_JPG_jpg.rf.81bf6bfc89d544eee22b798cacaf4fd7.jpg  \n",
            " extracting: train/DSC02136_JPG_jpg.rf.8b002e2f7bf275f9880ac5ad9dc41b65.jpg  \n",
            " extracting: train/DSC02139_JPG_jpg.rf.137ff8db84d375aff556637ed62c8be8.jpg  \n",
            " extracting: train/DSC02139_JPG_jpg.rf.4d2e58d5428d6ff9c7554aed5eeee9a5.jpg  \n",
            " extracting: train/DSC02139_JPG_jpg.rf.bec0f9698ae6e093576d703501e5d6d8.jpg  \n",
            " extracting: train/DSC02140_JPG_jpg.rf.6a3baaaf69f481c33aea4aff62a27c76.jpg  \n",
            " extracting: train/DSC02140_JPG_jpg.rf.de36691fdc62490b4723447ee599391b.jpg  \n",
            " extracting: train/DSC02141_JPG_jpg.rf.1d855a940767b3923b3cb0ce50deecea.jpg  \n",
            " extracting: train/DSC02141_JPG_jpg.rf.c6e15300de84bcdf3cef64837f210c77.jpg  \n",
            " extracting: train/DSC02142_JPG_jpg.rf.1556f0fb8c43b15da14af81d7f73aae6.jpg  \n",
            " extracting: train/DSC02144_JPG_jpg.rf.ddbf719720a8494b4f6ea11d1a04e9ad.jpg  \n",
            " extracting: train/DSC02145_JPG_jpg.rf.864e441e5b77f8e138feceb6f78a7653.jpg  \n",
            " extracting: train/DSC02146_JPG_jpg.rf.1cad3d6b8bf9b078b7473f8ef0fad49d.jpg  \n",
            " extracting: train/DSC02146_JPG_jpg.rf.5a5f644cdca1a87345f81f3fd14599a0.jpg  \n",
            " extracting: train/DSC02146_JPG_jpg.rf.78f64a29bbbdc012d18735969ff54324.jpg  \n",
            " extracting: train/DSC02147_JPG_jpg.rf.3b46ea0f231d63c0d56b439822628269.jpg  \n",
            " extracting: train/DSC02147_JPG_jpg.rf.439638145c41eb81e916e544fb05d47f.jpg  \n",
            " extracting: train/DSC02147_JPG_jpg.rf.7564befa12bcbf025e3c981ec3435ece.jpg  \n",
            " extracting: train/DSC02148_JPG_jpg.rf.0cffc98a6f0b0ae4318f73a85d85802f.jpg  \n",
            " extracting: train/DSC02148_JPG_jpg.rf.3e2508b5948b1492ea83f0091d3e7e74.jpg  \n",
            " extracting: train/DSC02150_JPG_jpg.rf.518de1f2e3dccc0c8bb345fab403085b.jpg  \n",
            " extracting: train/DSC02150_JPG_jpg.rf.8762afd19025f5ef7213ddadfec5ccaa.jpg  \n",
            " extracting: train/DSC02151_JPG_jpg.rf.6e4a4f10fbff5fd88cb5bf83230b880c.jpg  \n",
            " extracting: train/DSC02151_JPG_jpg.rf.7fe5bdd1ec07a77ebb9623bb8a346151.jpg  \n",
            " extracting: train/DSC02152_JPG_jpg.rf.7e80820136b3bdded69bcc86d347960b.jpg  \n",
            " extracting: train/DSC02153_JPG_jpg.rf.1a9cc86ca202b1d00c8efa6fc3460a8d.jpg  \n",
            " extracting: train/DSC02153_JPG_jpg.rf.90fa3978e90e0513672bcacd28765287.jpg  \n",
            " extracting: train/DSC02154_JPG_jpg.rf.00648ca74ffee5da722831027f408289.jpg  \n",
            " extracting: train/DSC02154_JPG_jpg.rf.4bc156b6c773a8a94174c02fab25f674.jpg  \n",
            " extracting: train/DSC02154_JPG_jpg.rf.621f9273acbd02daf6d3104720ac84a2.jpg  \n",
            " extracting: train/DSC02155_JPG_jpg.rf.f5fb7e02bb9c6361dd03907c9b5590d9.jpg  \n",
            " extracting: train/DSC02156_JPG_jpg.rf.2166cf1e4d4df14fa2798669bac37445.jpg  \n",
            " extracting: train/DSC02156_JPG_jpg.rf.9f5ff8cdb324a619e18fe81857aa5557.jpg  \n",
            " extracting: train/DSC02156_JPG_jpg.rf.c34cd44e30cab0bb192927160f240e91.jpg  \n",
            " extracting: train/DSC02157_JPG_jpg.rf.aade25b8dfcdff4a9c630ade18dde04d.jpg  \n",
            " extracting: train/DSC02157_JPG_jpg.rf.b2f9908d720e5ed1219b508036bf36a1.jpg  \n",
            " extracting: train/DSC02159_JPG_jpg.rf.2039b5295b728ec5b9519b9c8db1cbca.jpg  \n",
            " extracting: train/DSC02159_JPG_jpg.rf.42ddb266b93d59a96ba8e554e4644a76.jpg  \n",
            " extracting: train/DSC02159_JPG_jpg.rf.849ba6c5b5ac85faf2ebfbde544478a5.jpg  \n",
            " extracting: train/DSC02160_JPG_jpg.rf.32cd748c093c3b42f07a7503388b0a63.jpg  \n",
            " extracting: train/DSC02161_JPG_jpg.rf.0ce9c6407432fe4ffeff21edac698a3c.jpg  \n",
            " extracting: train/DSC02163_JPG_jpg.rf.1b7e9da4950cc1b456cfb597bc53c106.jpg  \n",
            " extracting: train/DSC02163_JPG_jpg.rf.b9b3a5a2e61f0ede5e3254901bed1e93.jpg  \n",
            " extracting: train/DSC02163_JPG_jpg.rf.df534d317d561f0b8555422b2174e6f0.jpg  \n",
            " extracting: train/DSC02164_JPG_jpg.rf.a3261969a063eb004936c275145abdea.jpg  \n",
            " extracting: train/DSC02164_JPG_jpg.rf.dd92263eda498543786f1af4ff0c907e.jpg  \n",
            " extracting: train/DSC02164_JPG_jpg.rf.fdf096f5e34b06169d7ce8e97bb9b5e3.jpg  \n",
            " extracting: train/DSC02165_JPG_jpg.rf.2d278f77b144e3f1affd0b0dd95b95c4.jpg  \n",
            " extracting: train/DSC02165_JPG_jpg.rf.5e0bcd18b3e42e1dd5add5ef5f72551d.jpg  \n",
            " extracting: train/DSC02166_JPG_jpg.rf.151c61ebbed2ecc2f64ea2e262ead1e0.jpg  \n",
            " extracting: train/DSC02166_JPG_jpg.rf.447a3b23ccd9cd2d9033e01f82be9f24.jpg  \n",
            " extracting: train/DSC02166_JPG_jpg.rf.d8cfa92a57924daf3c8a9b4010523076.jpg  \n",
            " extracting: train/DSC02167_JPG_jpg.rf.0c1a9792eeaab3f69809dc8696aa6334.jpg  \n",
            " extracting: train/DSC02167_JPG_jpg.rf.48f91192832b905b1a9fb30637ab78d9.jpg  \n",
            " extracting: train/DSC02167_JPG_jpg.rf.78c2d1f0f9ae4b89a0871a8198520a07.jpg  \n",
            " extracting: train/DSC02168_JPG_jpg.rf.0c54d7f35404de2228ddea14fe8504ee.jpg  \n",
            " extracting: train/DSC02168_JPG_jpg.rf.a664af7bd98833284447d6964547ff39.jpg  \n",
            " extracting: train/DSC02169_JPG_jpg.rf.c0859b3656e46edbb7f42e44a02de6c2.jpg  \n",
            " extracting: train/DSC02169_JPG_jpg.rf.f0792eadabd30b7f9405f48885762a4a.jpg  \n",
            " extracting: train/DSC02170_JPG_jpg.rf.468f4ef0014e9a56999f4c59045505ec.jpg  \n",
            " extracting: train/DSC02170_JPG_jpg.rf.d9b538d45f56df0e190ea8f97a7cc336.jpg  \n",
            " extracting: train/DSC02171_JPG_jpg.rf.ab870d4273470e38f9047bbcab318e8b.jpg  \n",
            " extracting: train/DSC02172_JPG_jpg.rf.a72b0a8f0ea66b9a997111c0cb88369c.jpg  \n",
            " extracting: train/DSC02173_JPG_jpg.rf.685c8b4b4a6c73d1cc717f4734ecd418.jpg  \n",
            " extracting: train/DSC02175_JPG_jpg.rf.21fa2cdb525668f1d9fe39e19cfbbda0.jpg  \n",
            " extracting: train/DSC02176_JPG_jpg.rf.132ad3d1af6a607fe6016fd52c1b75ed.jpg  \n",
            " extracting: train/DSC02176_JPG_jpg.rf.76362e723919bc02f4b573ce96e42235.jpg  \n",
            " extracting: train/DSC02177_JPG_jpg.rf.d1d6dcd788440de4b3ab9c3e2fb6691d.jpg  \n",
            " extracting: train/DSC02178_JPG_jpg.rf.bbbbe8c01d635808285b3150543a96dd.jpg  \n",
            " extracting: train/DSC02178_JPG_jpg.rf.c59461a774442c5d898e7f45f0a0d8c3.jpg  \n",
            " extracting: train/DSC02180_JPG_jpg.rf.7d9efad82ec6f0f3904afcbd87fbb30a.jpg  \n",
            " extracting: train/DSC02181_JPG_jpg.rf.93c66c66bfd61827490f4b6a4b416cb9.jpg  \n",
            " extracting: train/DSC02183_JPG_jpg.rf.22b99301da1a1716dccda10449c743b6.jpg  \n",
            " extracting: train/DSC02183_JPG_jpg.rf.ecdd16c83f2f9f9dabe20e092bf5b15d.jpg  \n",
            " extracting: train/DSC02184_JPG_jpg.rf.1204b85331f41fb69646cbacd56f8d28.jpg  \n",
            " extracting: train/DSC02184_JPG_jpg.rf.243d4a5e3b22fb5a270f6d1f369bac8a.jpg  \n",
            " extracting: train/DSC02185_JPG_jpg.rf.1862aa84912499cab3ac5a4fb7aeeafb.jpg  \n",
            " extracting: train/DSC02185_JPG_jpg.rf.f08554f35733f1e28bb1f13f0da06ec4.jpg  \n",
            " extracting: train/DSC02187_JPG_jpg.rf.66d3fec37fc52bd0c9d5b3a8f2a65c1d.jpg  \n",
            " extracting: train/DSC02187_JPG_jpg.rf.98eec3d3b0766e019f98d5bc767c55c6.jpg  \n",
            " extracting: train/DSC02188_JPG_jpg.rf.4218db20a712c0c09b980fe62f38fccc.jpg  \n",
            " extracting: train/DSC02188_JPG_jpg.rf.4266ad75cfbc099ffd6d778228819994.jpg  \n",
            " extracting: train/DSC02189_JPG_jpg.rf.2afc7968d2c52e3f84967d72011f5239.jpg  \n",
            " extracting: train/DSC02189_JPG_jpg.rf.46f47aaa4312400bd2ae2e1a52ca4006.jpg  \n",
            " extracting: train/DSC02189_JPG_jpg.rf.859c02acc93c0a09d9f9d4092831bafd.jpg  \n",
            " extracting: train/DSC02189_JPG_jpg.rf.f7de8231332f7d9d294e7c000aa89b51.jpg  \n",
            " extracting: train/DSC02190_JPG_jpg.rf.8591e1cf9557af4548889c844f15ad8a.jpg  \n",
            " extracting: train/DSC02190_JPG_jpg.rf.f9d665998ad18d26d555004384ebf454.jpg  \n",
            " extracting: train/DSC02191_JPG_jpg.rf.30f5097c404a9f28d05360c503425769.jpg  \n",
            " extracting: train/DSC02191_JPG_jpg.rf.adbc9c9d4ef6ca186e2e5e1b4195b8a1.jpg  \n",
            " extracting: train/DSC02191_JPG_jpg.rf.fefcfd4092dc678b4c9843d071227cbb.jpg  \n",
            " extracting: train/DSC02192_JPG_jpg.rf.73a1c680f03ecf0a7b12156bba284652.jpg  \n",
            " extracting: train/DSC02192_JPG_jpg.rf.dee8f134c733d5c72364ca3de127702b.jpg  \n",
            " extracting: train/DSC02194_JPG_jpg.rf.1495536d94cd3a919defb8b0cf173506.jpg  \n",
            " extracting: train/DSC02195_JPG_jpg.rf.2387a9d5e4d69e27f6830ec27a98bd38.jpg  \n",
            " extracting: train/DSC02195_JPG_jpg.rf.bbb8b907a96029798df05f99d6d1f3cc.jpg  \n",
            " extracting: train/DSC02197_JPG_jpg.rf.47b0d905f40934f35241ccc582daab25.jpg  \n",
            " extracting: train/DSC02197_JPG_jpg.rf.6b0b3ac16def24a0d059599795c96cd9.jpg  \n",
            " extracting: train/DSC02198_JPG_jpg.rf.1ee5d2e395ba4d11ff2b7b8c1f77c645.jpg  \n",
            " extracting: train/DSC02198_JPG_jpg.rf.c87e563587142a1f46deed5ac6dca88a.jpg  \n",
            " extracting: train/DSC02199_JPG_jpg.rf.1734a2a07826c42d5689f275e033e85b.jpg  \n",
            " extracting: train/DSC02199_JPG_jpg.rf.3160657022c5b876e9f0b1bb0f25fdd4.jpg  \n",
            " extracting: train/DSC02199_JPG_jpg.rf.ede00433ad14c677af84e3009b54d01f.jpg  \n",
            " extracting: train/DSC02200_JPG_jpg.rf.74591d402c0e607a80bfb0cb7c78e198.jpg  \n",
            " extracting: train/DSC02200_JPG_jpg.rf.b93166b6f2d430e3178018eda7972ee1.jpg  \n",
            " extracting: train/DSC02202_JPG_jpg.rf.c6a8e99760abb7f6f89bd0cd41fc3620.jpg  \n",
            " extracting: train/DSC02203_JPG_jpg.rf.55e7b9af4c5dfed49155123c7c86dfd0.jpg  \n",
            " extracting: train/DSC02203_JPG_jpg.rf.6127edf1f883c3787ea6775183ebed82.jpg  \n",
            " extracting: train/DSC02203_JPG_jpg.rf.7ee7c74dd7ade90d3632eeee15e95229.jpg  \n",
            " extracting: train/DSC02205_JPG_jpg.rf.f06bc85b18e8695e23cf3b6c05a35109.jpg  \n",
            " extracting: train/DSC02206_JPG_jpg.rf.247ccc60114a3a7a4c30d93eb8169459.jpg  \n",
            " extracting: train/DSC02206_JPG_jpg.rf.55ea7c785927692acd984818f2475825.jpg  \n",
            " extracting: train/DSC02206_JPG_jpg.rf.c0d879bade8fe77404d70efea1d25671.jpg  \n",
            " extracting: train/DSC02208_JPG_jpg.rf.0b71b9c74a1c4eda7496d3169b95ae84.jpg  \n",
            " extracting: train/DSC02208_JPG_jpg.rf.62d2b1fa225f57ab18d25aa8460f85fe.jpg  \n",
            " extracting: train/DSC02211_JPG_jpg.rf.60cdfe74cc1999e57ff1cba8dc370fd9.jpg  \n",
            " extracting: train/DSC02215_JPG_jpg.rf.03acad28109d3b944d1c176b06d8b16b.jpg  \n",
            " extracting: train/DSC02222_JPG_jpg.rf.a9c038782acabda7f28ebc83ec2c6be4.jpg  \n",
            " extracting: train/DSC02247_JPG_jpg.rf.196ac8c4bcd873cf8f6e1379952d8c47.jpg  \n",
            " extracting: train/DSC02249_JPG_jpg.rf.b0d94259f916e8af14ee2af0adf13679.jpg  \n",
            " extracting: train/DSC02257_JPG_jpg.rf.4a0304ad0f08084e81355fb14adba8e3.jpg  \n",
            " extracting: train/DSC02285_JPG_jpg.rf.d114ab9d4e49df017c1c5aa0c976c351.jpg  \n",
            " extracting: train/DSC02289_JPG_jpg.rf.9249e15147b10b152cba92a9e01902ab.jpg  \n",
            " extracting: train/DSC02292_JPG_jpg.rf.fc33b03f8ec32915f5b69eaaa0d15303.jpg  \n",
            " extracting: train/DSC02781_JPG_jpg.rf.f284d7c3acfb6b151d78a953a75d4a0b.jpg  \n",
            " extracting: train/DSC02802_JPG_jpg.rf.f36e73933ba64d9b0ab86eb9dbd27fb2.jpg  \n",
            " extracting: train/DSC02835_JPG_jpg.rf.8df0d132c4266ef0e873547ef3bb1824.jpg  \n",
            " extracting: train/DSC02860_JPG_jpg.rf.7eff7d17eaa866318b40d24881dbf5fd.jpg  \n",
            " extracting: train/DSC02876_JPG_jpg.rf.4080bb37495d13733d9bcf53c1206551.jpg  \n",
            " extracting: train/DSC02913_JPG_jpg.rf.8c105daf556880e6d505ef53a4027ffd.jpg  \n",
            " extracting: train/DSC02940_JPG_jpg.rf.9251035866df36f86eb8a4c7fcce4260.jpg  \n",
            " extracting: train/DSC02941_JPG_jpg.rf.b2e3aa3150d407392bd1e7ea4a2af6e3.jpg  \n",
            " extracting: train/DSC02960_JPG_jpg.rf.8339d9c5f92c41abe52f9e9da050c9d8.jpg  \n",
            " extracting: train/DSC03002_JPG_jpg.rf.b9868c6b9f71e9afd3243d26c5c897e3.jpg  \n",
            " extracting: train/DSC03004_JPG_jpg.rf.b97be95ee07f0407187437bc98602c89.jpg  \n",
            " extracting: train/DSC03012_JPG_jpg.rf.606ae393778d513a344b15e9b141595d.jpg  \n",
            " extracting: train/DSC03014_JPG_jpg.rf.ddd413c27a0df05e2f41a95d515e76e1.jpg  \n",
            " extracting: train/DSC03027_JPG_jpg.rf.83e5f8643655e0fb6c9e978a277955b5.jpg  \n",
            " extracting: train/DSC03029_JPG_jpg.rf.29595e72cccecdcf72eeb71f0cc8d42d.jpg  \n",
            " extracting: train/DSC03036_JPG_jpg.rf.b508bfa8b381e0be9c675fb2bf44fc55.jpg  \n",
            " extracting: train/DSC03047_JPG_jpg.rf.bc42c73d18c0075d8fc1dcb7325070a7.jpg  \n",
            " extracting: train/DSC03059_JPG_jpg.rf.87233ce4759349c5f2afc19e2e2232cc.jpg  \n",
            " extracting: train/DSC03062_JPG_jpg.rf.52ae3c8b4d75c0812d267f42549ea472.jpg  \n",
            " extracting: train/DSC03064_JPG_jpg.rf.57a84616d05f893025ae939c3b6d0c53.jpg  \n",
            " extracting: train/DSC03064_JPG_jpg.rf.f6b0c96183b4fc70b9b68cafee811981.jpg  \n",
            " extracting: train/DSC03065_JPG_jpg.rf.06c7890e9cb8ebf63fcedb583260fdf3.jpg  \n",
            " extracting: train/DSC03066_JPG_jpg.rf.6b222addb18d347c11e83d5bc661f805.jpg  \n",
            " extracting: train/DSC03067_JPG_jpg.rf.1e38fe8713a1170fb75fe18571674041.jpg  \n",
            " extracting: train/DSC03069_JPG_jpg.rf.b6132c59451dd2f8cc23f03cc1ff4798.jpg  \n",
            " extracting: train/DSC03069_JPG_jpg.rf.cc2d97c13011e7c5761d60f09534daf8.jpg  \n",
            " extracting: train/DSC03071_JPG_jpg.rf.6e420b885f5fbd4ca0f8a003ef70155e.jpg  \n",
            " extracting: train/DSC03077_JPG_jpg.rf.9fa177a20cd70bc9a31e9a5466669755.jpg  \n",
            " extracting: train/DSC03077_JPG_jpg.rf.e647ffcfda261e70e9a2de7d2b91a27d.jpg  \n",
            " extracting: train/F1883AW_jpg.rf.badb907b1a5fd3a08b9478f7005da71b.jpg  \n",
            " extracting: train/Foto0008_jpg.rf.0d35728ec6545085dc35b795722b972a.jpg  \n",
            " extracting: train/Hero-Getting-round-SE-Asia-on-a-scooter-Taiwan-Photo-credit-Unsplash-andrew-haimerl-476824-1920x1080__flip_jpg.rf.6323bd88d6d1c045c48d7177b5964844.jpg  \n",
            " extracting: train/Hero-Getting-round-SE-Asia-on-a-scooter-Taiwan-Photo-credit-Unsplash-andrew-haimerl-476824-1920x1080_jpg.rf.d333b80a654bccf344f1efd04bfbfbe5.jpg  \n",
            " extracting: train/IMG-20180108-WA0017_jpg.rf.7a78f60b760844d1a189e6738e8a62f5.jpg  \n",
            " extracting: train/IMG-20180108-WA0018_jpg.rf.030755011de1bf0317f673c58fa8e9dd.jpg  \n",
            " extracting: train/IMG-20180108-WA0020_jpg.rf.1cf6fb10da2f35ec16bfb3b9f1eefb92.jpg  \n",
            " extracting: train/IMG-20180108-WA0022_jpg.rf.552de2b175973a185b52934488ba0510.jpg  \n",
            " extracting: train/IMG-20180108-WA0023_jpg.rf.5a3426937735a8d31783d3ebb13483b1.jpg  \n",
            " extracting: train/IMG-20180108-WA0024_jpg.rf.318d46fea3ba9e10247210fbe5cce87a.jpg  \n",
            " extracting: train/IMG-20180108-WA0026_jpg.rf.b783d55a0b23607d1ad9fd539d8e4ca4.jpg  \n",
            " extracting: train/IMG-20180108-WA0028_jpg.rf.d63e32ca1b2a4ebfcf4114d8b13e1278.jpg  \n",
            " extracting: train/IMG-20180108-WA0030_jpg.rf.ce57405c48f044084c09fcbd5a06f641.jpg  \n",
            " extracting: train/IMG-20180108-WA0031_jpg.rf.772b26d372688bc1609353b640431d89.jpg  \n",
            " extracting: train/IMG-20180108-WA0032_jpg.rf.8abdf60c25fd9eb6fbbb9c78d6bf7318.jpg  \n",
            " extracting: train/IMG-20180108-WA0033_jpg.rf.a38eac22071f15884e21826fb4c72778.jpg  \n",
            " extracting: train/IMG-20180108-WA0034_jpg.rf.c49f6fd261eb4121aa8d30a382c6ebde.jpg  \n",
            " extracting: train/IMG-20180108-WA0037_jpg.rf.b53a0fe776ccb7510180418193d6053d.jpg  \n",
            " extracting: train/IMG-20180108-WA0041_jpg.rf.cf33f2e6675b7f8adb52b21e0d5043c2.jpg  \n",
            " extracting: train/IMG-20180108-WA0046_jpg.rf.21045f648dfe496b95e4f5ad1bf4f9f0.jpg  \n",
            " extracting: train/IMG-20180108-WA0048_jpg.rf.ffa3b428fd7ac9b27d8f00df6554c1cf.jpg  \n",
            " extracting: train/IMG-20180108-WA0050_jpg.rf.3f738dcea924d543bd2b55d49d90b568.jpg  \n",
            " extracting: train/IMG-20180108-WA0051_jpg.rf.bd9fa77892e892ed3a59edfa6f8dcf79.jpg  \n",
            " extracting: train/IMG-20180108-WA0054_jpg.rf.74408966fa3fb768aba89dec453b3ce4.jpg  \n",
            " extracting: train/IMG-20180108-WA0055_jpg.rf.ed878a87f14ca9582cd3cb1c0504d44c.jpg  \n",
            " extracting: train/IMG-20180108-WA0056_jpg.rf.94ff59fd3f73f83168deacc12eff0455.jpg  \n",
            " extracting: train/IMG-20180108-WA0057_jpg.rf.62390d18cf751d44b326b6a26692cde6.jpg  \n",
            " extracting: train/IMG-20180108-WA0059_jpg.rf.b35a9997f320659316183b4406913ed1.jpg  \n",
            " extracting: train/IMG-20180108-WA0060_jpg.rf.f4ffff395b64c173796c94855760c23c.jpg  \n",
            " extracting: train/IMG-20180108-WA0062_jpg.rf.7bef2f42ad07b8ba61dfdf44f33cdb5b.jpg  \n",
            " extracting: train/IMG-20180108-WA0064_jpg.rf.41d435d89daf5e26f018ff74729cd025.jpg  \n",
            " extracting: train/IMG-20180108-WA0066_jpg.rf.7e9a06bff7876f62ec0cf522ead54c5b.jpg  \n",
            " extracting: train/IMG-20180108-WA0068_jpg.rf.c9de76f667ba0b7389dba617a8f75a71.jpg  \n",
            " extracting: train/IMG-20180108-WA0069_jpg.rf.e49d71cf5a811761308e19a412947960.jpg  \n",
            " extracting: train/IMG-20180108-WA0070_jpg.rf.4f68ddc3e4f0714acd24475c641e6608.jpg  \n",
            " extracting: train/IMG-20180108-WA0072_jpg.rf.7d971ffeb49d59452491b6b9e8b85f93.jpg  \n",
            " extracting: train/IMG-20180108-WA0073_jpg.rf.8ff0cc5283704cfa725625a7e8fbcb88.jpg  \n",
            " extracting: train/IMG-20180108-WA0074_jpg.rf.359437c99a878ae15b6cd51a2dd31fbc.jpg  \n",
            " extracting: train/IMG-20180108-WA0075_jpg.rf.fb94a2e067827144f78cf7be42db25cc.jpg  \n",
            " extracting: train/IMG-20180108-WA0076_jpg.rf.1dce6f416aad46039f6f5ca4d8b44969.jpg  \n",
            " extracting: train/IMG-20180108-WA0077_jpg.rf.8be0cc994d91d73c4c61f5d80c4e8e31.jpg  \n",
            " extracting: train/IMG-20180108-WA0079_jpg.rf.7a5fdbe014d282da8b5e5b63915ebb7c.jpg  \n",
            " extracting: train/IMG-20180108-WA0080_jpg.rf.3fee84a4e53cb84120c2d2d09a7837b6.jpg  \n",
            " extracting: train/IMG-20180108-WA0081_jpg.rf.7c25e9c7f19061d73576e4c9707b8a87.jpg  \n",
            " extracting: train/IMG-20180108-WA0083_jpg.rf.c64454b495766cf9fbd281a364472753.jpg  \n",
            " extracting: train/IMG-20180108-WA0086_jpg.rf.cf9d06806c4d7417b6694e0adc68edd2.jpg  \n",
            " extracting: train/IMG-20180108-WA0087_jpg.rf.d06cdeccc353a03c928818248d3a555b.jpg  \n",
            " extracting: train/IMG-20180108-WA0090_jpg.rf.4e6c6278d7709301317ecb1c83abf703.jpg  \n",
            " extracting: train/IMG-20180108-WA0092_jpg.rf.fdb5766229953a4ff025d20654df5729.jpg  \n",
            " extracting: train/IMG-20180108-WA0093_jpg.rf.fad4605fb8445ea51c9b428f0e4cada7.jpg  \n",
            " extracting: train/IMG-20180108-WA0094_jpg.rf.8edfdee098fd80a84b621c48d0a0c772.jpg  \n",
            " extracting: train/IMG-20180108-WA0095_jpg.rf.a170403bba3df88e4ccb1b98b7ed4a9c.jpg  \n",
            " extracting: train/IMG-20180108-WA0096_jpg.rf.f8136b56160072be36b9a1e36133fde5.jpg  \n",
            " extracting: train/IMG-20180108-WA0097_jpg.rf.19e74655f9bc348d283c6184ebf45e0d.jpg  \n",
            " extracting: train/IMG-20180108-WA0099_jpg.rf.1266aaae400c891df5e7ba5de54e36eb.jpg  \n",
            " extracting: train/IMG-20180108-WA0100_jpg.rf.853b1e064e881baaca17bfb19cec2b1e.jpg  \n",
            " extracting: train/IMG-20180108-WA0101_jpg.rf.da03c97e1cc17002d46ef1eeb1322e6a.jpg  \n",
            " extracting: train/IMG-20180108-WA0103_jpg.rf.55c2e8bc5c463cc1bdc242722a3e67a6.jpg  \n",
            " extracting: train/IMG-20180108-WA0106_jpg.rf.f47af757bc5e5e79bf64c5b18b6f7d8e.jpg  \n",
            " extracting: train/IMG-20180108-WA0108_jpg.rf.ee0061de23a91a8986a2b23ec387e24c.jpg  \n",
            " extracting: train/IMG-20180108-WA0109_jpg.rf.5fca97c9e64be57f94f8ec4a741e6057.jpg  \n",
            " extracting: train/IMG-20180108-WA0110_jpg.rf.8c6d62000b32c0164f9c85a32f8a11da.jpg  \n",
            " extracting: train/IMG-20180108-WA0112_jpg.rf.ff62583880de58edde4efa24d6a5d807.jpg  \n",
            " extracting: train/IMG-20180108-WA0114_jpg.rf.30534e1ca0d3160bfc92977ab4b70447.jpg  \n",
            " extracting: train/IMG-20180108-WA0116_jpg.rf.913013f102d7ede3b7f67af3d5bba190.jpg  \n",
            " extracting: train/IMG-20180108-WA0117_jpg.rf.fc6dcb6e2ff60ce877507ed2fa2a73db.jpg  \n",
            " extracting: train/IMG-20180108-WA0118_jpg.rf.e681dc6cb690c41d58b91449d41eafa3.jpg  \n",
            " extracting: train/IMG-20180108-WA0120_jpg.rf.620469e4416b208aa0e81f55cc723dfd.jpg  \n",
            " extracting: train/IMG-20180108-WA0121_jpg.rf.62ceb3fb201616285ea391df0e9dc68a.jpg  \n",
            " extracting: train/IMG-20211122-WA0006_jpg.rf.fbdd2474022d4c74bb97ee8e6bb3d57e.jpg  \n",
            " extracting: train/IMG-20211122-WA0007_jpg.rf.146a5801ccfa56fdab7f04219ae9f6a4.jpg  \n",
            " extracting: train/IMG-20211122-WA0008_jpg.rf.26b7c8375a43e7a339cac16acea92e51.jpg  \n",
            " extracting: train/IMG-20211122-WA0009_jpg.rf.2a963e88e1f5271539e13e0311cabb53.jpg  \n",
            " extracting: train/IMG-20211122-WA0010_jpg.rf.b8538880756e04159eb86f00e14c33b1.jpg  \n",
            " extracting: train/IMG-20211122-WA0011_jpg.rf.c8f648eec3ef1af652dd7482bbaf3863.jpg  \n",
            " extracting: train/IMG-20211122-WA0012_jpg.rf.6ced5a023b1e8d08eea9655c2e73381c.jpg  \n",
            " extracting: train/IMG-20211122-WA0013_jpg.rf.18692e89d84543c99ee900fdbd447285.jpg  \n",
            " extracting: train/IMG-20211122-WA0015_jpg.rf.d719acc7a4c8794128232a87abf7ac04.jpg  \n",
            " extracting: train/IMG-20211122-WA0017_jpg.rf.d00a9aee5728851152c606a4fa094d86.jpg  \n",
            " extracting: train/IMG-20211122-WA0018_jpg.rf.9532f1a73ec32143d8c92b97abd2870d.jpg  \n",
            " extracting: train/IMG-20211122-WA0019_jpg.rf.dbcbb91283e0e976861b67bfafc998e3.jpg  \n",
            " extracting: train/IMG-20211122-WA0020_jpg.rf.0899704ecb675e9730cab23f31b9f0d4.jpg  \n",
            " extracting: train/IMG-20211122-WA0022_jpg.rf.6d5ad74df2459eb13c4de42fda1203c0.jpg  \n",
            " extracting: train/IMG-20211122-WA0035_jpg.rf.b1ea24b8d0ca176f829b0d5242e75d75.jpg  \n",
            " extracting: train/IMG-20211122-WA0036_jpg.rf.0983d298929f3266d7af30ed63d52f27.jpg  \n",
            " extracting: train/IMG-20211122-WA0039_jpg.rf.2cd8fc849d4693a9ff848ff84abdf8c9.jpg  \n",
            " extracting: train/IMG-20211122-WA0040_jpg.rf.390ff680dbf171231b6bd8c4d3174c0f.jpg  \n",
            " extracting: train/IMG-20211122-WA0041_jpg.rf.a35e52eeaf9c52e3f90d99d8ce4fbbcf.jpg  \n",
            " extracting: train/IMG-20211122-WA0042_jpg.rf.995626adae6d9918d629cab64758b77b.jpg  \n",
            " extracting: train/IMG-20211122-WA0043_jpg.rf.abc219b455fade7d04960deab1744230.jpg  \n",
            " extracting: train/IMG-20211122-WA0044_jpg.rf.061358d688c696305e11e6384d8db4e9.jpg  \n",
            " extracting: train/IMG-20211122-WA0046_jpg.rf.d52f541834542dace442a9dcb19e111c.jpg  \n",
            " extracting: train/IMG-20211122-WA0047_jpg.rf.f9ef3082530024c06755aa345f18ada9.jpg  \n",
            " extracting: train/IMG-20211122-WA0048_jpg.rf.b27264facce411ff04d8d4f9c5b5988c.jpg  \n",
            " extracting: train/IMG-20211123-WA0020_jpg.rf.269c12e9e8a7980d9a02a4004acf2861.jpg  \n",
            " extracting: train/IMG-20220515-WA0055_jpg.rf.02ed39db26e180334c9d6682b91c4f5c.jpg  \n",
            " extracting: train/IMG-20220515-WA0055_jpg.rf.1265f878c2738a05afb44bd484c7ca61.jpg  \n",
            " extracting: train/IMG-20220517-WA0021_jpg.rf.4e37f5388a944da9d7a2d62579abfe6a.jpg  \n",
            " extracting: train/IMG-20220517-WA0021_jpg.rf.61779b23b52b131ba04b7f0cd0fae9e9.jpg  \n",
            " extracting: train/IMG_20220518_203051_jpg.rf.7a9f7a545d9e16f5df0e944fcbf4eb37.jpg  \n",
            " extracting: train/IMG_20220518_203105_jpg.rf.2a56a4f6e3f581fd9dfb315c0dd6cc80.jpg  \n",
            " extracting: train/IMG_20220518_203148_jpg.rf.c9eaa57699e9571531942cf1459e628d.jpg  \n",
            " extracting: train/IMG_20220518_203336_jpg.rf.cb7a449fc9a6cff1dae1ff06ce9017d5.jpg  \n",
            " extracting: train/IMG_20220518_203633_jpg.rf.12930935e7f00063efacbf805ea8d478.jpg  \n",
            " extracting: train/IMG_5890__flip_jpg.rf.ecc1f5d9a4719d4000fc5270e8a9c901.jpg  \n",
            " extracting: train/IMG_5892_jpg.rf.fef98f018a50e6b471b64e5ec2890cf7.jpg  \n",
            " extracting: train/IMG_5894_jpg.rf.92ce157568c8b78cb37e4f30b89c9cf7.jpg  \n",
            " extracting: train/IMG_5895_jpg.rf.c823ad55045c16edc5a5d672b8287c31.jpg  \n",
            " extracting: train/IMG_5898__flip_jpg.rf.0afdb3bb8b48f716aa5f2460088f6b7b.jpg  \n",
            " extracting: train/IMG_5899_jpg.rf.56d4df1ea98e8da23de6a1b9e45e992d.jpg  \n",
            " extracting: train/IMG_8354_jpg.rf.7b2afd1806bc88297bc43cfb8c6029b1.jpg  \n",
            " extracting: train/IMG_8372_jpg.rf.b5fbfceb88465bf197869d98b24d1096.jpg  \n",
            " extracting: train/IMG_8388_jpg.rf.02ebe5ebc0f4810952defb577df33370.jpg  \n",
            " extracting: train/IMG_8401_jpg.rf.43acbd3344363719c8e519270e42cbad.jpg  \n",
            " extracting: train/IMG_8409_jpg.rf.f3e275c3ff25958afa627666129cd37c.jpg  \n",
            " extracting: train/IMG_8417_jpg.rf.3d95c018bdc69f3d98e3c270c966a68f.jpg  \n",
            " extracting: train/IMG_8467_jpg.rf.385c02259f6425da605f3db6f05c8b23.jpg  \n",
            " extracting: train/IMG_8469_jpg.rf.8b44875d0320b280cbaa0eebbd040356.jpg  \n",
            " extracting: train/Image_013195_jpg.rf.2684e6c399a6e25cbbd0555ee81cb5ad.jpg  \n",
            " extracting: train/KB1081ON_jpg.rf.3f48d25d8fb3254c38f2bc9c8ea3f5f1.jpg  \n",
            " extracting: train/KB1081ON_jpg.rf.7c3e58545213457850f068b3fb29e942.jpg  \n",
            " extracting: train/L1072AAN-1-_jpg.rf.7e320d261e55cf55e034c63bb4049b19.jpg  \n",
            " extracting: train/L1090LY_jpg.rf.156c6d1833d988f2ae0581043f7c85df.jpg  \n",
            " extracting: train/L12UL_jpg.rf.10fb6228dad6274dfdaf9b469389b9c2.jpg  \n",
            " extracting: train/L12UL_jpg.rf.d26b4387a7f63b1788d3fb9a0bcd3d66.jpg  \n",
            " extracting: train/L1564CZ-1-_jpg.rf.1db8901c6e2014de5ad7014c87aed139.jpg  \n",
            " extracting: train/L1564CZ-1-_jpg.rf.653f29ebb43feaec08d1e26dabec81c2.jpg  \n",
            " extracting: train/L1604AE_jpg.rf.72a7d466a65487da199ec26c8fa3e3d6.jpg  \n",
            " extracting: train/L9069GJ_jpg.rf.ec35f76c88b5194e4f0fc865b5702b3a.jpg  \n",
            " extracting: train/Mobil-10-_jpg.rf.b436e5f612c34c415f778ea28a82c62f.jpg  \n",
            " extracting: train/Mobil-102-_jpg.rf.a037b7077d7e78bcd2a1a63c2ccc6519.jpg  \n",
            " extracting: train/Mobil-103-_jpg.rf.78a9bbd33001832161f38029dcde5784.jpg  \n",
            " extracting: train/Mobil-105-_jpg.rf.ac61ee38698de30357f2e4bcb273ad06.jpg  \n",
            " extracting: train/Mobil-106-_jpg.rf.7b812fb8cc42591a7046d550607d1d6f.jpg  \n",
            " extracting: train/Mobil-107-_jpg.rf.0c06ab460bbcaf7148ce0140ba4f53db.jpg  \n",
            " extracting: train/Mobil-108-_jpg.rf.d776796e38ce6b35f5fd47be97698b87.jpg  \n",
            " extracting: train/Mobil-11-_jpg.rf.d805c754d37be05f191865d539d7b2a1.jpg  \n",
            " extracting: train/Mobil-110-_jpg.rf.58a8ca667909340ad3f69d3f2e3109d9.jpg  \n",
            " extracting: train/Mobil-111-_jpg.rf.13149f74e2d2cbfd9c4324896e1e318e.jpg  \n",
            " extracting: train/Mobil-112-_jpg.rf.057a19da9ddbb41ee17488653ee315cb.jpg  \n",
            " extracting: train/Mobil-113-_jpg.rf.cd53871c2d22d5108623ab5954873f81.jpg  \n",
            " extracting: train/Mobil-114-_jpg.rf.9ebc39ade0f94a8d997554ff67fddc9d.jpg  \n",
            " extracting: train/Mobil-115-_jpg.rf.585eecee4edd26c6114f589b83aee207.jpg  \n",
            " extracting: train/Mobil-116-_jpg.rf.7e5c1f8f68403c0f6a02c5b2360d5d6c.jpg  \n",
            " extracting: train/Mobil-117-_jpg.rf.edce1ff9c9b83a84a580c482d9e2a259.jpg  \n",
            " extracting: train/Mobil-118-_jpg.rf.0be3b05521ce5667da3a30436871923c.jpg  \n",
            " extracting: train/Mobil-119-_jpg.rf.5e02ac58d53abae62382610da2873be2.jpg  \n",
            " extracting: train/Mobil-120-_jpg.rf.3e066ed03eca34719937fc5dbbeacec9.jpg  \n",
            " extracting: train/Mobil-124-_jpg.rf.c0cf7de9b73fe3d6169fd701aafe096d.jpg  \n",
            " extracting: train/Mobil-125-_jpg.rf.511e594f18beb270637a976dbe2864cd.jpg  \n",
            " extracting: train/Mobil-127-_jpg.rf.a987536b66ecc8869398e209b58397af.jpg  \n",
            " extracting: train/Mobil-128-_jpg.rf.3298b87456d5c69e7891adb6896eea1d.jpg  \n",
            " extracting: train/Mobil-13-_jpg.rf.f9b89bb1be444cbf979c08c08cdc4803.jpg  \n",
            " extracting: train/Mobil-131-_jpg.rf.751ce1133321aa53efd3bd09c32ffdbd.jpg  \n",
            " extracting: train/Mobil-132-_jpg.rf.fa518cd5a264429098b0dcf68ba4d634.jpg  \n",
            " extracting: train/Mobil-133-_jpg.rf.3f95d9dd6dc081322c5c8096ef15742c.jpg  \n",
            " extracting: train/Mobil-134-_jpg.rf.ab0db4abf1e448f55d9abdbd010993cf.jpg  \n",
            " extracting: train/Mobil-135-_jpg.rf.465ca150d4a669ca936ff73ca9a1b7ae.jpg  \n",
            " extracting: train/Mobil-136-_jpg.rf.abe980c433ec6720c340a9d7c3535781.jpg  \n",
            " extracting: train/Mobil-138-_jpg.rf.04998c6c2d3f7c82ddd4f4622d680e8a.jpg  \n",
            " extracting: train/Mobil-139-_jpg.rf.98e082322ad7b5db806a0170745f2582.jpg  \n",
            " extracting: train/Mobil-140-_jpg.rf.65701d0a0b1627caf3ac57bf037cc9d5.jpg  \n",
            " extracting: train/Mobil-141-_jpg.rf.c389dadc10afd64c5ee5f71337641aef.jpg  \n",
            " extracting: train/Mobil-142-_jpg.rf.6d9f8425aed5c97cfa43140c9a0e2773.jpg  \n",
            " extracting: train/Mobil-144-_jpg.rf.2ca2037d08c8d870db3fcf3a70e3c584.jpg  \n",
            " extracting: train/Mobil-145-_jpg.rf.03b5b701268d2f38757c61d8217a032b.jpg  \n",
            " extracting: train/Mobil-149-_jpg.rf.a17b9e232531a332f2a3d86ba64bfbb9.jpg  \n",
            " extracting: train/Mobil-150-_jpg.rf.953631d3a4f93bb1ee641a561f910b4e.jpg  \n",
            " extracting: train/Mobil-151-_jpg.rf.eba11b69900edec56f9b060ace7790d7.jpg  \n",
            " extracting: train/Mobil-152-_jpg.rf.8ef5b6058bedd305b1c60bc10605b16a.jpg  \n",
            " extracting: train/Mobil-154-_jpg.rf.c0ac0bd74fbbead80e16cc040c7ddd90.jpg  \n",
            " extracting: train/Mobil-155-_jpg.rf.8884aec304f28100d337bc9f7062a56e.jpg  \n",
            " extracting: train/Mobil-156-_jpg.rf.981e5859b8b05fab53cd2eee5494fad2.jpg  \n",
            " extracting: train/Mobil-157-_jpg.rf.007d0c555d5834f07c1a3fad2f0451ad.jpg  \n",
            " extracting: train/Mobil-159-_jpg.rf.13eab0d8fc206f6a02d60bfefcb4d4f4.jpg  \n",
            " extracting: train/Mobil-16-_jpg.rf.c2507bb76450d0a66d8a4f46a1cbce18.jpg  \n",
            " extracting: train/Mobil-160-_jpg.rf.11b398a685b288d5d16fc3fdf2a93c5a.jpg  \n",
            " extracting: train/Mobil-162-_jpg.rf.f8ccaef8e25ccdb4261ed22bb81df36d.jpg  \n",
            " extracting: train/Mobil-163-_jpg.rf.8c7600e83cf0085210d7e7a86bff79ce.jpg  \n",
            " extracting: train/Mobil-164-_jpg.rf.f730dbd1b10413b24afc30fc3d15db57.jpg  \n",
            " extracting: train/Mobil-165-_jpg.rf.502d00d24953e3cf06da98567cfab3dd.jpg  \n",
            " extracting: train/Mobil-166-_jpg.rf.576bc44e3fb94708debfc17328ea9d30.jpg  \n",
            " extracting: train/Mobil-169-_jpg.rf.696c138d7b16916db7003ba0ecbbdaef.jpg  \n",
            " extracting: train/Mobil-17-_jpg.rf.051e1b68d47e623bca27cbfbc96fb9e2.jpg  \n",
            " extracting: train/Mobil-170-_jpg.rf.a3d12be26696275ca298791c83486123.jpg  \n",
            " extracting: train/Mobil-171-_jpg.rf.ce7af88601da3aa5c5097bda69f941e3.jpg  \n",
            " extracting: train/Mobil-175-_jpg.rf.e1297c9ca3bc3df713394dd1f26fc2c0.jpg  \n",
            " extracting: train/Mobil-176-_jpg.rf.130ec9cd4647a429b764bf55f51daa26.jpg  \n",
            " extracting: train/Mobil-177-_jpg.rf.7def497ad1ee68a8a192d99dca9f5e46.jpg  \n",
            " extracting: train/Mobil-178-_jpg.rf.d4bc8bb5deeb9d779259076dbc652c9e.jpg  \n",
            " extracting: train/Mobil-179-_jpg.rf.0f911406fe71d1304e5a09e09c26ff83.jpg  \n",
            " extracting: train/Mobil-18-_jpg.rf.20d5e3d0ec0ea3c6ef7999b27d81f174.jpg  \n",
            " extracting: train/Mobil-180-_jpg.rf.12fa7304b090988a780838703d75187b.jpg  \n",
            " extracting: train/Mobil-181-_jpg.rf.f7b565449813e0a589f14ce9dd16da59.jpg  \n",
            " extracting: train/Mobil-182-_jpg.rf.4e2dc681b11c6ee684b5e28177632094.jpg  \n",
            " extracting: train/Mobil-183-_jpg.rf.46b96c1deab13ea48bd8b2c888c44c67.jpg  \n",
            " extracting: train/Mobil-185-_jpg.rf.45a29bb13dad37d9f2c07930b7184ee5.jpg  \n",
            " extracting: train/Mobil-186-_jpg.rf.8a13f9d5015b4e6dfd63aa1df3102a52.jpg  \n",
            " extracting: train/Mobil-19-_jpg.rf.f54d657d8115becd689f2a67a5a3a58f.jpg  \n",
            " extracting: train/Mobil-191-_jpg.rf.bc8de7ff32f0bf334dc86554a5f0e7a4.jpg  \n",
            " extracting: train/Mobil-192-_jpg.rf.e7d9bdef4f789683c8692b44ac8dfa0a.jpg  \n",
            " extracting: train/Mobil-193-_jpg.rf.51e8868abb53022b6eb514ed1543e011.jpg  \n",
            " extracting: train/Mobil-196-_jpg.rf.867cb65989e4e0c78ed9b41e2a1f67a0.jpg  \n",
            " extracting: train/Mobil-197-_jpg.rf.59dca7305fb6eb13eeffb8f3887a0db5.jpg  \n",
            " extracting: train/Mobil-198-_jpg.rf.2a88710a8de00e52549b3baab075f47f.jpg  \n",
            " extracting: train/Mobil-199-_jpg.rf.d1a79c3be8ba19bd39fb11d63a6f7eba.jpg  \n",
            " extracting: train/Mobil-2-_jpg.rf.0c3377b04db30e0e1b1896a3737dcad1.jpg  \n",
            " extracting: train/Mobil-20-_jpg.rf.64d77de76e5fcbfb7ef3213d7abccddb.jpg  \n",
            " extracting: train/Mobil-201-_jpg.rf.7aeb3c7b74e9da70163ea87f2aa96ac0.jpg  \n",
            " extracting: train/Mobil-202-_jpg.rf.9b29b24c8487c1b90d7ae4c8ac15e963.jpg  \n",
            " extracting: train/Mobil-203-_jpg.rf.084a37c78837b2f04eb435a3e1ad0709.jpg  \n",
            " extracting: train/Mobil-204-_jpg.rf.3d67c8562c72f27b19a0d034df6e182f.jpg  \n",
            " extracting: train/Mobil-205-_jpg.rf.36689dc0cfd886b098190d11bf482526.jpg  \n",
            " extracting: train/Mobil-206-_jpg.rf.d08fdb32852c77ef081d55da8a68ac3f.jpg  \n",
            " extracting: train/Mobil-207-_jpg.rf.299e1ec00ed9b36f5335f5ef2b3b5186.jpg  \n",
            " extracting: train/Mobil-209-_jpg.rf.36dd3e2eac6395cab4b0fb4de1b925ca.jpg  \n",
            " extracting: train/Mobil-21-_jpg.rf.4ede8639273ee8261df6bdfe65aeb2e9.jpg  \n",
            " extracting: train/Mobil-210-_jpg.rf.78e67f8a8f711861b1da7362028c4df5.jpg  \n",
            " extracting: train/Mobil-211-_jpg.rf.5b5fa137241d2c792d84edafa9cd7172.jpg  \n",
            " extracting: train/Mobil-212-_jpg.rf.e76021d1e44a557ff01e5d69d857e721.jpg  \n",
            " extracting: train/Mobil-214-_jpg.rf.48669d5bc3ed1ebfa806838ee6680a2c.jpg  \n",
            " extracting: train/Mobil-215-_jpg.rf.f92e4b952cbfe4c601d3494e36e49313.jpg  \n",
            " extracting: train/Mobil-216-_jpg.rf.165429663924694caa707d3840668e3b.jpg  \n",
            " extracting: train/Mobil-217-_jpg.rf.d6a26076cbe40c80ae4efd726318b584.jpg  \n",
            " extracting: train/Mobil-219-_jpg.rf.d4ef94c1c2d4bec48f263b4962fcfae0.jpg  \n",
            " extracting: train/Mobil-220-_jpg.rf.4cfdfa739b9b96c51fe2cd8f13a3a7d4.jpg  \n",
            " extracting: train/Mobil-221-_jpg.rf.113e11eac40b8a6b51d1c22f40110590.jpg  \n",
            " extracting: train/Mobil-222-_jpg.rf.3596ac33e8893321246f597812d7cf4a.jpg  \n",
            " extracting: train/Mobil-223-_jpg.rf.4d50bd7f556ae4d73033aa0a0b9e5178.jpg  \n",
            " extracting: train/Mobil-225-_jpg.rf.4c4c721ed97a70f88bec25aaee0f3134.jpg  \n",
            " extracting: train/Mobil-227-_jpg.rf.f72c5fdf1f1b7a972a5b15cb06bba0b4.jpg  \n",
            " extracting: train/Mobil-228-_jpg.rf.8a379ad7fb8ebfe11fc1d8a77e12fb14.jpg  \n",
            " extracting: train/Mobil-229-_jpg.rf.581085b941f72e4340dd1b99bac624a4.jpg  \n",
            " extracting: train/Mobil-230-_jpg.rf.d55c9ff4ae7eb6b81ef7a98544ae87f8.jpg  \n",
            " extracting: train/Mobil-232-_jpg.rf.28ad1b989e8d4a1dc37c71252a63edde.jpg  \n",
            " extracting: train/Mobil-234-_jpg.rf.3ac9bad197b615fed19cc8d3b8435d11.jpg  \n",
            " extracting: train/Mobil-235-_jpg.rf.92050fe571a5d8d603b00f1a0a1d4e62.jpg  \n",
            " extracting: train/Mobil-236-_jpg.rf.d00bbfc8fa87a57a4092c4f70fcb99f5.jpg  \n",
            " extracting: train/Mobil-237-_jpg.rf.9121e3ac6ebc4488f995aaed11562b8e.jpg  \n",
            " extracting: train/Mobil-239-_jpg.rf.aeb882cdff46652c1709fe3c925416bb.jpg  \n",
            " extracting: train/Mobil-240-_jpg.rf.933c020db5203e7a79fa59db10e04ddd.jpg  \n",
            " extracting: train/Mobil-241-_jpg.rf.2e4d012b91a77bbcb1382bcc8dd50287.jpg  \n",
            " extracting: train/Mobil-242-_jpg.rf.66f549afd2ddb75fa51c96637b136057.jpg  \n",
            " extracting: train/Mobil-243-_jpg.rf.975c580d1aeba92c84084112cd9bbec8.jpg  \n",
            " extracting: train/Mobil-244-_jpg.rf.b2f779031a669416fb387e396b632621.jpg  \n",
            " extracting: train/Mobil-248-_jpg.rf.57ce99d6c92aacb2984e52eb0dc006c8.jpg  \n",
            " extracting: train/Mobil-249-_jpg.rf.82be795f440fc9be8f925e274d2bfad0.jpg  \n",
            " extracting: train/Mobil-25-_jpg.rf.49cfd55dba33fe96c08840500a8da65f.jpg  \n",
            " extracting: train/Mobil-250-_jpg.rf.824d5ee974d876ada1f597e5d6715a1f.jpg  \n",
            " extracting: train/Mobil-254-_jpg.rf.f3bf6d8846127be5507ae789aa618079.jpg  \n",
            " extracting: train/Mobil-256-_jpg.rf.0abd4ef543bdb51f2f0c2a15b41b1436.jpg  \n",
            " extracting: train/Mobil-258-_jpg.rf.99a7a32d05529f29bb9140a3b7132266.jpg  \n",
            " extracting: train/Mobil-26-_jpg.rf.7961ae5894306109f5f91c71d77019b6.jpg  \n",
            " extracting: train/Mobil-260-_jpg.rf.3b9080ee3fc0eee185490dcb06569f08.jpg  \n",
            " extracting: train/Mobil-261-_jpg.rf.78fa6aa4dc0c0f9e0667670a94e58f2d.jpg  \n",
            " extracting: train/Mobil-262-_jpg.rf.1dc106f80e44f37566f237abe7a5bd27.jpg  \n",
            " extracting: train/Mobil-263-_jpg.rf.936f98b7570d6e5de4db0cbd5e5cff17.jpg  \n",
            " extracting: train/Mobil-264-_jpg.rf.28da753c7ce01de8cc71d442a8024354.jpg  \n",
            " extracting: train/Mobil-267-_jpg.rf.5f5aa6b07a7443262443abfc6626bf14.jpg  \n",
            " extracting: train/Mobil-269-_jpg.rf.91cfc563081cfa653d2ffa127c79d749.jpg  \n",
            " extracting: train/Mobil-27-_jpg.rf.9c651acd6a4a485e67148327985996d4.jpg  \n",
            " extracting: train/Mobil-270-_jpg.rf.eb95f928a7d6b258ce7fa779c07f1fa2.jpg  \n",
            " extracting: train/Mobil-271-_jpg.rf.4da0fcd54420aee29a2cf13346576702.jpg  \n",
            " extracting: train/Mobil-272-_jpg.rf.e3f697f2e6dec71e0e27d4b278716844.jpg  \n",
            " extracting: train/Mobil-273-_jpg.rf.60525c85b9b11b044bdd9e3f62309292.jpg  \n",
            " extracting: train/Mobil-274-_jpg.rf.39a83e0252ae0e57e179f55f493d403b.jpg  \n",
            " extracting: train/Mobil-276-_jpg.rf.2d550e6f798cbebeb402fe09a3ddcd2f.jpg  \n",
            " extracting: train/Mobil-277-_jpg.rf.41b58672611944ecd2f58fd6ef9d2f80.jpg  \n",
            " extracting: train/Mobil-278-_jpg.rf.1d369aa73d713950ef1b9fa3f6cd452b.jpg  \n",
            " extracting: train/Mobil-279-_jpg.rf.c437892641bb4452c444a2889af0be6d.jpg  \n",
            " extracting: train/Mobil-281-_jpg.rf.160c0952b54d24e1378c492b403f9e2c.jpg  \n",
            " extracting: train/Mobil-283-_jpg.rf.9b65c969476644eb9ffb61bcced695b5.jpg  \n",
            " extracting: train/Mobil-284-_jpg.rf.3f9ba9c807eeee0a761f26633b5a274c.jpg  \n",
            " extracting: train/Mobil-285-_jpg.rf.c229e950e998e243348e2fbfb900e287.jpg  \n",
            " extracting: train/Mobil-286-_jpg.rf.fd134ddd0025b610eb16923043cbd6a3.jpg  \n",
            " extracting: train/Mobil-287-_jpg.rf.0c9defc4fc8c6e3f4eb6a3eaacc5d0db.jpg  \n",
            " extracting: train/Mobil-289-_jpg.rf.29ec01758b1a6aee01687dac083826a6.jpg  \n",
            " extracting: train/Mobil-29-_jpg.rf.36d03433818a108ed340ab0f9dbcc7e4.jpg  \n",
            " extracting: train/Mobil-291-_jpg.rf.76d09359e0eb249dfa9f0fb56340f0a5.jpg  \n",
            " extracting: train/Mobil-292-_jpg.rf.7166e5e0042c41d7a0e3841a76d29176.jpg  \n",
            " extracting: train/Mobil-293-_jpg.rf.d10ce6192bcc0f2f57f0707fa3f1c187.jpg  \n",
            " extracting: train/Mobil-294-_jpg.rf.e6edbbb0ded8898a852d7d935945dfc7.jpg  \n",
            " extracting: train/Mobil-295-_jpg.rf.9a8c84d11f135c3f525244473a64d035.jpg  \n",
            " extracting: train/Mobil-296-_jpg.rf.2fcae7e93dbb92d3bd13d501ca5e1bcd.jpg  \n",
            " extracting: train/Mobil-297-_jpg.rf.654f4ed4ccd33d5e63a22800e6266752.jpg  \n",
            " extracting: train/Mobil-298-_jpg.rf.ea882be608e1448a737e14c3277baadc.jpg  \n",
            " extracting: train/Mobil-301-_jpg.rf.aebae25d6d44bb5f347048bb769fb69e.jpg  \n",
            " extracting: train/Mobil-302-_jpg.rf.d312745495ff49c63920e21610f6698c.jpg  \n",
            " extracting: train/Mobil-304-_jpg.rf.ffe7ea961ba08909d3946776055dd8bc.jpg  \n",
            " extracting: train/Mobil-306-_jpg.rf.fef77a12d15f55008bbcaa96fcbe747b.jpg  \n",
            " extracting: train/Mobil-307-_jpg.rf.271bddc3c63bab49b5a031828f567389.jpg  \n",
            " extracting: train/Mobil-308-_jpg.rf.07cd7ed40b87bc2266090012bce3f880.jpg  \n",
            " extracting: train/Mobil-31-_jpg.rf.2adc32c078d445310ab8a6a16eff90d6.jpg  \n",
            " extracting: train/Mobil-310-_jpg.rf.0af8dc80f36a671033124e7f478c7cf9.jpg  \n",
            " extracting: train/Mobil-311-_jpg.rf.258a8c5c9fd03e03bb25c736ddf74fe1.jpg  \n",
            " extracting: train/Mobil-314-_jpg.rf.3ce685755b221289f7c9e7529888a51f.jpg  \n",
            " extracting: train/Mobil-315-_jpg.rf.6a820e91c353db05f1e5cb85b0598477.jpg  \n",
            " extracting: train/Mobil-316-_jpg.rf.1f34fa4402542c328a863a685a69a7af.jpg  \n",
            " extracting: train/Mobil-317-_jpg.rf.243f9d47fdf245a0e559b4e0140cee1f.jpg  \n",
            " extracting: train/Mobil-318-_jpg.rf.7879130b5fc8b5c37ca0665e6913aee8.jpg  \n",
            " extracting: train/Mobil-319-_jpg.rf.ac10b4e36e732830423d3101cc756896.jpg  \n",
            " extracting: train/Mobil-320-_jpg.rf.4c2658d1d49f6019195cde725db2974d.jpg  \n",
            " extracting: train/Mobil-321-_jpg.rf.e1f6fb656fa5fb7e09cadcb27e041660.jpg  \n",
            " extracting: train/Mobil-322-_jpg.rf.e368c2344acae70b2052329452077a86.jpg  \n",
            " extracting: train/Mobil-323-_jpg.rf.bce973b5c75321d070b019caa102b241.jpg  \n",
            " extracting: train/Mobil-324-_jpg.rf.a618de464b94ccb39f8a59a44fe24d03.jpg  \n",
            " extracting: train/Mobil-325-_jpg.rf.72735bc8180abcf4ea34bd971c795ae8.jpg  \n",
            " extracting: train/Mobil-326-_jpg.rf.7a3e08631f02c772f0bc2af09d8c74c9.jpg  \n",
            " extracting: train/Mobil-327-_jpg.rf.61fbc8ea89dfd989fce3733d671e999d.jpg  \n",
            " extracting: train/Mobil-330-_jpg.rf.fcc915c06489589a631aa22ca49786a6.jpg  \n",
            " extracting: train/Mobil-331-_jpg.rf.724ee7865ae9adb274d54c03caa64385.jpg  \n",
            " extracting: train/Mobil-332-_jpg.rf.6855c3e9e8f3ed49b2defd34d8360894.jpg  \n",
            " extracting: train/Mobil-333-_jpg.rf.327a709d25840da7af1dd84cca04d8a2.jpg  \n",
            " extracting: train/Mobil-335-_jpg.rf.b334ceaaaf9c90785a1791d04d9a1cc5.jpg  \n",
            " extracting: train/Mobil-338-_jpg.rf.1bde9cc69ed2664f2174a77898b53fb8.jpg  \n",
            " extracting: train/Mobil-339-_jpg.rf.5b441bc6cfaa1c97b11c1c4e27932cd8.jpg  \n",
            " extracting: train/Mobil-34-_jpg.rf.389f2d6037637d8e837c43a7fa867200.jpg  \n",
            " extracting: train/Mobil-340-_jpg.rf.8368e9deeadf6d6c9f91ae8542bdd20e.jpg  \n",
            " extracting: train/Mobil-342-_jpg.rf.c9eb3e6e05afd63eef5b6fcaf0216be1.jpg  \n",
            " extracting: train/Mobil-343-_jpg.rf.6c776ea34cef5324d48d74a386cf3a55.jpg  \n",
            " extracting: train/Mobil-345-_jpg.rf.430f4939626308d730ddf440e146ecfc.jpg  \n",
            " extracting: train/Mobil-347-_jpg.rf.3af04eb89e6668560f973ce4c3c3bd25.jpg  \n",
            " extracting: train/Mobil-348-_jpg.rf.6117ba52869fc1196ca395993986f41e.jpg  \n",
            " extracting: train/Mobil-350-_jpg.rf.3d475edae6ebbbc64f8473a03334ff4a.jpg  \n",
            " extracting: train/Mobil-351-_jpg.rf.e2f32f0963275ce1b6669d1bb4048f1e.jpg  \n",
            " extracting: train/Mobil-353-_jpg.rf.026359150e8b2d4902d5565a325d0a49.jpg  \n",
            " extracting: train/Mobil-354-_jpg.rf.cd9133028194897fbbead4407673105b.jpg  \n",
            " extracting: train/Mobil-356-_jpg.rf.7093ddc03116a174da9843b44df4d292.jpg  \n",
            " extracting: train/Mobil-357-_jpg.rf.c2791ed044bcc76f735d0a1fda45dd25.jpg  \n",
            " extracting: train/Mobil-358-_jpg.rf.3233ddf29c6ad9001c83a105140ab249.jpg  \n",
            " extracting: train/Mobil-359-_jpg.rf.fbf6c76523c787b93b9078c88d01992d.jpg  \n",
            " extracting: train/Mobil-36-_jpg.rf.e319d7e68c6847c8ffc63056626c1267.jpg  \n",
            " extracting: train/Mobil-361-_jpg.rf.55eb200a48fa5704113f456b489c2410.jpg  \n",
            " extracting: train/Mobil-362-_jpg.rf.5c7a159d1649f56f65e64d6ce7b30c67.jpg  \n",
            " extracting: train/Mobil-363-_jpg.rf.b7645ea4bb168445eb81e9a9a25bd34c.jpg  \n",
            " extracting: train/Mobil-365-_jpg.rf.a70d41f3f3c16bd1842e4788a4f7410a.jpg  \n",
            " extracting: train/Mobil-366-_jpg.rf.6f1830c77fab8690c26128b902c779c3.jpg  \n",
            " extracting: train/Mobil-367-_jpg.rf.621d1bae0314efd4b84c493528e8b925.jpg  \n",
            " extracting: train/Mobil-368-_jpg.rf.a23ba7bb160e47ac61ace1b234600afc.jpg  \n",
            " extracting: train/Mobil-369-_jpg.rf.3966a8543f80df7b5989f13c863afb70.jpg  \n",
            " extracting: train/Mobil-37-_jpg.rf.e5ec30b50ab8a41b8d28772f8395bc3d.jpg  \n",
            " extracting: train/Mobil-370-_jpg.rf.ab46f3e008813baf82dcb9e80ba21621.jpg  \n",
            " extracting: train/Mobil-372-_jpg.rf.aae61b7d441b326dd924579f35d848a7.jpg  \n",
            " extracting: train/Mobil-374-_jpg.rf.a05999a805f6cb9a811ed2dddaf79774.jpg  \n",
            " extracting: train/Mobil-375-_jpg.rf.43ad4d8e438beb8073e812562d93ab2a.jpg  \n",
            " extracting: train/Mobil-38-_jpg.rf.995b271729886446b17d26eacef13520.jpg  \n",
            " extracting: train/Mobil-39-_jpg.rf.cbd224191a3d618c9ad8bc69f9b5ebed.jpg  \n",
            " extracting: train/Mobil-4-_jpg.rf.e309e1f3b22a7cb6157147113b0564a1.jpg  \n",
            " extracting: train/Mobil-40-_jpg.rf.99246ea303b885637cf7104362ad4ee0.jpg  \n",
            " extracting: train/Mobil-41-_jpg.rf.760554dfd99766ab653ce520da780899.jpg  \n",
            " extracting: train/Mobil-42-_jpg.rf.85d0427eb4a3b8f415f3d5c9124bbb95.jpg  \n",
            " extracting: train/Mobil-44-_jpg.rf.91dea2a121723e19c2ddfdafc28ff3f7.jpg  \n",
            " extracting: train/Mobil-47-_jpg.rf.60c17d12d31a6cdbba1ed1cff906da45.jpg  \n",
            " extracting: train/Mobil-48-_jpg.rf.d50bfcdc24fabfcd613243843adea722.jpg  \n",
            " extracting: train/Mobil-49-_jpg.rf.f5c0ab8250416b22a69ad6b0e9c4a43d.jpg  \n",
            " extracting: train/Mobil-5-_jpg.rf.a7612efd0f91b87fc105fb66bf36d1aa.jpg  \n",
            " extracting: train/Mobil-50-_jpg.rf.33ca56af79530b69fd672be2028da0bb.jpg  \n",
            " extracting: train/Mobil-51-_jpg.rf.6f13676dacefaa73b1935e61b1d991c6.jpg  \n",
            " extracting: train/Mobil-52-_jpg.rf.6b9c095c52d31fabbbb39537d57a4a02.jpg  \n",
            " extracting: train/Mobil-53-_jpg.rf.4a21ac90a4e74cc794da3d5b1fceeafb.jpg  \n",
            " extracting: train/Mobil-54-_jpg.rf.61797ba01375609f100fea8755384da0.jpg  \n",
            " extracting: train/Mobil-56-_jpg.rf.5da73adb6b00445d70af6d9b117bc933.jpg  \n",
            " extracting: train/Mobil-57-_jpg.rf.6ec3512f9cc91efd959b5f34ff0e6ac5.jpg  \n",
            " extracting: train/Mobil-60-_jpg.rf.32778285bd15deb345f28dd5a3b2b891.jpg  \n",
            " extracting: train/Mobil-62-_jpg.rf.b201c88e858ffbce534569da4c58f1fc.jpg  \n",
            " extracting: train/Mobil-63-_jpg.rf.1bd907908705583555a029d904cc3418.jpg  \n",
            " extracting: train/Mobil-65-_jpg.rf.bffdbaaf1d600581e606bfe90e74e1cb.jpg  \n",
            " extracting: train/Mobil-68-_jpg.rf.f01b46a2c1bf3fd06bb76155a95e7b7b.jpg  \n",
            " extracting: train/Mobil-69-_jpg.rf.f2f5129e2d85259085bd4be096da04e4.jpg  \n",
            " extracting: train/Mobil-7-_jpg.rf.b5fbf56d35f945e2afa11611e4e489b7.jpg  \n",
            " extracting: train/Mobil-71-_jpg.rf.1c022b0e57cad8c0d3fc1d340cf88c03.jpg  \n",
            " extracting: train/Mobil-74-_jpg.rf.d5c788ea98e32ba7f5f890d258ff6054.jpg  \n",
            " extracting: train/Mobil-75-_jpg.rf.99bbe93feb69fc862f26cd46c29e802b.jpg  \n",
            " extracting: train/Mobil-77-_jpg.rf.71e10f962859fbb76c41073e663ea03d.jpg  \n",
            " extracting: train/Mobil-78-_jpg.rf.314b8b0290cd539c55c821dc09975fa6.jpg  \n",
            " extracting: train/Mobil-79-_jpg.rf.e80b634901e1bc2c384f87681c556f6a.jpg  \n",
            " extracting: train/Mobil-8-_jpg.rf.db26347fb6b9d052aa9bbe167747b284.jpg  \n",
            " extracting: train/Mobil-80-_jpg.rf.e15ce11ff1b24c89778d65507efaa329.jpg  \n",
            " extracting: train/Mobil-81-_jpg.rf.be99d6dbeb8cad9572545a3a8f27dea4.jpg  \n",
            " extracting: train/Mobil-82-_jpg.rf.9bcb96168a4758d9bf0b00c9a0483b0e.jpg  \n",
            " extracting: train/Mobil-84-_jpg.rf.bc3a0a0a244f0a034ab4a32db7b80fd5.jpg  \n",
            " extracting: train/Mobil-85-_jpg.rf.443da989601575da1de66dee3db35cda.jpg  \n",
            " extracting: train/Mobil-86-_jpg.rf.b41f3a8b2da4ede547487658cd0bc1c3.jpg  \n",
            " extracting: train/Mobil-89-_jpg.rf.17aa8c5c11b41da9f93074fa65206da4.jpg  \n",
            " extracting: train/Mobil-9-_jpg.rf.0796c48d940b8333cd016218153a8bb9.jpg  \n",
            " extracting: train/Mobil-91-_jpg.rf.e4d8dea1320ec6fe2acd50c3f28f14e1.jpg  \n",
            " extracting: train/Mobil-92-_jpg.rf.daa8be8c23c8f0e32baf1ed9b5c5d137.jpg  \n",
            " extracting: train/Mobil-94-_jpg.rf.6cddd0779a36897f1b0538acdff4a04b.jpg  \n",
            " extracting: train/Mobil-96-_jpg.rf.fb31818ceb497a8579270bd1008c6fd5.jpg  \n",
            " extracting: train/Mobil-97-_jpg.rf.4d0d61c08fdd86a3f7d1cf3b3c34f961.jpg  \n",
            " extracting: train/Mobil-98-_jpg.rf.11b13af99bf406a384a6389691aeccdb.jpg  \n",
            " extracting: train/Motor-1-_jpg.rf.1168991bfb8fe9dc63d59b27de93f0de.jpg  \n",
            " extracting: train/Motor-101-_jpg.rf.e2081c7c0ea6fe05e78ac03e044e5e2f.jpg  \n",
            " extracting: train/Motor-102-_jpg.rf.f3d43856f9b084a4189c0245b4aef979.jpg  \n",
            " extracting: train/Motor-104-_jpg.rf.73833cac6d761089e254157c745d252b.jpg  \n",
            " extracting: train/Motor-105-_jpg.rf.4bc4b562e49927e6f14aacd4671b8180.jpg  \n",
            " extracting: train/Motor-106-_jpg.rf.501d890610bd69e5fa19f0880f87cc3c.jpg  \n",
            " extracting: train/Motor-107-_jpg.rf.231b7861b9a9cca3143cf60211da9117.jpg  \n",
            " extracting: train/Motor-108-_jpg.rf.14fffad03ef9b3cafd751288ba97e6c7.jpg  \n",
            " extracting: train/Motor-109-_jpg.rf.43af6f05830933f73c3f1d683e3eea7e.jpg  \n",
            " extracting: train/Motor-110-_jpg.rf.2809a2f2c961513ce440f98812e30944.jpg  \n",
            " extracting: train/Motor-111-_jpg.rf.9a4cb37c1575ae4cbe527aa30871fda2.jpg  \n",
            " extracting: train/Motor-113-_jpg.rf.0ad0e0b7db784befb857d20226e9ed32.jpg  \n",
            " extracting: train/Motor-114-_jpg.rf.a7afdea2c06a7f018955d6f4a1343731.jpg  \n",
            " extracting: train/Motor-115-_jpg.rf.dec3eb6944a874bb5648dc38a6729879.jpg  \n",
            " extracting: train/Motor-119-_jpg.rf.896555c28720c9543e775afc341427d7.jpg  \n",
            " extracting: train/Motor-12-_jpg.rf.dc3f6458731177b10db0792f0bd69585.jpg  \n",
            " extracting: train/Motor-120-_jpg.rf.2882b11580e876af49c07bb7cb582549.jpg  \n",
            " extracting: train/Motor-122-_jpg.rf.d9519d01fd49c51e8ecad21fab47df14.jpg  \n",
            " extracting: train/Motor-123-_jpg.rf.72fe10be11e6dc2a2c4c868e4e09cbbe.jpg  \n",
            " extracting: train/Motor-125-_jpg.rf.28b1a5dcc52e606449de39d8a3c28928.jpg  \n",
            " extracting: train/Motor-126-_jpg.rf.ec949fa1a423d3eed5921a958278c230.jpg  \n",
            " extracting: train/Motor-127-_jpg.rf.101302c02fc79629a6a6682a14ddcf19.jpg  \n",
            " extracting: train/Motor-13-_jpg.rf.ba884e697e8b1807a65274827c86a1ed.jpg  \n",
            " extracting: train/Motor-132-_jpg.rf.d42454ad7aac855561427e7e35a5595c.jpg  \n",
            " extracting: train/Motor-133-_jpg.rf.58d3b6eebd671a573952f0ee1779dc93.jpg  \n",
            " extracting: train/Motor-136-_jpg.rf.3fed4358abfdf5f5a3e3c0e45f6defdf.jpg  \n",
            " extracting: train/Motor-137-_jpg.rf.5ca711d645f48e472c9eb03f5c8d3e86.jpg  \n",
            " extracting: train/Motor-138-_jpg.rf.ed0c1972e55f7c6af697a87bd051659c.jpg  \n",
            " extracting: train/Motor-139-_jpg.rf.382296318edf0dd7b9e00c6837abcb79.jpg  \n",
            " extracting: train/Motor-140-_jpg.rf.f13522818b6d07e1ded34e8a5834d5ec.jpg  \n",
            " extracting: train/Motor-143-_jpg.rf.17cd5e9d0c7326ae9c2ff08c38caa7a3.jpg  \n",
            " extracting: train/Motor-145-_jpg.rf.9b0b94f71d0f70262177f32f3cf8c477.jpg  \n",
            " extracting: train/Motor-146-_jpg.rf.f8ed14be6c023b5bccf6ab5c71dfec58.jpg  \n",
            " extracting: train/Motor-148-_jpg.rf.856746158289caffd7685fbbd2cf1f8b.jpg  \n",
            " extracting: train/Motor-149-_jpg.rf.d9eb52b8398f6cba9788df9f4162ed3f.jpg  \n",
            " extracting: train/Motor-15-_jpg.rf.a1192ea6fd764baf7158ab0230e00b0f.jpg  \n",
            " extracting: train/Motor-150-_jpg.rf.234d2b44636a36bea24296cbceb9d5bd.jpg  \n",
            " extracting: train/Motor-151-_jpg.rf.a7129273bc43181547f5b4ed5a321ffd.jpg  \n",
            " extracting: train/Motor-152-_jpg.rf.b5cacdc3c632ee4e8623cd6eddb0e5cb.jpg  \n",
            " extracting: train/Motor-154-_jpg.rf.5207346a952c40877b04319df127f71c.jpg  \n",
            " extracting: train/Motor-156-_jpg.rf.557a549ad4f34c83ee709c0358f61116.jpg  \n",
            " extracting: train/Motor-157-_jpg.rf.acb5f2f21ce332c4407f59a288d5deff.jpg  \n",
            " extracting: train/Motor-158-_jpg.rf.3e603b141f8eefc513b01d114d798cf5.jpg  \n",
            " extracting: train/Motor-159-_jpg.rf.0bb095b87dff40ee0bb9f2dedd5c6608.jpg  \n",
            " extracting: train/Motor-16-_jpg.rf.b1d2ab3ab599e46b855e45249d2ebeb4.jpg  \n",
            " extracting: train/Motor-160-_jpg.rf.30a99d55facbfac42df1885c675ebed5.jpg  \n",
            " extracting: train/Motor-162-_jpg.rf.84a3cd89d86eee97a4d6ec126913754f.jpg  \n",
            " extracting: train/Motor-164-_jpg.rf.0c4b896bb925dfb0107b0e24921b6896.jpg  \n",
            " extracting: train/Motor-165-_jpg.rf.b5e95e64bdd35474f92d47c3f48a1340.jpg  \n",
            " extracting: train/Motor-166-_jpg.rf.adc05f6607a8ef085a0cac4ad8495bb0.jpg  \n",
            " extracting: train/Motor-167-_jpg.rf.caa8249175213a9fcfb6cf855b9ebdcc.jpg  \n",
            " extracting: train/Motor-168-_jpg.rf.158d65c88a735fc10f957880bd674e66.jpg  \n",
            " extracting: train/Motor-17-_jpg.rf.bbd14d6d57125f1fc31d7b0574b68aa2.jpg  \n",
            " extracting: train/Motor-170-_jpg.rf.d5c3df240472dcc5c7799e5e522d3206.jpg  \n",
            " extracting: train/Motor-171-_jpg.rf.9ee186c181508fcc0bd72a471eca75fc.jpg  \n",
            " extracting: train/Motor-172-_jpg.rf.dbc817d76478eea2bd1b450bf253ee08.jpg  \n",
            " extracting: train/Motor-173-_jpg.rf.89c31279501645eb73d50a873db837a8.jpg  \n",
            " extracting: train/Motor-174-_jpg.rf.e11cb5ae0c1653cafd2e1b037ab45ba0.jpg  \n",
            " extracting: train/Motor-175-_jpg.rf.12388c248eb89d171230b6a576d30b0c.jpg  \n",
            " extracting: train/Motor-176-_jpg.rf.819b1e81265336a23f5ef2c753320778.jpg  \n",
            " extracting: train/Motor-177-_jpg.rf.9203284522b0f395621abb6843995e35.jpg  \n",
            " extracting: train/Motor-178-_jpg.rf.f471cd55809b00f04e77cb2ca62aed7f.jpg  \n",
            " extracting: train/Motor-179-_jpg.rf.15467014ddd7203fc1630e59b8026959.jpg  \n",
            " extracting: train/Motor-18-_jpg.rf.3188ffc79ca9f85d31fd75116a0c4a07.jpg  \n",
            " extracting: train/Motor-182-_jpg.rf.359ec7b745d5ac14d9bbc1d5dfdae629.jpg  \n",
            " extracting: train/Motor-183-_jpg.rf.e72a387cbad7fdd6e8e3a70b22055331.jpg  \n",
            " extracting: train/Motor-184-_jpg.rf.b81599c8d290ecf034c1c915d480093b.jpg  \n",
            " extracting: train/Motor-185-_jpg.rf.95ab23c64fc5f2466326cd7a6e52e0d7.jpg  \n",
            " extracting: train/Motor-186-_jpg.rf.1fcd4306589ad5efa2066477eaff512c.jpg  \n",
            " extracting: train/Motor-187-_jpg.rf.280e9fa8b715e025cdbc8318c8a3355c.jpg  \n",
            " extracting: train/Motor-188-_jpg.rf.1115f70438b2e341d4b3d9c49ced0c84.jpg  \n",
            " extracting: train/Motor-19-_jpg.rf.6ea51cb72ffa40e26b2f96cb8e404a80.jpg  \n",
            " extracting: train/Motor-190-_jpg.rf.3a0a7f8be0d0c023c112584a0afcafb4.jpg  \n",
            " extracting: train/Motor-192-_jpg.rf.07dd594fd8416403be7ba18a1cc3bf4a.jpg  \n",
            " extracting: train/Motor-193-_jpg.rf.524b8b7a792489a9b2445b061e22539a.jpg  \n",
            " extracting: train/Motor-195-_jpg.rf.6b4efed4bbb632aaf73208c876c456c5.jpg  \n",
            " extracting: train/Motor-196-_jpg.rf.1c2441f915808c24928dd40286a9b41e.jpg  \n",
            " extracting: train/Motor-197-_jpg.rf.904117bb733d5c22054bd3f6591c2e16.jpg  \n",
            " extracting: train/Motor-198-_jpg.rf.cf09bf528f2a72e7c8cf3e4d920ea136.jpg  \n",
            " extracting: train/Motor-199-_jpg.rf.91f13a0b07bda85d579d79238345905d.jpg  \n",
            " extracting: train/Motor-20-_jpg.rf.404b7c0d220bf1f9bdc402671ceba04f.jpg  \n",
            " extracting: train/Motor-200-_jpg.rf.f2183ffd759f09424cd0381cbcf2993a.jpg  \n",
            " extracting: train/Motor-201-_jpg.rf.6e3210e27712a64d7e0a7a120cf4753b.jpg  \n",
            " extracting: train/Motor-202-_jpg.rf.6b5e5b0a99cc32394d0fcf1c17a5edea.jpg  \n",
            " extracting: train/Motor-205-_jpg.rf.a9607afd66f409a729182f18162621ab.jpg  \n",
            " extracting: train/Motor-206-_jpg.rf.4aa6ecdfe5a0817f4567c114d4edeb7f.jpg  \n",
            " extracting: train/Motor-208-_jpg.rf.95580d81f3675c956b08102d54e1ec4b.jpg  \n",
            " extracting: train/Motor-209-_jpg.rf.93dd8fb221e39906a62c5eced8f701f2.jpg  \n",
            " extracting: train/Motor-21-_jpg.rf.7f3ac7b699c27b03d2bea8645a96266d.jpg  \n",
            " extracting: train/Motor-210-_jpg.rf.c42cb05241d006da34c2b8c3ba099333.jpg  \n",
            " extracting: train/Motor-212-_jpg.rf.d88b8c729fba8d908adb29954bbeed06.jpg  \n",
            " extracting: train/Motor-213-_jpg.rf.f6ec1826b004b037474f7c4b6d4315d5.jpg  \n",
            " extracting: train/Motor-215-_jpg.rf.a3422005aabd05937072166b761b1960.jpg  \n",
            " extracting: train/Motor-216-_jpg.rf.cb0d71e411f874c3fe20c172a7a9eef5.jpg  \n",
            " extracting: train/Motor-218-_jpg.rf.48fdb603c48cf4c62fe80811f55fb57e.jpg  \n",
            " extracting: train/Motor-219-_jpg.rf.de6a0ec534e04110489b9a1865211d70.jpg  \n",
            " extracting: train/Motor-22-_jpg.rf.67eea9fe751a418313521b7955318a8e.jpg  \n",
            " extracting: train/Motor-220-_jpg.rf.d2685b3aa46eb7cfffd4ecb08c92ddbc.jpg  \n",
            " extracting: train/Motor-221-_jpg.rf.3fd4c03acbaf41458c53392cf3e02e81.jpg  \n",
            " extracting: train/Motor-222-_jpg.rf.1c7a8c36722b5eca997d0a85a3368457.jpg  \n",
            " extracting: train/Motor-223-_jpg.rf.b14636b95282403e0b61bbbdef4cf400.jpg  \n",
            " extracting: train/Motor-224-_jpg.rf.3c2b673fb201d53529b476f08cb8f0e1.jpg  \n",
            " extracting: train/Motor-225-_jpg.rf.3f63402ae87e107082e6b19d095247be.jpg  \n",
            " extracting: train/Motor-227-_jpg.rf.09044fb8be5e5a5a8c3b89a8d19ba447.jpg  \n",
            " extracting: train/Motor-228-_jpg.rf.87b86fef449b9c0875c1a24668e07b86.jpg  \n",
            " extracting: train/Motor-229-_jpg.rf.1dab5087378ce41431ce5873b843359f.jpg  \n",
            " extracting: train/Motor-23-_jpg.rf.3ef68b50b19762bdc87868b9ae5942ac.jpg  \n",
            " extracting: train/Motor-230-_jpg.rf.586eaa4193641286804f9aebca16afe1.jpg  \n",
            " extracting: train/Motor-231-_jpg.rf.f652ce6983243ebc630f1534e5e6750d.jpg  \n",
            " extracting: train/Motor-232-_jpg.rf.1b0810265c3de7bd39a486076425bcca.jpg  \n",
            " extracting: train/Motor-235-_jpg.rf.9214cecae1b6fa2222be0801bb6183cb.jpg  \n",
            " extracting: train/Motor-236-_jpg.rf.e43ebe0a0b356151f06ee7af7c229a24.jpg  \n",
            " extracting: train/Motor-237-_jpg.rf.f3ebb391d78c0e0579e960e08ff073a8.jpg  \n",
            " extracting: train/Motor-238-_jpg.rf.a47e17c53dc06f9064d47a54f1a1ab5b.jpg  \n",
            " extracting: train/Motor-239-_jpg.rf.786388b31657f00fc26e268150fe5b2b.jpg  \n",
            " extracting: train/Motor-24-_jpg.rf.d1c34b542589bad3838840156f139c28.jpg  \n",
            " extracting: train/Motor-240-_jpg.rf.7c65a91552cdd31a22458a674d080ca0.jpg  \n",
            " extracting: train/Motor-241-_jpg.rf.d8c7feb2a884dde8a1f57cbd767744e4.jpg  \n",
            " extracting: train/Motor-242-_jpg.rf.b031ad0e3027003886232cec31c11f3b.jpg  \n",
            " extracting: train/Motor-243-_jpg.rf.449020bed7b157d43adc4a9cbae6cb29.jpg  \n",
            " extracting: train/Motor-246-_jpg.rf.a8f27c419474cf31f70355026f39ac65.jpg  \n",
            " extracting: train/Motor-247-_jpg.rf.3fdae1f714a0c9060fcdbcf29a979264.jpg  \n",
            " extracting: train/Motor-248-_jpg.rf.fd6fb31ce74372dd3e5de4dc21c27031.jpg  \n",
            " extracting: train/Motor-249-_jpg.rf.691fecd1f0dbbfae23b1b2c6942ba612.jpg  \n",
            " extracting: train/Motor-25-_jpg.rf.654e18723122f033750c98b97fa4cc5c.jpg  \n",
            " extracting: train/Motor-250-_jpg.rf.093f3e6df2782a4ca4bd0b5ffcf565e3.jpg  \n",
            " extracting: train/Motor-251-_jpg.rf.944ebbd7f525705448bacd7aae12a5f1.jpg  \n",
            " extracting: train/Motor-253-_jpg.rf.0c9ea329c2e1006066dac458b24512b3.jpg  \n",
            " extracting: train/Motor-254-_jpg.rf.c367de1ab4b45882630626c7c497b4f3.jpg  \n",
            " extracting: train/Motor-256-_jpg.rf.61801852470bb86cda68795520ae5110.jpg  \n",
            " extracting: train/Motor-259-_jpg.rf.1d6296ab8536c2a67c1f5511c2dc98f7.jpg  \n",
            " extracting: train/Motor-260-_jpg.rf.0b3104091ffaedc17fa6337c43bf4fe5.jpg  \n",
            " extracting: train/Motor-261-_jpg.rf.ec017eac1f5d58a714379682fefac1e5.jpg  \n",
            " extracting: train/Motor-263-_jpg.rf.6f94f79d6f275139978d293bd691e649.jpg  \n",
            " extracting: train/Motor-264-_jpg.rf.ebbef0e9c6bdda0470790bc441df083f.jpg  \n",
            " extracting: train/Motor-265-_jpg.rf.6c24de45975380cc80e6a118dcff79b9.jpg  \n",
            " extracting: train/Motor-266-_jpg.rf.ec94eac5ebcfd402258870c26113f272.jpg  \n",
            " extracting: train/Motor-267-_jpg.rf.2a0eb5476faf2487c09583ea24a18931.jpg  \n",
            " extracting: train/Motor-268-_jpg.rf.a50464198e02c9be53d251fe57dbcc8b.jpg  \n",
            " extracting: train/Motor-27-_jpg.rf.70add4d37075fdf1ea27e341cc7d6574.jpg  \n",
            " extracting: train/Motor-270-_jpg.rf.8ca9cd0147a6c0cf50fd9bc61cdd5e4c.jpg  \n",
            " extracting: train/Motor-272-_jpg.rf.b6726aeaf1944190d80d7c1eff8a4ad2.jpg  \n",
            " extracting: train/Motor-273-_jpg.rf.5a79ebab31f8b64a42a64587a98c8573.jpg  \n",
            " extracting: train/Motor-274-_jpg.rf.db4e65a6d911d7abdf33196fbaf1e18c.jpg  \n",
            " extracting: train/Motor-275-_jpg.rf.d86c69ed5c6f77cc4104aef3e10c8aa7.jpg  \n",
            " extracting: train/Motor-277-_jpg.rf.b520b267117f4488039ea7055099ce3e.jpg  \n",
            " extracting: train/Motor-278-_jpg.rf.007d90ea5f308d143fd574a29c45ca3d.jpg  \n",
            " extracting: train/Motor-279-_jpg.rf.9b40387c3e1880dd7dbfc82f2f4a557f.jpg  \n",
            " extracting: train/Motor-28-_jpg.rf.24ef066c2bb279f1dd8816a960e3da74.jpg  \n",
            " extracting: train/Motor-281-_jpg.rf.5d2d20e0f5df5df99f0afdf8fde342a5.jpg  \n",
            " extracting: train/Motor-282-_jpg.rf.34f10af578b5e7c2348e752ec0522d86.jpg  \n",
            " extracting: train/Motor-283-_jpg.rf.09a7e70ab7fd72063df47842c29a4f74.jpg  \n",
            " extracting: train/Motor-284-_jpg.rf.e766447e77301e539eca448a2075c830.jpg  \n",
            " extracting: train/Motor-285-_jpg.rf.b77967c20fd41f6a15c9345a7c1eced6.jpg  \n",
            " extracting: train/Motor-287-_jpg.rf.2cbe9f4a84bca326461d9d8167be3186.jpg  \n",
            " extracting: train/Motor-288-_jpg.rf.4904b2153ff92eab2d340ac621c08257.jpg  \n",
            " extracting: train/Motor-289-_jpg.rf.7fdf1d567eb5f3978989c0520399208a.jpg  \n",
            " extracting: train/Motor-292-_jpg.rf.9292c6f2438bc80941c64b3d721ef6f0.jpg  \n",
            " extracting: train/Motor-293-_jpg.rf.9e12c7c0f0b0c87e2fcb4ebabf8b7980.jpg  \n",
            " extracting: train/Motor-294-_jpg.rf.e15661ccc71cb7d758e8809391d7cea4.jpg  \n",
            " extracting: train/Motor-295-_jpg.rf.7cc23ea39e224193b24a47ff4e65fa23.jpg  \n",
            " extracting: train/Motor-296-_jpg.rf.b903299e3bc503e67077616651939c90.jpg  \n",
            " extracting: train/Motor-298-_jpg.rf.77eb718fca6653609f463aa5d320fc9a.jpg  \n",
            " extracting: train/Motor-299-_jpg.rf.081741742a7b77bc790db1b9b483d2a6.jpg  \n",
            " extracting: train/Motor-3-_jpg.rf.fa5d3246bbc01481453847a83130022b.jpg  \n",
            " extracting: train/Motor-301-_jpg.rf.431a6373c0f8ca40254333eb128f2f17.jpg  \n",
            " extracting: train/Motor-302-_jpg.rf.5f8334aface1455dfc36f780b628d769.jpg  \n",
            " extracting: train/Motor-303-_jpg.rf.fc785442bdf1209ee514d92b4ef0fca1.jpg  \n",
            " extracting: train/Motor-308-_jpg.rf.8664e14a92cf991d78f72bc32480b8de.jpg  \n",
            " extracting: train/Motor-309-_jpg.rf.28bebf32859be06a67208439c6faafd1.jpg  \n",
            " extracting: train/Motor-31-_jpg.rf.faadfcb2412a07d50a98ca7cdd307e76.jpg  \n",
            " extracting: train/Motor-311-_jpg.rf.70d13cb086d44ecf92e6929543755f0d.jpg  \n",
            " extracting: train/Motor-312-_jpg.rf.9867144ef038cef0abe071015f7d8e36.jpg  \n",
            " extracting: train/Motor-313-_jpg.rf.29e150b14f9fe98e1856729db0121cfc.jpg  \n",
            " extracting: train/Motor-314-_jpg.rf.e776c30ddc3b8e06e6538c817390ae86.jpg  \n",
            " extracting: train/Motor-315-_jpg.rf.cd5df8bbac0279a1b97194fbc299d316.jpg  \n",
            " extracting: train/Motor-316-_jpg.rf.01e49db9b257b9cfca07c1b8724c26a4.jpg  \n",
            " extracting: train/Motor-317-_jpg.rf.d4ea1fd51b5f8629ab51dd48f1d15c12.jpg  \n",
            " extracting: train/Motor-32-_jpg.rf.7917421727364dcf38f9225ac35518ef.jpg  \n",
            " extracting: train/Motor-321-_jpg.rf.613f3cdb65d4eb6071fe47a02d5daeeb.jpg  \n",
            " extracting: train/Motor-322-_jpg.rf.917b2ee6e5bbfff71f3f6a1b14b0603d.jpg  \n",
            " extracting: train/Motor-324-_jpg.rf.3019447048d514de68a461c0de1d5015.jpg  \n",
            " extracting: train/Motor-328-_jpg.rf.55c827c2c2c7c3fcca5386834d67bfff.jpg  \n",
            " extracting: train/Motor-33-_jpg.rf.b677c17f68cbee08cc4165e190556c9a.jpg  \n",
            " extracting: train/Motor-331-_jpg.rf.323746fd3b0e56a039c4f984efe8beae.jpg  \n",
            " extracting: train/Motor-334-_jpg.rf.6b2574c86d3de8bec814e755cf523654.jpg  \n",
            " extracting: train/Motor-335-_jpg.rf.0ce7cbc143faad19c45989aef7b93b94.jpg  \n",
            " extracting: train/Motor-339-_jpg.rf.93e95e77a93daa40e156b1b1d8319e84.jpg  \n",
            " extracting: train/Motor-34-_jpg.rf.01312e96f1ab2a521cc6d4c1c74dac54.jpg  \n",
            " extracting: train/Motor-341-_jpg.rf.ebd588fde61b2049f4fb64e5797ccebc.jpg  \n",
            " extracting: train/Motor-342-_jpg.rf.135f9cb8120405912cad858247c5c93f.jpg  \n",
            " extracting: train/Motor-343-_jpg.rf.2c942d9e3429ed1c7815c3d0c6492cef.jpg  \n",
            " extracting: train/Motor-345-_jpg.rf.508dd29341f9bf43a00fec368143693a.jpg  \n",
            " extracting: train/Motor-346-_jpg.rf.473fe47a31ccc356c580d371f5d8628c.jpg  \n",
            " extracting: train/Motor-348-_jpg.rf.033dfcfde6fc61e10ada89f43fcc59c1.jpg  \n",
            " extracting: train/Motor-349-_jpg.rf.62327ce00bb7a05425703f768f1d6d05.jpg  \n",
            " extracting: train/Motor-351-_jpg.rf.75948006db6b5347c8b60648fa601599.jpg  \n",
            " extracting: train/Motor-352-_jpg.rf.1bea5ab0bda6ff91e3867d22f07478a3.jpg  \n",
            " extracting: train/Motor-353-_jpg.rf.55a00111429cf7336c6e3743096b8774.jpg  \n",
            " extracting: train/Motor-354-_jpg.rf.7e61cfcc9d7c66f6ed93e751a10283fe.jpg  \n",
            " extracting: train/Motor-355-_jpg.rf.b122602a24ea056c78fb4c927fe39ab0.jpg  \n",
            " extracting: train/Motor-356-_jpg.rf.526d21c52d2d19a2739cc58babefd0bd.jpg  \n",
            " extracting: train/Motor-357-_jpg.rf.7330ef31d5a1b3c56f2fb17bafd052c9.jpg  \n",
            " extracting: train/Motor-359-_jpg.rf.cf833e0f3c680c27c5b5ce959b9a82ab.jpg  \n",
            " extracting: train/Motor-36-_jpg.rf.cbe6f295f7cd8147aa64c5525ed5ef39.jpg  \n",
            " extracting: train/Motor-360-_jpg.rf.5efbbcc6f40c785744c1f08171731e14.jpg  \n",
            " extracting: train/Motor-361-_jpg.rf.7abd97bc232e21c5495b35db2bca311a.jpg  \n",
            " extracting: train/Motor-362-_jpg.rf.3b9d6da35b2eaa9092e04f8c0b9e5534.jpg  \n",
            " extracting: train/Motor-364-_jpg.rf.1314694cde7c7f1eb66ef15d9717de5e.jpg  \n",
            " extracting: train/Motor-365-_jpg.rf.3124ac96f307fc6fe6c167a73f5de419.jpg  \n",
            " extracting: train/Motor-366-_jpg.rf.f0d3679cf4cce0c346d9c70764ff219c.jpg  \n",
            " extracting: train/Motor-367-_jpg.rf.f46fa0b30f250a30b76681c2d2722f4c.jpg  \n",
            " extracting: train/Motor-368-_jpg.rf.307edfde7d598a23cec785455fa9dbae.jpg  \n",
            " extracting: train/Motor-369-_jpg.rf.8f7e80c42a594b855196670d690051e8.jpg  \n",
            " extracting: train/Motor-37-_jpg.rf.4b8081a0795bb42893c8921fe2221afc.jpg  \n",
            " extracting: train/Motor-370-_jpg.rf.7b2c56fef12ca27659457eb387cf7bf2.jpg  \n",
            " extracting: train/Motor-375-_jpg.rf.3807347bf706263dc7538d662288d99d.jpg  \n",
            " extracting: train/Motor-39-_jpg.rf.57028bb3525a5cb0ec2b766c859dd691.jpg  \n",
            " extracting: train/Motor-4-_jpg.rf.35839b0cd2eee7449f3af3792893ae0c.jpg  \n",
            " extracting: train/Motor-40-_jpg.rf.69d0feeb0d8d5aa02472e94536f9862a.jpg  \n",
            " extracting: train/Motor-42-_jpg.rf.87f6bdaee5c5d3601bbaaf110de17e17.jpg  \n",
            " extracting: train/Motor-43-_jpg.rf.15268bc8685172080ed7b15ca62fe204.jpg  \n",
            " extracting: train/Motor-44-_jpg.rf.74a205bf35c022413f8a8fe82a29da46.jpg  \n",
            " extracting: train/Motor-47-_jpg.rf.84568093afcba32ae71bfe3dc57e5f53.jpg  \n",
            " extracting: train/Motor-48-_jpg.rf.5c9906196cff3681b2b4c3f1addc62d5.jpg  \n",
            " extracting: train/Motor-49-_jpg.rf.f455383d87ae34d5d0b89da8bf763056.jpg  \n",
            " extracting: train/Motor-5-_jpg.rf.7e8149b5cd59eeac694146c36622cfc5.jpg  \n",
            " extracting: train/Motor-50-_jpg.rf.c856baedd961d132e4b3915bc23d1b4c.jpg  \n",
            " extracting: train/Motor-51-_jpg.rf.866964f88cc825a170020bcc7f92cae1.jpg  \n",
            " extracting: train/Motor-52-_jpg.rf.3e625886a0dd557dc920a1715c1b9e80.jpg  \n",
            " extracting: train/Motor-53-_jpg.rf.dc8cf9101182918a3505f300e9b513a6.jpg  \n",
            " extracting: train/Motor-54-_jpg.rf.9ec9b80fc3ad219f4c460e6dac2ddf4b.jpg  \n",
            " extracting: train/Motor-56-_jpg.rf.779f08b44965759590db912405de4764.jpg  \n",
            " extracting: train/Motor-58-_jpg.rf.8c0f8872aa810c51d0a484144d7af25b.jpg  \n",
            " extracting: train/Motor-59-_jpg.rf.1a32326e4b338b74c0393b7740e287c9.jpg  \n",
            " extracting: train/Motor-60-_jpg.rf.72e4c046b75759edfab6fee53ec4d266.jpg  \n",
            " extracting: train/Motor-62-_jpg.rf.cf892dc2b24918320ab76354fc0bccb9.jpg  \n",
            " extracting: train/Motor-63-_jpg.rf.44ba6a832b59828f9d125dddc078c05f.jpg  \n",
            " extracting: train/Motor-66-_jpg.rf.93ed202aaf8f2fd1055310bed45cfeab.jpg  \n",
            " extracting: train/Motor-67-_jpg.rf.a38018d86f8ba9844395ba7f5d283480.jpg  \n",
            " extracting: train/Motor-68-_jpg.rf.1b31a3270c47d29f1a7b2ca59aaaa23f.jpg  \n",
            " extracting: train/Motor-69-_jpg.rf.ea869c18caa9917b2cdc99a5882b4c40.jpg  \n",
            " extracting: train/Motor-71-_jpg.rf.69e22b183cb87097de7690d6e059f14b.jpg  \n",
            " extracting: train/Motor-72-_jpg.rf.d71f98c57b303027086953a405f2b551.jpg  \n",
            " extracting: train/Motor-76-_jpg.rf.76b91b7d5e891e0502a4356ad02e9cf6.jpg  \n",
            " extracting: train/Motor-78-_jpg.rf.af193fa5997c9d3cf04c07db2efaaade.jpg  \n",
            " extracting: train/Motor-79-_jpg.rf.4d18508294ed852f20551c0604642eb4.jpg  \n",
            " extracting: train/Motor-8-_jpg.rf.a6dd79f884c4bc522eecc7f3db10938f.jpg  \n",
            " extracting: train/Motor-80-_jpg.rf.b065545b99857f542f121ac9bf226041.jpg  \n",
            " extracting: train/Motor-83-_jpg.rf.431eea61323a45bca90b7a58a97c4e70.jpg  \n",
            " extracting: train/Motor-84-_jpg.rf.dafcdc6b19f87403bb34c17d843ebda5.jpg  \n",
            " extracting: train/Motor-86-_jpg.rf.5eab661427e69c23961c12f9f6b5132e.jpg  \n",
            " extracting: train/Motor-87-_jpg.rf.59348816e140334537d205a24066cb8d.jpg  \n",
            " extracting: train/Motor-88-_jpg.rf.130ae8cda82119f0a4d5b091a71c42fc.jpg  \n",
            " extracting: train/Motor-89-_jpg.rf.0be9b9a5d72bd114349b820ea7f41358.jpg  \n",
            " extracting: train/Motor-90-_jpg.rf.6cf96eb7a0fb4a0287629dca53a1cf1c.jpg  \n",
            " extracting: train/Motor-93-_jpg.rf.202f557eaf824fc64e280d67e1aa7b6b.jpg  \n",
            " extracting: train/Motor-94-_jpg.rf.fd87f71dbc5c8d0d8349355bddc06340.jpg  \n",
            " extracting: train/Motor-95-_jpg.rf.9e833e6d7d6c04154cd21243abcbb3f0.jpg  \n",
            " extracting: train/Motor-96-_jpg.rf.ed7ffd63761aa858acfae1acf7a10e5a.jpg  \n",
            " extracting: train/Motor-97-_jpg.rf.4c41151284687b8f280f461f819e2fef.jpg  \n",
            " extracting: train/Motor-98-_jpg.rf.d7804ecea6551cd15d83fdd88b09c0f5.jpg  \n",
            " extracting: train/N1824KJ_jpg.rf.9eee994cc30b59f884d08473a7704c9d.jpg  \n",
            " extracting: train/N731CS_jpg.rf.0c1ddfc829c7d0c59955a4487046bb6b.jpg  \n",
            " extracting: train/N731CS_jpg.rf.d52df717869eb849fba94300d96ef2aa.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-13-12-23_jpg.rf.19bf3959e2a05f5ba34c701f805ba85a.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-13-12-23_jpg.rf.7fb15603cbfaf39e26da830022f5f459.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-13-12-24_jpg.rf.2f2c3837ca6c6579fbc26d0ffa7ffccc.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-13-12-24_jpg.rf.3bca7106f6e73e68e2b914955da1d900.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-13-12-25_jpg.rf.ca4feb48035813b7857ddad7a5dc7866.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-13-12-26_jpg.rf.147ff9f5ebe5b13a8e149cac7f9c0566.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-13-12-26_jpg.rf.9185ce7c4ac41feeee02f50124f25675.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-13-12-28_jpg.rf.9f4e804cd3482f180c10600be6c1c458.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-13-12-29_jpg.rf.695665ee832f2c194e63c68650e9d1b9.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-13-12-29_jpg.rf.ab8f7dab12af59fa1a2f9f63b25259ac.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-13-12-30_jpg.rf.ee1207f1115457bad15451455c7027ad.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-13-12-31-1-_jpg.rf.726d89c365ad9d047366bc9a29c1fc38.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-13-12-31_jpg.rf.61dca21bf9546a4109bcea361337507d.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-13-12-31_jpg.rf.678ca03815f527978c7b153b7ed1ce13.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-13-12-32-1-_jpg.rf.26864c60a88e7d3f44d145d136ec02b0.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-13-12-33-1-_jpg.rf.185c4a57dbf08850f62fc9498afa0553.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-13-12-33_jpg.rf.2e0e23146b0df3201d5b9065cac2208c.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-13-12-33_jpg.rf.be3b3a59384f48a7dba30a59a64a6a11.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-13-12-34-1-_jpg.rf.b166e6ed971e1d4b3e4988ff65413079.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-13-12-34-1-_jpg.rf.cb8fbb80c539b384d89f7b70d9420e1f.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-13-12-34_jpg.rf.e7d2df815b245a9af29254efbcbf6583.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-13-12-35-1-_jpg.rf.747a4383c3b5f705a5503d4231d16ab9.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-13-12-35_jpg.rf.5dbdf636000e69e960c2ce0e37154c84.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-16-44-18_jpg.rf.d21e50e17edd377964587b8e400efe22.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-16-44-19_jpg.rf.908e2e56cea00b795d862cd20d2dc591.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-16-44-19_jpg.rf.a061be84d781b4c6198a4464c1780d78.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-16-44-21_jpg.rf.0c670634d326ccd622ccdc5c2a5b3303.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-16-44-23_jpg.rf.b1eec47574558583cb6677792a236a82.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-16-44-23_jpg.rf.f0872165ae77974e1ccc87398ae0d180.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-16-44-24_jpg.rf.4a27237aff5d4238026a2cad6ff7a940.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-16-44-24_jpg.rf.efcecf763ed69c0472107e6204d04bf1.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-16-44-25_jpg.rf.76075966673c1ae3f23c97c851ed564d.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-16-44-25_jpg.rf.85355c6c0104094a17767581be0d1943.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-16-44-26_jpg.rf.86b693245cf476754f217edcc3bfc97a.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-16-44-27-1-_jpg.rf.3781a50ba3abf758f63e32f7b0136077.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-16-44-27-1-_jpg.rf.c7ede84b94a5d054bd1fba0a84799546.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-16-44-27_jpg.rf.944fbe17cf3d6c2e24c7684c4997eb27.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-16-44-28-1-_jpg.rf.3a02a0f9fe8c4cb44eae6a5e7cecad2e.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-16-44-30-1-_jpg.rf.e883c8e918e657a10f7f14e0a0576cdf.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-16-44-30_jpg.rf.1b13e1ba8c04849613dba20722f3e7dc.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-16-44-30_jpg.rf.c43d64acf05dc01ef71c41d4f5bd3be9.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-16-44-50_jpg.rf.1095ad791946bb8c444c87f7652cf2e2.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-16-44-50_jpg.rf.c72d93d51315e36233691318b3cdfee6.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-16-44-51-1-_jpg.rf.6a38e86d8210c474acfe170b900fa70b.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-16-44-51-1-_jpg.rf.df9431d2d4242c0a8af9dcd3fb3b46b6.jpg  \n",
            " extracting: train/PHOTO-2022-05-17-16-44-51_jpg.rf.5bf76bcf84f2cabda13e7feb51abd392.jpg  \n",
            " extracting: train/P_20211122_114537_jpg.rf.f3ee20cc26d40d98a1e869f4eda76353.jpg  \n",
            " extracting: train/P_20211122_114545_jpg.rf.4af47633c0625eff25da001922f0da5e.jpg  \n",
            " extracting: train/P_20211122_114606_jpg.rf.e9e1799e0d25f67ebf15f4c99f28010f.jpg  \n",
            " extracting: train/P_20211122_114618_jpg.rf.b61e55a87072d922add2fe6af1be94bc.jpg  \n",
            " extracting: train/Pelat-10-_jpg.rf.bf2c06bec35540c6c49b4598be21a2c2.jpg  \n",
            " extracting: train/Pelat-100-_jpg.rf.b8284ef3eefa3eeac4d1355d1427b525.jpg  \n",
            " extracting: train/Pelat-101-_jpg.rf.23331b703c4592731dd630785bfa8b4f.jpg  \n",
            " extracting: train/Pelat-103-_jpg.rf.e1fdd84c55cf180198c84f84df5965c2.jpg  \n",
            " extracting: train/Pelat-105-_jpg.rf.63d237020af70beffd3ccd5aed26bef2.jpg  \n",
            " extracting: train/Pelat-106-_jpg.rf.266cf9605e8b5fd10e64ee5c87162aaa.jpg  \n",
            " extracting: train/Pelat-107-_jpg.rf.ef59c10752c9a7a49cf5f540deaa57c4.jpg  \n",
            " extracting: train/Pelat-108-_jpg.rf.01d07d83044b59f73ae36830082b82c2.jpg  \n",
            " extracting: train/Pelat-11-_jpg.rf.5b62450da40a318b8a23d8cf49a5a137.jpg  \n",
            " extracting: train/Pelat-110-_jpg.rf.1afa86e9e3e1956146d251fd9cde747f.jpg  \n",
            " extracting: train/Pelat-111-_jpg.rf.ff66a2baea145abae4355854a4e4be08.jpg  \n",
            " extracting: train/Pelat-112-_jpg.rf.a0ede8b94cf13aaab83674f4f74aec6d.jpg  \n",
            " extracting: train/Pelat-113-_jpg.rf.0f8f9d41ed5d1254858a017bfeeb1a4d.jpg  \n",
            " extracting: train/Pelat-115-_jpg.rf.0c82a4fba9c11e20433efa67ce084af6.jpg  \n",
            " extracting: train/Pelat-116-_jpg.rf.1641963784386665021bd66667031ad0.jpg  \n",
            " extracting: train/Pelat-117-_jpg.rf.3868bd5f5ff7c5afc040ab6b6766bec4.jpg  \n",
            " extracting: train/Pelat-118-_jpg.rf.16eaedf64031ed3ab1d1d152df64f6d5.jpg  \n",
            " extracting: train/Pelat-12-_jpg.rf.e031c3e5ae8b236397344d1ed6d269aa.jpg  \n",
            " extracting: train/Pelat-121-_jpg.rf.c77542fddc852c46872f80aba1ba6826.jpg  \n",
            " extracting: train/Pelat-122-_jpg.rf.b6d3ee296b3bed748d892c33c170a324.jpg  \n",
            " extracting: train/Pelat-123-_jpg.rf.192588c239c4905b7e581f107a1e40f5.jpg  \n",
            " extracting: train/Pelat-125-_jpg.rf.15c8c226aedafb2d0cecf0b2673533ea.jpg  \n",
            " extracting: train/Pelat-126-_jpg.rf.1dd901f13063c3e669982629ac5c2353.jpg  \n",
            " extracting: train/Pelat-128-_jpg.rf.09b56b0dc09a088afb3b94d4f387bae0.jpg  \n",
            " extracting: train/Pelat-129-_jpg.rf.50f115fb2e2fb88bfc36667a7e7e35b7.jpg  \n",
            " extracting: train/Pelat-13-_jpg.rf.a0e3027a2ce4849cf27de1ca4190909d.jpg  \n",
            " extracting: train/Pelat-131-_jpg.rf.511980e0d9763212a137c68b8ac697a8.jpg  \n",
            " extracting: train/Pelat-132-_jpg.rf.2ce7800dbbb5b6431a769ee95a267968.jpg  \n",
            " extracting: train/Pelat-133-_jpg.rf.b7d70899ecb26324fd17be8c7e725a86.jpg  \n",
            " extracting: train/Pelat-134-_jpg.rf.9bbcdb83ee144d61a2f1c3eb6f5bce61.jpg  \n",
            " extracting: train/Pelat-135-_jpg.rf.d650888f120284035e28f4fbe9111e69.jpg  \n",
            " extracting: train/Pelat-136-_jpg.rf.08118a61460cdae7c23275512a4602cc.jpg  \n",
            " extracting: train/Pelat-137-_jpg.rf.0eb36b1b54e9c6a7ca69f694b0f60df4.jpg  \n",
            " extracting: train/Pelat-139-_jpg.rf.aa0cfa2e6bcd1bee09368d7e70768058.jpg  \n",
            " extracting: train/Pelat-140-_jpg.rf.54ff115d53a4e2ec09bf1e055a5c49a2.jpg  \n",
            " extracting: train/Pelat-141-_jpg.rf.644dd44b704a0c60faa1d14d8908cc35.jpg  \n",
            " extracting: train/Pelat-142-_jpg.rf.4bb7e1e65486e0b2dd15c48087b45ecb.jpg  \n",
            " extracting: train/Pelat-143-_jpg.rf.f9df45dcea393067cf51093c98c41371.jpg  \n",
            " extracting: train/Pelat-144-_jpg.rf.8ecd08ebff28a64f9063ae6a26b91d87.jpg  \n",
            " extracting: train/Pelat-146-_jpg.rf.0bb980799653ae38f90226cfe4abea4d.jpg  \n",
            " extracting: train/Pelat-147-_jpg.rf.4f445740bd93ea0594fe9320020758c7.jpg  \n",
            " extracting: train/Pelat-148-_jpg.rf.412b9945868136871392e1d4b1c4e56d.jpg  \n",
            " extracting: train/Pelat-149-_jpg.rf.2b3f7db717052de58cac33734b6f6ded.jpg  \n",
            " extracting: train/Pelat-15-_jpg.rf.7ecd95d00511816dc2ee6344bfce378b.jpg  \n",
            " extracting: train/Pelat-155-_jpg.rf.f536bcc2c883a67f2619b87b5d73650b.jpg  \n",
            " extracting: train/Pelat-156-_jpg.rf.6cd019f4715694054bd207e022c32173.jpg  \n",
            " extracting: train/Pelat-158-_jpg.rf.a152e9e1a3ba539cce553bafc0f6fd03.jpg  \n",
            " extracting: train/Pelat-159-_jpg.rf.fc0a11ebbd88a3e4c447fb3333b9b536.jpg  \n",
            " extracting: train/Pelat-16-_jpg.rf.e8b643f705162c42da284d8dae6b9a3e.jpg  \n",
            " extracting: train/Pelat-161-_jpg.rf.0f4b63d9a3a4e93f1a42da14a739005e.jpg  \n",
            " extracting: train/Pelat-162-_jpg.rf.6397c7adfbda49778271fc0c98c96ff8.jpg  \n",
            " extracting: train/Pelat-163-_jpg.rf.f858052119abe235f818a01f7a00cacf.jpg  \n",
            " extracting: train/Pelat-164-_jpg.rf.f965c7c2df79304a98756a647961d7c0.jpg  \n",
            " extracting: train/Pelat-166-_jpg.rf.7f13d9959e0d31fe12d882b1be9e2c12.jpg  \n",
            " extracting: train/Pelat-167-_jpg.rf.76fd6321888ea4a5f3aa14544cfe0cd8.jpg  \n",
            " extracting: train/Pelat-168-_jpg.rf.f962728ff7bcbc5afca6cf5095b7811b.jpg  \n",
            " extracting: train/Pelat-169-_jpg.rf.635dd732f7bbb58b3c7ef64ec7a736cf.jpg  \n",
            " extracting: train/Pelat-17-_jpg.rf.1a25c291227d98e9e7fac6f5cd47d436.jpg  \n",
            " extracting: train/Pelat-170-_jpg.rf.4befb2aff1aa4747e925edf2dd59961b.jpg  \n",
            " extracting: train/Pelat-171-_jpg.rf.57c71fb1683f8f05ff73b00d97046814.jpg  \n",
            " extracting: train/Pelat-172-_jpg.rf.7e084cec27d93ceab4189c7945636abb.jpg  \n",
            " extracting: train/Pelat-173-_jpg.rf.69e59e96c842f42bd7fe737f2096acb8.jpg  \n",
            " extracting: train/Pelat-174-_jpg.rf.381caa45c58ffa121252c9d74739ad21.jpg  \n",
            " extracting: train/Pelat-176-_jpg.rf.4e09e0b7b180dc18490dca9d15a5df0e.jpg  \n",
            " extracting: train/Pelat-177-_jpg.rf.f114fbaf23755fd9bbdf6e39895b6e68.jpg  \n",
            " extracting: train/Pelat-178-_jpg.rf.3263cd20c31ca83d9719e616fe387e78.jpg  \n",
            " extracting: train/Pelat-179-_jpg.rf.70f3b7fd20881cba7954750da267c25a.jpg  \n",
            " extracting: train/Pelat-180-_jpg.rf.5e0941b2dd053e6c3be2f5d9f693f91d.jpg  \n",
            " extracting: train/Pelat-181-_jpg.rf.02c5a6dbdc21ccdb493a9a7d9e9d6f36.jpg  \n",
            " extracting: train/Pelat-182-_jpg.rf.9c2018fe5d2df6533e349ecc48ec43b4.jpg  \n",
            " extracting: train/Pelat-184-_jpg.rf.eecd7e2a510b850a98bda9e59e041b56.jpg  \n",
            " extracting: train/Pelat-185-_jpg.rf.017ed028d7c988c36a0f4cd302152e8f.jpg  \n",
            " extracting: train/Pelat-189-_jpg.rf.f6ed344db05f5c28ccc019ea92327543.jpg  \n",
            " extracting: train/Pelat-190-_jpg.rf.099c83d0b3faae734070dfffd67af61d.jpg  \n",
            " extracting: train/Pelat-191-_jpg.rf.d4f18e9a9d27513cb90123d7649f0d0c.jpg  \n",
            " extracting: train/Pelat-193-_jpg.rf.65eb48305dbd521df4e90ca4c340ecf6.jpg  \n",
            " extracting: train/Pelat-195-_jpg.rf.537991279a6b585d65e824c1e0a58914.jpg  \n",
            " extracting: train/Pelat-196-_jpg.rf.6c2b909dc23094159e0e208eb022ee41.jpg  \n",
            " extracting: train/Pelat-197-_jpg.rf.394989bcfbad8d2b6a636c5efeb45c08.jpg  \n",
            " extracting: train/Pelat-199-_jpg.rf.20567787eede4fbe3af6003d742db960.jpg  \n",
            " extracting: train/Pelat-2-_jpg.rf.eaf3fd1158408b0980998bd3cdcf4fef.jpg  \n",
            " extracting: train/Pelat-200-_jpg.rf.c625cffbbe102af45e1c7c425882a5e9.jpg  \n",
            " extracting: train/Pelat-202-_jpg.rf.cb4e01e8a2ef63c4d6c6dbcd673ba438.jpg  \n",
            " extracting: train/Pelat-204-_jpg.rf.f3b2b56abd0b5c4f16ad25b2690ac91b.jpg  \n",
            " extracting: train/Pelat-205-_jpg.rf.7def0948fbd97f4c05f009db4620fbea.jpg  \n",
            " extracting: train/Pelat-206-_jpg.rf.2d3c8b5997423dd7599bb9ae4d2c30de.jpg  \n",
            " extracting: train/Pelat-207-_jpg.rf.e204ce6a60b3c7a2ce5bcf93e4100dc4.jpg  \n",
            " extracting: train/Pelat-209-_jpg.rf.774fc10a7bd17f3f7cb3ff89f77a9230.jpg  \n",
            " extracting: train/Pelat-210-_jpg.rf.82df709a5f0817e3a709c09e402d9a9a.jpg  \n",
            " extracting: train/Pelat-211-_jpg.rf.96415751969e21263a7bc41e0a3e61e2.jpg  \n",
            " extracting: train/Pelat-212-_jpg.rf.d5b1338bc9b3b3cd6fa782ee2d9a24bc.jpg  \n",
            " extracting: train/Pelat-213-_jpg.rf.a322014d90f5e92666962a55595e253a.jpg  \n",
            " extracting: train/Pelat-214-_jpg.rf.84d1a2505949a5850296a9d9da4bac02.jpg  \n",
            " extracting: train/Pelat-215-_jpg.rf.1449fd39d1e15fc2b85bafcd82ab3554.jpg  \n",
            " extracting: train/Pelat-218-_jpg.rf.cd3dd5c599f1f0859a6b109ea5aa0be2.jpg  \n",
            " extracting: train/Pelat-22-_jpg.rf.f3574f53689341ae939b2cdc1d03eb8a.jpg  \n",
            " extracting: train/Pelat-220-_jpg.rf.e1873ada1ca8877ac1a883e21bbb364b.jpg  \n",
            " extracting: train/Pelat-221-_jpg.rf.963df1275202b985182c2dcca44dc9a0.jpg  \n",
            " extracting: train/Pelat-222-_jpg.rf.dee4d6c3f9774631d2598e63c27ea08a.jpg  \n",
            " extracting: train/Pelat-223-_jpg.rf.acedcdef76a7df87e06f76929068a2ba.jpg  \n",
            " extracting: train/Pelat-224-_jpg.rf.fe68f19d9e6dc977d5ea3d576273202f.jpg  \n",
            " extracting: train/Pelat-225-_jpg.rf.736f24f75f3a1ce33c1303eaaf01ff09.jpg  \n",
            " extracting: train/Pelat-227-_jpg.rf.a12d072f2a8abca9b3fa1c9dda0e3e71.jpg  \n",
            " extracting: train/Pelat-228-_jpg.rf.292521aa53695dc41a7bc3085f5592b0.jpg  \n",
            " extracting: train/Pelat-229-_jpg.rf.b286de7912d0058637256284afc00b18.jpg  \n",
            " extracting: train/Pelat-23-_jpg.rf.c91d68722e502e3cea2873e814cce659.jpg  \n",
            " extracting: train/Pelat-230-_jpg.rf.6b6941bfdae6b5065147f1b99b127ae9.jpg  \n",
            " extracting: train/Pelat-231-_jpg.rf.860535b85d0b0e5fbb21df36a6668a2d.jpg  \n",
            " extracting: train/Pelat-232-_jpg.rf.a1dbfd801b3732f1a45ed7f1f72c358b.jpg  \n",
            " extracting: train/Pelat-233-_jpg.rf.63f11b799ca9d9fe19cadeb229b6827b.jpg  \n",
            " extracting: train/Pelat-234-_jpg.rf.ce574a65df1c8c4d4f05d626513fe947.jpg  \n",
            " extracting: train/Pelat-238-_jpg.rf.6592a100a96678835f7dfa2930b19d64.jpg  \n",
            " extracting: train/Pelat-240-_jpg.rf.1c3edd50507e5bbb2b1d6a498ca2e396.jpg  \n",
            " extracting: train/Pelat-242-_jpg.rf.5615afd75c485b27d3d2740c1f7d443a.jpg  \n",
            " extracting: train/Pelat-243-_jpg.rf.d88b96129bf8e4e11a93d1d96757fa68.jpg  \n",
            " extracting: train/Pelat-244-_jpg.rf.56ec3c69daffa49e99785e2eda118a1f.jpg  \n",
            " extracting: train/Pelat-245-_jpg.rf.6b4b8627f75166d666faad9a5c2b703a.jpg  \n",
            " extracting: train/Pelat-246-_jpg.rf.c67ff602af7e6dd5a930e30a82815fd1.jpg  \n",
            " extracting: train/Pelat-247-_jpg.rf.2a0f3803ff460447c9858facb538c792.jpg  \n",
            " extracting: train/Pelat-248-_jpg.rf.bcca87e95c3544a09d30940750b96288.jpg  \n",
            " extracting: train/Pelat-249-_jpg.rf.a92bb2301f097447a01e33eae8215edc.jpg  \n",
            " extracting: train/Pelat-252-_jpg.rf.060c951541ef2e69ac73ca1645704592.jpg  \n",
            " extracting: train/Pelat-253-_jpg.rf.57da33dc991d33d3c9796a50ee930fe0.jpg  \n",
            " extracting: train/Pelat-254-_jpg.rf.658701026591c5678f6ac4ce436209b4.jpg  \n",
            " extracting: train/Pelat-257-_jpg.rf.3f11d5f62ce30266fedd672970440f1a.jpg  \n",
            " extracting: train/Pelat-26-_jpg.rf.d62b084ba8e3f4614d87a60e56454b67.jpg  \n",
            " extracting: train/Pelat-260-_jpg.rf.2e27362c1a37e005759bdce0ac3677f7.jpg  \n",
            " extracting: train/Pelat-261-_jpg.rf.dadc60e963d949c7585d35bd423d6684.jpg  \n",
            " extracting: train/Pelat-263-_jpg.rf.2114c323b333ee0ecaba292603fc3055.jpg  \n",
            " extracting: train/Pelat-264-_jpg.rf.c1c7186e17600fb2facf4c86e2c5f6d7.jpg  \n",
            " extracting: train/Pelat-266-_jpg.rf.fbc3a978e3c7c215b370e9fbf16d5643.jpg  \n",
            " extracting: train/Pelat-267-_jpg.rf.4481fd017dab76aa37f76415f4df6de2.jpg  \n",
            " extracting: train/Pelat-269-_jpg.rf.793a0a68bd314368bfa9ac8ad8411d22.jpg  \n",
            " extracting: train/Pelat-27-_jpg.rf.b2fadbb3af5a475b2f6668c11151a502.jpg  \n",
            " extracting: train/Pelat-270-_jpg.rf.ecb11599d47b49d49bf2e6bd4649fe2d.jpg  \n",
            " extracting: train/Pelat-272-_jpg.rf.64fbaeb84d30285d3bcdb3dd880de2a1.jpg  \n",
            " extracting: train/Pelat-273-_jpg.rf.9172b54a29f9c55296bf27ec23038346.jpg  \n",
            " extracting: train/Pelat-274-_jpg.rf.a03c8950e7784c2a9e1e4848378559b7.jpg  \n",
            " extracting: train/Pelat-275-_jpg.rf.e4bc47763d7810d88e3eabb25ed9b9dd.jpg  \n",
            " extracting: train/Pelat-276-_jpg.rf.ae1f9ba7c6f1f2db781e1856f4fe8968.jpg  \n",
            " extracting: train/Pelat-277-_jpg.rf.433e203565080565a47adbcb0b6061ab.jpg  \n",
            " extracting: train/Pelat-279-_jpg.rf.e4bf7bd616d7e2407f4d3dd68eb69e4f.jpg  \n",
            " extracting: train/Pelat-280-_jpg.rf.eb1a68511ca2fbcb6ae249bfc8bbabe1.jpg  \n",
            " extracting: train/Pelat-282-_jpg.rf.391747f834d254e6cce0aa200d10402a.jpg  \n",
            " extracting: train/Pelat-284-_jpg.rf.2eebec9b312050feaf57200ef23fe478.jpg  \n",
            " extracting: train/Pelat-285-_jpg.rf.87f421074388f6de4b908494392ef5dc.jpg  \n",
            " extracting: train/Pelat-286-_jpg.rf.22559a46a1a68a846cbfae2391163a31.jpg  \n",
            " extracting: train/Pelat-287-_jpg.rf.1fa7adae056c6158fd2debd6d1778677.jpg  \n",
            " extracting: train/Pelat-288-_jpg.rf.63c3b478614b5cacfb64100d9b430c69.jpg  \n",
            " extracting: train/Pelat-289-_jpg.rf.c4d7b82f48a056325131edb916ec5b90.jpg  \n",
            " extracting: train/Pelat-290-_jpg.rf.17853fac2a0dfe968407440fa3c7179e.jpg  \n",
            " extracting: train/Pelat-291-_jpg.rf.624dee3ee7f33e708943f33396237ba8.jpg  \n",
            " extracting: train/Pelat-293-_jpg.rf.bda95c8b39a2b9a2a5a2dcfb4860cdbd.jpg  \n",
            " extracting: train/Pelat-294-_jpg.rf.4cdb72ef4dc79077057ffc7e775e6b08.jpg  \n",
            " extracting: train/Pelat-295-_jpg.rf.e6dd290968333aa101d003fcf3179f71.jpg  \n",
            " extracting: train/Pelat-298-_jpg.rf.b806035c9ee0ef41f942aa02daacc2ab.jpg  \n",
            " extracting: train/Pelat-299-_jpg.rf.3d8855ec6a1c6c8e352b16a526bc802b.jpg  \n",
            " extracting: train/Pelat-3-_jpg.rf.a255f97226ed9e9424969a27438034d9.jpg  \n",
            " extracting: train/Pelat-301-_jpg.rf.6d70316cb6f8c68a394fde120bdfab37.jpg  \n",
            " extracting: train/Pelat-302-_jpg.rf.7b60e93477b9afaea6ab11a09b176232.jpg  \n",
            " extracting: train/Pelat-303-_jpg.rf.d66d205fec63566921ad1ff2edff961f.jpg  \n",
            " extracting: train/Pelat-304-_jpg.rf.55c358aa1a3e1b138a58dfc8f5ab959c.jpg  \n",
            " extracting: train/Pelat-306-_jpg.rf.044138511e655284d6856911fe90ab76.jpg  \n",
            " extracting: train/Pelat-307-_jpg.rf.c6bbe230ed4d6e3fd319cec570b2f065.jpg  \n",
            " extracting: train/Pelat-308-_jpg.rf.16af2cee3b03a7c5192cec53602b44b0.jpg  \n",
            " extracting: train/Pelat-309-_jpg.rf.d833e39d8a1a7709cc54f36778826b41.jpg  \n",
            " extracting: train/Pelat-31-_jpg.rf.bef993547a44583e3fea522c2e79799a.jpg  \n",
            " extracting: train/Pelat-310-_jpg.rf.44c1e70714c485f893342129f9c73e5e.jpg  \n",
            " extracting: train/Pelat-311-_jpg.rf.d4392d14aaee67c53de03a24b9f7db02.jpg  \n",
            " extracting: train/Pelat-313-_jpg.rf.57974ebe9820b4104f841b67cc7aa8a7.jpg  \n",
            " extracting: train/Pelat-314-_jpg.rf.08a6f62d808da1a81ddacf14f20ef7a3.jpg  \n",
            " extracting: train/Pelat-315-_jpg.rf.df2fb2b6e91594a30822d77ec8f511c0.jpg  \n",
            " extracting: train/Pelat-318-_jpg.rf.99ec3d8e7b9b6430d927c75ea3c99dbf.jpg  \n",
            " extracting: train/Pelat-32-_jpg.rf.925a281fafc888d4844d07b030e627c9.jpg  \n",
            " extracting: train/Pelat-320-_jpg.rf.b5cf4f24c9f23e76c8efa8010d43a397.jpg  \n",
            " extracting: train/Pelat-321-_jpg.rf.59757dac665ed5a9d15a4b037b162c52.jpg  \n",
            " extracting: train/Pelat-325-_jpg.rf.d2aab9171a554b05673d38fe36c49834.jpg  \n",
            " extracting: train/Pelat-328-_jpg.rf.1efb70bb543d2c9a86862d4785c413c0.jpg  \n",
            " extracting: train/Pelat-329-_jpg.rf.9c88a6f655de3cf2f705f32a75f21671.jpg  \n",
            " extracting: train/Pelat-33-_jpg.rf.69fbbedd83c1f75209a26d79c8dd73d2.jpg  \n",
            " extracting: train/Pelat-331-_jpg.rf.d86f460eedc9a3ed5d52f531b9452912.jpg  \n",
            " extracting: train/Pelat-332-_jpg.rf.6c182c1d5f3fa472625ace7c4cbc2fe8.jpg  \n",
            " extracting: train/Pelat-333-_jpg.rf.bd4305bba68b6a15b3e43292c5df8818.jpg  \n",
            " extracting: train/Pelat-337-_jpg.rf.1fd9a0b2352ea63ab7269b6835fb24fe.jpg  \n",
            " extracting: train/Pelat-339-_jpg.rf.d8deb8a77a3cd9a7f3039f4d72046e8d.jpg  \n",
            " extracting: train/Pelat-34-_jpg.rf.457a010fa974d5b6f32928c8d063ee39.jpg  \n",
            " extracting: train/Pelat-340-_jpg.rf.f23c59f7eeb2fd3f807778300e8f10be.jpg  \n",
            " extracting: train/Pelat-341-_jpg.rf.8865a7f8acf46d55e5d87af0fb68aca7.jpg  \n",
            " extracting: train/Pelat-342-_jpg.rf.bcbf86dce3037784c1268110fcc366cc.jpg  \n",
            " extracting: train/Pelat-343-_jpg.rf.84fe74d1b6dd18013ded379b6a4624a5.jpg  \n",
            " extracting: train/Pelat-344-_jpg.rf.8ea4502826a1c658832a8369d853607e.jpg  \n",
            " extracting: train/Pelat-349-_jpg.rf.e40ff7c1fe498b11b27018d71c704ba9.jpg  \n",
            " extracting: train/Pelat-350-_jpg.rf.d7591c03ed3a5e51bafd46dc46b221d6.jpg  \n",
            " extracting: train/Pelat-355-_jpg.rf.c8625cedb6e63f7b4c00d2f30c0af5bb.jpg  \n",
            " extracting: train/Pelat-356-_jpg.rf.cea32a319369a945195a283919c73686.jpg  \n",
            " extracting: train/Pelat-357-_jpg.rf.2cbbf7c62d3c7833936196627378735f.jpg  \n",
            " extracting: train/Pelat-358-_jpg.rf.03d2d19d4587acdd1e0a9b8a22eedcb5.jpg  \n",
            " extracting: train/Pelat-359-_jpg.rf.bacf8e6d2b175224e45caf814fb11a06.jpg  \n",
            " extracting: train/Pelat-36-_jpg.rf.6e4f01e60e3b64e049dc56c96355905a.jpg  \n",
            " extracting: train/Pelat-360-_jpg.rf.c95cc8d3b51a72c93f2e4681b4682596.jpg  \n",
            " extracting: train/Pelat-361-_jpg.rf.eaed7072584f0059d65c31835012ac74.jpg  \n",
            " extracting: train/Pelat-362-_jpg.rf.f47dfe1c2d99560c46f308bdab6a3cb1.jpg  \n",
            " extracting: train/Pelat-363-_jpg.rf.819147f59b1dc15e82376c01ca6a9a93.jpg  \n",
            " extracting: train/Pelat-364-_jpg.rf.810a3ecb5ef0ee05ccfc33315836734a.jpg  \n",
            " extracting: train/Pelat-365-_jpg.rf.32b1de9195358377846e98751e6b5ff5.jpg  \n",
            " extracting: train/Pelat-366-_jpg.rf.793e1fd4ec746b813322526ca1fd8e8f.jpg  \n",
            " extracting: train/Pelat-367-_jpg.rf.cd60fc33c7e870af8c14310214d0b9ea.jpg  \n",
            " extracting: train/Pelat-368-_jpg.rf.7a28b271e8944b753343df8e3f4bce56.jpg  \n",
            " extracting: train/Pelat-369-_jpg.rf.6bdf0050368b19bb4f665e3fea6f75ca.jpg  \n",
            " extracting: train/Pelat-370-_jpg.rf.baa76d4680af32f6e40eda186cbd6039.jpg  \n",
            " extracting: train/Pelat-371-_jpg.rf.b4ceacecd5c34d6d47debb592c87b40c.jpg  \n",
            " extracting: train/Pelat-373-_jpg.rf.aabe471aa10752e2fc1b41516514a042.jpg  \n",
            " extracting: train/Pelat-374-_jpg.rf.901ba6aeff06c75223f97ed864837bc2.jpg  \n",
            " extracting: train/Pelat-38-_jpg.rf.a582e81b5d13c826cf0aebb8dcbe9891.jpg  \n",
            " extracting: train/Pelat-39-_jpg.rf.98b0282db107dcf8b97b58a78b9c08ba.jpg  \n",
            " extracting: train/Pelat-4-_jpg.rf.7b5d1559d0b629dde013102576bf8348.jpg  \n",
            " extracting: train/Pelat-40-_jpg.rf.c5b9ee3d28d8ebbdacb577ce08c6f0cb.jpg  \n",
            " extracting: train/Pelat-41-_jpg.rf.12784f6ebf1b53f0c7720dbbb203963f.jpg  \n",
            " extracting: train/Pelat-43-_jpg.rf.c9c1db33868f3b56107ec3eb520362d4.jpg  \n",
            " extracting: train/Pelat-44-_jpg.rf.effb500ae8898aec7f0273f5427f203b.jpg  \n",
            " extracting: train/Pelat-45-_jpg.rf.bb376b819ac837ef588a09ec0f966833.jpg  \n",
            " extracting: train/Pelat-46-_jpg.rf.15d683d27a7d938c040ca32ce242a237.jpg  \n",
            " extracting: train/Pelat-47-_jpg.rf.fab9922cf7f78f97a00a5b71691a6a2b.jpg  \n",
            " extracting: train/Pelat-48-_jpg.rf.347188918b6a73a21ecb832116f773bf.jpg  \n",
            " extracting: train/Pelat-5-_jpg.rf.3436292dac140cd64efae7b55f225248.jpg  \n",
            " extracting: train/Pelat-50-_jpg.rf.6201d1f64ebd2be10a5824d58f0385a0.jpg  \n",
            " extracting: train/Pelat-51-_jpg.rf.d10ba144d781e7815f431360662ad089.jpg  \n",
            " extracting: train/Pelat-52-_jpg.rf.cad1a900e5a47863a2c37f9d3f2de32b.jpg  \n",
            " extracting: train/Pelat-54-_jpg.rf.6b081ad55ea88a38b7ab5a5fef577d74.jpg  \n",
            " extracting: train/Pelat-55-_jpg.rf.6b22c77f924d144ff2c6ff557bd82051.jpg  \n",
            " extracting: train/Pelat-56-_jpg.rf.8aaa153b9f5ef9bc4e2102569502245a.jpg  \n",
            " extracting: train/Pelat-59-_jpg.rf.5345fc13a1c9497e5f10a364668fef41.jpg  \n",
            " extracting: train/Pelat-6-_jpg.rf.1df1a84ab3ddc822ecae36d8bb9527c1.jpg  \n",
            " extracting: train/Pelat-61-_jpg.rf.b0f4a31f19de864e1bfa801a2332227c.jpg  \n",
            " extracting: train/Pelat-62-_jpg.rf.bc7ee52e3110a4aa7ea3452b474af1e9.jpg  \n",
            " extracting: train/Pelat-63-_jpg.rf.18ef75f043921ea4ba25762c8688638e.jpg  \n",
            " extracting: train/Pelat-64-_jpg.rf.ac6eb6d083c6a83951ab48be5a194ceb.jpg  \n",
            " extracting: train/Pelat-65-_jpg.rf.49bd074b251ec52a9b44755c44223900.jpg  \n",
            " extracting: train/Pelat-66-_jpg.rf.a2ffc220c5880129258bd57644a0e385.jpg  \n",
            " extracting: train/Pelat-68-_jpg.rf.16368ea71e4246c2e8e488af4f3def6a.jpg  \n",
            " extracting: train/Pelat-70-_jpg.rf.35c15121f51815074dab40591491d298.jpg  \n",
            " extracting: train/Pelat-71-_jpg.rf.7008f96051ed16d63b2cdb228f22138f.jpg  \n",
            " extracting: train/Pelat-72-_jpg.rf.c02f983349ce64f3d8bbf376af842bc0.jpg  \n",
            " extracting: train/Pelat-73-_jpg.rf.c3dd207c9e783b1fb6da42b4b31676a6.jpg  \n",
            " extracting: train/Pelat-74-_jpg.rf.c33c4d9ae5ec34df6c8417c335e77989.jpg  \n",
            " extracting: train/Pelat-76-_jpg.rf.f40cc11e965667c15d88394645a62a0a.jpg  \n",
            " extracting: train/Pelat-77-_jpg.rf.a515a777fc8cba714c2104019262cf40.jpg  \n",
            " extracting: train/Pelat-78-_jpg.rf.8ce6ba70847c8c470f5812d257d14a92.jpg  \n",
            " extracting: train/Pelat-79-_jpg.rf.9e073b65dee5a1fe921bbe3184394d7c.jpg  \n",
            " extracting: train/Pelat-81-_jpg.rf.717a162b26b2af8159a60b1d3562cbc2.jpg  \n",
            " extracting: train/Pelat-82-_jpg.rf.be7007ba6187f672de4a369d5ab8aeda.jpg  \n",
            " extracting: train/Pelat-83-_jpg.rf.f9b86626856b55bfb1b37ac90ae858b8.jpg  \n",
            " extracting: train/Pelat-85-_jpg.rf.4e12d6ed5b174526ec9c0a6d492593fc.jpg  \n",
            " extracting: train/Pelat-87-_jpg.rf.925503e1a207bebfc6052dc3e18b1f9b.jpg  \n",
            " extracting: train/Pelat-88-_jpg.rf.05a07608cc3bdd27157650f8ed129d27.jpg  \n",
            " extracting: train/Pelat-89-_jpg.rf.eb7c88b811e7e46ac39f77f39d8c6857.jpg  \n",
            " extracting: train/Pelat-9-_jpg.rf.d7d6af7d27ac9eda237cf12ae9c503e0.jpg  \n",
            " extracting: train/Pelat-90-_jpg.rf.ef2af0aff887ca7db12cc50d3e78ef25.jpg  \n",
            " extracting: train/Pelat-92-_jpg.rf.ad6d68c43ff4cb9d45002261fd12e84d.jpg  \n",
            " extracting: train/Pelat-93-_jpg.rf.3274ca5a53ed028716188e2b44f5b532.jpg  \n",
            " extracting: train/Pelat-95-_jpg.rf.31a3afe5046f76bb87001df0996d6c2a.jpg  \n",
            " extracting: train/Pelat-96-_jpg.rf.163f495c87c6dc002a114876b2682b02.jpg  \n",
            " extracting: train/Screenshot_20220517-140026_Gallery_jpg.rf.ce52c841e3c9778abf2d457c457be61e.jpg  \n",
            " extracting: train/Screenshot_20220517-140053_Gallery_jpg.rf.ca811d66caf2c1929bac8e640b297ea1.jpg  \n",
            " extracting: train/Screenshot_20220517-140144_Gallery_jpg.rf.44377b102b5132ff4a3404ef254da205.jpg  \n",
            " extracting: train/Screenshot_20220517-140154_Gallery_jpg.rf.61b34b0571cdd442a95564ab36885b83.jpg  \n",
            " extracting: train/Screenshot_20220517-140206_Gallery_jpg.rf.5476a42001f598881116494bc3bbadd6.jpg  \n",
            " extracting: train/Screenshot_20220517-140216_Gallery_jpg.rf.fedb2f75ff6c3d9e345e75ef78a422a6.jpg  \n",
            " extracting: train/Screenshot_20220517-140228_Gallery_jpg.rf.76fa6496accf1864d4c93038525d4a6b.jpg  \n",
            " extracting: train/Screenshot_20220517-140245_Gallery_jpg.rf.86054edafbc9dc652c21c74b111c9d48.jpg  \n",
            " extracting: train/Screenshot_20220517-140317_Gallery_jpg.rf.6346479cafb955dc8d3e0ca5601980f3.jpg  \n",
            " extracting: train/Screenshot_20220517-140329_Gallery_jpg.rf.b00eac5540a2671a6d41d72edc88d45b.jpg  \n",
            " extracting: train/Screenshot_20220517-140338_Gallery_jpg.rf.42d6695d715c4f8d88bb951bc01a9f70.jpg  \n",
            " extracting: train/Screenshot_20220517-140449_Gallery_jpg.rf.ea2cf4789bce4807030f23a24c7a49de.jpg  \n",
            " extracting: train/Screenshot_20220517-140507_Gallery_jpg.rf.b87149730a6b99cac061fc4541d0689c.jpg  \n",
            " extracting: train/Screenshot_20220517-140531_Gallery_jpg.rf.0bdf06a0ceaf4d2d6291dc93b18488b9.jpg  \n",
            " extracting: train/Screenshot_20220517-140544_Gallery_jpg.rf.7beefe66ff4b180e3a4f82dd61f22da7.jpg  \n",
            " extracting: train/Screenshot_20220517-140555_Gallery_jpg.rf.49e77925a2e6cbba0880989505a10111.jpg  \n",
            " extracting: train/Screenshot_20220517-140604_Gallery_jpg.rf.5fae0f2365ebfc0e3994c1d01bc304b1.jpg  \n",
            " extracting: train/Screenshot_20220517-140616_Gallery_jpg.rf.84d5813d46bf1f9a7b6849270a646017.jpg  \n",
            " extracting: train/Screenshot_20220517-140624_Gallery_jpg.rf.a23ab6b18844601115bc3e7799a6cfe0.jpg  \n",
            " extracting: train/Screenshot_20220517-140632_Gallery_jpg.rf.3eef284634b139d96a6dd721164e1b8b.jpg  \n",
            " extracting: train/Truk-100-_jpg.rf.4916efc5895c013af5fc8c6ebc64e4a4.jpg  \n",
            " extracting: train/Truk-102-_jpg.rf.04ea3d5026e8bb88c89cdb36b9156f0f.jpg  \n",
            " extracting: train/Truk-103-_jpg.rf.99c037bed22498b348210524c60a703e.jpg  \n",
            " extracting: train/Truk-105-_jpg.rf.91a3b68fbd2cbab07f05b94a9e47dd5c.jpg  \n",
            " extracting: train/Truk-106-_jpg.rf.2a99d19db535c5f0489eeb6c4f177d74.jpg  \n",
            " extracting: train/Truk-107-_jpg.rf.8adb625f06a38c9566f1f3e7708bf249.jpg  \n",
            " extracting: train/Truk-108-_jpg.rf.3e14bfcb686aff3b1d7a3f92a386c206.jpg  \n",
            " extracting: train/Truk-11-_jpg.rf.a8b9d705ba04a8fe5c3b592a13fe664c.jpg  \n",
            " extracting: train/Truk-110-_jpg.rf.9317e89bfe48a68abffc3b3c6d879f9a.jpg  \n",
            " extracting: train/Truk-113-_jpg.rf.87152a82743b85a6ff6c7d611c6c88a6.jpg  \n",
            " extracting: train/Truk-114-_jpg.rf.f15e1f32743b61c44be3b708a1685bee.jpg  \n",
            " extracting: train/Truk-117-_jpg.rf.ff7f3dbfbdcb8e0a1170850dec226049.jpg  \n",
            " extracting: train/Truk-12-_jpg.rf.179d1efe4b12bf6b616166843c2d6fb4.jpg  \n",
            " extracting: train/Truk-120-_jpg.rf.5457112cd1bffb7030cba5db1ebcc091.jpg  \n",
            " extracting: train/Truk-124-_jpg.rf.12f8fd227bf886b24b349c43fee6f3e9.jpg  \n",
            " extracting: train/Truk-126-_jpg.rf.5e9cf095ca2a1a6f68cdb4aed64e73e6.jpg  \n",
            " extracting: train/Truk-128-_jpg.rf.ca20c7ec04eb910944605d373b60c1dc.jpg  \n",
            " extracting: train/Truk-129-_jpg.rf.11eddd804cf01a692b22f5fb22472bf9.jpg  \n",
            " extracting: train/Truk-13-_jpg.rf.580c6e722aa8ecc59ef046af41a079f4.jpg  \n",
            " extracting: train/Truk-130-_jpg.rf.e2f4ccd4fa6443628ebe8fb913e8b8b7.jpg  \n",
            " extracting: train/Truk-132-_jpg.rf.f7d4d1a7e78882a67fe9c4a7bdfd88be.jpg  \n",
            " extracting: train/Truk-134-_jpg.rf.29414da5b8b40e8e94f368ef62d6b901.jpg  \n",
            " extracting: train/Truk-135-_jpg.rf.353ee131621d776a1077ba7361b186d8.jpg  \n",
            " extracting: train/Truk-137-_jpg.rf.eddc3ed4c0c677a7d5d4fc7babcb3cfa.jpg  \n",
            " extracting: train/Truk-138-_jpg.rf.337795a5352da0f471e248bb0ed1689f.jpg  \n",
            " extracting: train/Truk-14-_jpg.rf.8dd4e615c358fad868541df362e57b26.jpg  \n",
            " extracting: train/Truk-140-_jpg.rf.c8921df37fac47128ba652a8a5911481.jpg  \n",
            " extracting: train/Truk-142-_jpg.rf.86835567188328aae0775ab205928551.jpg  \n",
            " extracting: train/Truk-143-_jpg.rf.236fd4619cb77366ca6f5084c12e3c1c.jpg  \n",
            " extracting: train/Truk-144-_jpg.rf.07f14e7cf2c23977e8608636e36f2763.jpg  \n",
            " extracting: train/Truk-145-_jpg.rf.c369c17bff139f97067832177294c575.jpg  \n",
            " extracting: train/Truk-146-_jpg.rf.1b7e2d8f4fd98f2feb1667097fa16b6c.jpg  \n",
            " extracting: train/Truk-147-_jpg.rf.cb81829b04b73388cf8e2964d6cd8c33.jpg  \n",
            " extracting: train/Truk-148-_jpg.rf.cb9c3750d7550755aa69daa878ff41b5.jpg  \n",
            " extracting: train/Truk-149-_jpg.rf.c07baae9df4229e3f639ad90a7ca88ed.jpg  \n",
            " extracting: train/Truk-150-_jpg.rf.fc7a94a0c32d5f5e0c78acace11363ca.jpg  \n",
            " extracting: train/Truk-151-_jpg.rf.68a0e590287c4fae05372eff6820cca2.jpg  \n",
            " extracting: train/Truk-152-_jpg.rf.f38e24278abc188f03f5ca72ffc35343.jpg  \n",
            " extracting: train/Truk-153-_jpg.rf.46c527cabdc6dcc2102277644c2cb390.jpg  \n",
            " extracting: train/Truk-154-_jpg.rf.83b717616e2e49502f58a01de6eb4fc8.jpg  \n",
            " extracting: train/Truk-155-_jpg.rf.17525b14d844d5c848a6e307c4de91a9.jpg  \n",
            " extracting: train/Truk-156-_jpg.rf.1bd1e3aa950eecc9e2c2c0115a92fe9a.jpg  \n",
            " extracting: train/Truk-157-_jpg.rf.4fd9f79f699fee333defa32dc4325416.jpg  \n",
            " extracting: train/Truk-158-_jpg.rf.341993c861da3afc403a19396bff2094.jpg  \n",
            " extracting: train/Truk-160-_jpg.rf.acd43ce3a04a925429b0c74095f4f830.jpg  \n",
            " extracting: train/Truk-161-_jpg.rf.a3c89e9f0aada0f132b2c13d54eef592.jpg  \n",
            " extracting: train/Truk-162-_jpg.rf.d971288a039ac0d773e1e2dc6a144f59.jpg  \n",
            " extracting: train/Truk-163-_jpg.rf.3ab46c111f245d81ca9eb91d81880e03.jpg  \n",
            " extracting: train/Truk-165-_jpg.rf.7f593eb1767fefc05ef033f60ff22d54.jpg  \n",
            " extracting: train/Truk-166-_jpg.rf.9316fafd1955f4cd1fd13182bcd282c8.jpg  \n",
            " extracting: train/Truk-169-_jpg.rf.186c04f711b829b78f2f7ccfb1748476.jpg  \n",
            " extracting: train/Truk-17-_jpg.rf.2c5e4f182f85fbc9be8a2944bb20dd91.jpg  \n",
            " extracting: train/Truk-170-_jpg.rf.e741fa30aa46f8d2147fe8c43d16d6b5.jpg  \n",
            " extracting: train/Truk-171-_jpg.rf.5d9fc351504268fd64ca96c5ac237d0d.jpg  \n",
            " extracting: train/Truk-172-_jpg.rf.abbde9c53b0d15315e10702985a94ae0.jpg  \n",
            " extracting: train/Truk-173-_jpg.rf.9572ec755020836ab4c5c17103289f3f.jpg  \n",
            " extracting: train/Truk-174-_jpg.rf.0f315d9ee6b504b2f77aaa32db1ae19d.jpg  \n",
            " extracting: train/Truk-175-_jpg.rf.693e5353e4083754a64dead7628c439c.jpg  \n",
            " extracting: train/Truk-176-_jpg.rf.96c8822c94dd7d68b1e726458db332ec.jpg  \n",
            " extracting: train/Truk-177-_jpg.rf.299bab2523cc72ff6a026eafc95758e6.jpg  \n",
            " extracting: train/Truk-178-_jpg.rf.1bc6bbc54277e83c5f2a3c2c4af93989.jpg  \n",
            " extracting: train/Truk-179-_jpg.rf.e1b6f3fc61cd06396885d06e4b010288.jpg  \n",
            " extracting: train/Truk-18-_jpg.rf.82b7ed20fc1b7ff4781c32476a5e73a0.jpg  \n",
            " extracting: train/Truk-181-_jpg.rf.4ef971bb6ccac359ac0510a70550fc26.jpg  \n",
            " extracting: train/Truk-182-_jpg.rf.32a1f86063098a75a77ef7995ce48cc5.jpg  \n",
            " extracting: train/Truk-183-_jpg.rf.ed1f94f5b0d06c938067ded0646034fe.jpg  \n",
            " extracting: train/Truk-185-_jpg.rf.51da50e51d255839c71ae8803f593e5f.jpg  \n",
            " extracting: train/Truk-186-_jpg.rf.75d3591a6ea1fd805bac315714720ecb.jpg  \n",
            " extracting: train/Truk-188-_jpg.rf.58c840405a220757dde9d08c5149ed24.jpg  \n",
            " extracting: train/Truk-19-_jpg.rf.2fd8b38778235d1ada5c13498cce6cfc.jpg  \n",
            " extracting: train/Truk-190-_jpg.rf.965111d3160d341fccf6d58164d46592.jpg  \n",
            " extracting: train/Truk-191-_jpg.rf.d1e6bdf0af0e0528dff964d2980369ad.jpg  \n",
            " extracting: train/Truk-192-_jpg.rf.30e2c0280299fbca1f4030c47eecab9e.jpg  \n",
            " extracting: train/Truk-194-_jpg.rf.b30d71eae6079199b350d3f284f31675.jpg  \n",
            " extracting: train/Truk-195-_jpg.rf.f126971c9e4937aa9e9a8e2f11899d33.jpg  \n",
            " extracting: train/Truk-196-_jpg.rf.1685a94abeeccf7da2082f196ef0aa55.jpg  \n",
            " extracting: train/Truk-197-_jpg.rf.fa040c31bb746b7d3d50f7c203057626.jpg  \n",
            " extracting: train/Truk-198-_jpg.rf.afa6c60b1472ae1b2e36e01e61d9bf49.jpg  \n",
            " extracting: train/Truk-2-_jpg.rf.9826bf8b4906062d0a2563c908c207a0.jpg  \n",
            " extracting: train/Truk-20-_jpg.rf.7cfcf12c8ba07bba73cb6d1dbde687d8.jpg  \n",
            " extracting: train/Truk-201-_jpg.rf.8b42f2c561a1258268c4b7ee9a5d1272.jpg  \n",
            " extracting: train/Truk-203-_jpg.rf.efe944042181c4a644dd80691e40f210.jpg  \n",
            " extracting: train/Truk-205-_jpg.rf.05239894e5b2ec624146f4196ece6718.jpg  \n",
            " extracting: train/Truk-206-_jpg.rf.efb3929995f303106eed229195dfe9e5.jpg  \n",
            " extracting: train/Truk-207-_jpg.rf.01f6dcc4b1eb768b65a9bb25f4a2f594.jpg  \n",
            " extracting: train/Truk-208-_jpg.rf.3b490a084efb098f77cc74d523232563.jpg  \n",
            " extracting: train/Truk-209-_jpg.rf.5788ae4a89ae57df560a7f161c3dc0b9.jpg  \n",
            " extracting: train/Truk-21-_jpg.rf.2825ebe626bbb86c6b8e21846d359878.jpg  \n",
            " extracting: train/Truk-211-_jpg.rf.3aacb01a431518036bb31b42e93717d7.jpg  \n",
            " extracting: train/Truk-212-_jpg.rf.24fa772ae71a9d79ba89dff7bf03fe3f.jpg  \n",
            " extracting: train/Truk-213-_jpg.rf.7f885d31d950c9446bde6ab4b8b1e030.jpg  \n",
            " extracting: train/Truk-214-_jpg.rf.dd0f8eed2b02299cedb9cce49cea13be.jpg  \n",
            " extracting: train/Truk-215-_jpg.rf.57397670ad658dfdadbf26612661f19c.jpg  \n",
            " extracting: train/Truk-217-_jpg.rf.ce4728d5f522ef8d8d3a783c89d77ae2.jpg  \n",
            " extracting: train/Truk-218-_jpg.rf.7bd1e19221f2f06c0ffedbf3ba33bd55.jpg  \n",
            " extracting: train/Truk-219-_jpg.rf.d9808bb224cbd5e30d48bc54bcf4be53.jpg  \n",
            " extracting: train/Truk-22-_jpg.rf.5b9a16c4e80e95edde7559c1b0e2e20f.jpg  \n",
            " extracting: train/Truk-220-_jpg.rf.d74d82886edfaa0ac42e9040a9cac21a.jpg  \n",
            " extracting: train/Truk-222-_jpg.rf.9afdbdf2e94ba032204b21d94a553a15.jpg  \n",
            " extracting: train/Truk-224-_jpg.rf.d105001eb76698225d223696660aca5f.jpg  \n",
            " extracting: train/Truk-225-_jpg.rf.9415fc0e67461f588e77911f6dea20d9.jpg  \n",
            " extracting: train/Truk-226-_jpg.rf.e11bd28cf7935156dafcbf64f98f9497.jpg  \n",
            " extracting: train/Truk-229-_jpg.rf.baacdbf8a1d51f8ad575c5c3658354cc.jpg  \n",
            " extracting: train/Truk-230-_jpg.rf.2638730526592faec6bbb9b69cb9c08c.jpg  \n",
            " extracting: train/Truk-234-_jpg.rf.c4e5c79ab9628f4466365e6bad1db049.jpg  \n",
            " extracting: train/Truk-235-_jpg.rf.71bfc273242b6d2923c3cb3b006d07bc.jpg  \n",
            " extracting: train/Truk-238-_jpg.rf.e9d81e178e8e4ef18f6cacaa881df586.jpg  \n",
            " extracting: train/Truk-239-_jpg.rf.3c3396f90b12f30217e9a69db9867d1b.jpg  \n",
            " extracting: train/Truk-241-_jpg.rf.40f4a8497bf05c1d46761fea21d1096c.jpg  \n",
            " extracting: train/Truk-242-_jpg.rf.7d3514a50c92c916a406d66245da8800.jpg  \n",
            " extracting: train/Truk-243-_jpg.rf.b9fe1e8486563b317140f3bcb700cada.jpg  \n",
            " extracting: train/Truk-244-_jpg.rf.1291b6d6a7bfaabc42deff993af49481.jpg  \n",
            " extracting: train/Truk-247-_jpg.rf.be3a3ba289b09d422cd2d32ae4cf0728.jpg  \n",
            " extracting: train/Truk-248-_jpg.rf.d0e3b2911c19cdcf3bd429a92ceaeb11.jpg  \n",
            " extracting: train/Truk-249-_jpg.rf.501fba477c460284955396a2961c0b38.jpg  \n",
            " extracting: train/Truk-25-_jpg.rf.7d0e518134987b154af55b4bda1eeddd.jpg  \n",
            " extracting: train/Truk-251-_jpg.rf.a06fd5dbfe08b387e6b732c2a1e17bac.jpg  \n",
            " extracting: train/Truk-252-_jpg.rf.cb7b05919e76a8521d2564f4d9f5dac0.jpg  \n",
            " extracting: train/Truk-253-_jpg.rf.e716ce1ebebf2e6eb47b3165e8954079.jpg  \n",
            " extracting: train/Truk-254-_jpg.rf.6069c5a2bbd9edadab01371a240d046d.jpg  \n",
            " extracting: train/Truk-255-_jpg.rf.90ff5c9bafbb1a927641318d286d99be.jpg  \n",
            " extracting: train/Truk-257-_jpg.rf.d59cf165ed33cc0690cdac9c555bdcfd.jpg  \n",
            " extracting: train/Truk-259-_jpg.rf.342b929941669ce2cc43f66730d8c9b8.jpg  \n",
            " extracting: train/Truk-26-_jpg.rf.c0682382334e9607481da791ce95da57.jpg  \n",
            " extracting: train/Truk-260-_jpg.rf.3b79c43124897de2b627389aee66f4ec.jpg  \n",
            " extracting: train/Truk-261-_jpg.rf.4b6584b663c498e134d414ad72020d16.jpg  \n",
            " extracting: train/Truk-262-_jpg.rf.3e79afe23b92d92ce789dc2ff89ca9da.jpg  \n",
            " extracting: train/Truk-263-_jpg.rf.804fb8712a3f50ee96b4577d86ec7f6b.jpg  \n",
            " extracting: train/Truk-264-_jpg.rf.f8639b653ec169ddd35185f562815710.jpg  \n",
            " extracting: train/Truk-265-_jpg.rf.0724bdfe21cb8d5967b5a43c11a285a4.jpg  \n",
            " extracting: train/Truk-266-_jpg.rf.22ce39d40b7a2918bd27e43d96008357.jpg  \n",
            " extracting: train/Truk-268-_jpg.rf.bd76efd42cf94f86b9c6b87aebfee0ef.jpg  \n",
            " extracting: train/Truk-27-_jpg.rf.59ba3c43b0cdceefbe22e915de04d408.jpg  \n",
            " extracting: train/Truk-270-_jpg.rf.7037a466b5b5132bd5f76ce84961e2cf.jpg  \n",
            " extracting: train/Truk-271-_jpg.rf.d4f6033646ff3e63976350b526d2fb61.jpg  \n",
            " extracting: train/Truk-272-_jpg.rf.b6e16852ddc335c3596cf27035e30b2a.jpg  \n",
            " extracting: train/Truk-275-_jpg.rf.b9ab4826dd8e0d04f698fd690a4cd444.jpg  \n",
            " extracting: train/Truk-276-_jpg.rf.eab41b61092d82557de2159cacd6ac23.jpg  \n",
            " extracting: train/Truk-277-_jpg.rf.c441cb3f0f211ace5ce9da3d1c16ad4a.jpg  \n",
            " extracting: train/Truk-278-_jpg.rf.340a230745fd980a30b9571453f68998.jpg  \n",
            " extracting: train/Truk-280-_jpg.rf.850a7d251793361e5fbf6e4a5e89e27a.jpg  \n",
            " extracting: train/Truk-283-_jpg.rf.8b7273529c91bb37aa0169671cd5d9c9.jpg  \n",
            " extracting: train/Truk-284-_jpg.rf.b904f1437e0209409b4757197f4710cc.jpg  \n",
            " extracting: train/Truk-285-_jpg.rf.9ecc7554c0235d9895e9e5d66c635417.jpg  \n",
            " extracting: train/Truk-286-_jpg.rf.0188bb9272b826afe50948e9f7aee365.jpg  \n",
            " extracting: train/Truk-287-_jpg.rf.16f416506d3890aaf732b3c307ff344c.jpg  \n",
            " extracting: train/Truk-288-_jpg.rf.a22de5ce6df0d32908ae837a08b7aebf.jpg  \n",
            " extracting: train/Truk-289-_jpg.rf.a81c6fff9bb98b14ed836aa893fcc8a2.jpg  \n",
            " extracting: train/Truk-291-_jpg.rf.81e7610bfbd2f226725c1c07c04490ed.jpg  \n",
            " extracting: train/Truk-292-_jpg.rf.b2502d3386b18f7c80fbc6091c87c87a.jpg  \n",
            " extracting: train/Truk-293-_jpg.rf.81d4fc9f7ee2ea20473198d2efa898a8.jpg  \n",
            " extracting: train/Truk-294-_jpg.rf.8180dfb5be90de59907dc264702b72d9.jpg  \n",
            " extracting: train/Truk-295-_jpg.rf.b91571b52a7e2bcedddca9f03e1f7b55.jpg  \n",
            " extracting: train/Truk-298-_jpg.rf.4590f16b6b97a083891256ac00ae3bea.jpg  \n",
            " extracting: train/Truk-299-_jpg.rf.67aa04827e13e9d53c545fe3b420ee07.jpg  \n",
            " extracting: train/Truk-300-_jpg.rf.dfc2f2538183739de37d0a8ce1a71006.jpg  \n",
            " extracting: train/Truk-301-_jpg.rf.4f00a92ec234746494f0d3ee7d778731.jpg  \n",
            " extracting: train/Truk-302-_jpg.rf.b2ebe031b892b8f2836c671442d4ad35.jpg  \n",
            " extracting: train/Truk-303-_jpg.rf.38e2c274eb3d56abae528d64d10da808.jpg  \n",
            " extracting: train/Truk-304-_jpg.rf.43b635f7514ec0722ea6e5a0d7b44a61.jpg  \n",
            " extracting: train/Truk-305-_jpg.rf.ba446a8430c2b6265c1df9af9117d73a.jpg  \n",
            " extracting: train/Truk-306-_jpg.rf.4906e87af49d53746136d15370a93fb3.jpg  \n",
            " extracting: train/Truk-307-_jpg.rf.140ec1dab10039f90e66e04d415bcf41.jpg  \n",
            " extracting: train/Truk-308-_jpg.rf.f7f206974d7027bb2142295d6981ef5e.jpg  \n",
            " extracting: train/Truk-31-_jpg.rf.e8ecca6a429c6bf4a6e3dc268352f602.jpg  \n",
            " extracting: train/Truk-310-_jpg.rf.c93d5e97c4badaacf54ea39e9ca9f5c4.jpg  \n",
            " extracting: train/Truk-311-_jpg.rf.0c8796e931fd74e267801d5767064c80.jpg  \n",
            " extracting: train/Truk-312-_jpg.rf.c1876967e43ad81083a3cb808607a526.jpg  \n",
            " extracting: train/Truk-314-_jpg.rf.ea9e65ced26893ab7c56431b733e0948.jpg  \n",
            " extracting: train/Truk-315-_jpg.rf.4c5f453e2ee496ebe38b55bc72eec761.jpg  \n",
            " extracting: train/Truk-317-_jpg.rf.20753a86207a6f4eda201138a91502db.jpg  \n",
            " extracting: train/Truk-318-_jpg.rf.6f1f4a7094ea4fce2dab0f69025e7b6c.jpg  \n",
            " extracting: train/Truk-319-_jpg.rf.274043e880e7a15cc3f82fb92498faff.jpg  \n",
            " extracting: train/Truk-32-_jpg.rf.87145755a6e253f5a1db0a170442dad2.jpg  \n",
            " extracting: train/Truk-320-_jpg.rf.234b7dfce9b758718e5d8035ff8c06a4.jpg  \n",
            " extracting: train/Truk-321-_jpg.rf.ebd2fb81faac4c8cf9a5f0660acaa944.jpg  \n",
            " extracting: train/Truk-322-_jpg.rf.effbf0047a7c0bebc2490da49d060bf6.jpg  \n",
            " extracting: train/Truk-325-_jpg.rf.8689656bb01dc97b31af87450ad48745.jpg  \n",
            " extracting: train/Truk-326-_jpg.rf.9e0c5d26c074596bd2ef4211d5b5eca2.jpg  \n",
            " extracting: train/Truk-327-_jpg.rf.f90ee2daf9c7a7bc1e1d93289b0d884e.jpg  \n",
            " extracting: train/Truk-328-_jpg.rf.765c87c52aeede425c31284089cf8188.jpg  \n",
            " extracting: train/Truk-329-_jpg.rf.cb59901b21ae0124c1084cf2f6b11b31.jpg  \n",
            " extracting: train/Truk-330-_jpg.rf.8146821e9b6f645ad3cc692d39ddd1cd.jpg  \n",
            " extracting: train/Truk-332-_jpg.rf.85983cb315639a088168c8ae5bb82dd8.jpg  \n",
            " extracting: train/Truk-333-_jpg.rf.61a71f5e1b32eb5d9ad8768fab8cf074.jpg  \n",
            " extracting: train/Truk-334-_jpg.rf.6b124371498439ddf18015e2db39973e.jpg  \n",
            " extracting: train/Truk-335-_jpg.rf.7b38435e1024b9d1754e12e3b50d184f.jpg  \n",
            " extracting: train/Truk-338-_jpg.rf.fa6a58fc2869972f3a0e6279b2c00510.jpg  \n",
            " extracting: train/Truk-340-_jpg.rf.196e33d018624f9efce9306e7bc79e14.jpg  \n",
            " extracting: train/Truk-342-_jpg.rf.086d6a60f35d86dd00f0e528d92fbd01.jpg  \n",
            " extracting: train/Truk-343-_jpg.rf.1066e03cadaad969dfd4853f79179844.jpg  \n",
            " extracting: train/Truk-344-_jpg.rf.674928cf2c453947a9a19de72313d844.jpg  \n",
            " extracting: train/Truk-347-_jpg.rf.ab8868600247267d0e7ca808e9f7c24d.jpg  \n",
            " extracting: train/Truk-349-_jpg.rf.4b0a7e6fa272c142cb11375851a7f7d1.jpg  \n",
            " extracting: train/Truk-351-_jpg.rf.79141d647b9f32b3d772c2fd61620e38.jpg  \n",
            " extracting: train/Truk-352-_jpg.rf.cdec6039dbadfcab02c8bf285cda8326.jpg  \n",
            " extracting: train/Truk-353-_jpg.rf.51b3d48c09518245b428b272d4cf1e5f.jpg  \n",
            " extracting: train/Truk-355-_jpg.rf.fc51eb981ebb158ced85ba0e926dabb5.jpg  \n",
            " extracting: train/Truk-356-_jpg.rf.593574e485c34bc05e37277197af8081.jpg  \n",
            " extracting: train/Truk-357-_jpg.rf.50e35cbd2779c85d835d93019a4c98e2.jpg  \n",
            " extracting: train/Truk-358-_jpg.rf.f4e3fba57e3edec1f3ddd689eccc1ba9.jpg  \n",
            " extracting: train/Truk-359-_jpg.rf.9732616f55a04669ad695d6b2f443466.jpg  \n",
            " extracting: train/Truk-360-_jpg.rf.154862536ea2963f11c1e731b3d35c19.jpg  \n",
            " extracting: train/Truk-363-_jpg.rf.967db248e89014445f22d41ad56b67ad.jpg  \n",
            " extracting: train/Truk-364-_jpg.rf.429909c105b1f128a3e7fbbacac9c472.jpg  \n",
            " extracting: train/Truk-367-_jpg.rf.3199544232a38efcdab13b704372c275.jpg  \n",
            " extracting: train/Truk-369-_jpg.rf.37bcba8b7c364d5d97827cb534b398b0.jpg  \n",
            " extracting: train/Truk-370-_jpg.rf.b69de8d98f8dd60e36ce0dcbedf47992.jpg  \n",
            " extracting: train/Truk-373-_jpg.rf.30d2984bbf72a755c84c7eddced2fe69.jpg  \n",
            " extracting: train/Truk-374-_jpg.rf.67b9d16300671747aa24336b10765bd4.jpg  \n",
            " extracting: train/Truk-38-_jpg.rf.84a2b34c931321fc3dad97a4f1738de1.jpg  \n",
            " extracting: train/Truk-39-_jpg.rf.d8108c89b435d50cacc1de47360385d4.jpg  \n",
            " extracting: train/Truk-40-_jpg.rf.be2aa2737797bd335db5bbedcef73b74.jpg  \n",
            " extracting: train/Truk-41-_jpg.rf.61b76fd2be31f0394af3ad934adc99c5.jpg  \n",
            " extracting: train/Truk-43-_jpg.rf.cd220adf29386f0b3416093a4d01af9f.jpg  \n",
            " extracting: train/Truk-44-_jpg.rf.b4fabcf1f9749e8e3f42fe39b0c0e3f6.jpg  \n",
            " extracting: train/Truk-45-_jpg.rf.a7fdf406628c55c1aca41023522aa3a1.jpg  \n",
            " extracting: train/Truk-46-_jpg.rf.89f6c4913dccf18f0ff4d81dc2fd9333.jpg  \n",
            " extracting: train/Truk-47-_jpg.rf.336b829042e0fde5194bb903b99e47f6.jpg  \n",
            " extracting: train/Truk-48-_jpg.rf.b638387007c2372c58db8e1d6c2400c1.jpg  \n",
            " extracting: train/Truk-5-_jpg.rf.782755fc6f79c5431f2ce4d26b0a0f50.jpg  \n",
            " extracting: train/Truk-50-_jpg.rf.51b18ba8529fdbd4fa71caa48cbc1d09.jpg  \n",
            " extracting: train/Truk-51-_jpg.rf.d50dccbab71aedb87939e366e90d170e.jpg  \n",
            " extracting: train/Truk-52-_jpg.rf.35a3ad197a9b00dec5734a06d929f432.jpg  \n",
            " extracting: train/Truk-53-_jpg.rf.b23dc747cc0e8c5c4477382a72002b74.jpg  \n",
            " extracting: train/Truk-54-_jpg.rf.8b9e96fd42a2dc168811582209ac9da7.jpg  \n",
            " extracting: train/Truk-57-_jpg.rf.aec580574b266dc1b606852a165c145f.jpg  \n",
            " extracting: train/Truk-58-_jpg.rf.725c1bb67488d4265de06ae1d26cccb9.jpg  \n",
            " extracting: train/Truk-59-_jpg.rf.b564146c8c65135c9a7f7e1a04508968.jpg  \n",
            " extracting: train/Truk-6-_jpg.rf.2d2292b234c52bd2e430a8e8a57e0858.jpg  \n",
            " extracting: train/Truk-60-_jpg.rf.6e4b9297bbf790f3bc1ccdeb88df40d2.jpg  \n",
            " extracting: train/Truk-61-_jpg.rf.6ad6144be72077f5091091c72ae54c13.jpg  \n",
            " extracting: train/Truk-63-_jpg.rf.2b601955f29ef965e85f2a7f71c64427.jpg  \n",
            " extracting: train/Truk-64-_jpg.rf.a7bae8a50cd87ce069ac4803bdc39b61.jpg  \n",
            " extracting: train/Truk-65-_jpg.rf.b4694b92d16f951ed3b3a195036a86c9.jpg  \n",
            " extracting: train/Truk-67-_jpg.rf.d735c0ffad25da2d227796b5e8fa1640.jpg  \n",
            " extracting: train/Truk-68-_jpg.rf.760094bb5a6e23638bebf5239da9f400.jpg  \n",
            " extracting: train/Truk-69-_jpg.rf.73d665f38009702d37211bc674bb399e.jpg  \n",
            " extracting: train/Truk-73-_jpg.rf.1fc8bebb29beee9105d5c013cc056434.jpg  \n",
            " extracting: train/Truk-74-_jpg.rf.94d0ced95fb66d672fc2d672393f9010.jpg  \n",
            " extracting: train/Truk-75-_jpg.rf.3546ff0559e325dfaae3496b9b1c5cc1.jpg  \n",
            " extracting: train/Truk-76-_jpg.rf.371b7a738a4aacd9e2517badb10422dc.jpg  \n",
            " extracting: train/Truk-77-_jpg.rf.c7596821e4ff1a4b61dd09f81e9cbe88.jpg  \n",
            " extracting: train/Truk-78-_jpg.rf.a797122fbbb3631f6af5f076d63b0c5a.jpg  \n",
            " extracting: train/Truk-79-_jpg.rf.19c6e77bed5d7f188fe30e6b77740e43.jpg  \n",
            " extracting: train/Truk-8-_jpg.rf.b8ffa31288481cd4e2a65899ac7367f1.jpg  \n",
            " extracting: train/Truk-80-_jpg.rf.e32cc2ab2c9148f37df2b9240963e092.jpg  \n",
            " extracting: train/Truk-81-_jpg.rf.7d68a8645c2a911db0614ec225df4665.jpg  \n",
            " extracting: train/Truk-83-_jpg.rf.eee63b53312a605f6bd185b721c824b4.jpg  \n",
            " extracting: train/Truk-84-_jpg.rf.783b2e15b3e09f36af7c33751afe70c0.jpg  \n",
            " extracting: train/Truk-85-_jpg.rf.0d4b7fd839a68b524c95ad21693b9f1f.jpg  \n",
            " extracting: train/Truk-86-_jpg.rf.4fcb892b1f594d50992626fb81ddebdb.jpg  \n",
            " extracting: train/Truk-88-_jpg.rf.99a1943265db1b364eeeb02e210ecef7.jpg  \n",
            " extracting: train/Truk-89-_jpg.rf.5b29108fd1c11701e24a761bfc186ff1.jpg  \n",
            " extracting: train/Truk-9-_jpg.rf.671969df248f6631eb48e328adff751b.jpg  \n",
            " extracting: train/Truk-90-_jpg.rf.1a8a17216e3d93b3c766a0ac47e1f6cb.jpg  \n",
            " extracting: train/Truk-91-_jpg.rf.4fb403547af2dddbab9345f1d8d36d05.jpg  \n",
            " extracting: train/Truk-92-_jpg.rf.e27fcb71b84cf46f0c50b4ec14e5a012.jpg  \n",
            " extracting: train/Truk-94-_jpg.rf.cef469976024291787b6b9c3d288cfca.jpg  \n",
            " extracting: train/Truk-95-_jpg.rf.fb4a4445c5d7ee42c4e7236015259fd7.jpg  \n",
            " extracting: train/Truk-99-_jpg.rf.a75573b1420973fca7c920f2758be45b.jpg  \n",
            " extracting: train/W1588TE-1-_jpg.rf.e396d7e4a520419e98159b52f2118472.jpg  \n",
            " extracting: train/W1588TE_jpg.rf.38fc37c23514f8ebd69fcac09eb8a658.jpg  \n",
            " extracting: train/Z1859LD_jpg.rf.aa7859e6595f5764b6140ed36c9d68da.jpg  \n",
            " extracting: train/_annotations.coco.json  \n",
            " extracting: train/ad-assets-2F21452-NT129720-2Ffield__jpg.rf.86e35941dcba09a51eba350add6a14e0.jpg  \n",
            " extracting: train/adad_PNG_jpg.rf.abe8ebbe470e358a3228d26f3b44906a.jpg  \n",
            " extracting: train/afas_PNG_jpg.rf.64c96d7bc1368f11f4c4cbfb0a8cb85a.jpg  \n",
            " extracting: train/anggota-linmas-dan-pecalang-melaksanakan-penertiban-penggunaan-masker-ppkm-psbb-jawa-bali_jpg.rf.b6cca758b2e56079e97a2c9a2db5662a.jpg  \n",
            " extracting: train/article-2598032-1CE7535A00000578-844_634x426__flip_jpg.rf.393a6a6d553091dcba1581bc8da3328c.jpg  \n",
            " extracting: train/asd_PNG_jpg.rf.d67fe734d5dcca00987f9dbf331185ce.jpg  \n",
            " extracting: train/asdfasw_PNG_jpg.rf.ecc64af4d6b1b26b8bb00cdac30beebb.jpg  \n",
            " extracting: train/asdqwe_PNG_jpg.rf.05223eb45e370788f3f865a47f58f838.jpg  \n",
            " extracting: train/asfdasd_PNG_jpg.rf.5f69a6d4f6e8564a6d0d394d577b2230.jpg  \n",
            " extracting: train/asia-vietnam-hanoi-traffic-traffic-jam-traffic-congestion-motorbikes-C8GFWR__flip_jpg.rf.4177de62a60289dd3b8c6cc195b7aaac.jpg  \n",
            " extracting: train/asian-motorbike-crowd-traffic-street-ho-chi-minh-city-vietnam-people-riding-helmets-62946642__flip_jpg.rf.b50451f701264f12a4a7c03ea30ebc74.jpg  \n",
            " extracting: train/asian-motorbike-crowd-traffic-street-ho-chi-minh-city-vietnam-people-riding-helmets-62946642_jpg.rf.d7a5ecd98df53bb9d2a25fe8ff4dbd05.jpg  \n",
            " extracting: train/awsfasfqw_PNG_jpg.rf.3943b725e9dac8fbd568846db324bfc1.jpg  \n",
            " extracting: train/cek-pemilik-plat-nomor-kendaraan-online-dari-hp_jpg.rf.45e4fe17879ee7de073803a2ac38a2c9.jpg  \n",
            " extracting: train/couple-goal-riding-biker-magazine-riding-the-motorcycle__flip_jpg.rf.7bc01ec2e35c911897fb18e650088a12.jpg  \n",
            " extracting: train/couple-goal-riding-biker-magazine-riding-the-motorcycle_jpg.rf.a64450edb2192d0fc536dfb4f766c709.jpg  \n",
            " extracting: train/dasdqwfqw_PNG_jpg.rf.873c1c7abcf7cd03b7074ffee6044cdf.jpg  \n",
            " extracting: train/depositphotos_121501430-stock-photo-mature-couple-sitting-on-scooter_jpg.rf.2f46660f8eff88f317cd1356fb9948be.jpg  \n",
            " extracting: train/e12ew_PNG_jpg.rf.510f12e271a1036ecb208efe88687d48.jpg  \n",
            " extracting: train/e1asdasd_PNG_jpg.rf.6d505ce8fc69bfd6cdf18ddfc3cad874.jpg  \n",
            " extracting: train/e1dasda_PNG_jpg.rf.5a158aaafb64c1f1ef2eb09f08d04893.jpg  \n",
            " extracting: train/easdasd_PNG_jpg.rf.fb328e8a87382e6668f49744790c711e.jpg  \n",
            " extracting: train/eqwasf_PNG_jpg.rf.e09bf527973843195276e476ea87c8f7.jpg  \n",
            " extracting: train/eqweqwe_PNG_jpg.rf.e80d19a93a98c3b2f727ac06c3688885.jpg  \n",
            " extracting: train/fe-120-ps574_jpg.rf.13773623939ebcbc27a057cb829a9904.jpg  \n",
            " extracting: train/fqqw_PNG_jpg.rf.7824bd36a9d6f74d6532e2f74a9976a4.jpg  \n",
            " extracting: train/fuso-34tb_jpg.rf.9e6acd84ed648835f9440923348eefb3.jpg  \n",
            " extracting: train/hanoi-vietnam-january-people-riding-motorbikes-busy-street-hanoi-vietnam-people-riding-motorbikes-busy-street-hanoi-120908376_jpg.rf.ef64f616a7f13a05c918c80ac608f133.jpg  \n",
            " extracting: train/https___s3-ap-northeast-1-amazonaws-com_psh-ex-ftnikkei-3937bb4_images_5_4_8_1_15041845-4-eng-GB_8D8A8513__flip_jpg.rf.27666698dffd18d17b0298d5e748c3d5.jpg  \n",
            " extracting: train/images230_jpg.rf.b89dd3d746b418663236f6054271df75.jpg  \n",
            " extracting: train/images238_jpg.rf.982c6c257bb280be5599afe390da1898.jpg  \n",
            " extracting: train/images240_jpg.rf.ada4e830e738fc691c566323d579bb21.jpg  \n",
            " extracting: train/images242_jpg.rf.3c278479604852dfdfceaca85657c936.jpg  \n",
            " extracting: train/images269_jpg.rf.71e0f6584ba6007779460a5bdd05c9b2.jpg  \n",
            " extracting: train/images278_jpg.rf.e6ed82bee13c8bb9dccd6aeeb84dee39.jpg  \n",
            " extracting: train/images298_jpg.rf.111485fda1e5330daf45cfca7c4a6399.jpg  \n",
            " extracting: train/images318_jpg.rf.9d13ee592a760e38539440986aa0bd5e.jpg  \n",
            " extracting: train/images327_jpg.rf.ff53b3eced8d70474fc352fff2367078.jpg  \n",
            " extracting: train/images328_jpg.rf.75cb4d3837667c3b4d60a4ba05d82e71.jpg  \n",
            " extracting: train/images339_jpg.rf.cf500bebcbb63d6479c61a6fcd29560a.jpg  \n",
            " extracting: train/images346_jpg.rf.384962f5a8f879bd7fec509acd876f74.jpg  \n",
            " extracting: train/images348_jpg.rf.798c6c250dc53b5aa5a3b8586fb8d498.jpg  \n",
            " extracting: train/images350_jpg.rf.6e91b46c65dd58dccbfb0cc93877d295.jpg  \n",
            " extracting: train/images351_jpg.rf.1d786dce82b8eeecc72291bee1492f2d.jpg  \n",
            " extracting: train/images367_jpg.rf.af3b672bbc527a27b0d831d513f74c7b.jpg  \n",
            " extracting: train/images369_jpg.rf.1d85a3ada588d8c99cb9f31e5affc35c.jpg  \n",
            " extracting: train/images376_jpg.rf.cc7a23a8d1565e70887c0f7383221996.jpg  \n",
            " extracting: train/images377_jpg.rf.461501e55ed1a9352d75582bc971418d.jpg  \n",
            " extracting: train/images381_jpg.rf.ae2a868ab39559ac9964435c3f054ee2.jpg  \n",
            " extracting: train/images382_jpg.rf.d840eaaa3add9623764b678ec6bbcb12.jpg  \n",
            " extracting: train/images383_jpg.rf.55ac4d5f6a150c2dc6b7f533ab7e401a.jpg  \n",
            " extracting: train/images385_jpg.rf.bcb9c702e0594c9db7ec26c97117b385.jpg  \n",
            " extracting: train/images387_jpg.rf.ad827a4bdc1f6152952df2b78c79b85d.jpg  \n",
            " extracting: train/images391_jpg.rf.058ce59e8d6ecfa5c795974d0335b99b.jpg  \n",
            " extracting: train/images400_jpg.rf.bf6c31bdffd49b8cd4807e40dffdd130.jpg  \n",
            " extracting: train/images44_jpg.rf.ee46073cbb65e223b7386aabe41c8978.jpg  \n",
            " extracting: train/images47_jpg.rf.74db1ee00c5ba98ef5d68fa7b2734b35.jpg  \n",
            " extracting: train/images52_jpg.rf.496fa4e1378738e2fea9f8299a29df8e.jpg  \n",
            " extracting: train/images54_jpg.rf.f7b85baf743c2fc303acebe6bcaab91f.jpg  \n",
            " extracting: train/images56_jpg.rf.00b0fd75dc4dd82c667795de121a961e.jpg  \n",
            " extracting: train/images58_jpg.rf.cf02e3f092920628ae4e28bcfdb4c462.jpg  \n",
            " extracting: train/images5_jpg.rf.715c92efa61062ac0fd4d101210b21d5.jpg  \n",
            " extracting: train/images60_jpg.rf.9972e2453ea2ab14002c1a0a8dbe69fa.jpg  \n",
            " extracting: train/images66_jpg.rf.b652d9db174a2da3d89b26fb34c8870f.jpg  \n",
            " extracting: train/images67_jpg.rf.deb4c6464b99131a0dd283fb3ba12e15.jpg  \n",
            " extracting: train/images6_jpg.rf.8b51f8e1f517248d99e2721d0036a578.jpg  \n",
            " extracting: train/images6_jpg.rf.c270508dc9788ba03ee01163d3d66d1e.jpg  \n",
            " extracting: train/images74_jpg.rf.fea625f4c1341466fc9795ab110311a1.jpg  \n",
            " extracting: train/images85_jpg.rf.a6a2e46886fbf6cba08eb3cede6ecb95.jpg  \n",
            " extracting: train/images90_jpg.rf.7fb81feac48f41d564a31b751669c992.jpg  \n",
            " extracting: train/images91_jpg.rf.21e15111b2cc030b517ea07ef2f8bd41.jpg  \n",
            " extracting: train/images92_jpg.rf.216517b79820f4fd7d77371456940857.jpg  \n",
            " extracting: train/images94_jpg.rf.04e3c484dde0adb74a2e419b29618254.jpg  \n",
            " extracting: train/img-p1651820217548-2_haxe3b_jpg.rf.2f854e7598a4977e8872bdde91e9153d.jpg  \n",
            " extracting: train/img-p1652107308949-1_xwovs6_jpg.rf.7391ce1c696093b437ced6bf951f6af8.jpg  \n",
            " extracting: train/img-p1652107308949-2_acmddq_jpg.rf.64d29a4861693d4a20e6cbad5ea2fc6f.jpg  \n",
            " extracting: train/img-p1652158769921-1_bzzoyi_jpg.rf.4ef1e493b81a2eefbaaefc1498e7f12e.jpg  \n",
            " extracting: train/img-p1652158769921-1_bzzoyi_jpg.rf.b3f4862f89b25411d16a0f689dd7f346.jpg  \n",
            " extracting: train/img-p1652159099741-1_yrdmem_jpg.rf.3c0030b2a831ab6dbea33bd3210a347d.jpg  \n",
            " extracting: train/img-p1652159099741-2_kct1x8_jpg.rf.9fc367c1739d727acbd9de479a3e1037.jpg  \n",
            " extracting: train/img-p1652159099741-2_kct1x8_jpg.rf.c88222fdec995a7c52893f5e55508445.jpg  \n",
            " extracting: train/img-p1652170725870-1_wvshgl_jpg.rf.6dbac6e2e0330348759f982d4eb185a8.jpg  \n",
            " extracting: train/img-p1652170725870-1_wvshgl_jpg.rf.9dcf0035528d1ecb39444cca370bb4b7.jpg  \n",
            " extracting: train/img-p1652234792788-1_rgesaj_jpg.rf.5fce5a1ceb2b222be33a8e7d7ee219ff.jpg  \n",
            " extracting: train/img-p1652234792788-1_rgesaj_jpg.rf.795325a482aa4c6574899c3215a51d7e.jpg  \n",
            " extracting: train/img-p1652234792788-2_x2ivdk_jpg.rf.fde906728aa9595d61976553ff2f23f2.jpg  \n",
            " extracting: train/img-p1652263017285-1_fli5yi_jpg.rf.d6c0266da90ab7be5ea3f3ddf636dc7a.jpg  \n",
            " extracting: train/img-p1652320270036-1_qdbazn_jpg.rf.c0a7d698ded770dfd98cdf4f77adb9c6.jpg  \n",
            " extracting: train/img-p1652320270036-2_k8tanl_jpg.rf.c0aa750fbc2eed4ac94ec23db7595850.jpg  \n",
            " extracting: train/img-p1652329424223-1_hjomi7_jpg.rf.be09fdb9b93f44651b11b2d3a9d8a0d9.jpg  \n",
            " extracting: train/img-p1652331040084-1_rdmc94_jpg.rf.7d621d026e48ae28a981a1b1e46bcf34.jpg  \n",
            " extracting: train/img-p1652331040084-2_hrr7bj_jpg.rf.18d1326c44e380a7b84c05ce759e6b0b.jpg  \n",
            " extracting: train/img-p1652333486992-2_gxnw20_jpg.rf.ad5ddcfe0e2a6d22cd34402e7d645792.jpg  \n",
            " extracting: train/img-p1652339531515-1_zvybsy_jpg.rf.d9190103931804c13fc60bc988906cc3.jpg  \n",
            " extracting: train/img-p1652342497571-1_pbcwh9_jpg.rf.b036c98df53f6de09c4ba1fd83ecf88c.jpg  \n",
            " extracting: train/img-p1652342497571-2_lahfkd_jpg.rf.9c2a8d5a06c95811a931dee75cc09bf9.jpg  \n",
            " extracting: train/img-p1652354746041-2_bz3rmj_jpg.rf.d0b11cd7c791f2fe768da7fd7974ad67.jpg  \n",
            " extracting: train/img-p1652354746041-2_bz3rmj_jpg.rf.f8ea84779badfe33a0c0b9807b55147e.jpg  \n",
            " extracting: train/img-p1652445794492-1_iyrvf7_jpg.rf.171702a30dbf3ed38e88323c16394c7a.jpg  \n",
            " extracting: train/img-p1652446607682-1_vhyo46_jpg.rf.792eaeca08a01d060c28268ad1afa8cc.jpg  \n",
            " extracting: train/img-p1652446607682-2_idxdcx_jpg.rf.e19a07219dd42f38121441408c544406.jpg  \n",
            " extracting: train/img-p1652454297915-1_htjzsx_jpg.rf.6a61eff0dab431907894b79266d7a4e8.jpg  \n",
            " extracting: train/img-p1652454297915-1_htjzsx_jpg.rf.d7ddc586a269131bc5d253d8c49f800f.jpg  \n",
            " extracting: train/img-p1652454297915-2_phw14k_jpg.rf.15e50d5b1825b60b5f6b1c6e16f97ffe.jpg  \n",
            " extracting: train/img-p1652545847960-2_qebtrh_jpg.rf.196fce1b9946d1939019c11b3f428e04.jpg  \n",
            " extracting: train/img-p1652706727912-2_binchc_jpg.rf.87b47f359d78da440f2df37edb148b02.jpg  \n",
            " extracting: train/img-p1652706727912-2_binchc_jpg.rf.ecaa043827b8bc1eb680218047bbe9f6.jpg  \n",
            " extracting: train/img-p1652713533367-2_gdciz7_jpg.rf.08ca0b28bca247580ea4845a7bcfcbc6.jpg  \n",
            " extracting: train/img-p1652713533367-2_gdciz7_jpg.rf.ef3cf98acba2b3a4851e377ca278533f.jpg  \n",
            " extracting: train/img-p1652773434128-2_nguqqm_jpg.rf.4cbdedfd41fa9e0bff63446a726a8a6a.jpg  \n",
            " extracting: train/img-p1652773434128-2_nguqqm_jpg.rf.71c03d4f4cf383edaa895b77988e4c3e.jpg  \n",
            " extracting: train/img-p1652775611668-1_hydn6i_jpg.rf.2eb8fafb40b5993fff051106a78b1d49.jpg  \n",
            " extracting: train/img-p1652857474976-1_nvwznb_jpg.rf.05faa05d603af0ead9a4b3e4c2d9cb32.jpg  \n",
            " extracting: train/img-p1652857474976-2_t9akoc_jpg.rf.5741c21d712ede3a7fbeb97ae6a199b2.jpg  \n",
            " extracting: train/img-p1652857474976-2_t9akoc_jpg.rf.5869fc156c4b13c6a694d4cc6a2eccec.jpg  \n",
            " extracting: train/img-p1652857847718-1_icriyb_jpg.rf.622fdb49da48d898f1a9a24d7ac4fe75.jpg  \n",
            " extracting: train/img-p1652857847718-2_jmjvel_jpg.rf.677dc7afacfda44f94ec71306e756f8a.jpg  \n",
            " extracting: train/img-p1652857847718-2_jmjvel_jpg.rf.98150414a7f849f4d4495fa994808071.jpg  \n",
            " extracting: train/img-p1652875748731-1_k64hdi_jpg.rf.b8589ea43372a452d68e4c0bd929bcc9.jpg  \n",
            " extracting: train/img-p1652875748731-2_mhqg1n_jpg.rf.5dabc5f4e57c0f18cb82bbc0c79b75fc.jpg  \n",
            " extracting: train/img-p1652885548798-1_bbhow8_jpg.rf.00c8d7073807c25aba112444049a0bee.jpg  \n",
            " extracting: train/img-p1652885548798-1_bbhow8_jpg.rf.73507eed510c8362a2772bf5a2ab7ec3.jpg  \n",
            " extracting: train/img-p1652889006582-2_cy7uno_jpg.rf.0448ae2953e38c978a2afafb2b1bf887.jpg  \n",
            " extracting: train/img-p1652889006582-2_cy7uno_jpg.rf.b9262a9a0784ff2f8f2b9fe9af123a8b.jpg  \n",
            " extracting: train/img-p1652889315521-2_hmgx0d_jpg.rf.2033d4a329d4e5c2cf88aaa52b2d0897.jpg  \n",
            " extracting: train/img-p1652889315521-2_hmgx0d_jpg.rf.98f06ab1082e52b2570f9e996e7f989b.jpg  \n",
            " extracting: train/maxresdefault-990x556-1_jpg.rf.b251eb1f6858ff4600c295dcc7316bd5.jpg  \n",
            " extracting: train/maxresdefault_jpg.rf.62f864297a3b1697f0b8cc6f5708987f.jpg  \n",
            " extracting: train/mini-tesla-model-s-for-kids-inset-license-plate-model-910_jpg.rf.655555a9e45cc984fa4d36f7d1d8b089.jpg  \n",
            " extracting: train/mobil-bekas-city-car-di-olx-dengan-jarak-tempuh-40000-45000-km-3_43_jpg.rf.4afbf5900a18bb7fa9368312553568b4.jpg  \n",
            " extracting: train/mobil_honda_jazz_rs_2013_matic_putih_plat_b_4231645_1502692175_jpg.rf.87265719244505e146dfe8af79779252.jpg  \n",
            " extracting: train/pelat-nomor-kendaraan-putih-1_169_jpeg_jpg.rf.efe38fdd3ef8fec944cce290d36bd931.jpg  \n",
            " extracting: train/pelat-nomor-khusus-motor-listrik3499_jpg.rf.7ea27b5a1a34645fb712f4263202d882.jpg  \n",
            " extracting: train/plat-kendaraan-unik-liputantimes-com-thumbnail-1-660x330_png_jpg.rf.4d22ebe78bdcdd7f7c9b22bf2bca319c.jpg  \n",
            " extracting: train/plat-nomor-putih-728x404_jpg.rf.cc7c944f50c9b4409d9f25491f04f758.jpg  \n",
            " extracting: train/plat2_jpg.rf.86a7dedb2ea6700181247e2a02db0e2d.jpg  \n",
            " extracting: train/removelicenseplatewhensellingcar_jpg.rf.d18e7c08655b8c2c256fd0b4e8f7ac9b.jpg  \n",
            " extracting: train/viar_q1_jpg.rf.579d1f7377c184a79a962fafa165d540.jpg  \n",
            "   creating: valid/\n",
            " extracting: valid/-0471C451-8CA5-4CEA-8EFD-3B0F147BF4B7-png_jpg.rf.9b43f3f32a181d44027004074913b2be.jpg  \n",
            " extracting: valid/-0585CFA0-7CD6-45D3-B7EB-1A109425F90D-png_jpg.rf.8af0bd244e0e904518bdbc511aa37ac7.jpg  \n",
            " extracting: valid/-05A70844-9653-4F87-9807-1ED0709FED44-png_jpg.rf.74fedd12149d470aca4aca8ce355d29f.jpg  \n",
            " extracting: valid/-0AE13AAD-2BD5-490E-B245-D51927B1EBBC-png_jpg.rf.a2103d854b537f490342b6bc86869b33.jpg  \n",
            " extracting: valid/-0C60C602-CF70-4679-BB4E-5A1CA33EF472-png_jpg.rf.540e83dff1dbf3db18e1a98e51fa74d1.jpg  \n",
            " extracting: valid/-0D39FCF1-152A-4C52-A0F2-64670E54DB6D-png_jpg.rf.890d2062dd40bda2a12e2093124e9124.jpg  \n",
            " extracting: valid/-0DEDC30B-FD9A-4A41-ABC0-DBEDE7C1C712-png_jpg.rf.b07dc33a654404e113812f91d2a3095a.jpg  \n",
            " extracting: valid/-0F270652-2281-4F2C-BF74-1091482A2939-png_jpg.rf.4b3161d5bc12fed87f094c15664b054b.jpg  \n",
            " extracting: valid/-11F0AF93-D3D0-4415-A4A0-B3430EA0886B-png_jpg.rf.9e530a41f934e7c47f96b607e471e58d.jpg  \n",
            " extracting: valid/-139B5DE6-BF8F-446C-B829-262C82389B8B-png_jpg.rf.7a78d7714fb94bb0ab958f096ec10b3c.jpg  \n",
            " extracting: valid/-152B35A7-2687-4126-B46B-5382319E7A3C-png_jpg.rf.52c04746a45bf2ba8d08d88101891b87.jpg  \n",
            " extracting: valid/-18994A3D-5086-4626-9746-C209358A65CC-png_jpg.rf.ce9e1d186fe66c30eb117f6594c170bb.jpg  \n",
            " extracting: valid/-1AED8217-3B98-4458-83DD-32F5CA3851FF-png_jpg.rf.3938fcdcc80ebdd2242e0d6fd3a0ae82.jpg  \n",
            " extracting: valid/-1B34BD79-4F5F-4106-AA41-7F931AFD231A-png_jpg.rf.4e43311e7c01b30bd742d0cde3e603ae.jpg  \n",
            " extracting: valid/-1B59F314-F3FE-4352-A076-48D5D98B1372-png_jpg.rf.2cd1fdf307c0046474d707c2fb182776.jpg  \n",
            " extracting: valid/-1CB4058F-662E-4470-8889-D0E5F9EAC264-png_jpg.rf.31ed34f7b74ab41b9207708f5055a03d.jpg  \n",
            " extracting: valid/-20370F09-C43F-47FF-AEDD-1508B10C5D42-png_jpg.rf.47ebf548553b6bb320d69f17c366d640.jpg  \n",
            " extracting: valid/-2202A4F3-BE1B-4E4C-8D0C-DCBDAA8F5303-png_jpg.rf.91afe4f71be1ab86315c5334cc40e224.jpg  \n",
            " extracting: valid/-232F1AAC-99B4-4968-8EF1-6B89C021BE11-png_jpg.rf.b635a10683b2ecd4a73ef16711eeda55.jpg  \n",
            " extracting: valid/-25B75F91-9590-4B9D-A441-755612305E00-png_jpg.rf.a512bd788e91ff94d0c7e0e2492b3400.jpg  \n",
            " extracting: valid/-26A4102E-9D99-421D-91DC-9E66089FF2F6-png_jpg.rf.b4b108e22755e11089b7e4e4fe1d4944.jpg  \n",
            " extracting: valid/-26D423C9-C9F8-4CA3-B49E-3664225FB20C-png_jpg.rf.e0640302632ed1150d93a8de4667636e.jpg  \n",
            " extracting: valid/-28A7CBC5-452A-4B8D-91E0-397F87E23E7F-png_jpg.rf.b2c3d83753719fffa2bae06c13fecece.jpg  \n",
            " extracting: valid/-2FA327E9-55B3-4CBB-8C63-54720A0F2EED-png_jpg.rf.1ae38867c5aea548deb16ef99f015b8b.jpg  \n",
            " extracting: valid/-3130BF7E-8143-44C3-AC0D-8068C9108560-png_jpg.rf.da2e36c7a251dac9466fec7d9edb5844.jpg  \n",
            " extracting: valid/-3163ca687f_jpg.rf.d87106d61df970ddd74868c3b6760591.jpg  \n",
            " extracting: valid/-332D2462-631E-4F9D-914E-9EA5A217A8FA-png_jpg.rf.25f3c2321ba613706312347acf1a3d0c.jpg  \n",
            " extracting: valid/-341F28F4-B515-475F-8729-F40EFDDDF0C2-png_jpg.rf.8476efb563e60849512c798eb4f612ab.jpg  \n",
            " extracting: valid/-375965D7-1A26-4644-AF71-19B3585749B4-png_jpg.rf.f9fbe5dfbe9c9c46ec107f8986cf3ad3.jpg  \n",
            " extracting: valid/-3D852B22-EFF0-4CD1-8BC7-7A9B657E4875-png_jpg.rf.d7a504b04969be5333da6a22730a5d7d.jpg  \n",
            " extracting: valid/-3EFC4A6B-3110-48FC-AC22-404D9A3443DA-png_jpg.rf.70f23915d203031509349c41ce03672d.jpg  \n",
            " extracting: valid/-3F3761A7-259D-401F-9563-1D7CDDBE92A4-png_jpg.rf.8764c8574876ff39fc8196aef5f12fa0.jpg  \n",
            " extracting: valid/-410FB936-1128-4721-89DE-79E2F58D3B24-png_jpg.rf.4e894a0d1fe67099146dfbbfdfcdbf88.jpg  \n",
            " extracting: valid/-45D13BE2-E6D3-4465-B1CE-3A73FCDFB83F-png_jpg.rf.290abf9e0461505847abefe421e07dda.jpg  \n",
            " extracting: valid/-46E5DC75-7D59-4D30-9025-24CA943CCF36-png_jpg.rf.addf78e284d75ccd822686f35cecca92.jpg  \n",
            " extracting: valid/-4BB97EA4-824F-4351-B178-A426E8AE6051-png_jpg.rf.a48409fcf20afd8d21df4a6412cbae03.jpg  \n",
            " extracting: valid/-4D888E2B-7F5D-4626-B4FF-E092A163D4B5-png_jpg.rf.7fdc857ec2e17b24163e2997cf7ed02f.jpg  \n",
            " extracting: valid/-53C40FB0-F866-4F4A-A410-D32C65C75BB4-png_jpg.rf.a2e1ce607df914f423e406b29322450b.jpg  \n",
            " extracting: valid/-56EF2068-CDF4-4068-80A1-E567375D4AE6-png_jpg.rf.e9756168b3e1a3e4e375e5d12fb294c4.jpg  \n",
            " extracting: valid/-59D02DDC-DB49-41DA-8B1F-33712FDE8CEE-png_jpg.rf.a64858e1f030506f359cb393377a87fb.jpg  \n",
            " extracting: valid/-5AF06BED-94B4-4CFE-9682-4D5AB122CE95-png_jpg.rf.0c7a8cd0e0025d831002d908fa42fec6.jpg  \n",
            " extracting: valid/-5C9472C7-6F7B-45B6-A2F4-0CE739421A98-png_jpg.rf.c9a0fa5f425c1ddfb3cb48c9f4de887f.jpg  \n",
            " extracting: valid/-5EA2A12A-708A-4984-80AC-438C76933457-png_jpg.rf.2ed1e8923ebad43eaf3093b6dd0811ac.jpg  \n",
            " extracting: valid/-608B1B77-EBBE-4E69-AB2F-13A3A5ED4C39-png_jpg.rf.bdf8982448737009483e8012e5c08738.jpg  \n",
            " extracting: valid/-6254A622-2157-4AD7-BB2C-4A3F4E465B5A-png_jpg.rf.c844d3362b7fb290dea9b5190593f29b.jpg  \n",
            " extracting: valid/-67A4D449-E510-4E00-9670-57BE579333CA-png_jpg.rf.10093e07751031f200972ee722dc7416.jpg  \n",
            " extracting: valid/-69AFCC3C-BC3B-41C8-A68A-8C645EB0D18C-png_jpg.rf.67c059671ce5b1b803e2f18419cbb612.jpg  \n",
            " extracting: valid/-6CE344F5-B7D2-4008-91F4-240859DF99F4-png_jpg.rf.cc3aa8eeeea27cecddee11f042251662.jpg  \n",
            " extracting: valid/-6CEAABEE-4CD1-4355-808B-EC5CCA98188E-png_jpg.rf.927eba1599b5deb35b996b973cfefb0c.jpg  \n",
            " extracting: valid/-6D282D80-AF13-4D14-919D-C071DD61EDCE-png_jpg.rf.e2ca0862e3dff17ac0ac29bbe6d2dc3e.jpg  \n",
            " extracting: valid/-6F4972B8-D275-4BE4-8219-CDF53D2F86C3-png_jpg.rf.46ce658436d2870fec8b550e83ad65cc.jpg  \n",
            " extracting: valid/-78F4C78C-3A14-4F7F-BE52-432212951D93-png_jpg.rf.419db7ea65ed87b772eac247960d81e7.jpg  \n",
            " extracting: valid/-7B18A2AD-E7BB-48C9-B81F-91593FD3068D-png_jpg.rf.6b78e193b312ecabe220a78e341d6119.jpg  \n",
            " extracting: valid/-7D594ED2-F6AD-4F7E-A58E-174C244D3E37-png_jpg.rf.edd0b447b58fbefacf71233ab8760103.jpg  \n",
            " extracting: valid/-7E37B3B7-140B-4D05-9757-A121EA2D41E0-png_jpg.rf.07b893d3086864d105a77b33cb9a90e5.jpg  \n",
            " extracting: valid/0000147617-e4eb190337827f8bbbcc9317d-1_jpg.rf.18a57cf0516ce8db1af13485d62365d6.jpg  \n",
            " extracting: valid/0000147617-e4eb190337827f8bbbcc9317d_jpg.rf.1453831b983eb9b05f4a487d32158b29.jpg  \n",
            " extracting: valid/010222-012216-1-1-0-cam1_jpg.rf.d07240cc12b6ea727026fcd6b96361b0.jpg  \n",
            " extracting: valid/010222-013334-1-1-0-cam1_jpg.rf.446d232cb79ae49f0b5485b91a0ddab5.jpg  \n",
            " extracting: valid/010222-014143-1-1-0-cam1_jpg.rf.6c8934a968977ad38d40b9d071283a10.jpg  \n",
            " extracting: valid/010222-014144-1-1-0-cam1_jpg.rf.3bf2d0b77b2ebc3b7edd2b8282d44618.jpg  \n",
            " extracting: valid/010222-014647-1-1-0-cam1_jpg.rf.c05c3395d0f492573bbe560b483913f7.jpg  \n",
            " extracting: valid/010222-015113-1-1-0-cam1_jpg.rf.d380ac78618a35714845f61e9cff0881.jpg  \n",
            " extracting: valid/010222-015215-1-1-0-cam1_jpg.rf.145fc5e5db9f81f891955be213918f9c.jpg  \n",
            " extracting: valid/010222-020856-1-1-0-cam1_jpg.rf.7b93a12566662e95f0d06ec360da1945.jpg  \n",
            " extracting: valid/010222-021716-1-1-0-cam1_jpg.rf.c9ab87a14f376943500b0c5d246dfa09.jpg  \n",
            " extracting: valid/010222-022110-1-1-0-cam1_jpg.rf.246eafae802d044cc7731ff5e1d15375.jpg  \n",
            " extracting: valid/010222-023727-1-1-0-cam1_jpg.rf.612f123795a826a9d40489cc4c7f1c23.jpg  \n",
            " extracting: valid/010222-024023-1-1-0-cam1_jpg.rf.9cc28b1789ce8edb6b0454855cdcfdca.jpg  \n",
            " extracting: valid/010222-024030-1-1-0-cam1_jpg.rf.148963474ef51c4a60a27bedb8a23b8d.jpg  \n",
            " extracting: valid/010222-024521-1-1-0-cam1_jpg.rf.427b4764009f4ae7380cf0950df400ab.jpg  \n",
            " extracting: valid/010222-024640-1-1-0-cam1_jpg.rf.02207cee4c6e4bc062d00aa0a2eebc47.jpg  \n",
            " extracting: valid/010222-024707-1-1-0-cam1_jpg.rf.acfc09d6023dab3aaa979823b2fab29c.jpg  \n",
            " extracting: valid/010222-030739-1-1-0-cam1_jpg.rf.dff5b278148d3d11906a49531e05c3aa.jpg  \n",
            " extracting: valid/010222-032026-1-1-0-cam1_jpg.rf.436154ccf230d0f989772aed35b91616.jpg  \n",
            " extracting: valid/010222-032238-1-1-0-cam1_jpg.rf.908dd7db1c189e5cc24006ed907d6d04.jpg  \n",
            " extracting: valid/010222-033026-1-1-0-cam1_jpg.rf.fab0276b8d20757fe40a879b73c85646.jpg  \n",
            " extracting: valid/010222-033149-1-1-0-cam1_jpg.rf.cad571a76612ef1208ed2e94439146b8.jpg  \n",
            " extracting: valid/010222-034759-1-1-0-cam1_jpg.rf.92de14d2cf09b6f14898891071621750.jpg  \n",
            " extracting: valid/010222-035617-1-1-0-cam1_jpg.rf.a50abecac1d06f3cb5f816169a105863.jpg  \n",
            " extracting: valid/010222-040150-1-1-0-cam1_jpg.rf.d437c6fb06ce22ec93606a5cae1dc00d.jpg  \n",
            " extracting: valid/010222-040627-1-1-0-cam1_jpg.rf.a4577929071f3d28a3a50b56fdb94ed1.jpg  \n",
            " extracting: valid/010222-042139-1-1-0-cam1_jpg.rf.d16ad94dafe68f761f7aafc3ead677b3.jpg  \n",
            " extracting: valid/010222-055446-1-1-0-cam1_jpg.rf.d2a84ca59e8dbd08820c107839db228f.jpg  \n",
            " extracting: valid/010222-080738-1-1-0-cam1_jpg.rf.eaa0a2c6da0789e5cea0a57e4375e982.jpg  \n",
            " extracting: valid/010222-080902-1-1-0-cam1_jpg.rf.1bf1da058c1347e3db8a381914e1c21e.jpg  \n",
            " extracting: valid/010222-082652-1-1-0-cam1_jpg.rf.05c94a865682572fcb59a10cfbf16bbf.jpg  \n",
            " extracting: valid/010222-093220-1-1-0-cam1_jpg.rf.bdccc4ca42e2c29a8a398b11ff0295db.jpg  \n",
            " extracting: valid/010222-112744-1-1-0-cam1_jpg.rf.b735842ad40e026ee233c9fb095e517a.jpg  \n",
            " extracting: valid/010222-134208-1-1-0-cam1_jpg.rf.91292303332b29b7f374f6b1c2588203.jpg  \n",
            " extracting: valid/010222-141527-1-1-0-cam1_jpg.rf.999339a90d8bfc8c2e2135155599b833.jpg  \n",
            " extracting: valid/010222-154402-1-1-0-cam1_jpg.rf.e5124713f6789f773a7416fc16adf8b8.jpg  \n",
            " extracting: valid/010222-171021-1-1-0-cam1_jpg.rf.db299a9b76fdf194f800bddf006b2f6c.jpg  \n",
            " extracting: valid/010222-174616-1-1-0-cam1_jpg.rf.755972e3f399b73996972167ead42884.jpg  \n",
            " extracting: valid/010222-183936-1-1-0-cam1_jpg.rf.9f6a11f777d3288376875d4dcabd4caa.jpg  \n",
            " extracting: valid/010222-185509-1-1-0-cam1_jpg.rf.e4dba9bc94c3f50ba413755a2a75d1d5.jpg  \n",
            " extracting: valid/010222-223707-1-1-0-cam1_jpg.rf.535c336fabc5bd53f764048ad851e72e.jpg  \n",
            " extracting: valid/010222-224622-1-1-0-cam1_jpg.rf.639ce35e4a91642637d4cebe9d8fdb79.jpg  \n",
            " extracting: valid/020222-024341-1-1-0-cam1_jpg.rf.6cc383cd26dca90941a84998fe1daac4.jpg  \n",
            " extracting: valid/020222-030330-1-1-0-cam1_jpg.rf.91c6e8e7f460db3dcf5908b0bdcb6a05.jpg  \n",
            " extracting: valid/020222-031557-1-1-0-cam1_jpg.rf.9c7792138cff8f8ad1cdad09aa926c8c.jpg  \n",
            " extracting: valid/020222-032001-1-1-0-cam1_jpg.rf.78ea67c8bfb4198491a85d4be357fbf6.jpg  \n",
            " extracting: valid/020222-034638-1-1-0-cam1_jpg.rf.0e0dbf5283269272d03e1924ae8733c6.jpg  \n",
            " extracting: valid/020222-034935-1-1-0-cam1_jpg.rf.71eb795cb7a9154e491bc664da9babf5.jpg  \n",
            " extracting: valid/020222-035058-1-1-0-cam1_jpg.rf.73b6a3c0bbddecc462cb679c1b0ec843.jpg  \n",
            " extracting: valid/020222-035213-1-1-0-cam1_jpg.rf.84855ba7a6cf177ab00c7f60b686c4bb.jpg  \n",
            " extracting: valid/020222-035558-1-1-0-cam1_jpg.rf.1792646689a1ea29431bb8be7b4a9ffc.jpg  \n",
            " extracting: valid/020222-040549-1-1-0-cam1_jpg.rf.128b2c4f964289469ae4c54dc922b136.jpg  \n",
            " extracting: valid/020222-041345-1-1-0-cam1_jpg.rf.b335bd5a570aca9b2e64776d87eadc22.jpg  \n",
            " extracting: valid/020222-042216-1-1-0-cam1_jpg.rf.d147fdd2aca1f6a4d27e03f04e319d4e.jpg  \n",
            " extracting: valid/020222-042537-1-1-0-cam1_jpg.rf.c42bd7bba3b3b40f897d2f3b97dacf05.jpg  \n",
            " extracting: valid/020222-043111-1-1-0-cam1_jpg.rf.8bb73065a8bd5fc6e9ae0b9556e8621c.jpg  \n",
            " extracting: valid/020222-043827-1-1-0-cam1_jpg.rf.89a28dcabe5412c646867fd65bfe4071.jpg  \n",
            " extracting: valid/020222-043829-1-1-0-cam1_jpg.rf.6559f07fb1da9eae6dadf72bb2853942.jpg  \n",
            " extracting: valid/020222-043831-1-1-0-cam1_jpg.rf.85894ecf929612d776967ec76534fbcb.jpg  \n",
            " extracting: valid/020222-045015-1-1-0-cam1_jpg.rf.2aaa4b5eaeee0de03e2787a170731696.jpg  \n",
            " extracting: valid/020222-064223-1-1-0-cam1_jpg.rf.848d348a1411247a0886e90dace6db90.jpg  \n",
            " extracting: valid/020222-082827-1-1-0-cam1_jpg.rf.244a4c8bdb65fc02ce0bbb6dfeee90d3.jpg  \n",
            " extracting: valid/020222-135625-1-1-0-cam1_jpg.rf.38ad0aa1472c5dfe10d6bafecc0947eb.jpg  \n",
            " extracting: valid/020222-144857-1-1-0-cam1_jpg.rf.151e1ea5ff0a91c79fb65f9841d11fe6.jpg  \n",
            " extracting: valid/020222-195200-1-1-0-cam1_jpg.rf.4fa378a66f78d2f8a34726ffbf8b7fda.jpg  \n",
            " extracting: valid/020222-223936-1-1-0-cam1_jpg.rf.7ccdf98d5b554b8ca32523cf7628a9f8.jpg  \n",
            " extracting: valid/0394_jpg.rf.89008ac45b4415bd3fc0be27fcbd20b2.jpg  \n",
            " extracting: valid/0397_jpg.rf.fdf6f1a007584f52b2162c75fb418539.jpg  \n",
            " extracting: valid/0407_jpg.rf.fe9fdf3186dea7820305843fce67bd8d.jpg  \n",
            " extracting: valid/0411_jpg.rf.a4c817416d54d96fa507155489bad0f2.jpg  \n",
            " extracting: valid/0415_jpg.rf.087088a9ff5d47d3d2c45dfe2c51ac09.jpg  \n",
            " extracting: valid/0417_jpg.rf.789b5dd00f235162f6120671ce5d7643.jpg  \n",
            " extracting: valid/0418_jpg.rf.aa35059b623ea592f0cedfbbf0636e60.jpg  \n",
            " extracting: valid/0424_jpg.rf.49cce96571b3776a40c35e043e7c6ed8.jpg  \n",
            " extracting: valid/0428_jpg.rf.984a2975ecf2e2448b372ce0d3cb8c01.jpg  \n",
            " extracting: valid/0432_jpg.rf.78772ddde2651f4da87537247905d2c5.jpg  \n",
            " extracting: valid/0437_jpg.rf.f173a51dfd9912badd5dd767b47e1e7c.jpg  \n",
            " extracting: valid/0461_jpg.rf.56f818df9149aa3b7b3e9c66d2bdeccf.jpg  \n",
            " extracting: valid/0470_jpg.rf.952fc5d6a7229f6007bd82fa05934ff8.jpg  \n",
            " extracting: valid/0471_jpg.rf.ade22a032d7ea414cd0d0df91f2de236.jpg  \n",
            " extracting: valid/0473_jpg.rf.9403bf67e039c2c60e6af59572e6bdd0.jpg  \n",
            " extracting: valid/0484_jpg.rf.791f6f3cea1f393085790b2e4bbd05f1.jpg  \n",
            " extracting: valid/0488_jpg.rf.6ab3d85ff4379d144b88a1e26c7c9d45.jpg  \n",
            " extracting: valid/0494_jpg.rf.f90f4499e1a2ddcf4ea0b9fb67187dc4.jpg  \n",
            " extracting: valid/0495_jpg.rf.364ca3dfe689342b759e47acf3927738.jpg  \n",
            " extracting: valid/0497_jpg.rf.323dd1b2e0c20de00361dd27e2b3a163.jpg  \n",
            " extracting: valid/0501_jpg.rf.89780a3bb64a40c3e5145fc0b5b8487f.jpg  \n",
            " extracting: valid/0505_jpg.rf.a4df6d7ce84888d04822c20e7403095c.jpg  \n",
            " extracting: valid/0510_jpg.rf.c687a99bc4470c51e74b634112abf3f1.jpg  \n",
            " extracting: valid/0512_jpg.rf.c64c41f8939ab6b567e2b6386407a880.jpg  \n",
            " extracting: valid/0514_jpg.rf.fd1b4015590e493484c4339053cc212a.jpg  \n",
            " extracting: valid/0518_jpg.rf.db8028604e3e3ff87a396ccceae90a89.jpg  \n",
            " extracting: valid/0519_jpg.rf.de20fd9b559f55cca4e6d7f8439c7393.jpg  \n",
            " extracting: valid/0522_jpg.rf.b13c20070e21a1c6ca4dbd79dec95c56.jpg  \n",
            " extracting: valid/0526_jpg.rf.d4bbe9b78ff266442304ba744941ef0b.jpg  \n",
            " extracting: valid/0535_jpg.rf.3b7439382ff87dae54d2a7debb6dfbfe.jpg  \n",
            " extracting: valid/0537_jpg.rf.7a1a3672e4ac16a10c60a23e9a9d3a63.jpg  \n",
            " extracting: valid/0538_jpg.rf.c047e3f763034b46d20017e942fb3b26.jpg  \n",
            " extracting: valid/0542_jpg.rf.353fc65e027858c847cc7ee17cb165a3.jpg  \n",
            " extracting: valid/0555_jpg.rf.b14ea6bab3bf74fac1a37bd77f185f35.jpg  \n",
            " extracting: valid/0556_jpg.rf.b677da47aa37fa91f53a77ffd8a4c281.jpg  \n",
            " extracting: valid/0559_jpg.rf.2894551cda676373ea01967110de9eab.jpg  \n",
            " extracting: valid/0568_jpg.rf.ee4294051cd80600721cfc3450fcf99c.jpg  \n",
            " extracting: valid/0581_jpg.rf.695f67001fe4d68b64c460fad9757394.jpg  \n",
            " extracting: valid/0589_jpg.rf.d34d0bd6e6faac81df81f5ebfccdb49e.jpg  \n",
            " extracting: valid/0591_jpg.rf.c7f58b7dfbe8edf5caf660abe05526a4.jpg  \n",
            " extracting: valid/0602_jpg.rf.8141430cbc0ed7920364051b8cb422fd.jpg  \n",
            " extracting: valid/0609_jpg.rf.0a2a4f208de68e7f6ec4036a5c9ed553.jpg  \n",
            " extracting: valid/0610_jpg.rf.ebe428cf0dec1ef035107dd8bb7fb369.jpg  \n",
            " extracting: valid/0612_jpg.rf.50582c571ebdd83f247c74377e8fbb5b.jpg  \n",
            " extracting: valid/0618_jpg.rf.ce72e8bc975d0e9a5ff5ac4aebabe913.jpg  \n",
            " extracting: valid/0630_jpg.rf.3cd1ba1920d661ddd77bef1e4a97fa44.jpg  \n",
            " extracting: valid/0638_jpg.rf.9b670bb11e05eae3caef00c408908ea0.jpg  \n",
            " extracting: valid/0645_jpg.rf.a18ba23d37eb952c8042a69695b6a015.jpg  \n",
            " extracting: valid/0652_jpg.rf.fbe12be34bbcc97b1a66dcbb9275f130.jpg  \n",
            " extracting: valid/0655_jpg.rf.33e1214192086db4695f366805bca447.jpg  \n",
            " extracting: valid/0677_jpg.rf.6efd086cb68eb57db9410ae8dd39ccea.jpg  \n",
            " extracting: valid/0680_jpg.rf.3573e531d8a57a00a53f1b5a56e36c2f.jpg  \n",
            " extracting: valid/0682_jpg.rf.88385df3da864a515a3474475effbb81.jpg  \n",
            " extracting: valid/0683_jpg.rf.0cbf56d48f9d519269622fccf75ab34d.jpg  \n",
            " extracting: valid/0693_jpg.rf.182ed170c28f62c5313233f4008a75a3.jpg  \n",
            " extracting: valid/0695_jpg.rf.800d9749e93bb0dfc46c9e9e66f573d8.jpg  \n",
            " extracting: valid/0696_jpg.rf.564acab3b47c6f90bc6ecb9992b40e60.jpg  \n",
            " extracting: valid/0699_jpg.rf.97c0db862ad7de6228471f8bd45b2f25.jpg  \n",
            " extracting: valid/070122-114055-1-1-0-197265625-cam1_jpg.rf.bdf437da9a65c8a2db12895d32998c28.jpg  \n",
            " extracting: valid/070122-120345-1-1-0-379150390625-cam1_jpg.rf.0f5eb6e3b40d549df74903f2abcfaa41.jpg  \n",
            " extracting: valid/070122-121013-1-1-0-39306640625-cam1_jpg.rf.91cb9a34e23ffd4e78960a5f43b1f935.jpg  \n",
            " extracting: valid/070122-122133-1-1-0-236572265625-cam1_jpg.rf.734f51908f686fe1fb17ce4ec3f400a5.jpg  \n",
            " extracting: valid/070122-123954-1-1-0-259765625-cam1_jpg.rf.f4772db441656e9961f9a5bc1fbad9a4.jpg  \n",
            " extracting: valid/070122-124341-1-1-0-3056640625-cam1_jpg.rf.8bbb1fd478c95a288e7723d8b45540b4.jpg  \n",
            " extracting: valid/070122-134303-1-1-0-2412109375-cam1_jpg.rf.65c33ca4e8d009fe3cbd7b871ac53082.jpg  \n",
            " extracting: valid/070122-134727-1-1-0-319580078125-cam1_jpg.rf.d844b7cabf2a1ec8ffa720cbaf50af20.jpg  \n",
            " extracting: valid/070122-143941-1-1-0-291015625-cam1_jpg.rf.13e3e985daad27f7c71f26817be77bd2.jpg  \n",
            " extracting: valid/070122-144825-1-1-0-33544921875-cam1_jpg.rf.f2cca90c42ff78da58afcce65ed1ed97.jpg  \n",
            " extracting: valid/0701_jpg.rf.1251085396f7b7a44d74a268dfccf263.jpg  \n",
            " extracting: valid/0702_jpg.rf.8456b25f2a8197d408c56c27e8d0a63a.jpg  \n",
            " extracting: valid/0703_jpg.rf.a8ff35aec7c0271495c0436bc4d4cb9e.jpg  \n",
            " extracting: valid/0712_jpg.rf.b502ed014bd6984494658e981bccb6a7.jpg  \n",
            " extracting: valid/0714_jpg.rf.d8a9b2119ca4b952a93c5afe1b6b039d.jpg  \n",
            " extracting: valid/0717_jpg.rf.a47e4555c6f87db5f6b638a0cf5d8dd1.jpg  \n",
            " extracting: valid/0724_jpg.rf.8a9e8b9a7305ddb4530e768df2347369.jpg  \n",
            " extracting: valid/0727_jpg.rf.e2da55022e227b837dfd5f409e56895d.jpg  \n",
            " extracting: valid/0733_jpg.rf.5f54102da3826e461b7366e428d4783d.jpg  \n",
            " extracting: valid/0747_jpg.rf.72f348f1ea425ddc6747cffa761553bf.jpg  \n",
            " extracting: valid/0750_jpg.rf.25563ccabeaa8fab32214b48bd27c364.jpg  \n",
            " extracting: valid/0759_jpg.rf.2b635d469934215b4a508cc0c0d611f9.jpg  \n",
            " extracting: valid/0760_jpg.rf.260b5f876ef22a3102918eb704b15b65.jpg  \n",
            " extracting: valid/0761_jpg.rf.0a4a491b0f540f7f94f3d4bb20e8bfca.jpg  \n",
            " extracting: valid/0769_jpg.rf.adf5b6f6e4d2c6277f5b8b26c0f6c7e8.jpg  \n",
            " extracting: valid/077006000_1466184933-kepala_kuning-1_jpg.rf.8b1789219007797b2c1ff746672c0bef.jpg  \n",
            " extracting: valid/0770_jpg.rf.2c0253c8263c21aba3a44b9bee4a999f.jpg  \n",
            " extracting: valid/0780_jpg.rf.b2a3f8031ce6e08830f4d4707ad605be.jpg  \n",
            " extracting: valid/0782_jpg.rf.4f3819057e472e0a7b4a77c8305c5bf6.jpg  \n",
            " extracting: valid/0789_jpg.rf.b619cd1d4af17aa022e75e220b8a3198.jpg  \n",
            " extracting: valid/0791_jpg.rf.4531c822b8e9f6165d7605f491855663.jpg  \n",
            " extracting: valid/0799_jpg.rf.85de0807e0c9913341c713d798639fce.jpg  \n",
            " extracting: valid/080222-013619-1-1-0-cam1_jpg.rf.4f494583d7ff08192fce495d46191120.jpg  \n",
            " extracting: valid/080222-025152-1-1-0-cam1_jpg.rf.90084d25f51eb96b7cf26919b2cfb596.jpg  \n",
            " extracting: valid/080222-030825-1-1-0-cam1_jpg.rf.dbdc976a0651ab63917d2591abbf74de.jpg  \n",
            " extracting: valid/080222-064901-1-1-0-cam1_jpg.rf.a9757701a28ed1ff39e21e56ba53ddb9.jpg  \n",
            " extracting: valid/080222-071106-1-1-0-cam1_jpg.rf.ddd465e5ee1955fc564e784fc7f81359.jpg  \n",
            " extracting: valid/080222-082057-1-1-0-cam1_jpg.rf.b808e840b031f213ded36d8043c40605.jpg  \n",
            " extracting: valid/080222-101134-1-1-0-cam1_jpg.rf.c466dccae2d9581f14076fc0fff980cb.jpg  \n",
            " extracting: valid/080222-142255-1-1-0-cam1_jpg.rf.0e7a9ff35a87b015dd545f08c2562d6d.jpg  \n",
            " extracting: valid/080222-150004-1-1-0-cam1_jpg.rf.43f2fed917b56a8405891f6f2821288b.jpg  \n",
            " extracting: valid/080222-150331-1-1-0-cam1_jpg.rf.40b447347779c831c3042a2b940adbf0.jpg  \n",
            " extracting: valid/080222-154138-1-1-0-cam1_jpg.rf.67aec00010ef1c1a51ab3a18cd8c92d6.jpg  \n",
            " extracting: valid/080222-170408-1-1-0-cam1_jpg.rf.6cdf1078ec819ad92d66a9a025894077.jpg  \n",
            " extracting: valid/080222-172224-1-1-0-cam1_jpg.rf.3a99aa75ab38cd99ee07dc72c69f027d.jpg  \n",
            " extracting: valid/080222-172358-1-1-0-cam1_jpg.rf.3222375c1124dfb488c4746d05a7dbcc.jpg  \n",
            " extracting: valid/080222-172411-1-1-0-cam1_jpg.rf.690e227bad2321a58b6d680073545d77.jpg  \n",
            " extracting: valid/080222-172710-1-1-0-cam1_jpg.rf.ef9d50ceabb9091e8a12239740bbbe7e.jpg  \n",
            " extracting: valid/080222-181608-1-1-0-cam1_jpg.rf.4974d6eac59fa9a9c947bee92e6022f7.jpg  \n",
            " extracting: valid/080222-184601-1-1-0-cam1_jpg.rf.29b757450f3dd8544883528a06f8eb80.jpg  \n",
            " extracting: valid/080222-184627-1-1-0-cam1_jpg.rf.b2e8ef64d6d4fec048e26fc794c30200.jpg  \n",
            " extracting: valid/080222-190941-1-1-0-cam1_jpg.rf.51c9ebabcffd7867417bc20af050fe7a.jpg  \n",
            " extracting: valid/080222-203753-1-1-0-cam1_jpg.rf.ed086c8eb116af91a8a1a5872dd9c285.jpg  \n",
            " extracting: valid/080222-204328-1-1-0-cam1_jpg.rf.39b20a21e4fc8a52549f45d2262ee4d0.jpg  \n",
            " extracting: valid/080222-223715-1-1-0-cam1_jpg.rf.aae3e0dfa201161a02484ebeb8b1ed5a.jpg  \n",
            " extracting: valid/080222-225849-1-1-0-cam1_jpg.rf.f7411fb34a1266d9475e36e8433cabc3.jpg  \n",
            " extracting: valid/080222-235703-1-1-0-cam1_jpg.rf.6ed7fb551e3bfd5c6cd60a15955b1d50.jpg  \n",
            " extracting: valid/0803_jpg.rf.a18ee100c368bb4b1bbc5ba775ebd7fe.jpg  \n",
            " extracting: valid/0807_jpg.rf.3f473f0aa12f2268ea730a00b44c7ae6.jpg  \n",
            " extracting: valid/0811_jpg.rf.22b09bf5f85c3dc4c474fc24f7a2a69f.jpg  \n",
            " extracting: valid/0812_jpg.rf.e30c70f9ac2fa0b6f12ef391755a9bd5.jpg  \n",
            " extracting: valid/0813_jpg.rf.e80388e6cba4f80275e042e9fc4189b8.jpg  \n",
            " extracting: valid/0817_jpg.rf.7a5813c1352baae42b3eb04af3feb797.jpg  \n",
            " extracting: valid/0819_jpg.rf.5e3a2fb2388c50fcde5a9df9af616e71.jpg  \n",
            " extracting: valid/0822_jpg.rf.2fe8ec6533afb44435f63868040c04d2.jpg  \n",
            " extracting: valid/090222-001125-1-1-0-cam1_jpg.rf.162bcadf8186d8d757b7bbd8161e9c48.jpg  \n",
            " extracting: valid/090222-005442-1-1-0-cam1_jpg.rf.3d8171a2af81ac5190f5e4e9adaefe4a.jpg  \n",
            " extracting: valid/090222-013410-1-1-0-cam1_jpg.rf.a63079d3b9dfe7d0227602d388731b29.jpg  \n",
            " extracting: valid/090222-013947-1-1-0-cam1_jpg.rf.61ce9883ce9aa16d298433657a40e062.jpg  \n",
            " extracting: valid/090222-014947-1-1-0-cam1_jpg.rf.edd1e0294a15309b7bf300f86d1893de.jpg  \n",
            " extracting: valid/090222-015824-1-1-0-cam1_jpg.rf.3eb642e71567f92f9c2e78ef7849e163.jpg  \n",
            " extracting: valid/090222-020057-1-1-0-cam1_jpg.rf.297f4b85c191fcb988135bb919438013.jpg  \n",
            " extracting: valid/090222-044850-1-1-0-cam1_jpg.rf.bfbe5b9aa58f6d3d0f5e549df1b1d68b.jpg  \n",
            " extracting: valid/090222-053723-1-1-0-cam1_jpg.rf.9eed37991b75bcc464e956101f75630f.jpg  \n",
            " extracting: valid/090222-055613-1-1-0-cam1_jpg.rf.fa8f8cebd9551c058fabd9f7ee6208e5.jpg  \n",
            " extracting: valid/090222-060335-1-1-0-cam1_jpg.rf.573e7b299cd88abe6d5d40f443b709f1.jpg  \n",
            " extracting: valid/090222-061046-1-1-0-cam1_jpg.rf.7e6515fe730003987cb167332f15017b.jpg  \n",
            " extracting: valid/090222-061442-1-1-0-cam1_jpg.rf.44ff3c9eafc6fc4fe73bbb8161578ed0.jpg  \n",
            " extracting: valid/090222-061722-1-1-0-cam1_jpg.rf.d2b874cd79964c8c89bfd03f1daaad58.jpg  \n",
            " extracting: valid/090222-062555-1-1-0-cam1_jpg.rf.905fc8bd643db026606a6c713f1de9e7.jpg  \n",
            " extracting: valid/090222-062806-1-1-0-cam1_jpg.rf.7ede0e20fa81e002cd0deb62389fd77d.jpg  \n",
            " extracting: valid/090222-063044-1-1-0-cam1_jpg.rf.64eac5255a0d9d9cb8662362d338e476.jpg  \n",
            " extracting: valid/090222-064811-1-1-0-cam1_jpg.rf.bf368eecae0fc954899c180ddf17515d.jpg  \n",
            " extracting: valid/090222-071726-1-1-0-cam1_jpg.rf.564fab704407a23ca91364d4a4a49a29.jpg  \n",
            " extracting: valid/090222-072752-1-1-0-cam1_jpg.rf.58639be6361b938e4db25bc7986d6bab.jpg  \n",
            " extracting: valid/090222-080932-1-1-0-cam1_jpg.rf.03ab5e52645b73f565c3dbc1398c2177.jpg  \n",
            " extracting: valid/090222-082314-1-1-0-cam1_jpg.rf.7f3deabe4321c87eb2d6cacdc9651a63.jpg  \n",
            " extracting: valid/090222-082740-1-1-0-cam1_jpg.rf.4a726fb1a92c6e8b05070f03bc67222c.jpg  \n",
            " extracting: valid/090222-133956-1-1-0-cam1_jpg.rf.f5035dc6ffaedbc79f7f97c26d068228.jpg  \n",
            " extracting: valid/090222-140124-1-1-0-cam1_jpg.rf.5db03d05fe9ef452afa3a7f1f1549926.jpg  \n",
            " extracting: valid/0ZO0S_jpg.rf.b8ca1e9d5e06234cb80009f50376f7fb.jpg  \n",
            " extracting: valid/100-E-6467-QW-09-20_jpeg_jpg.rf.d7f4fde36fb94412328057b76a7f8daf.jpg  \n",
            " extracting: valid/101_1184_jpg.rf.aea111e05b9677beb4267ab340c74c61.jpg  \n",
            " extracting: valid/101_jpg.rf.1a4cce82dfb14d82e4882d63e7f5c01c.jpg  \n",
            " extracting: valid/103_jpg.rf.59b1b0116d9d7f4582a354eb4a541509.jpg  \n",
            " extracting: valid/106985_0_jpg.rf.1415c6ea8ba49e454b5a29ae636b265f.jpg  \n",
            " extracting: valid/10_jpeg_jpg.rf.419c1bb5dfbbaf78f55d70aba0ef5bd0.jpg  \n",
            " extracting: valid/10_jpg.rf.89ada79d93bb8c451b854634c93c5f67.jpg  \n",
            " extracting: valid/110-E-4753-QV-08-20_jpeg_jpg.rf.df3333f3f965da019af7d70dbb271851.jpg  \n",
            " extracting: valid/110222-065352-1-1-0-cam1_jpg.rf.b0df431b67b90d8a7bee4fba621db168.jpg  \n",
            " extracting: valid/110222-071337-1-1-0-cam1_jpg.rf.270973cd18e351e6714047cff7d57151.jpg  \n",
            " extracting: valid/110222-072458-1-1-0-cam1_jpg.rf.6a669c068146f23bd01db497afd7f231.jpg  \n",
            " extracting: valid/110222-080251-1-1-0-cam1_jpg.rf.2e44584210305a1972fb45da7fc21697.jpg  \n",
            " extracting: valid/110222-081215-1-1-0-cam1_jpg.rf.5bd139e45f7cf20b123041a760e2b128.jpg  \n",
            " extracting: valid/110222-082817-1-1-0-cam1_jpg.rf.e80ebdda8c3e1a224f6b104ad71ff489.jpg  \n",
            " extracting: valid/110222-084455-1-1-0-cam1_jpg.rf.0635ab30fca835bc67c5588826f61e3c.jpg  \n",
            " extracting: valid/110222-085804-1-1-0-cam1_jpg.rf.881bbe2a61c4c0f27c58e881137cff71.jpg  \n",
            " extracting: valid/110222-104957-1-1-0-cam1_jpg.rf.ba6bcf6dbe7a81cd1c18d915fe64e6a9.jpg  \n",
            " extracting: valid/110222-142105-1-1-0-cam1_jpg.rf.abc21103c2211257f6b8008639300bc7.jpg  \n",
            " extracting: valid/110222-144839-1-1-0-cam1_jpg.rf.db6f8be6c4b4342fcca552f9d3ca63d8.jpg  \n",
            " extracting: valid/110222-150829-1-1-0-cam1_jpg.rf.5a6733463b880129ed96972d62b00f78.jpg  \n",
            " extracting: valid/110222-153848-1-1-0-cam1_jpg.rf.576582672599b092ecb1a166917424a0.jpg  \n",
            " extracting: valid/110222-153932-1-1-0-cam1_jpg.rf.6d0d740e5548f6c62e6b858a085a2026.jpg  \n",
            " extracting: valid/110222-154046-1-1-0-cam1_jpg.rf.ded7ae5636558f63a852cfacdc593908.jpg  \n",
            " extracting: valid/110222-154920-1-1-0-cam1_jpg.rf.9b7180f3e275547a67540969022196c3.jpg  \n",
            " extracting: valid/110222-155010-1-1-0-cam1_jpg.rf.9f1e467814b1a399b51730ff5862d50d.jpg  \n",
            " extracting: valid/110222-155354-1-1-0-cam1_jpg.rf.8ba62d15fdcb2591ee35a2b8290f9fa6.jpg  \n",
            " extracting: valid/110222-160139-1-1-0-cam1_jpg.rf.8e1d35d12afdb5dbcca023e3a59b1692.jpg  \n",
            " extracting: valid/110222-160229-1-1-0-cam1_jpg.rf.82b13e56637e0176f905d33418b4d880.jpg  \n",
            " extracting: valid/110222-160836-1-1-0-cam1_jpg.rf.fe5660f9c8151c9e2f695dc00100b6f7.jpg  \n",
            " extracting: valid/110222-161349-1-1-0-cam1_jpg.rf.4bd1c33e33a80e05cbd1f9fc89d2f1d3.jpg  \n",
            " extracting: valid/110222-164240-1-1-0-cam1_jpg.rf.0ca90b2aacc1f1f6f103e42a92de66f8.jpg  \n",
            " extracting: valid/110222-172253-1-1-0-cam1_jpg.rf.c3b4abd11c6cb94c2f4973c8b266dd39.jpg  \n",
            " extracting: valid/110222-172325-1-1-0-cam1_jpg.rf.139dde5a45f9b89664e3f79ee586a9b6.jpg  \n",
            " extracting: valid/110222-175554-1-1-0-cam1_jpg.rf.adcfa156d7a47d9f22ffa389f6bb43b8.jpg  \n",
            " extracting: valid/110222-175604-1-1-0-cam1_jpg.rf.256b18ec299bfa91991a67891c6563f5.jpg  \n",
            " extracting: valid/110222-181017-1-1-0-cam1_jpg.rf.935bed14a7dd5b159be9276bb1a73f4e.jpg  \n",
            " extracting: valid/110222-181741-1-1-0-cam1_jpg.rf.0747448e72062e4685d62bb749ea92d1.jpg  \n",
            " extracting: valid/110222-181928-1-1-0-cam1_jpg.rf.f55e46fdad2bd987007296a3d28e815d.jpg  \n",
            " extracting: valid/110222-182842-1-1-0-cam1_jpg.rf.3a448e05768365857cb0b3e14b4cd507.jpg  \n",
            " extracting: valid/110222-184015-1-1-0-cam1_jpg.rf.cf354209081412a5e5f01456f7e08b78.jpg  \n",
            " extracting: valid/110222-201434-1-1-0-cam1_jpg.rf.33ef0ca385bc8075f9bb2567d1876209.jpg  \n",
            " extracting: valid/110222-205117-1-1-0-cam1_jpg.rf.00cc71f6225adee2195eaea932b7ce11.jpg  \n",
            " extracting: valid/110222-225315-1-1-0-cam1_jpg.rf.bfcf65a848fa0d965ec853cae13e4aa4.jpg  \n",
            " extracting: valid/110222-230358-1-1-0-cam1_jpg.rf.278ad7cf0bea2aa5bc569045bee863db.jpg  \n",
            " extracting: valid/110222-231906-1-1-0-cam1_jpg.rf.a40fff16a09fedd6d035cc8db8ba2445.jpg  \n",
            " extracting: valid/110222-234902-1-1-0-cam1_jpg.rf.f0ae4ec75c0129b42bbded11d961ec31.jpg  \n",
            " extracting: valid/111_jpg.rf.b322bbb0e82833357ab809675d309749.jpg  \n",
            " extracting: valid/113_jpg.rf.3877878225218897367c3760f8607d31.jpg  \n",
            " extracting: valid/114-E-3536-O-06-10_jpg.rf.a445814b3cc684900d7c252df918d8e3.jpg  \n",
            " extracting: valid/11546_Sb4733_14_jpg.rf.13869800aecae7360fd34a96fb8fbeb1.jpg  \n",
            " extracting: valid/1157524truk1780x390_jpg.rf.6f0fd2f45429bbf3e5138209755b44bd.jpg  \n",
            " extracting: valid/1157524truk1780x390_jpg.rf.df227fc6069eff0a5061cc4bd0fd3d30.jpg  \n",
            " extracting: valid/115988_jpg.rf.a0be6785c17a3060215467dfc90bd3a1.jpg  \n",
            " extracting: valid/119_jpg.rf.45e5949397c1f4416c7a1f0ea3272431.jpg  \n",
            " extracting: valid/11_jpeg_jpg.rf.d47bccd8daad05a53cac489fa69b3b6d.jpg  \n",
            " extracting: valid/12-E-2462-QF-02-19_jpeg_jpg.rf.a204d03a0d368cb03414e15274a406e0.jpg  \n",
            " extracting: valid/120222-003317-1-1-0-cam1_jpg.rf.709c8a523454a8453522cfbe8fa5f607.jpg  \n",
            " extracting: valid/120222-051626-1-1-0-cam1_jpg.rf.f07a37c82178b27655a198c2269be230.jpg  \n",
            " extracting: valid/120222-055935-1-1-0-cam1_jpg.rf.ec9461736a8bff8add38cf0b5cc7fb65.jpg  \n",
            " extracting: valid/120222-061208-1-1-0-cam1_jpg.rf.3fbbf33b8d63b75aa2273e0e0f8b8305.jpg  \n",
            " extracting: valid/120222-061442-1-1-0-cam1_jpg.rf.a4f22a4a08daa9d455ebba96bf5db3fb.jpg  \n",
            " extracting: valid/120222-061504-1-1-0-cam1_jpg.rf.61bc25fe45476ec5ff678c1d63e3ab71.jpg  \n",
            " extracting: valid/120222-061540-1-1-0-cam1_jpg.rf.e10b2d753da6777553d06a1bf7a90b32.jpg  \n",
            " extracting: valid/120222-064410-1-1-0-cam1_jpg.rf.3071a127046bd35f0eb6feb46dc4fba9.jpg  \n",
            " extracting: valid/120222-074018-1-1-0-cam1_jpg.rf.cbe67cf3cbeade2dd386b4b244b7e1df.jpg  \n",
            " extracting: valid/120222-101902-1-1-0-cam1_jpg.rf.58a1ee121f5ec5280341e51cc126652e.jpg  \n",
            " extracting: valid/120222-110716-1-1-0-cam1_jpg.rf.dc087a326fb9a3dd1fcd99fd6afabf8f.jpg  \n",
            " extracting: valid/120222-134234-1-1-0-cam1_jpg.rf.52b2353a6ff72b34b4779aa5cac6411f.jpg  \n",
            " extracting: valid/120222-145825-1-1-0-cam1_jpg.rf.5772ccb746c7d30d011a799d7d35c723.jpg  \n",
            " extracting: valid/120222-155650-1-1-0-cam1_jpg.rf.55725222fc81a67ce425dd55566e545d.jpg  \n",
            " extracting: valid/120222-160924-1-1-0-cam1_jpg.rf.4f1579f3de7d765470f625e132148d95.jpg  \n",
            " extracting: valid/120222-172518-1-1-0-cam1_jpg.rf.e7d0a979feee393d5f5297777b631e8f.jpg  \n",
            " extracting: valid/120222-190219-1-1-0-cam1_jpg.rf.b8d3f40dbdfa2e4f33f8d93cd0945722.jpg  \n",
            " extracting: valid/120222-211608-1-1-0-cam1_jpg.rf.1df95406224854dfddf40422626ef7bd.jpg  \n",
            " extracting: valid/120222-221149-1-1-0-cam1_jpg.rf.3254337dbaba50d180388e4fd21f591a.jpg  \n",
            " extracting: valid/120222-224047-1-1-0-cam1_jpg.rf.04e7069859e9507669c1fdd449d9c8d8.jpg  \n",
            " extracting: valid/120_jpg.rf.c3ec8d41dfce4f111a083662bfeb1a92.jpg  \n",
            " extracting: valid/1211192truk1780x390_jpg.rf.56dd2786c68f422534ee4ff04439d0fc.jpg  \n",
            " extracting: valid/1211192truk1780x390_jpg.rf.793b9ed3799c1051074432cabf07b138.jpg  \n",
            " extracting: valid/122-E-3206-PAO-06-22_jpeg_jpg.rf.7b8311fa2280949eedfd578605963790.jpg  \n",
            " extracting: valid/122235900-ho-chi-minh-city-viet-nam-april-26-2019-group-of-vietnamese-wear-glasses-face-mask-ride-motorbike-un_jpg.rf.01837ee697affc98e879ba85e6171c14.jpg  \n",
            " extracting: valid/128-E-4877-SV-05-21_jpg.rf.ca220cd05ca144b2d4b728931c2841e9.jpg  \n",
            " extracting: valid/129_jpg.rf.9c153ab2d8e7c666a1f28309496b3443.jpg  \n",
            " extracting: valid/130-E-9967-P-12-22_jpg.rf.de4ac4ac29a970379938f0e3477a23ad.jpg  \n",
            " extracting: valid/130222-014244-1-1-0-cam1_jpg.rf.d575bcd06649ac91320a43b847aa2d9c.jpg  \n",
            " extracting: valid/130222-015106-1-1-0-cam1_jpg.rf.63f26944dc49e3b61bc66d8057c2bb0e.jpg  \n",
            " extracting: valid/130222-032131-1-1-0-cam1_jpg.rf.5385156c3709c3e13bf6e2e689cd4e4f.jpg  \n",
            " extracting: valid/130222-055002-1-1-0-cam1_jpg.rf.abe1bcf5fc8422d41f17fcc246f82ccf.jpg  \n",
            " extracting: valid/130222-064003-1-1-0-cam1_jpg.rf.afcf6aa063ffb2fe340eaf85fe90e1a1.jpg  \n",
            " extracting: valid/130222-070050-1-1-0-cam1_jpg.rf.f4d8936069abbf4e713e0c2e42fd85e5.jpg  \n",
            " extracting: valid/130222-071343-1-1-0-cam1_jpg.rf.c2c324f978576d017776399941e9e815.jpg  \n",
            " extracting: valid/130222-073934-1-1-0-cam1_jpg.rf.930c2e5296cfedf0bbcfa1995b213011.jpg  \n",
            " extracting: valid/130222-140808-1-1-0-cam1_jpg.rf.2d63c343501cc8c406d5bd9971c81b4d.jpg  \n",
            " extracting: valid/130222-154003-1-1-0-cam1_jpg.rf.75565a65f700c87fdbda3c2ec4dcbced.jpg  \n",
            " extracting: valid/130222-155001-1-1-0-cam1_jpg.rf.47d93c797ecf5495a4c743f885f9f98a.jpg  \n",
            " extracting: valid/130222-155544-1-1-0-cam1_jpg.rf.18244c0671a480d0ea593c4ba75e2cd2.jpg  \n",
            " extracting: valid/130222-155703-1-1-0-cam1_jpg.rf.3a4435e6bfc62506c4b52bb1240644b7.jpg  \n",
            " extracting: valid/130222-175044-1-1-0-cam1_jpg.rf.f1696dfe71ecb972aa3820ca407992fb.jpg  \n",
            " extracting: valid/130222-180811-1-1-0-cam1_jpg.rf.817cae11b7b341ea14f8a4a575360fd0.jpg  \n",
            " extracting: valid/130_jpg.rf.1912877958b227ecd84ceae7281d996b.jpg  \n",
            " extracting: valid/1360d6f2-23a9-4c09-b708-a1049865e80c-jpg_jpg.rf.2ccea70a6865d103242f9d0ea314d1d6.jpg  \n",
            " extracting: valid/13685839-hanoi-vietnam-february-19-traffic-on-hanoi-street-hanoi-vietnam-february-19-2011-in-hanoi-vietnam__flip_jpg.rf.4c506144b59ec5181b973fecdcf1983a.jpg  \n",
            " extracting: valid/13_jpg.rf.bddf523e3f156b441b462aa960160dce.jpg  \n",
            " extracting: valid/14-E-1129-RP-07-18_jpg.rf.3948a14c374940a240ccc5631ec04a39.jpg  \n",
            " extracting: valid/140222-000112-1-1-0-cam1_jpg.rf.d193e27de2d87a04e8404cd3b6fd2c6a.jpg  \n",
            " extracting: valid/140222-003042-1-1-0-cam1_jpg.rf.e7760757bdd1b47a68b16ec812e6bdbb.jpg  \n",
            " extracting: valid/140222-014419-1-1-0-cam1_jpg.rf.5c5ea8149eab429ccf1bd1a9caa8d87a.jpg  \n",
            " extracting: valid/140222-021017-1-1-0-cam1_jpg.rf.60bb3fde5a331433feca4197ccb85b3f.jpg  \n",
            " extracting: valid/140222-023629-1-1-0-cam1_jpg.rf.50337cc34e210678fff42c4c69c02488.jpg  \n",
            " extracting: valid/140222-055129-1-1-0-cam1_jpg.rf.30ad808b6ea0cbb066a294c1c4e554e0.jpg  \n",
            " extracting: valid/140222-055557-1-1-0-cam1_jpg.rf.129c4b1443dd88ccad246868efd353cb.jpg  \n",
            " extracting: valid/140222-060645-1-1-0-cam1_jpg.rf.ef8374709e307e4930c19715bc8a95ad.jpg  \n",
            " extracting: valid/140222-060812-1-1-0-cam1_jpg.rf.76b8e8430d737f8295529d00b43a9751.jpg  \n",
            " extracting: valid/140222-061458-1-1-0-cam1_jpg.rf.ea31fd34b381adad97e6617fee7c6c48.jpg  \n",
            " extracting: valid/140222-063014-1-1-0-cam1_jpg.rf.314fdc4312c12cfd56b6dde80c89571d.jpg  \n",
            " extracting: valid/140222-063028-1-1-0-cam1_jpg.rf.9b15206e8e41f20f442ff4854e7c5798.jpg  \n",
            " extracting: valid/140222-065015-1-1-0-cam1_jpg.rf.7aa0a04b824bfae1099bfffd25647322.jpg  \n",
            " extracting: valid/140222-065032-1-1-0-cam1_jpg.rf.17c7d27b62e2e24e0f7dddf6f06b16c2.jpg  \n",
            " extracting: valid/140222-071010-1-1-0-cam1_jpg.rf.f06710a523526a9627c33b50570d18a8.jpg  \n",
            " extracting: valid/140222-083215-1-1-0-cam1_jpg.rf.0b22f6b089193d18cb231def470ff694.jpg  \n",
            " extracting: valid/140222-083704-1-1-0-cam1_jpg.rf.1339a8f9d4364cd772c19d213054bfe8.jpg  \n",
            " extracting: valid/140222-091725-1-1-0-cam1_jpg.rf.a6c3f04d6aa624dae9920f53e60132f0.jpg  \n",
            " extracting: valid/140222-094816-1-1-0-cam1_jpg.rf.7b9f3799f5bf52d0a9fdf5af8c9776ae.jpg  \n",
            " extracting: valid/140222-104725-1-1-0-cam1_jpg.rf.c1bd0d30f68d88baf9695fc9de735c0a.jpg  \n",
            " extracting: valid/140222-111605-1-1-0-cam1_jpg.rf.488e7cbd6753eca3797c444d76070636.jpg  \n",
            " extracting: valid/140222-113318-1-1-0-cam1_jpg.rf.2be21e730c179cfc5c43614dbcf710eb.jpg  \n",
            " extracting: valid/140222-131200-1-1-0-cam1_jpg.rf.56e4f4689ae33832924d320bfc412749.jpg  \n",
            " extracting: valid/140222-135244-1-1-0-cam1_jpg.rf.13c74f06e7eab1c0b7f13a3f92722beb.jpg  \n",
            " extracting: valid/140222-144101-1-1-0-cam1_jpg.rf.dab01808ec0356203c999bffc7bdb88a.jpg  \n",
            " extracting: valid/140222-144941-1-1-0-cam1_jpg.rf.192920421e1b53133dbfd45dcfd8efd4.jpg  \n",
            " extracting: valid/140222-145522-1-1-0-cam1_jpg.rf.15df0f7c838225ca87cb5b56b428cf78.jpg  \n",
            " extracting: valid/140222-151229-1-1-0-cam1_jpg.rf.481764c97997cbb6f474a34cd593547b.jpg  \n",
            " extracting: valid/140222-151905-1-1-0-cam1_jpg.rf.aa18f47ec55ed61e106c8f817c2ed544.jpg  \n",
            " extracting: valid/140222-153557-1-1-0-cam1_jpg.rf.9da790871f329601269f4cf28e319bb8.jpg  \n",
            " extracting: valid/140222-153621-1-1-0-cam1_jpg.rf.22a97639f6ca4c30639698d822293d40.jpg  \n",
            " extracting: valid/140222-154842-1-1-0-cam1_jpg.rf.bfb8702a12022d3e79b3efc77f94fce5.jpg  \n",
            " extracting: valid/140222-155048-1-1-0-cam1_jpg.rf.4c577453cb7fd28875fb7c902d11d871.jpg  \n",
            " extracting: valid/140222-155252-1-1-0-cam1_jpg.rf.2ef842f6325de4e8d8f4eba11fa138bc.jpg  \n",
            " extracting: valid/140222-155843-1-1-0-cam1_jpg.rf.f01af4ca92becebbb891c1e9b2f71ebd.jpg  \n",
            " extracting: valid/140222-160115-1-1-0-cam1_jpg.rf.67a628dfd6dfa610a6e06d764f99c4b1.jpg  \n",
            " extracting: valid/140222-162700-1-1-0-cam1_jpg.rf.42f54a093038b48f24fc44318a07c356.jpg  \n",
            " extracting: valid/140222-163509-1-1-0-cam1_jpg.rf.29b91d112bcb37cf7fad7f1c09947ffd.jpg  \n",
            " extracting: valid/140222-165019-1-1-0-cam1_jpg.rf.9fe47b00c1f445ff5e6a4cfbf28dc807.jpg  \n",
            " extracting: valid/140222-171904-1-1-0-cam1_jpg.rf.0dbc66cf2035727cd88ead17ba531368.jpg  \n",
            " extracting: valid/140222-172225-1-1-0-cam1_jpg.rf.eb9b3b8674b9f86cb1140f5d79a085d6.jpg  \n",
            " extracting: valid/140222-172817-1-1-0-cam1_jpg.rf.bf9f72532cacc8a0ce294f2dde455bfb.jpg  \n",
            " extracting: valid/140222-173030-1-1-0-cam1_jpg.rf.0a4ecb012f139545c84c9f298f0727a6.jpg  \n",
            " extracting: valid/140222-174440-1-1-0-cam1_jpg.rf.94c45e6571b5d010476087f4f19b1c2a.jpg  \n",
            " extracting: valid/140222-174650-1-1-0-cam1_jpg.rf.a2751dae22e544c178ab79bb682e46c2.jpg  \n",
            " extracting: valid/140222-180500-1-1-0-cam1_jpg.rf.60efff1848a2ddcf6de695954a99fd02.jpg  \n",
            " extracting: valid/140222-183100-1-1-0-cam1_jpg.rf.fd99833d5c092b8a062be7b4060d8c3a.jpg  \n",
            " extracting: valid/141101_jpg.rf.22530a328dcf883e5b6f8f907ac7fcca.jpg  \n",
            " extracting: valid/143302_jpg.rf.5b337f0c61e886b2c036e31a68060632.jpg  \n",
            " extracting: valid/146_jpg.rf.ef0b7f85f443e63046f10a0925298972.jpg  \n",
            " extracting: valid/147-E-2881-QAA-10-22_jpg.rf.0002170edcd2997f5d7b93f80b3cae72.jpg  \n",
            " extracting: valid/14931_1100209_6-1_jpg.rf.432f1285bc88384bc03c264f62e049b0.jpg  \n",
            " extracting: valid/14931_1100209_7-1_jpg.rf.07ca144da1c6ddf8da256ddeeb2efaf8.jpg  \n",
            " extracting: valid/14931_1100209_7-1_jpg.rf.ea34a0cdce0767e6b299a7e7f7e82cc0.jpg  \n",
            " extracting: valid/14_jpeg_jpg.rf.af45ca353268dc5e0553f0481919d7bb.jpg  \n",
            " extracting: valid/150_jpg.rf.10fff6fad2242b935200a968173d0ffe.jpg  \n",
            " extracting: valid/151-E-5090-TW-05-18_jpg.rf.c118c846e871cf4f87d6927b8b20a55c.jpg  \n",
            " extracting: valid/1517432936821_jpg.rf.f0055b4e84d20145c53498fc2dda8b35.jpg  \n",
            " extracting: valid/152-E-3772-SV-05-16_jpeg_jpg.rf.a40fc88e7eb99ee00397f900ae79ec4c.jpg  \n",
            " extracting: valid/153_jpg.rf.1c8897d0a5ff951922790261d73ca2e9.jpg  \n",
            " extracting: valid/1574233981_ets2_03894_jpg.rf.5cbe2ed59dd6f25acf2194ee1e769bf5.jpg  \n",
            " extracting: valid/1598286031-20130714_082914-1024x768_jpg.rf.1adcaf0c409c0185a5af05c80439f9c6.jpg  \n",
            " extracting: valid/16012-colt-jual-mobil-mitsubishi-can_jpg.rf.f5b7fe47f32df97e21c08935b9364e0e.jpg  \n",
            " extracting: valid/16482_1806189169446_jpg.rf.ae69f19b69e4dc8473a7e3204209d5a9.jpg  \n",
            " extracting: valid/16482_1806189169446_jpg.rf.b5bc8e95e91bf3a3974e6602ec26aaf9.jpg  \n",
            " extracting: valid/16482_3666418146613_jpg.rf.508050a9cb4a2b0079a5e16b7ee5b378.jpg  \n",
            " extracting: valid/16482_4786988467249_jpg.rf.fa2cbc2be13d09603622d79920f43d7e.jpg  \n",
            " extracting: valid/16482_6538366098693_jpg.rf.9954f61f732fd96b61d79168999f7038.jpg  \n",
            " extracting: valid/164_jpg.rf.e869e3b17c694848a7d66f05d685f3d8.jpg  \n",
            " extracting: valid/168_jpg.rf.401bec679a69a1d50b683a9892353ad8.jpg  \n",
            " extracting: valid/169-E-2637-WM-02-21_jpg.rf.d25282789e9416be2fcd8674e8762ef8.jpg  \n",
            " extracting: valid/16_jpeg_jpg.rf.b46c7f61aebdd53d6b29ff73b2bdc5ed.jpg  \n",
            " extracting: valid/171443_jpg.rf.c9e2cc7c8e4eece621f62d3a021c2809.jpg  \n",
            " extracting: valid/175_jpg.rf.db8b62f7257836438caa262dc5917e9b.jpg  \n",
            " extracting: valid/177-E-2380-SA-09-18_jpg.rf.3eab99e69ea4821213f854c51bb42c99.jpg  \n",
            " extracting: valid/178-E-5430-SL-02-20_jpg.rf.860d9096e4b35bb7024e7dea167adc59.jpg  \n",
            " extracting: valid/17828_5789ACS01_2_jpg.rf.f97c11c3999b86c1e4e3bcd4a78a09a2.jpg  \n",
            " extracting: valid/17828_5993AFS01_3_jpg.rf.62708db32dd13fdafde69ff9c291bc9c.jpg  \n",
            " extracting: valid/17828_6080AFS01_7-1_jpg.rf.d40a813ba115431442c57621f78d7d34.jpg  \n",
            " extracting: valid/17828_6080AFS01_7-1_jpg.rf.f29cc5aec315d7f9e1e34334294eef7c.jpg  \n",
            " extracting: valid/17828_6137AFS01_11_jpg.rf.28612c118c51914dc2c0df72abf712b0.jpg  \n",
            " extracting: valid/182_jpg.rf.0bf3e7a4786c9eda276c4c0ac8118831.jpg  \n",
            " extracting: valid/184-07_jpg.rf.14496b035568951244de80789372cfa5.jpg  \n",
            " extracting: valid/185-E-6017-SR-03-13_jpg.rf.86422e464bcd4cf0ebe0e25fe01adb16.jpg  \n",
            " extracting: valid/186-E-6173-IM-11-18_jpeg_jpg.rf.4572ee1b98ac8b4e000dfcb9e7c9c4ab.jpg  \n",
            " extracting: valid/186_jpg.rf.e007aae52c9634f616c9553bc21a03e3.jpg  \n",
            " extracting: valid/188-E-2647-SL-01-20_jpeg_jpg.rf.7e69cdc53f3a22c9d4358216d44c4cc6.jpg  \n",
            " extracting: valid/188_jpg.rf.11d2785f5bd5aed797c90a3d01b57439.jpg  \n",
            " extracting: valid/18_jpeg_jpg.rf.ac3b3bb695c78a65d4991f458a33b27c.jpg  \n",
            " extracting: valid/18_jpg.rf.95e52de7dbc0fd511ee13c06c5f53448.jpg  \n",
            " extracting: valid/19575a5n4f_jpg.rf.a3292b7294ea81aa793b952d87e27532.jpg  \n",
            " extracting: valid/1991-mitsubishi-canter-crew-cab-flat_jpg.rf.3667f8310e18fcd61df6f596fdcb38c8.jpg  \n",
            " extracting: valid/1BCE466D-FE13-4738-8CE1-752980A1622F_jpg.rf.ceb2a79e138b35cfd2b13ecc7c12a6f1.jpg  \n",
            " extracting: valid/1_1_jpg.rf.57fe4cfe7b09196f6948605a7277c8f3.jpg  \n",
            " extracting: valid/1_jpeg_jpg.rf.0a35cea89f8f753c4ec3ccb16594a776.jpg  \n",
            " extracting: valid/2-80757120-Motor-Vespa-primavera-3vie-2014-Plat-AB-Tangan-Pertama-Mesin-CVT-Halus-Harga-Neg_jpg.rf.073c8e5e1d3164c716aa5fa3e5b671a5.jpg  \n",
            " extracting: valid/2-E-6223-PAC-05-21_jpeg_jpg.rf.999936692ac989573550049a7e15dfe0.jpg  \n",
            " extracting: valid/20-E-4221-RL-04-19_jpg.rf.566ed40023b1f0faba07f96ec27b88c4.jpg  \n",
            " extracting: valid/20-kode-plat-kendaraan-kota-Semarang-_jpg.rf.ee82fc531a8c43ec8d17ec0e8c852492.jpg  \n",
            " extracting: valid/200275_jpg.rf.4deb1156846987ce592fca2a75faec43.jpg  \n",
            " extracting: valid/2007-mitsubishi-fuso-fk200-24ft-box-_jpg.rf.8b03fb2b55a69777fd251cd368a9a33e.jpg  \n",
            " extracting: valid/2007-mitsubishi-fuso-fm260-26-box-tr_jpg.rf.57cbba4ceebd3dc7f9594330227730b5.jpg  \n",
            " extracting: valid/2008-mitsubishi-fuso-wrecker-tow-tru-1_jpg.rf.755609bdc31d2beda439c16f3af6b38c.jpg  \n",
            " extracting: valid/2009-Mitsubishi-Canter-mini-dump-tru_jpg.rf.cb8a0443e7413646a8c1cdf1d2ab9e3a.jpg  \n",
            " extracting: valid/2009-Mitsubishi-Canter-mini-dump-tru_jpg.rf.fb62511ad77c6ee4e82fcde0dbdb286a.jpg  \n",
            " extracting: valid/200_jpg.rf.5d79231dfeb8baab569e87764ca00878.jpg  \n",
            " extracting: valid/2010-mitsubishi-fuso-26-ft-box-truck-1_jpg.rf.f78c148296d6d36d66ce2e96f07a85ab.jpg  \n",
            " extracting: valid/2010-mitsubishi-fuso-26-ft-box-truck_jpg.rf.a993a37a874fed91c341a4dbe3787f38.jpg  \n",
            " extracting: valid/2010-mitsubishi-fuso-26-ft-box-truck_jpg.rf.dffa8925f646032498c0b539be572df9.jpg  \n",
            " extracting: valid/2010-mitsubishi-fuso-fe145-12ft-box-_jpg.rf.0305cf1476959d0470a8fc238123f830.jpg  \n",
            " extracting: valid/2010-mitsubishi-fuso-fe145-12ft-box-_jpg.rf.9ac2546d9034dfb62e098218b79fffcc.jpg  \n",
            " extracting: valid/2012-mitsubishi-fuso-canter-fe160-du_jpg.rf.258bf1f87864243e10c8691a94aba192.jpg  \n",
            " extracting: valid/2012-mitsubishi-fuso-fe160-16ft-dump-1_jpg.rf.bacd6e8250f906db8df1efc9d7981917.jpg  \n",
            " extracting: valid/2012-mitsubishi-fuso-fe160-16ft-dump-2_jpg.rf.0ef648485213f65e9c254b9c7f65afa0.jpg  \n",
            " extracting: valid/20121009_123807_jpg.rf.1e7472b887fd0109e08d2d2a307035fc.jpg  \n",
            " extracting: valid/2013-Fuso-Canter-4x4-1-1_jpg.rf.69cd21823badea0a663b2f2b8dc1ead5.jpg  \n",
            " extracting: valid/2013-Mitsubishi-18ft-Refrigerated-Va_jpg.rf.739fd37084ec0981828643dd03727a04.jpg  \n",
            " extracting: valid/2013-Mitsubishi-18ft-Refrigerated-Va_jpg.rf.c9985fdf8c42a7f64609c177198c9fc0.jpg  \n",
            " extracting: valid/2013-Mitsubishi-18ft-Refrigerated-Va_jpg.rf.cc8c5ee29877bdcf27fac84f579bb5c1.jpg  \n",
            " extracting: valid/2013-Mitsubishi-Fuso-Canter-7C15-PBU-1_jpg.rf.e4865fc3a308d136eedabbc2d884189d.jpg  \n",
            " extracting: valid/2014-mitsubishi-fuso-fe160-14-feet-b_jpg.rf.135504ecd70c69c703a02d1fa7edff41.jpg  \n",
            " extracting: valid/2014-mitsubishi-fuso-fe160-14-feet-b_jpg.rf.dbfd9645845e29510efe64caa67014ef.jpg  \n",
            " extracting: valid/2015-Mitsubishi-Fuso-Canter-7C15-4x2-1_jpg.rf.f28fb457cd5c9d1704edc7bcb9dd4fa2.jpg  \n",
            " extracting: valid/2015-Mitsubishi-Fuso-Canter-7C15-4x2_jpg.rf.87e763e5cd3b8cc86294a986708562f9.jpg  \n",
            " extracting: valid/2015-Mitsubishi-Fuso-Canter-7C15-4x2_jpg.rf.bfa20cd5a3bfea385108d892cfa31501.jpg  \n",
            " extracting: valid/20170325_115955_HDRw_1u_jpg.rf.19b79f36d08719f7dceff18d3eac7a0e.jpg  \n",
            " extracting: valid/20170325_115955_HDRw_1u_jpg.rf.63fe92627df39366317bb90029236ce8.jpg  \n",
            " extracting: valid/201707170712_fuso-1024x512_jpg.rf.7e215f0c91ff38834a3674914ba30c7a.jpg  \n",
            " extracting: valid/201707170712_fuso_jpg.rf.a2f2bb2ead0900c658c0d4a13f8381bf.jpg  \n",
            " extracting: valid/20171211_122519_jpg.rf.e71b60172c28ac0a2996a3a0f804d123.jpg  \n",
            " extracting: valid/20171211_160452_jpg.rf.484c485e02ff3938759a3fb319ed5539.jpg  \n",
            " extracting: valid/20171212_073548_jpg.rf.b7fd7fb23251b2c9329d6bc1f2dae109.jpg  \n",
            " extracting: valid/20171212_124349_jpg.rf.86bcf792b6130927c80a11df4ade455f.jpg  \n",
            " extracting: valid/20180925_133619_jpg.rf.078a0b559417686235f80b163fb67c7d.jpg  \n",
            " extracting: valid/20180925_133619_jpg.rf.2dd67673ed19cbf11eeec221578c89ed.jpg  \n",
            " extracting: valid/201_jpg.rf.680b380a400c7ce8b06861563f21a39e.jpg  \n",
            " extracting: valid/2020-09-19-16-41-50-1100x674_jpg.rf.6a2685aa88bbc9a62f63af5ddb271a80.jpg  \n",
            " extracting: valid/2020-09-19-16-41-50-1100x674_jpg.rf.d3150fc17e38eb89efc893bcea91302a.jpg  \n",
            " extracting: valid/2020_05_27-15_33_11_b60e87473be7eebe0962d671d3c57270_400x267_thumb_jpg.rf.4fd673b0e53faa94de394dbe04f7fae6.jpg  \n",
            " extracting: valid/2021-fuso-fe180-steel-dumptruck-oran_jpg.rf.6d535be6d022b2eced542014fc9331d1.jpg  \n",
            " extracting: valid/2021-fuso-fe180-steel-dumptruck-oran_jpg.rf.edaef6af6941c8176799da6a043ed6e7.jpg  \n",
            " extracting: valid/2021-fuso-fe180-steel-dumptruck-west_jpg.rf.a493159abbfcfbd9d6c9e8578d77059c.jpg  \n",
            " extracting: valid/202111102011-main-cropped_1636549889_jpg.rf.b55224f0b433d37f3bdb9854e63f39e9.jpg  \n",
            " extracting: valid/20211122_114147_jpg.rf.5a65a691dc33ed3fb174789812970583.jpg  \n",
            " extracting: valid/20211122_114252_jpg.rf.a1a9a70560b0a63f56c735de5c8c2b32.jpg  \n",
            " extracting: valid/20211122_114259_jpg.rf.d9a08227140304ea8c0ef4c1ea33a6f7.jpg  \n",
            " extracting: valid/20211122_114312_jpg.rf.da6d04f823cf8653f13736a52c7bc3f8.jpg  \n",
            " extracting: valid/20211122_114401_jpg.rf.3763e0d4d6a8db51669c512521a3b03e.jpg  \n",
            " extracting: valid/20211122_114445_jpg.rf.4d2f1dc1711638e69dab325d110abb80.jpg  \n",
            " extracting: valid/20211122_114627_jpg.rf.c7f8e387ddb8c17cb297402e950f4804.jpg  \n",
            " extracting: valid/20211122_114633_jpg.rf.1bca98bf55cbab4234f475bc7a6e49dd.jpg  \n",
            " extracting: valid/20211122_114644_jpg.rf.ebcc771e42b1a3db861a9e620cb938fb.jpg  \n",
            " extracting: valid/2022-05-15-09_45_38-20220514_111222-mp4-VLC-media-player_jpg.rf.a4781d9794c60ef9cb13d63c4c632292.jpg  \n",
            " extracting: valid/2022-05-15-09_48_58-20220514_111222-mp4-VLC-media-player_jpg.rf.d823846b4ef34a107a58ff2bf1e637ad.jpg  \n",
            " extracting: valid/2022-05-15-09_49_13-20220514_111222-mp4-VLC-media-player_jpg.rf.6f9cb95476c6a4cda1bb54fa2419b256.jpg  \n",
            " extracting: valid/2022-05-15-09_49_57-20220514_111222-mp4-VLC-media-player_jpg.rf.1318df8137222c8db0a335a0d719240d.jpg  \n",
            " extracting: valid/2022-05-15-09_49_57-20220514_111222-mp4-VLC-media-player_jpg.rf.1b8b772f4a936622fe1865fbb3ec7f95.jpg  \n",
            " extracting: valid/2022-05-15-09_54_19-20220514_111222-mp4-VLC-media-player_jpg.rf.4f05e79bc6569eb9dc80934b37fff071.jpg  \n",
            " extracting: valid/2022-05-15-09_54_24-20220514_111222-mp4-VLC-media-player_jpg.rf.47802eddf71406e3308de8e825a7367a.jpg  \n",
            " extracting: valid/2022-05-15-09_55_11-20220514_111222-mp4-VLC-media-player_jpg.rf.7ebc4e5e285414503a8186ef05fb18c6.jpg  \n",
            " extracting: valid/2022-05-15-09_59_01-20220514_111444-mp4-VLC-media-player_jpg.rf.06d07a040fb9d283ed014598252ac3d9.jpg  \n",
            " extracting: valid/2022-05-15-09_59_54-20220514_111444-mp4-VLC-media-player_jpg.rf.1567bf232a324722b9d835d57098508b.jpg  \n",
            " extracting: valid/2022-05-15-10_02_45-20220514_112722-mp4-VLC-media-player_jpg.rf.b257494cb4c75870a706e879f1e58a80.jpg  \n",
            " extracting: valid/2022-05-15-10_02_50-20220514_112722-mp4-VLC-media-player_jpg.rf.2936f46c1a6f90f595582272c98508ee.jpg  \n",
            " extracting: valid/2022-05-15-10_03_23-20220514_112722-mp4-VLC-media-player_jpg.rf.198e92a30e95f4ed12ec02b821c3b649.jpg  \n",
            " extracting: valid/2022-05-15-10_03_42-20220514_112722-mp4-VLC-media-player_jpg.rf.adb5050c08e75f39df9813f95da5dac0.jpg  \n",
            " extracting: valid/2022-05-15-10_04_52-20220514_112722-mp4-VLC-media-player_jpg.rf.c425ff068136cbeb0d87539df38b91cc.jpg  \n",
            " extracting: valid/2022-05-15-10_04_59-20220514_112722-mp4-VLC-media-player_jpg.rf.5ce7382605ce0a24f7204e9ce2a622cd.jpg  \n",
            " extracting: valid/2022-05-15-10_04_59-20220514_112722-mp4-VLC-media-player_jpg.rf.601f9433eaffa667c97f5d89a7beeaa1.jpg  \n",
            " extracting: valid/2022-05-15-10_09_46-20220514_112722-mp4-VLC-media-player_jpg.rf.f5dd695521102a3a06f3627f89cc3ecf.jpg  \n",
            " extracting: valid/2022-05-15-10_11_48-20220514_112722-mp4-VLC-media-player_jpg.rf.744a4ee3623d6681b9c5efcbac76aa06.jpg  \n",
            " extracting: valid/2022-05-15-10_12_10-20220514_112722-mp4-VLC-media-player_jpg.rf.14a32017191977305f400be43430f246.jpg  \n",
            " extracting: valid/2022-05-15-10_12_36-20220514_112722-mp4-VLC-media-player_jpg.rf.3c2978ae75a725b66d28421ac01c8f50.jpg  \n",
            " extracting: valid/2022-05-15-10_14_36-20220514_112722-mp4-VLC-media-player_jpg.rf.5c6248e7abd04f074db9ed3e907dce1b.jpg  \n",
            " extracting: valid/20220515_154342_jpg.rf.3b832536dfb20f2f7fd068d581bcd3d3.jpg  \n",
            " extracting: valid/20220515_154342_jpg.rf.fb9cd917c3c6fec6f919356832dec0ca.jpg  \n",
            " extracting: valid/20220516_144158_jpg.rf.5ac16914de43ebba9fd4d1d405d2bfbe.jpg  \n",
            " extracting: valid/20220516_144218_jpg.rf.6be1b118d7256216bf2c6c2bf40c13c4.jpg  \n",
            " extracting: valid/20220516_144302_jpg.rf.d4e602ff53878fccd0c9dfc3add68230.jpg  \n",
            " extracting: valid/20220516_144337_jpg.rf.df550102c4b15d5b81982167bbe9daf8.jpg  \n",
            " extracting: valid/20220516_144654_jpg.rf.0a295c86b52e9587f04751479a9d2384.jpg  \n",
            " extracting: valid/20220516_144852_jpg.rf.6393cc994291ed65ea4903faa7c4a495.jpg  \n",
            " extracting: valid/20220516_145140_jpg.rf.848eede737b8036480fee41bf69be93e.jpg  \n",
            " extracting: valid/20220517_123121_jpg.rf.01eb1606b10af768e4da2e8d6a0394dd.jpg  \n",
            " extracting: valid/20220517_123134_jpg.rf.69b8fa585bc66cdd70912e5b2358dcee.jpg  \n",
            " extracting: valid/20220517_123221_jpg.rf.e5428d5fa169d6560072be95f73e95bd.jpg  \n",
            " extracting: valid/20220517_123344_jpg.rf.5daf29dbc17e3b6cab279b7d63edb438.jpg  \n",
            " extracting: valid/20220517_123344_jpg.rf.c8e65d9423892fe7493df21cca4885c1.jpg  \n",
            " extracting: valid/20220517_123417_jpg.rf.dbd43265cc1778968e5fca3bc0adbba7.jpg  \n",
            " extracting: valid/20220517_123427_jpg.rf.d6dfe80181dba0aaf27833e5b3e2fdf7.jpg  \n",
            " extracting: valid/20220517_123659_jpg.rf.02362a760e85325cfc5ff069b4d8910e.jpg  \n",
            " extracting: valid/20220517_124043_jpg.rf.66773b2dfc7d8e5fd829f8a5709f7dd5.jpg  \n",
            " extracting: valid/20220517_124529_jpg.rf.76c28d05a60d7d7e3875d551654e135c.jpg  \n",
            " extracting: valid/20220517_124619_jpg.rf.d9970ee126596267c1eb0d3f9268e2fe.jpg  \n",
            " extracting: valid/20220517_124723_jpg.rf.d8a4d40b913739a354e1de036fdc46af.jpg  \n",
            " extracting: valid/20220517_124922_jpg.rf.e7287fa54f84665f054303fc1d8d0419.jpg  \n",
            " extracting: valid/20220517_124937_jpg.rf.22372ca58aba77d6681232c3b00225fa.jpg  \n",
            " extracting: valid/20220517_124959_jpg.rf.74955961d1d8a8dbe5105cf4fd06215a.jpg  \n",
            " extracting: valid/20220517_125113_jpg.rf.da6adb53e39e2f257519077b3ce1ad10.jpg  \n",
            " extracting: valid/203_jpg.rf.680b58fdd7cc91644a9c1fee76fa86c4.jpg  \n",
            " extracting: valid/212241_jpg.rf.ef0a0427f6d99fe151f462be2f40bc7b.jpg  \n",
            " extracting: valid/21452_NT130964_2-1_jpg.rf.1feb85caece55f35dcdf5d784363113e.jpg  \n",
            " extracting: valid/21452_NT130964_2-1_jpg.rf.3a588083cc5e30ba4977297f700a92ce.jpg  \n",
            " extracting: valid/21452_NT789-1_19-1_jpg.rf.3891b4ade25ef09de0725405c1910113.jpg  \n",
            " extracting: valid/218_jpg.rf.f04220b133c9957d40af66927b7e482d.jpg  \n",
            " extracting: valid/21_jpg.rf.fc7f23aa2a258cc9706834a8e3ff414a.jpg  \n",
            " extracting: valid/22-E-5234-YF-11-20_jpeg_jpg.rf.42d9de05bdb4f1800bd9b4bfb1fb8946.jpg  \n",
            " extracting: valid/220_jpg.rf.ca2380dbe64e6be477e94ae2717050f8.jpg  \n",
            " extracting: valid/226_jpg.rf.18cab0722ab9e28b2ad09366da3d90a6.jpg  \n",
            " extracting: valid/228698_jpg.rf.22950428c938d27d5ef5f91a8ba13a51.jpg  \n",
            " extracting: valid/234_jpg.rf.3854b5c80399e3429e9cdd8e465c2640.jpg  \n",
            " extracting: valid/245302_jpg.rf.5c469588c7af436078c6ce2faffebbd2.jpg  \n",
            " extracting: valid/247-E-2148-RI-01-16_jpg.rf.a6915744fa01626865fbc0cd5177366a.jpg  \n",
            " extracting: valid/249-E-3507-TS-12-17_jpeg_jpg.rf.49311449fe3368a8a3cfa7b66baf6fe6.jpg  \n",
            " extracting: valid/249_jpg.rf.4d3fd86d25d44525b70b9efb267c1777.jpg  \n",
            " extracting: valid/250_jpg.rf.18bc2e5859352b3f8f946d7b4f991699.jpg  \n",
            " extracting: valid/251395_jpg.rf.f09abf1ddc909077be61476223518fa8.jpg  \n",
            " extracting: valid/252-E-2113-PAG-09-21_jpeg_jpg.rf.02b7495bf3027bccb1dd1a3d969a5202.jpg  \n",
            " extracting: valid/2530355363_287ac9442d_b_jpg.rf.1ef03259cec74501de1b83e35d56d7d3.jpg  \n",
            " extracting: valid/25397-colt-fe-truk-mitsubishi-colt-d_jpg.rf.1190cb19d7e63adb47bf5bc71c61451d.jpg  \n",
            " extracting: valid/25397-colt-fe-truk-mitsubishi-colt-d_jpg.rf.6e10f25df7b8c70848ad5c9586dfa05f.jpg  \n",
            " extracting: valid/254_jpg.rf.ad789e6dd9c8cc46516cec96b9ed2f69.jpg  \n",
            " extracting: valid/256_jpg.rf.a58e5647a3cca9bb4e04c55c78ce3bfb.jpg  \n",
            " extracting: valid/257301_jpg.rf.9b73c8af84a1b5a3b02a0853399b28f2.jpg  \n",
            " extracting: valid/258540_jpg.rf.69aa4174b46453c294a22902760661da.jpg  \n",
            " extracting: valid/258_jpg.rf.0f1faf77f72b803e37d476c3687cbea7.jpg  \n",
            " extracting: valid/25_jpg.rf.19d7cf3f612df36d849f7498b8333985.jpg  \n",
            " extracting: valid/26-E-4016-TO-08-22_jpeg_jpg.rf.6c0cbb65517749e064e66495eb66f6a1.jpg  \n",
            " extracting: valid/270-E-2891-TT-01-18_jpg.rf.763ee7db700fd94ba5de0c7371c5638a.jpg  \n",
            " extracting: valid/275_jpg.rf.840566ea2a1fd71b4ee1460cfffdb757.jpg  \n",
            " extracting: valid/275_jpg.rf.a8de482ce73a377d5d988088329c5cc0.jpg  \n",
            " extracting: valid/277_jpg.rf.0a9a843ca0b590b05648a9eaf1f900a0.jpg  \n",
            " extracting: valid/2788_1807600_1_jpg.rf.5530a5725b006d5c613467774f4e7e1d.jpg  \n",
            " extracting: valid/282-E-5519-PAK-03-22_jpg.rf.748ab68a91ee0ed64a63b24a7845efdf.jpg  \n",
            " extracting: valid/283-E-2870-QAA-10-22_jpeg_jpg.rf.d784feb127508605956f2bd53e9e293a.jpg  \n",
            " extracting: valid/284__flip_jpg.rf.788e004e952a58484c36937a2bfb3892.jpg  \n",
            " extracting: valid/284_jpg.rf.c105dfab745bf1c51e3eb2a58585a56f.jpg  \n",
            " extracting: valid/285_jpg.rf.7f796668ccf6e720407cd29be4545c03.jpg  \n",
            " extracting: valid/286-E-5817-PT-04-18_jpeg_jpg.rf.fad1f39af99067bc21122cf4bd4db507.jpg  \n",
            " extracting: valid/286__flip_jpg.rf.9235a50138447f17ff0c945f2a904f82.jpg  \n",
            " extracting: valid/286_jpg.rf.69e3430fd8a038b088de1f50370cefe7.jpg  \n",
            " extracting: valid/288_jpg.rf.4875fd3a13884d31e60f4c5d055b237f.jpg  \n",
            " extracting: valid/291__flip_jpg.rf.97694b570e58607f266643a503cecb89.jpg  \n",
            " extracting: valid/292_jpg.rf.5972783b4cc41b4b1a81234867fafba5.jpg  \n",
            " extracting: valid/297-E-1169-PY-05-20_jpg.rf.05d5f316afeff3edb384ddd27b1e9caa.jpg  \n",
            " extracting: valid/299_jpg.rf.8d063697f3da8703d401c14a8a45ed85.jpg  \n",
            " extracting: valid/29_jpg.rf.6a398ec46c1f2d2ef93970fe0467770b.jpg  \n",
            " extracting: valid/2_jpeg_jpg.rf.91eab374a15fd96ad86bba629680fd7d.jpg  \n",
            " extracting: valid/3-1196451409-Motor-Sport-Bekas-Honda-New-CBR-Tahun-2017-Like-New-Harga-Murah-Low-KM-Lengkap-_jpg.rf.8d887c38d95f78ab4b36cab8adc374d0.jpg  \n",
            " extracting: valid/30-E-5032-QD-12-18_jpeg_jpg.rf.71c197584d61692cbcf6da22eb02f00c.jpg  \n",
            " extracting: valid/302__flip_jpg.rf.662f6115d48f6db6ed6f6b7955964e20.jpg  \n",
            " extracting: valid/30364-1_jpg.rf.2ec99fcaf8666b09499a167cb62cff4d.jpg  \n",
            " extracting: valid/3040974006_jpg.rf.eb1e419b90615a0e1f7debaa2e59ca09.jpg  \n",
            " extracting: valid/305-E-4964-SN-07-20_jpeg_jpg.rf.e770433073745ecd07586ff04bc5e212.jpg  \n",
            " extracting: valid/308-E-5024-SO-09-20_jpg.rf.42890a3bdc1bd6e2209a6546257ef5e1.jpg  \n",
            " extracting: valid/309_jpg.rf.217c2d0e8663102c86f655a78e3e03ac.jpg  \n",
            " extracting: valid/309_jpg.rf.ad5f0674888e7b16e14d4e1c6296beee.jpg  \n",
            " extracting: valid/310-E-6193-QF-02-10_jpeg_jpg.rf.5e93fa33ac539cde443e203a434c37a0.jpg  \n",
            " extracting: valid/312-E-3212-OL-08-19_jpg.rf.04923dc7bcd2e56940ff9994da0b9483.jpg  \n",
            " extracting: valid/312_jpg.rf.0bfd1e028e8ced95dac67b8238168c32.jpg  \n",
            " extracting: valid/313__flip_jpg.rf.28e4cea00c61246d7fd8c9451605a948.jpg  \n",
            " extracting: valid/315_jpg.rf.9257c6f0b3f2278a9675280a109b30af.jpg  \n",
            " extracting: valid/316_jpg.rf.35c55c86c48f42a6319591249d20c2dd.jpg  \n",
            " extracting: valid/3173ec56-a792-47ff-9b18-79fc37729b95_jpg.rf.53fa7d4b1e6c929fef1bfa9fe9a7a395.jpg  \n",
            " extracting: valid/3173ec56-a792-47ff-9b18-79fc37729b95_jpg.rf.b7d9723525b8cb892ba8e2474d8cb2c1.jpg  \n",
            " extracting: valid/318-E-5827-QT-06-20_jpg.rf.52010d29c5436fa15171c0b703273623.jpg  \n",
            " extracting: valid/322__flip_jpg.rf.2132ed8be3375de281873bc4e3130283.jpg  \n",
            " extracting: valid/32455_44329_230732_jpg.rf.253401b468178f427b5bf92e117e2e78.jpg  \n",
            " extracting: valid/324_jpg.rf.e75045b57272a424bbcdcb6bba6ad1f4.jpg  \n",
            " extracting: valid/325_jpg.rf.6975a66d13d24c03f7ef12f86605c587.jpg  \n",
            " extracting: valid/328-E-1992-RN-04-22_jpeg_jpg.rf.f3b79ce7cd1ebfd67aa9b92917f6d6d0.jpg  \n",
            " extracting: valid/332_jpg.rf.be266063674e5e233fcf9784d619eabe.jpg  \n",
            " extracting: valid/333-E-2247-RY-05-18_jpeg_jpg.rf.366d2d3926de45e25ccc6fa2589d51a2.jpg  \n",
            " extracting: valid/336_jpg.rf.b64bde30f25ea3c2b00bb1f6abecf3db.jpg  \n",
            " extracting: valid/337-E-3955-PAK-02-22_jpeg_jpg.rf.1b96137bedae00ceb535b97ad7a33db5.jpg  \n",
            " extracting: valid/339-E-4966-SN-07-20_jpg.rf.415ea3946c0b0a8c5420ad1f6a378fad.jpg  \n",
            " extracting: valid/34-E-2987-QC-10-18_jpeg_jpg.rf.d95227f0e4638c454f8a629d928eef41.jpg  \n",
            " extracting: valid/341-E-6047-QT-07-20_jpg.rf.324341e035796656fdd5e38db53e1f19.jpg  \n",
            " extracting: valid/342_jpg.rf.f16a527244b47b2fff0a758ceedc7f86.jpg  \n",
            " extracting: valid/34715_jpg.rf.11440962a33c291540607a5d63d00a01.jpg  \n",
            " extracting: valid/348-E-4160TQ-10-17_jpeg_jpg.rf.313af442e0d8f11fe3b199cced8ec430.jpg  \n",
            " extracting: valid/349-E-4378-SG-07-19_jpeg_jpg.rf.5afcb64f7b9f9a8df18253d3fc1a6a93.jpg  \n",
            " extracting: valid/349_jpg.rf.062a6363ce4ec25964b7ea24201fd75c.jpg  \n",
            " extracting: valid/35-E-5026-SF-06-18_jpeg_jpg.rf.cb59888c4534ca1f2b16459c9846603b.jpg  \n",
            " extracting: valid/350-E-3577-PAI-12-21_jpg.rf.4694b64479ad299c63a12b466512cd34.jpg  \n",
            " extracting: valid/3534274-foto-camion_jpg.rf.8bf129180b615a7eefac69b7eeb413f5.jpg  \n",
            " extracting: valid/3534274-foto-camion_jpg.rf.b305f8d5ab9c8c2a23fad389e9bd3dd3.jpg  \n",
            " extracting: valid/356_jpg.rf.7f0f8c17e8c98b980972d4638081822d.jpg  \n",
            " extracting: valid/357_jpg.rf.9078e9e1d99a2b9d132cb8363f851ad9.jpg  \n",
            " extracting: valid/36038_47874_245202_jpg.rf.138218161987953c66409b275c5eed62.jpg  \n",
            " extracting: valid/3626_2211076_1_jpg.rf.206463d85d485a2ada91559fea71ec72.jpg  \n",
            " extracting: valid/363_jpg.rf.f2c387b9603ebb2097291de1775f99a2.jpg  \n",
            " extracting: valid/36484_48363_248254_jpg.rf.7358cf7c7ce38b465aa463be508457eb.jpg  \n",
            " extracting: valid/36486_48365_248258_jpg.rf.e3a23c20a1b38e2e31ba7641e6959ae9.jpg  \n",
            " extracting: valid/365_jpg.rf.0357cb7f2e5d0ac7b2228e600ec6238d.jpg  \n",
            " extracting: valid/374506_jpg.rf.27aa1f48c7d4a3a611b4ef8ec6970d9c.jpg  \n",
            " extracting: valid/376_jpg.rf.53bad984022b1758e203e22c232a8aa4.jpg  \n",
            " extracting: valid/377_jpg.rf.283c8db32c78ccc30b827f5ac455416f.jpg  \n",
            " extracting: valid/383_jpg.rf.91faa3d1c5df1b24592dd717c622b42b.jpg  \n",
            " extracting: valid/384_jpg.rf.4a27df32fb9f7159963f6f0096d4e553.jpg  \n",
            " extracting: valid/385_jpg.rf.526d01aed0274c1d4ba50f27168e0477.jpg  \n",
            " extracting: valid/398_jpg.rf.55ff7239182c74923d239a63101ac116.jpg  \n",
            " extracting: valid/399_jpg.rf.6def6e8f92d49756f4ef1bc80af55438.jpg  \n",
            " extracting: valid/4-E-6226-YZ-12-19_jpg.rf.863ff8e5e9ac24def4fb9f9f823c5b9d.jpg  \n",
            " extracting: valid/400358_jpg.rf.045f368c0e1190a967aac747dbbecd01.jpg  \n",
            " extracting: valid/400_jpg.rf.cb6c72c16ea1ebfc8b77ccea4bef519d.jpg  \n",
            " extracting: valid/402_jpg.rf.112f8c8c6a2d8443a5304c7a9f672c75.jpg  \n",
            " extracting: valid/406716_fuso2nd_jpg43571b893bc1565318_jpg.rf.be3f96d7ab42925a85b81793a3b7bfcc.jpg  \n",
            " extracting: valid/406716_fuso2nd_jpg43571b893bc1565318_jpg.rf.e4534dfd44747a772fc499a3757d27dc.jpg  \n",
            " extracting: valid/408_jpg.rf.90625c9800168fd8b1148b301fb758f3.jpg  \n",
            " extracting: valid/409606_jpg.rf.b7abc18cf3709867d815c7cf91e88f16.jpg  \n",
            " extracting: valid/410378_jpg.rf.31a7278480990289ea983bd88be763f3.jpg  \n",
            " extracting: valid/416_jpg.rf.22e8da98df19d4328db827558ee71e56.jpg  \n",
            " extracting: valid/41728_53604_276708_jpg.rf.24d3549d8d2ae18729ffe1a7a5bc091c.jpg  \n",
            " extracting: valid/417_jpg.rf.f110defd2b2104843e83289fee3be46d.jpg  \n",
            " extracting: valid/418_jpg.rf.cc090e742bed48707790e80cf3b02087.jpg  \n",
            " extracting: valid/425_jpg.rf.d70af0c5c47573c952bdc221910b0b1c.jpg  \n",
            " extracting: valid/429_jpg.rf.b67bb2df3f85c46f6e50b73765dde351.jpg  \n",
            " extracting: valid/435_jpg.rf.81a7570fee178c2d991be716e756a096.jpg  \n",
            " extracting: valid/436_jpg.rf.be65c103ca05e787d480df8690494ff9.jpg  \n",
            " extracting: valid/454739_jpg.rf.92db5b15e146e4a19f3e0641a157b78a.jpg  \n",
            " extracting: valid/45490_57349_308284_jpg.rf.dc91b75f9a67e81e60597b3ebe486c48.jpg  \n",
            " extracting: valid/467_jpg.rf.cb40c6cb5a4a0c11952c40182c96ffc4.jpg  \n",
            " extracting: valid/472_jpg.rf.226d22c3c77fc507f8433793b818e34d.jpg  \n",
            " extracting: valid/476_jpg.rf.180b3e04c7aff69b4b1103d1e96c6e13.jpg  \n",
            " extracting: valid/478_jpg.rf.6482209b4e953c5db76ca93ed30058fb.jpg  \n",
            " extracting: valid/486984_jpg.rf.0d4afcba4946039227d61f6f7e8c2b42.jpg  \n",
            " extracting: valid/486_jpg.rf.9f8716d674f1cf8bcbb16bbdc5f513f2.jpg  \n",
            " extracting: valid/487_jpg.rf.05bed6c95d524afdfe5662ed8a094c2b.jpg  \n",
            " extracting: valid/48_jpg.rf.7174e2cd9e930e4dbf2a9d9bd4ac8e72.jpg  \n",
            " extracting: valid/493_jpg.rf.cf172a8915d8bc765ee68a82572803b7.jpg  \n",
            " extracting: valid/500_jpg.rf.09bd9f627b61f0825ccd0936693b9a1c.jpg  \n",
            " extracting: valid/505379_jpg.rf.aa7518cf69029aaaa18403dec14bb02d.jpg  \n",
            " extracting: valid/506_jpg.rf.9777e9c4806d9e69706d271f30c918b0.jpg  \n",
            " extracting: valid/510742_jpg.rf.59164ec891cddef68330d4a8e2d424e2.jpg  \n",
            " extracting: valid/518_jpg.rf.328eb55d4fb9dc33a4bf4c8da202b590.jpg  \n",
            " extracting: valid/519386_jpg.rf.8321f95fb09923dc30102e0c27125fd6.jpg  \n",
            " extracting: valid/521_jpg.rf.ff157177be282e828f7a85097ee42b73.jpg  \n",
            " extracting: valid/522_jpg.rf.9369b67e3e5ef93df20dbd2eb1747926.jpg  \n",
            " extracting: valid/524107_jpg.rf.1e00433dd247c3391ef12fddb4173b20.jpg  \n",
            " extracting: valid/524_jpg.rf.bb8660c5777e6ea4927cd32fd6ef76cb.jpg  \n",
            " extracting: valid/525987_jpg.rf.764f20da3109a7d7cff0aa3cec687787.jpg  \n",
            " extracting: valid/53241f12843e709981c8804a647fcc41_jpg.rf.261ce754834684ff99507c99504069b1.jpg  \n",
            " extracting: valid/541_jpg.rf.bd6df78d19620092397cc524c5545367.jpg  \n",
            " extracting: valid/543189_jpg.rf.0fb4b5bc4c50f8969e2fa14a1db16cf9.jpg  \n",
            " extracting: valid/543_jpg.rf.a31f90e62998feb8442bcfc4ae8b90b6.jpg  \n",
            " extracting: valid/544767_jpg.rf.528a8e3b8aee33017cff1beabb6c6e92.jpg  \n",
            " extracting: valid/545_jpg.rf.a5bac3a7c546766b17c91634c3bb37b7.jpg  \n",
            " extracting: valid/54_jpg.rf.4578f5da0e612532280e34118775a977.jpg  \n",
            " extracting: valid/551_jpg.rf.9ed8c6589429d28594ef221940529cf7.jpg  \n",
            " extracting: valid/556762_jpg.rf.4aff418233afec67e8dfe2b69121895a.jpg  \n",
            " extracting: valid/565_jpg.rf.f26ec0f54332b3741fa396db2c14df3f.jpg  \n",
            " extracting: valid/5728b902e329d168_jpg.rf.e2d3e9930ff59016337fe01845d84047.jpg  \n",
            " extracting: valid/574138_jpg.rf.e6dc130f28729492019c60c895a94f5f.jpg  \n",
            " extracting: valid/57877d_jpg.rf.2f8bf48ad494cf6686327d045d266ca3.jpg  \n",
            " extracting: valid/57_jpg.rf.8ee5b5c172858181537d9aa69cc645f0.jpg  \n",
            " extracting: valid/582_jpg.rf.2b67b5c12bc0fb82d7e89a27ea5d3a9b.jpg  \n",
            " extracting: valid/586_jpg.rf.393187e41cc0c4226078a21233c66815.jpg  \n",
            " extracting: valid/596_jpg.rf.67a7fc565eff58a1ba78285e25785e7a.jpg  \n",
            " extracting: valid/597_jpg.rf.64c01f967e3dfd87e4a536d1d3721f18.jpg  \n",
            " extracting: valid/6-E-3237-QY-11-20_jpeg_jpg.rf.bb9563d3c358d43f0097b4d5e8b3f9f5.jpg  \n",
            " extracting: valid/600540-720x490_jpg.rf.d917e7e9ebfd1c66a75c3a2203b7bc8a.jpg  \n",
            " extracting: valid/6007931417_jpg.rf.1d46548463d9d4b25f51d56efd4fcef8.jpg  \n",
            " extracting: valid/601200_jpg.rf.94b66520b49a7872baef6b8b119d45a1.jpg  \n",
            " extracting: valid/604_jpg.rf.e0028486149b0e890e50ce900991b168.jpg  \n",
            " extracting: valid/608_jpg.rf.229ffd1033478bae9662b26372d65215.jpg  \n",
            " extracting: valid/61-E-6472-SB-11-18_jpeg_jpg.rf.eb0c08dddd8ab7ed128a6fb4424deb36.jpg  \n",
            " extracting: valid/610036_jpg.rf.178c23052db216779bb005a1509f3290.jpg  \n",
            " extracting: valid/610661_jpg.rf.201b73fec2175a41ca8a73d1548d64c7.jpg  \n",
            " extracting: valid/616269383_jpg.rf.c5314b9744da46b325b74dff93fc7f00.jpg  \n",
            " extracting: valid/618228_jpg.rf.7a836e0ca681d9c88f4153cf966cd0e3.jpg  \n",
            " extracting: valid/61_jpg.rf.13d79f81bb4fa2707f4ddad43a34a1ed.jpg  \n",
            " extracting: valid/62134526-adult-man-rides-yellow-scooter-scooter-on-the-empty-road-good-fuel-accelerates-engine-compact-mean-o__flip_jpg.rf.3d9987fa7640c0f67874648cc251f656.jpg  \n",
            " extracting: valid/62134526-adult-man-rides-yellow-scooter-scooter-on-the-empty-road-good-fuel-accelerates-engine-compact-mean-o_jpg.rf.954e07cf7a30c6c2af07c51c031f5992.jpg  \n",
            " extracting: valid/623_jpg.rf.2c9582c63d770f4df97f023c257ed781.jpg  \n",
            " extracting: valid/636_jpg.rf.ab9972d00a4b2bc90e7bc6a441b3e999.jpg  \n",
            " extracting: valid/640_jpg.rf.030bf27071226569331f2f6096220f23.jpg  \n",
            " extracting: valid/645595_jpg.rf.1b083fc3148a7310062498f493d0ac15.jpg  \n",
            " extracting: valid/647_jpg.rf.047faadb31f81dd661902f5e8b1fe104.jpg  \n",
            " extracting: valid/649_jpg.rf.97446d04c2cf00eb836270229d65f7e5.jpg  \n",
            " extracting: valid/655_jpg.rf.95e0454f45152a133a662c842fde9bc5.jpg  \n",
            " extracting: valid/656975_jpg.rf.46b2876714ead6d5f63d944be1893717.jpg  \n",
            " extracting: valid/65827a_jpg.rf.98344e95b5e03f08551cec04f59171c3.jpg  \n",
            " extracting: valid/659_jpg.rf.42ca277b0cb849970f75e4d16ae7e0bf.jpg  \n",
            " extracting: valid/660825_jpg.rf.40caf79c98c2f7e15e60e5eeee036b60.jpg  \n",
            " extracting: valid/660_jpg.rf.b8a6d02747d78fe2746ab478f62c245e.jpg  \n",
            " extracting: valid/67-E-4387-SK-11-21_jpeg_jpg.rf.faa1984ed32c1ebb4d5f74b9f02446ff.jpg  \n",
            " extracting: valid/673_jpg.rf.9b03eb92f376093cade5035b8ae30ad8.jpg  \n",
            " extracting: valid/675458_jpg.rf.eddf31c20c0999c23e7e0e45098b4c8e.jpg  \n",
            " extracting: valid/67697v_jpg.rf.bf250f8ccec9681f299c36e5fe1d7127.jpg  \n",
            " extracting: valid/676_jpg.rf.9ffce76f46d80bcd368a70b106338c6b.jpg  \n",
            " extracting: valid/679_jpg.rf.4faefd8d81804575610238c7e7d5e6d8.jpg  \n",
            " extracting: valid/69-E-5792-TT-01-22_jpg.rf.11de53600165f7f28d6cb50d1ea081ef.jpg  \n",
            " extracting: valid/69-E-5792-TT-01-22_jpg.rf.a8865c4d34d7bd50f8973ec73239613b.jpg  \n",
            " extracting: valid/693_jpg.rf.b94c1ab3472dfebb4694898319ca1db7.jpg  \n",
            " extracting: valid/694343_jpg.rf.f789700c6a50299091a0212c20440ae7.jpg  \n",
            " extracting: valid/69_jpg.rf.40182096544971a957f2930538c7bb91.jpg  \n",
            " extracting: valid/6_jpeg_jpg.rf.c3e4d8d4c3b6e94bb4a4c36d2f932563.jpg  \n",
            " extracting: valid/703943_jpg.rf.10c0dcc142827c0f72552761d1b778d6.jpg  \n",
            " extracting: valid/711_jpg.rf.62012669646af74b44fe0d6038b9a9ed.jpg  \n",
            " extracting: valid/712_jpg.rf.5a08449364cff746af1abc5beb423c9e.jpg  \n",
            " extracting: valid/714199_jpg.rf.c6d65f99bc68004e6510f3d780e9514f.jpg  \n",
            " extracting: valid/718_jpg.rf.2eb20565ea1516c13c59c3f5c691697c.jpg  \n",
            " extracting: valid/71_jpg.rf.3f8e232e494574265e97e1758033096f.jpg  \n",
            " extracting: valid/729614_jpg.rf.69f134b01593ae53ff94dc6ee75e9a26.jpg  \n",
            " extracting: valid/73-E-5043-PAL-04-22_jpeg_jpg.rf.3a0cf5f0a5dfcfb5c949e1a1863ea630.jpg  \n",
            " extracting: valid/739_jpg.rf.a4ba019eade7f8034439e0d1e10677d8.jpg  \n",
            " extracting: valid/744_jpg.rf.3872493ce38d77c2a4c847a1c39f5080.jpg  \n",
            " extracting: valid/746_jpg.rf.c601f61f4694651b0d89fca7c4e96588.jpg  \n",
            " extracting: valid/747_jpg.rf.2a4a8fa6e66ce1cb9215322ea606587e.jpg  \n",
            " extracting: valid/750_jpg.rf.3baa56c7c9a0447e5447cb31a1edfdd8.jpg  \n",
            " extracting: valid/755998_jpg.rf.478b9ee57969dac5c0a8c0ec86bbc0ad.jpg  \n",
            " extracting: valid/758_jpg.rf.dda6638848269e63f32fa72adda3c6b3.jpg  \n",
            " extracting: valid/75_jpg.rf.459c66ccd8d358a1094962218320fd3c.jpg  \n",
            " extracting: valid/76-E-5361-TI-01-18_jpg.rf.d9cae99020b5ebc79fb1fca40e79f090.jpg  \n",
            " extracting: valid/76-E-5361-TI-01-18_jpg.rf.f62c92883e6fa6d25159760a958db8bd.jpg  \n",
            " extracting: valid/761_jpg.rf.b6641a7a11efa545d8ba8f2188951475.jpg  \n",
            " extracting: valid/76_jpg.rf.283aa57dc8884b5d5e074dc37113c7ab.jpg  \n",
            " extracting: valid/786_jpg.rf.47e1dfafcd39433e67791eac55ba8528.jpg  \n",
            " extracting: valid/789357_jpg.rf.8b3fef1c74f2a5f57321357ffb324ad7.jpg  \n",
            " extracting: valid/790485_jpg.rf.f41611a9bfc4d2acd6fd2c8e175adf99.jpg  \n",
            " extracting: valid/793944_jpg.rf.0228ecca9de195c23768412d9948dc22.jpg  \n",
            " extracting: valid/793_jpg.rf.7c082efe953ab7f1c33f883c22d4154c.jpg  \n",
            " extracting: valid/79445_jpg.rf.fa940d3e0be29b84fcdab552ad666f06.jpg  \n",
            " extracting: valid/796685_jpg.rf.41dc35da2a15b3462c6aa0df21abeef6.jpg  \n",
            " extracting: valid/7_PNG_jpg.rf.6e4f8bfde70f81e664e6e7883009fa0b.jpg  \n",
            " extracting: valid/811629_jpg.rf.a19cd6f70a2f853514f82f1c484b2666.jpg  \n",
            " extracting: valid/830005_2_original_jpg.rf.e6c58762f6f203d061e7d1fe53956ea8.jpg  \n",
            " extracting: valid/842548_jpg.rf.dd0168cb3355829909db7cf731b5e32b.jpg  \n",
            " extracting: valid/847666-2012-mitsubishi-fuso-super-gr_jpg.rf.d420bb2156f48379565b721686e8930e.jpg  \n",
            " extracting: valid/847675-2012-mitsubishi-fuso-super-gr_jpg.rf.5cec2fdb3104ebd5c0f84e29db561207.jpg  \n",
            " extracting: valid/85253776_2b95428a-d831-48ab-b568-e076363e439d-jpg_jpg.rf.43a58a586989f472cfbe81b1bc242e4d.jpg  \n",
            " extracting: valid/85_jpg.rf.1f9c9731382703ef00e21235efca9745.jpg  \n",
            " extracting: valid/87-E-6673-ZQ-04-18_jpg.rf.c1d4d2479f1ca17f26cba25842eff94f.jpg  \n",
            " extracting: valid/880738_jpg.rf.510d3b79df34dec5659259ced20765b8.jpg  \n",
            " extracting: valid/88_jpg.rf.6a229b81f18c8bd3f8b4d820e9c0968a.jpg  \n",
            " extracting: valid/89357_jpg.rf.272133d9c4f1af62b3ede49e306a538e.jpg  \n",
            " extracting: valid/898858_jpg.rf.5f95f871aec572edef54e9fd3e744625.jpg  \n",
            " extracting: valid/8_jpeg_jpg.rf.9040d88b1b8343ad97573bdb978ac1cf.jpg  \n",
            " extracting: valid/9041_1413578135698_jpg.rf.f2b5d90dad4eadc6de9f4f99f9f926c7.jpg  \n",
            " extracting: valid/91-E-6554-ZL-05-22_jpg.rf.39aef807b1825451cdc6920597a9ec8d.jpg  \n",
            " extracting: valid/91247a_jpg.rf.51aa7621d56620790891234fb71daf1e.jpg  \n",
            " extracting: valid/91247a_jpg.rf.8306421bdd2f7992a26523e6a05ee4a9.jpg  \n",
            " extracting: valid/913897_jpg.rf.e9d49639ceb20c60f51ae5c668b9aa6b.jpg  \n",
            " extracting: valid/92182b_jpg.rf.0b15ae869baea60cd7b4f37d8f20ce52.jpg  \n",
            " extracting: valid/95_jpg.rf.ca9d62d1a6d8fa4c50d51098a6e61786.jpg  \n",
            " extracting: valid/999589157_7_jpg.rf.f870dc6ed57737a31ff4e3aa9fdc255c.jpg  \n",
            " extracting: valid/A10_png_jpg.rf.ab80151bb5f84af47b056a700a06d940.jpg  \n",
            " extracting: valid/A16_png_jpg.rf.75668d2daec069746b7a5bf7fb49a001.jpg  \n",
            " extracting: valid/A16_png_jpg.rf.e0500382924587b8e3711d191e468ebd.jpg  \n",
            " extracting: valid/A1729XM_jpg.rf.42c42126f3d2dadc6e27ceeaad21a69c.jpg  \n",
            " extracting: valid/A18_png_jpg.rf.3352fbe865e4a82de90e60f5b287d2e1.jpg  \n",
            " extracting: valid/A1_png_jpg.rf.d646b4de0370db39ff8da80aeaa0402f.jpg  \n",
            " extracting: valid/A20_png_jpg.rf.9bf5c4f75d27f804e71ecea8a0147b02.jpg  \n",
            " extracting: valid/A21_png_jpg.rf.b1cf47f23b5e0938c1dafee454e44171.jpg  \n",
            " extracting: valid/A21_png_jpg.rf.dee914f4f49548ddfb138b6096b21f1d.jpg  \n",
            " extracting: valid/A22_png_jpg.rf.7718fc0140d837907fbb70ff2b4f648e.jpg  \n",
            " extracting: valid/A22_png_jpg.rf.77c394ea73cebd2cf7e1288d5969a54d.jpg  \n",
            " extracting: valid/A22_png_jpg.rf.acb7e1cef30940d6f3f7986fe7eb0c98.jpg  \n",
            " extracting: valid/A25_png_jpg.rf.3baf96fac24444bde482ff36ae29e4f7.jpg  \n",
            " extracting: valid/A25_png_jpg.rf.a48c4751dfb915f851cb531b9659be04.jpg  \n",
            " extracting: valid/A26_png_jpg.rf.653edd041d948b3dfe842d9d330d19be.jpg  \n",
            " extracting: valid/A26_png_jpg.rf.b29be9e006d7013e23f4d87392de9e6a.jpg  \n",
            " extracting: valid/A27_png_jpg.rf.72fd9d71dcfacc456ac8b42e69b6ed00.jpg  \n",
            " extracting: valid/A35_png_jpg.rf.412e8a118110cd90e5f42f09d4bfefff.jpg  \n",
            " extracting: valid/A38_png_jpg.rf.1405adb5729a8071144f6169242da4b4.jpg  \n",
            " extracting: valid/A38_png_jpg.rf.5a23f520abef0b3bdf66d85442164cce.jpg  \n",
            " extracting: valid/A38_png_jpg.rf.7e0d1e94d87d7eca3ffba139b8a79ebf.jpg  \n",
            " extracting: valid/A3_png_jpg.rf.3628665c9cade1ab247b6c05eb2a1756.jpg  \n",
            " extracting: valid/A3_png_jpg.rf.5f1d19342965aeda27d5ef79767b3635.jpg  \n",
            " extracting: valid/A3_png_jpg.rf.a02704df42961d60b49a9cfe870135ee.jpg  \n",
            " extracting: valid/A4_png_jpg.rf.1051dd4419bd7599144cae941fa80a80.jpg  \n",
            " extracting: valid/A8_png_jpg.rf.160cb5e0c706fb971c6efc202234e27b.jpg  \n",
            " extracting: valid/AA5627JT_jpg.rf.63be6eede5072c8f34f95b059647a9c1.jpg  \n",
            " extracting: valid/B1036BVH_jpg.rf.bec70825165c8853c7ac3b0b4e045f4f.jpg  \n",
            " extracting: valid/B1192FJE_jpg.rf.0a89e29c9c9e10e21289c0174d7d3335.jpg  \n",
            " extracting: valid/B1410BLQ_jpg.rf.654d38cc55afdffd1c931992ce9e65a2.jpg  \n",
            " extracting: valid/B1429SJU_jpg.rf.513a5b1db7d9e29cbce272134f59e9e6.jpg  \n",
            " extracting: valid/B1523KBL_jpg.rf.4f3150cbb41651650e853930dc9c18df.jpg  \n",
            " extracting: valid/B1636BRW-1-_jpg.rf.74e6cfad5dc3f409be0897ece26a68a5.jpg  \n",
            " extracting: valid/B1809SOF_jpg.rf.f2a31deeae3c50bee0dd209e55835c7d.jpg  \n",
            " extracting: valid/B1869ERN_jpg.rf.f8ccfb452b50eb0f89bc75b67b454f34.jpg  \n",
            " extracting: valid/B2127BKW-1-_jpg.rf.27e9e724cd3aa77592b427c17d1b79b6.jpg  \n",
            " extracting: valid/B222FB_jpg.rf.42ee63085b593a71342a9f5320a1cfa6.jpg  \n",
            " extracting: valid/B2460PON_jpg.rf.ca45184eb3b9b8bf24a3e497d1f79b44.jpg  \n",
            " extracting: valid/B304AKO_jpg.rf.8f09c7eccc60b91544b3ba3633bc59bf.jpg  \n",
            " extracting: valid/BP8118B_jpg.rf.53087de62158047f347680e30cafafa2.jpg  \n",
            " extracting: valid/Baru-Kepala-Emas1_jpg.rf.c94ebdc3b21ecb6c3e5b80b45e9c64cf.jpg  \n",
            " extracting: valid/Bus-1-_jpg.rf.ba57a8a08d8fbb290e8c2711e0481902.jpg  \n",
            " extracting: valid/Bus-114-_jpg.rf.b9bcc23ad8804ba6ded7aff8a0bb8834.jpg  \n",
            " extracting: valid/Bus-118-_jpg.rf.530ae3896a6ef09d2efe2067d3cb1c30.jpg  \n",
            " extracting: valid/Bus-119-_jpg.rf.5bccd5fb44af74a108fd9ffd07e97478.jpg  \n",
            " extracting: valid/Bus-129-_jpg.rf.40d6a64d43b26998195a6628860058c7.jpg  \n",
            " extracting: valid/Bus-13-_jpg.rf.f87abf45416b3f481ca064b5ae38219a.jpg  \n",
            " extracting: valid/Bus-132-_jpg.rf.9596cadd95bf67883b88a3c3aae4e52c.jpg  \n",
            " extracting: valid/Bus-137-_jpg.rf.8f9b7dbed29be3c776c0136c0a83283a.jpg  \n",
            " extracting: valid/Bus-140-_jpg.rf.25c966b0f914835b806c2c2d3868cdf2.jpg  \n",
            " extracting: valid/Bus-144-_jpg.rf.5ccc6c1f4168c3ea1d52956b745831a8.jpg  \n",
            " extracting: valid/Bus-153-_jpg.rf.a7fbc356197dfd0fa9d63f2732fe362d.jpg  \n",
            " extracting: valid/Bus-154-_jpg.rf.f763b77ba30afa95c73b7850ef68591d.jpg  \n",
            " extracting: valid/Bus-157-_jpg.rf.ed227d61a2fe3e25455476e92457e8b5.jpg  \n",
            " extracting: valid/Bus-158-_jpg.rf.96153d28c32702e5eeba0b6e0e68913c.jpg  \n",
            " extracting: valid/Bus-162-_jpg.rf.4d9de0cced722c981bd561b7e4b2b5a4.jpg  \n",
            " extracting: valid/Bus-164-_jpg.rf.9df3d9d2b57b51c6d783445fbfc2978c.jpg  \n",
            " extracting: valid/Bus-175-_jpg.rf.d97664457ad7dc53c48d0de5673d0ffc.jpg  \n",
            " extracting: valid/Bus-183-_jpg.rf.7edec9b9574310f7f0a8c4b4b8bea3d5.jpg  \n",
            " extracting: valid/Bus-186-_jpg.rf.91ee93a86f649aa2f6860426744226be.jpg  \n",
            " extracting: valid/Bus-191-_jpg.rf.bc93813a327f6e8a433160bae7becd56.jpg  \n",
            " extracting: valid/Bus-196-_jpg.rf.d66aa44fab3a18d81f608cf372261655.jpg  \n",
            " extracting: valid/Bus-199-_jpg.rf.89e5f8945d0c94c4d92bcf2a756ec347.jpg  \n",
            " extracting: valid/Bus-2-_jpg.rf.9b9603464b29215e5657124c237fd8b4.jpg  \n",
            " extracting: valid/Bus-207-_jpg.rf.c6e054271e9b26ef09de7901fce95c8f.jpg  \n",
            " extracting: valid/Bus-216-_jpg.rf.b6778d778e955617cbb4db04e72821ee.jpg  \n",
            " extracting: valid/Bus-217-_jpg.rf.83d04d47d5bf45d5b575c8d95a5706b8.jpg  \n",
            " extracting: valid/Bus-225-_jpg.rf.bc5c338506c7e2a05c626e9ad503bf9b.jpg  \n",
            " extracting: valid/Bus-231-_jpg.rf.04994da3fa4b26d2ac3259d5a41b59f2.jpg  \n",
            " extracting: valid/Bus-235-_jpg.rf.e8af14e5f04d8530809dba2e6fa1ad3d.jpg  \n",
            " extracting: valid/Bus-244-_jpg.rf.c266e884268d37008ba54c4c572b367e.jpg  \n",
            " extracting: valid/Bus-247-_jpg.rf.5a773b73c5e05c193b35b5d6ac1fb1cb.jpg  \n",
            " extracting: valid/Bus-248-_jpg.rf.3cf571519447d2d51c8f3f8b3667d4b5.jpg  \n",
            " extracting: valid/Bus-249-_jpg.rf.a99a035611e9e19c708ead74a9a8ff27.jpg  \n",
            " extracting: valid/Bus-251-_jpg.rf.d050c10b8acac713c8403fefbfb50fa7.jpg  \n",
            " extracting: valid/Bus-255-_jpg.rf.227450fcac2f026a05ad8cad7d5b9053.jpg  \n",
            " extracting: valid/Bus-256-_jpg.rf.4a9bfaf374bcded2f54a36e7b1b0e4c0.jpg  \n",
            " extracting: valid/Bus-257-_jpg.rf.a3738544f1b16521ec1396bc741f84e1.jpg  \n",
            " extracting: valid/Bus-259-_jpg.rf.03d1efc739dd38bb191e24122f0f8249.jpg  \n",
            " extracting: valid/Bus-269-_jpg.rf.01476a25f93f0cb0fb8abb88c159fea2.jpg  \n",
            " extracting: valid/Bus-282-_jpg.rf.769414101efd3b245287f521a14d108f.jpg  \n",
            " extracting: valid/Bus-289-_jpg.rf.e3b7324cd1c36ad662b6738468640127.jpg  \n",
            " extracting: valid/Bus-296-_jpg.rf.f1e77f17874818b71f15cbf159406869.jpg  \n",
            " extracting: valid/Bus-297-_jpg.rf.3da0c82fcd115d6c733f3d5e09753eb9.jpg  \n",
            " extracting: valid/Bus-300-_jpg.rf.19fd328f783cd019b1915036b12963b9.jpg  \n",
            " extracting: valid/Bus-304-_jpg.rf.3abdca0c7e3511b28af3517833ec7383.jpg  \n",
            " extracting: valid/Bus-305-_jpg.rf.e70e25fd8ec183785b38c412bf9dbf11.jpg  \n",
            " extracting: valid/Bus-32-_jpg.rf.891767fd8e7af875ed8875dc2edfc003.jpg  \n",
            " extracting: valid/Bus-320-_jpg.rf.229ab05d7598bfa34c27715cd18206b6.jpg  \n",
            " extracting: valid/Bus-327-_jpg.rf.1e47b759eef1c4a3740017c10f60dc8a.jpg  \n",
            " extracting: valid/Bus-332-_jpg.rf.61c8932912b027d8f729b96c336d48ef.jpg  \n",
            " extracting: valid/Bus-340-_jpg.rf.999bdb64fb843d8e299c79084eb1affa.jpg  \n",
            " extracting: valid/Bus-341-_jpg.rf.53175030cb5e704200e8632aa0217152.jpg  \n",
            " extracting: valid/Bus-345-_jpg.rf.b756a7c4469ce200b3ed17d7c9044ee9.jpg  \n",
            " extracting: valid/Bus-354-_jpg.rf.4158d6c7a666363a6b8a13e48b2ba5a2.jpg  \n",
            " extracting: valid/Bus-362-_jpg.rf.ea00ff522d792b0c6dae0d6135234da1.jpg  \n",
            " extracting: valid/Bus-370-_jpg.rf.2d69adac7b3503878cf01f247034ea46.jpg  \n",
            " extracting: valid/Bus-372-_jpg.rf.ad13cca61a6d23b34c746c44ef034dae.jpg  \n",
            " extracting: valid/Bus-375-_jpg.rf.feb0ae88c6e13619ab1b80a65f605415.jpg  \n",
            " extracting: valid/Bus-377-_jpg.rf.1001f30ce7536d59e41f5da2c71c0791.jpg  \n",
            " extracting: valid/Bus-379-_jpg.rf.377fded3aecc0c9f3095ffc069236dfa.jpg  \n",
            " extracting: valid/Bus-384-_jpg.rf.444744a49aba4164254237e5114bd9a3.jpg  \n",
            " extracting: valid/Bus-386-_jpg.rf.2d68a8377147f3ce1e5a46fb2ed70455.jpg  \n",
            " extracting: valid/Bus-39-_jpg.rf.7d629d5c36c868b131864e5195336ab3.jpg  \n",
            " extracting: valid/Bus-391-_jpg.rf.aa8d277765cd3eb0fdd559e27e4b18de.jpg  \n",
            " extracting: valid/Bus-392-_jpg.rf.cfa704b089aaf5e886ec736adc6b1dd4.jpg  \n",
            " extracting: valid/Bus-41-_jpg.rf.987816f1f5de9affeb6473ad5c382137.jpg  \n",
            " extracting: valid/Bus-48-_jpg.rf.fdbd8c949cf76d79357b9e1170496d04.jpg  \n",
            " extracting: valid/Bus-49-_jpg.rf.aaaf181a3d88d9962d9cfa784fb1d543.jpg  \n",
            " extracting: valid/Bus-51-_jpg.rf.90613281e1757ec46ec8701e275a0dd0.jpg  \n",
            " extracting: valid/Bus-66-_jpg.rf.3477c0ebb39ce30e5b228447613f46fa.jpg  \n",
            " extracting: valid/Bus-72-_jpg.rf.5bacdf1b3d45307b04a32fbd4ea9a7e1.jpg  \n",
            " extracting: valid/Bus-75-_jpg.rf.57369e195c913e9abac4d8846171df83.jpg  \n",
            " extracting: valid/Bus-84-_jpg.rf.53d2f1e2726122771d728b28a2c1f3ab.jpg  \n",
            " extracting: valid/Bus-87-_jpg.rf.1f6ceea927a9f5ef394086e9352d2af1.jpg  \n",
            " extracting: valid/Bus-96-_jpg.rf.841e65e504716cb6550c8b06546081d7.jpg  \n",
            " extracting: valid/Cars412_png_jpg.rf.1dc1d85bf5c741676f84d6aff52a3602.jpg  \n",
            " extracting: valid/Cars416_png_jpg.rf.f443908a6169ed692d25e52f02d95d06.jpg  \n",
            " extracting: valid/Cek-Plat_jpg.rf.9c3b945109410c1beb0014123015bc19.jpg  \n",
            " extracting: valid/Cutting-Sticker-Truk-Canter-Variasi-2_jpg.rf.40861be59497ea288d99d8c3751d4c96.jpg  \n",
            " extracting: valid/DK1275AE_jpg.rf.820cedb3826f16b9c567fda7f20eb0c3.jpg  \n",
            " extracting: valid/DN1306AX_jpg.rf.e12eca02aa904d73449138ddfe516090.jpg  \n",
            " extracting: valid/DSC01701_JPG_jpg.rf.f86c6e26364c3829d23d2d45db963f9a.jpg  \n",
            " extracting: valid/DSC01709_JPG_jpg.rf.2367bcded7d47e8ff6f778f1e2b47025.jpg  \n",
            " extracting: valid/DSC01720_JPG_jpg.rf.cdf2b49be1e743d1123e8ffe74f2083e.jpg  \n",
            " extracting: valid/DSC01721_JPG_jpg.rf.0432921aa70da323df5901133dc47d2a.jpg  \n",
            " extracting: valid/DSC01723_JPG_jpg.rf.8178a407d42945938b544fe778df6056.jpg  \n",
            " extracting: valid/DSC01728_JPG_jpg.rf.c332a569a8bd76f9f48b6cecbeb263af.jpg  \n",
            " extracting: valid/DSC01733_JPG_jpg.rf.fb9007bd3d9bf58ea34fe0995dea9ab4.jpg  \n",
            " extracting: valid/DSC01919_JPG_jpg.rf.f23e98fa85f9dbeda27ba7742033937d.jpg  \n",
            " extracting: valid/DSC01922_JPG-Copy-Copy_jpg.rf.b7b4cf07bedaeb5a480831f41d546eef.jpg  \n",
            " extracting: valid/DSC01940_JPG_jpg.rf.3a031abf3a7c4a3cd0f992ba7bbaf1c7.jpg  \n",
            " extracting: valid/DSC01940_JPG_jpg.rf.8cd26dca909a46e4033581817b119897.jpg  \n",
            " extracting: valid/DSC01943_JPG_jpg.rf.da32e49c7b83f37a3d3829bae51fc18c.jpg  \n",
            " extracting: valid/DSC01959_JPG-Copy-Copy_jpg.rf.55d42a1c6ff57a0a0b42a6f11c217d8f.jpg  \n",
            " extracting: valid/DSC01959_JPG-Copy-Copy_jpg.rf.c4f1877dd6816375df428b2b5c3b86f1.jpg  \n",
            " extracting: valid/DSC01961_JPG_jpg.rf.121e0194be7775bc2de51f01d4576043.jpg  \n",
            " extracting: valid/DSC01963_JPG_jpg.rf.66269a1fe1d537c8896a734019b60c5a.jpg  \n",
            " extracting: valid/DSC01964_JPG_jpg.rf.58139b7108be060ac2958fca6a08b350.jpg  \n",
            " extracting: valid/DSC01968_JPG_jpg.rf.632b8b239f7c1b66a34afa6046707be1.jpg  \n",
            " extracting: valid/DSC01970_JPG_jpg.rf.319848ce34707b1eb6d98d99740e2c9d.jpg  \n",
            " extracting: valid/DSC01972_JPG_jpg.rf.513f53b20834b6c487d6b89d5c52ddc4.jpg  \n",
            " extracting: valid/DSC01973_JPG_jpg.rf.904726f2403f18673c9b4dd904b962a5.jpg  \n",
            " extracting: valid/DSC01975_JPG_jpg.rf.9c06015347092373d5cc8a10751830a6.jpg  \n",
            " extracting: valid/DSC01976_JPG_jpg.rf.70aa0be3b7890a560a6371ae5bdecf4b.jpg  \n",
            " extracting: valid/DSC01976_JPG_jpg.rf.ce40f5472ae2c1f895aefcda286b3e35.jpg  \n",
            " extracting: valid/DSC01981_JPG_jpg.rf.0751e52f48baae33224725f68c37fb9a.jpg  \n",
            " extracting: valid/DSC01983_JPG_jpg.rf.8ce83cae47b30e6bad7b0b07dc6d34c1.jpg  \n",
            " extracting: valid/DSC01984_JPG_jpg.rf.0ae90688bfd78edff5038242014e9601.jpg  \n",
            " extracting: valid/DSC01985_JPG_jpg.rf.07055507fadec3a971519d32715c0187.jpg  \n",
            " extracting: valid/DSC01986_JPG_jpg.rf.fa0ff016908742694d5aa2bd28d78011.jpg  \n",
            " extracting: valid/DSC01990_JPG_jpg.rf.9403cad276d4737daf586eef22f663c0.jpg  \n",
            " extracting: valid/DSC01990_JPG_jpg.rf.f1832f22a7866425bc8e92bbd44122ba.jpg  \n",
            " extracting: valid/DSC01991_JPG_jpg.rf.04f0d9fb3e9f9b591f0c7b68c7d9b8d7.jpg  \n",
            " extracting: valid/DSC01991_JPG_jpg.rf.a9bbaeef265dc1802c58c03d4b1da4ac.jpg  \n",
            " extracting: valid/DSC01992_JPG_jpg.rf.ba3c615a0a2808384a9d49e57c7ac8f9.jpg  \n",
            " extracting: valid/DSC01993_JPG_jpg.rf.39c2586b2c8630f8066a385fe5223b4b.jpg  \n",
            " extracting: valid/DSC01993_JPG_jpg.rf.d120a52af066626ff2eb8e70fcd04473.jpg  \n",
            " extracting: valid/DSC01994_JPG_jpg.rf.cf1d507453837a5bfc2163be79677909.jpg  \n",
            " extracting: valid/DSC01995_JPG_jpg.rf.6e2f498cf3f68106a041a3a25471cbc1.jpg  \n",
            " extracting: valid/DSC01996_JPG_jpg.rf.465f37d9ce42678f22e887c11970eb99.jpg  \n",
            " extracting: valid/DSC01998_JPG_jpg.rf.76d476305ed63ab6075ca143eccb862e.jpg  \n",
            " extracting: valid/DSC02004_JPG_jpg.rf.3197f2545d7d32870a1fb1dbc0bf1248.jpg  \n",
            " extracting: valid/DSC02008_JPG_jpg.rf.b79dd587af1bd401f469a57aa738d9db.jpg  \n",
            " extracting: valid/DSC02019_JPG_jpg.rf.31546485841cf50a77fe2765bc24e916.jpg  \n",
            " extracting: valid/DSC02022_JPG_jpg.rf.55c9c9734aafdbc99464a1893d9ac638.jpg  \n",
            " extracting: valid/DSC02024_JPG_jpg.rf.f9b6943753f31394651bd20e3263b452.jpg  \n",
            " extracting: valid/DSC02025_JPG_jpg.rf.278eab9a8caeb3febb07bb52b01fe55c.jpg  \n",
            " extracting: valid/DSC02030_JPG_jpg.rf.80353b2f368fec1967c14af8d26d06c6.jpg  \n",
            " extracting: valid/DSC02031_JPG_jpg.rf.bd9ed7e01ba7b13eb88c5a1188a38203.jpg  \n",
            " extracting: valid/DSC02039_JPG_jpg.rf.f0ac9b6c7e58abbee045ac3326a92d0a.jpg  \n",
            " extracting: valid/DSC02042_JPG_jpg.rf.36a28b3cd1a69b65b085841988ae110f.jpg  \n",
            " extracting: valid/DSC02054_JPG_jpg.rf.594781eeff45126adec21fe29351e30d.jpg  \n",
            " extracting: valid/DSC02057_JPG_jpg.rf.32583cfb442d68d7e4c6ebdaa6fea5f5.jpg  \n",
            " extracting: valid/DSC02060_JPG_jpg.rf.106262802404d489d0d4b49e78a16d53.jpg  \n",
            " extracting: valid/DSC02062_JPG_jpg.rf.07202c3d7fab05abc1eae069b7f43f9a.jpg  \n",
            " extracting: valid/DSC02063_JPG_jpg.rf.120f329c8983c47f86ef094c5b6957ee.jpg  \n",
            " extracting: valid/DSC02072_JPG-Copy_jpg.rf.a9e29b5d4c4b8d8c68454b9e7d5ced14.jpg  \n",
            " extracting: valid/DSC02075_JPG-Copy_jpg.rf.1cbfd369ba5691fabdbbcb67b56f6400.jpg  \n",
            " extracting: valid/DSC02086_JPG_jpg.rf.54d1101a2c7251fa13817afc0186b132.jpg  \n",
            " extracting: valid/DSC02088_JPG_jpg.rf.821bf04a66629bb73b2bf13268b6c12c.jpg  \n",
            " extracting: valid/DSC02089_JPG_jpg.rf.558d71be0b86d3155696ca34df553ab1.jpg  \n",
            " extracting: valid/DSC02090_JPG_jpg.rf.2894fbcd6f81be3df842cea3cde9a50a.jpg  \n",
            " extracting: valid/DSC02090_JPG_jpg.rf.9ef256ba3c36e5f431452ab5cd99fb77.jpg  \n",
            " extracting: valid/DSC02092_JPG_jpg.rf.778d3f6b5dabe94d3f35ea312c635e98.jpg  \n",
            " extracting: valid/DSC02095_JPG_jpg.rf.ccb48a6a2ad01010082ea01db7f994ea.jpg  \n",
            " extracting: valid/DSC02096_JPG_jpg.rf.97dfc9e3a7789054143d75dbd992706b.jpg  \n",
            " extracting: valid/DSC02097_JPG_jpg.rf.a1add721424eab59166273d27ca33b50.jpg  \n",
            " extracting: valid/DSC02098_JPG_jpg.rf.f58105113e4b17a9a9a9ad7cb7218ac4.jpg  \n",
            " extracting: valid/DSC02098_JPG_jpg.rf.f785b17ef39bfa6977ed35793e3dacb1.jpg  \n",
            " extracting: valid/DSC02100_JPG_jpg.rf.f8244d3b4e91516fb752088946f9bdd6.jpg  \n",
            " extracting: valid/DSC02106_JPG_jpg.rf.9a6dd442081cc1ce100c82ae8898e456.jpg  \n",
            " extracting: valid/DSC02106_JPG_jpg.rf.f5ad18a8db3dbae2b0942bbdc005ef99.jpg  \n",
            " extracting: valid/DSC02112_JPG_jpg.rf.0679a2e0d6530cecda6954663736b724.jpg  \n",
            " extracting: valid/DSC02117_JPG_jpg.rf.007153001d3e9015dbd5a72c95ad0055.jpg  \n",
            " extracting: valid/DSC02117_JPG_jpg.rf.7754ccfbd74e201596fec219c1ff5750.jpg  \n",
            " extracting: valid/DSC02118_JPG_jpg.rf.f419bf86f5c90b1fa79d01853d3e89d9.jpg  \n",
            " extracting: valid/DSC02119_JPG_jpg.rf.0316c8ff7e2ec0084ddd12f0b63ceecf.jpg  \n",
            " extracting: valid/DSC02119_JPG_jpg.rf.35d8395bb702b30d112e641f86d7a4b2.jpg  \n",
            " extracting: valid/DSC02119_JPG_jpg.rf.ace0706966caa96c3785d4676ae5fb86.jpg  \n",
            " extracting: valid/DSC02122_JPG_jpg.rf.d507bd888b0335a553cf6b0f02a4e7ea.jpg  \n",
            " extracting: valid/DSC02124_JPG_jpg.rf.063636a9549c0e5c6c3f20b6955c39dc.jpg  \n",
            " extracting: valid/DSC02127_JPG_jpg.rf.171bc1fcc1243f073f28d39d2d8f2452.jpg  \n",
            " extracting: valid/DSC02127_JPG_jpg.rf.b468dbf3ac06b639b58dc7e558eae48d.jpg  \n",
            " extracting: valid/DSC02128_JPG_jpg.rf.c632d90b82dd4a2e00aa8d8ea6f78ba2.jpg  \n",
            " extracting: valid/DSC02133_JPG_jpg.rf.03c3eb31d2760a356d9f48e37da2a0e9.jpg  \n",
            " extracting: valid/DSC02137_JPG_jpg.rf.980162fa8ea4960f3b56b169505bb572.jpg  \n",
            " extracting: valid/DSC02137_JPG_jpg.rf.bd4e2d6b9cdda5d301b871f648dbb158.jpg  \n",
            " extracting: valid/DSC02140_JPG_jpg.rf.2cce6e6677288375156b4842859f4002.jpg  \n",
            " extracting: valid/DSC02141_JPG_jpg.rf.287672233795d99a1cd7366f392f5ebc.jpg  \n",
            " extracting: valid/DSC02142_JPG_jpg.rf.2134b95c0976564b1c645867f65b2882.jpg  \n",
            " extracting: valid/DSC02142_JPG_jpg.rf.59143c0dec45c204ca32496d5c990067.jpg  \n",
            " extracting: valid/DSC02144_JPG_jpg.rf.0311abe8e9c30e345315645aeee4b500.jpg  \n",
            " extracting: valid/DSC02144_JPG_jpg.rf.f795e04fff6e75fdffc1307a0858190d.jpg  \n",
            " extracting: valid/DSC02145_JPG_jpg.rf.5e93258ae68a34fe8c066e11d31deaf5.jpg  \n",
            " extracting: valid/DSC02148_JPG_jpg.rf.eb916259da778bd8c36d94cee9e6f764.jpg  \n",
            " extracting: valid/DSC02150_JPG_jpg.rf.d4f60ea7ab2bc1c499e19a58515a0826.jpg  \n",
            " extracting: valid/DSC02151_JPG_jpg.rf.b0403f528aa194502ef8e3be66edfb3f.jpg  \n",
            " extracting: valid/DSC02157_JPG_jpg.rf.f500b8ea54b32823e9a0bb9032f83bb6.jpg  \n",
            " extracting: valid/DSC02160_JPG_jpg.rf.307e83d6445e7c2df4448b7247ee32cf.jpg  \n",
            " extracting: valid/DSC02160_JPG_jpg.rf.485a493f2501f28e72873bb3188b226d.jpg  \n",
            " extracting: valid/DSC02161_JPG_jpg.rf.a740ffcf1d68c93d544cc937255fdd93.jpg  \n",
            " extracting: valid/DSC02161_JPG_jpg.rf.fd2f8fda990dafcf9b9ce61406089be5.jpg  \n",
            " extracting: valid/DSC02168_JPG_jpg.rf.f43f4e47169fce45dd6a3b24959cfc2d.jpg  \n",
            " extracting: valid/DSC02169_JPG_jpg.rf.7afb87e118ddeacc6b9635f863b76357.jpg  \n",
            " extracting: valid/DSC02170_JPG_jpg.rf.a8800b3ed0435017a597821adfd35c36.jpg  \n",
            " extracting: valid/DSC02171_JPG_jpg.rf.5d3c229292fbd9fcf0ba7c519e1df739.jpg  \n",
            " extracting: valid/DSC02171_JPG_jpg.rf.d4091ffc7e6d66c4544f2d6ed51aa341.jpg  \n",
            " extracting: valid/DSC02180_JPG_jpg.rf.2fd1e45d1c56a5399b2f3b54c0ff5d55.jpg  \n",
            " extracting: valid/DSC02181_JPG_jpg.rf.9b7ae63a11ea28cb4de4da95fc1beccc.jpg  \n",
            " extracting: valid/DSC02183_JPG_jpg.rf.32d273d068e8f99ae5690d87512a8db5.jpg  \n",
            " extracting: valid/DSC02184_JPG_jpg.rf.392b9a806fe046d6ce9bb89f6966e3ab.jpg  \n",
            " extracting: valid/DSC02185_JPG_jpg.rf.4419c2ebf1dd0332b7a4065fcbaa17ca.jpg  \n",
            " extracting: valid/DSC02186_JPG_jpg.rf.3d0234058d74b8b6bbe9a6116267b5f4.jpg  \n",
            " extracting: valid/DSC02187_JPG_jpg.rf.9d5655c24a16823be9fdcac398924d91.jpg  \n",
            " extracting: valid/DSC02188_JPG_jpg.rf.ad8bb332b051c7bda626ad033fd18614.jpg  \n",
            " extracting: valid/DSC02190_JPG_jpg.rf.194a3f1ebd1bb080fba1a0a9a9d47b5b.jpg  \n",
            " extracting: valid/DSC02195_JPG_jpg.rf.3f1e58a75e26f1bd5eeae07a46cb35ce.jpg  \n",
            " extracting: valid/DSC02197_JPG_jpg.rf.b0ea6e3ebe3c725ae2813d3b57da0eaf.jpg  \n",
            " extracting: valid/DSC02200_JPG_jpg.rf.4d9ef7197ec73fcae36b6a8f09351e49.jpg  \n",
            " extracting: valid/DSC02205_JPG_jpg.rf.026261528b8b7d69b9d44b78e71c9b26.jpg  \n",
            " extracting: valid/DSC02205_JPG_jpg.rf.211578a21c39d0266375b747f2d3bb39.jpg  \n",
            " extracting: valid/DSC02212_JPG_jpg.rf.102338fadb40fcfbc34f8c884a452233.jpg  \n",
            " extracting: valid/DSC02227_JPG_jpg.rf.aa9e946788bcc536595034d9aa54dac0.jpg  \n",
            " extracting: valid/DSC02239_JPG_jpg.rf.f63eb0793ccb37dfe3a8cc4b194e0df1.jpg  \n",
            " extracting: valid/DSC02801_JPG_jpg.rf.68890aeefb1805face0fdb7409edf4e2.jpg  \n",
            " extracting: valid/DSC02807_JPG_jpg.rf.84be88d5190b597cf452226d3f9e6764.jpg  \n",
            " extracting: valid/DSC02846_JPG_jpg.rf.9124f2b10a124696d0af59f7b73496b6.jpg  \n",
            " extracting: valid/DSC02870_JPG_jpg.rf.e4ed8f362b4639600e8deb0800589477.jpg  \n",
            " extracting: valid/DSC02872_JPG_jpg.rf.9b2fd6f421b1997446e5f27892f6f2bf.jpg  \n",
            " extracting: valid/DSC03065_JPG_jpg.rf.1ed95964a671b75443626ebacb1967e5.jpg  \n",
            " extracting: valid/DSC03071_JPG_jpg.rf.29d93883a0a2975b384941252e561059.jpg  \n",
            " extracting: valid/DSC03077_JPG_jpg.rf.b2da382521013425f6a0806fbfb0f562.jpg  \n",
            " extracting: valid/IMG-20180108-WA0019_jpg.rf.27125d673ec56734c4563dedfc0244f8.jpg  \n",
            " extracting: valid/IMG-20180108-WA0021_jpg.rf.4dd1df8588a0c2778a890b108a26dd67.jpg  \n",
            " extracting: valid/IMG-20180108-WA0029_jpg.rf.3573686993ccf20d3d24661f66e8077e.jpg  \n",
            " extracting: valid/IMG-20180108-WA0035_jpg.rf.7e7d9538b72a0194d87b81d1871b9719.jpg  \n",
            " extracting: valid/IMG-20180108-WA0036_jpg.rf.134aa11d46201d85d19e328ebc963be7.jpg  \n",
            " extracting: valid/IMG-20180108-WA0040_jpg.rf.81223b010ca51d4b1d9cf9cb6a3e4927.jpg  \n",
            " extracting: valid/IMG-20180108-WA0043_jpg.rf.499b5e172323c2e85f2ec675a4a62d91.jpg  \n",
            " extracting: valid/IMG-20180108-WA0045_jpg.rf.353489aaacf2fe9fd49569c0941ca253.jpg  \n",
            " extracting: valid/IMG-20180108-WA0047_jpg.rf.66cd939c1d652590d2c8e662c2e38919.jpg  \n",
            " extracting: valid/IMG-20180108-WA0052_jpg.rf.a275e71d7b7a76c7e8ea61ae6381d40c.jpg  \n",
            " extracting: valid/IMG-20180108-WA0063_jpg.rf.86f9ce5ce7e9df347535ce18ec328d29.jpg  \n",
            " extracting: valid/IMG-20180108-WA0067_jpg.rf.d1962c0e7590448b0b3cf881deecef06.jpg  \n",
            " extracting: valid/IMG-20180108-WA0078_jpg.rf.9403e2eb08fac64170775d8b02bf5021.jpg  \n",
            " extracting: valid/IMG-20180108-WA0082_jpg.rf.4b710229357462add5ba188e34593f66.jpg  \n",
            " extracting: valid/IMG-20180108-WA0089_jpg.rf.fb884b64f30fc9eb1e7af0507462505c.jpg  \n",
            " extracting: valid/IMG-20180108-WA0091_jpg.rf.94e49c344eb7e1f7e818fffc0d0b5501.jpg  \n",
            " extracting: valid/IMG-20180108-WA0104_jpg.rf.45949a4d71d3598f11d11bc3ac0f3610.jpg  \n",
            " extracting: valid/IMG-20180108-WA0107_jpg.rf.4858668820783695e08edde2a0eee377.jpg  \n",
            " extracting: valid/IMG-20180108-WA0111_jpg.rf.678f699dc23a7f1a8edb35bf79ca28c1.jpg  \n",
            " extracting: valid/IMG-20180108-WA0115_jpg.rf.3cff70d3d96c204471d206b5ed7e2492.jpg  \n",
            " extracting: valid/IMG-20180108-WA0119_jpg.rf.11437e5b64a2bc14bc38e8f60df7f8c4.jpg  \n",
            " extracting: valid/IMG-20211122-WA0014_jpg.rf.ccb8d3dc81ead5f2ebe4f66e2e215d1a.jpg  \n",
            " extracting: valid/IMG-20211122-WA0024_jpg.rf.d2230d734f1b53fe7628087e4b865a4d.jpg  \n",
            " extracting: valid/IMG-20211122-WA0034_jpg.rf.f3338992523908df1f465a4babcc4657.jpg  \n",
            " extracting: valid/IMG-20211122-WA0038_jpg.rf.cbbaf7b13dc0bb517778c7955b8fda0f.jpg  \n",
            " extracting: valid/IMG-20211123-WA0022_jpg.rf.a7fd86a3a79b354826b964048d526b91.jpg  \n",
            " extracting: valid/IMG-20220515-WA0020_jpg.rf.a6bc241534550cbe6dacadcb681924e2.jpg  \n",
            " extracting: valid/IMG_5889__flip_jpg.rf.f7196902b561dd963e7e9f45a7214934.jpg  \n",
            " extracting: valid/IMG_5898_jpg.rf.a3e3e56c8f866c76457ba29276470332.jpg  \n",
            " extracting: valid/IMG_8473_jpg.rf.384723e5d30dee0f5d8451b5100659e3.jpg  \n",
            " extracting: valid/IMG_8494_jpg.rf.450605f34c6ee6c5a39d724789e0dfee.jpg  \n",
            " extracting: valid/L1564CZ_jpg.rf.32c95300c8619431c7ba876f012b9d99.jpg  \n",
            " extracting: valid/L9069GJ_jpg.rf.6c9feb10aff4f3a3c75be15bc283bf4e.jpg  \n",
            " extracting: valid/Mobil-1-_jpg.rf.83293f2461d7a7338c417cf6ed4e0b73.jpg  \n",
            " extracting: valid/Mobil-100-_jpg.rf.d42d7175c1e7afe5a4cbcd768acce48a.jpg  \n",
            " extracting: valid/Mobil-101-_jpg.rf.6c63bdfae0d28496d105258ef5d32d9d.jpg  \n",
            " extracting: valid/Mobil-104-_jpg.rf.58a36bea321a4851e71a9ebba120e830.jpg  \n",
            " extracting: valid/Mobil-109-_jpg.rf.794d5ad4bab71f8125b8e6ba644ee436.jpg  \n",
            " extracting: valid/Mobil-12-_jpg.rf.c6475b1a11f82e0316570ccedc39b171.jpg  \n",
            " extracting: valid/Mobil-122-_jpg.rf.14e24c406c0ab8d96b809bcb75824373.jpg  \n",
            " extracting: valid/Mobil-123-_jpg.rf.a3dc80e1b0c8d89bb9f195352b07ec84.jpg  \n",
            " extracting: valid/Mobil-126-_jpg.rf.78e03556df662f2e949919deb8ffc082.jpg  \n",
            " extracting: valid/Mobil-129-_jpg.rf.1e2c940f8d2660ac3491746580e20153.jpg  \n",
            " extracting: valid/Mobil-130-_jpg.rf.9a62e4344dc40a9e4a9cd3f2fdd3d783.jpg  \n",
            " extracting: valid/Mobil-146-_jpg.rf.e6af8316e52867747a2af7fdad7397e3.jpg  \n",
            " extracting: valid/Mobil-148-_jpg.rf.ca46f9f0a166359dec35afbefcde85c0.jpg  \n",
            " extracting: valid/Mobil-153-_jpg.rf.1e3b818081b0ef1dc8d3cbf7f795bdf7.jpg  \n",
            " extracting: valid/Mobil-168-_jpg.rf.0c3ced5fcf6fa90d8857f6cfadcd0f88.jpg  \n",
            " extracting: valid/Mobil-173-_jpg.rf.7513d7f7006ac5c0da4a10e38ff80446.jpg  \n",
            " extracting: valid/Mobil-184-_jpg.rf.cd58a05c1b0c3a0e79aa67ea5350f223.jpg  \n",
            " extracting: valid/Mobil-187-_jpg.rf.c1fbc7a5a7c41c34ee88603e0e0f792a.jpg  \n",
            " extracting: valid/Mobil-189-_jpg.rf.dd265b714dea1ad4128d744f295c2224.jpg  \n",
            " extracting: valid/Mobil-194-_jpg.rf.2981b5972a0dd01e90b1115d125b8c1c.jpg  \n",
            " extracting: valid/Mobil-195-_jpg.rf.4a7c0799b3cfadae264cb24dda3dabc4.jpg  \n",
            " extracting: valid/Mobil-208-_jpg.rf.f6ed78b55999d1c9484a8d8f0849a268.jpg  \n",
            " extracting: valid/Mobil-213-_jpg.rf.0bdeff40071b44bcac298a760bb889bf.jpg  \n",
            " extracting: valid/Mobil-218-_jpg.rf.ced34b79e8cb9723aed79a970747d302.jpg  \n",
            " extracting: valid/Mobil-22-_jpg.rf.72edb2541ff7694adec10853ef054c9b.jpg  \n",
            " extracting: valid/Mobil-224-_jpg.rf.008b82665129535ee7126b2b738aedbf.jpg  \n",
            " extracting: valid/Mobil-226-_jpg.rf.4f8adb0c60df9d16c36d9b6edcb052fc.jpg  \n",
            " extracting: valid/Mobil-23-_jpg.rf.edf53cfdfc2fadf10e75f8b8e0f68676.jpg  \n",
            " extracting: valid/Mobil-233-_jpg.rf.88544207104d082276066913c8018df8.jpg  \n",
            " extracting: valid/Mobil-238-_jpg.rf.8c03968a5dc0dc50a16642111bbdba23.jpg  \n",
            " extracting: valid/Mobil-24-_jpg.rf.9519fd321a317f82be6eea7057b61c1f.jpg  \n",
            " extracting: valid/Mobil-246-_jpg.rf.4f581e4aae7315c925c462e652b43fd8.jpg  \n",
            " extracting: valid/Mobil-247-_jpg.rf.3ca58e69ba36ed27bc58a1e35f1f35a5.jpg  \n",
            " extracting: valid/Mobil-252-_jpg.rf.23a16715d0bc8478dd801ff9a51589f8.jpg  \n",
            " extracting: valid/Mobil-253-_jpg.rf.3497230e6bf9fdb701e04b85b04db3c7.jpg  \n",
            " extracting: valid/Mobil-257-_jpg.rf.d2ca9896b12e626aef7d1d3fb4c06b01.jpg  \n",
            " extracting: valid/Mobil-265-_jpg.rf.11a7734fa4da98b554eb0cf84a629eaf.jpg  \n",
            " extracting: valid/Mobil-266-_jpg.rf.4354effd4bd5928a6c8b0f9dcdb0775c.jpg  \n",
            " extracting: valid/Mobil-268-_jpg.rf.1ef5aa08e41dbe6aabbb606e67c1044b.jpg  \n",
            " extracting: valid/Mobil-28-_jpg.rf.9dbec7bed4326b7b51b93c62329c4de4.jpg  \n",
            " extracting: valid/Mobil-280-_jpg.rf.f384bf2dbab9408f7426607a81c2ba00.jpg  \n",
            " extracting: valid/Mobil-282-_jpg.rf.1165d524b8db0f1aa515ed9b6c0cc23e.jpg  \n",
            " extracting: valid/Mobil-288-_jpg.rf.cf39eab918931c171dc40d8a3c5c289e.jpg  \n",
            " extracting: valid/Mobil-299-_jpg.rf.fb06d6302ad5fe28367b0c31761d4690.jpg  \n",
            " extracting: valid/Mobil-30-_jpg.rf.632bb59a220b3b59c1be431833575334.jpg  \n",
            " extracting: valid/Mobil-312-_jpg.rf.ae0a494c53cfcc552668bcab7784a0c6.jpg  \n",
            " extracting: valid/Mobil-32-_jpg.rf.99c159833d6e009b53ef8c01402910ff.jpg  \n",
            " extracting: valid/Mobil-328-_jpg.rf.b1d4fef43e5b6ff52e0ac276a5d1c085.jpg  \n",
            " extracting: valid/Mobil-329-_jpg.rf.9ee30c55801844ec49e8288ff5566647.jpg  \n",
            " extracting: valid/Mobil-33-_jpg.rf.09be348246664b8a21ee2b887f13c768.jpg  \n",
            " extracting: valid/Mobil-334-_jpg.rf.1d7aa6066b7bc5ca4c5cf872c3cb769e.jpg  \n",
            " extracting: valid/Mobil-337-_jpg.rf.1a94861d93ef3d7fd32ba6bd0df53e24.jpg  \n",
            " extracting: valid/Mobil-341-_jpg.rf.70af4450817a40d4acfff450b17cba07.jpg  \n",
            " extracting: valid/Mobil-344-_jpg.rf.3365b21bbd5aecd88658502b81736512.jpg  \n",
            " extracting: valid/Mobil-346-_jpg.rf.8fbe4a676f0368a64620f26832ce21b0.jpg  \n",
            " extracting: valid/Mobil-349-_jpg.rf.2ff026c7867e9cd04ca2180df944cafb.jpg  \n",
            " extracting: valid/Mobil-352-_jpg.rf.7aedc299ca0fc277c19ecf6e2c197fcf.jpg  \n",
            " extracting: valid/Mobil-355-_jpg.rf.ad38ab74ff995daca10d41f7397280e4.jpg  \n",
            " extracting: valid/Mobil-360-_jpg.rf.53b149491015385ea0a31b99652437ef.jpg  \n",
            " extracting: valid/Mobil-371-_jpg.rf.b6184e180e960ea6c74d0a6060aa9cef.jpg  \n",
            " extracting: valid/Mobil-373-_jpg.rf.3b04a123be23bf11c48757e4a2ca2154.jpg  \n",
            " extracting: valid/Mobil-43-_jpg.rf.b64c2cf78633d36db277329e01e3a15c.jpg  \n",
            " extracting: valid/Mobil-45-_jpg.rf.744d93b42e1b7dd4cb20a9efd82bdf5d.jpg  \n",
            " extracting: valid/Mobil-58-_jpg.rf.3e7cce67797f6919744cca520bc76582.jpg  \n",
            " extracting: valid/Mobil-59-_jpg.rf.b4912e9ea00819691d266dc5bde95a83.jpg  \n",
            " extracting: valid/Mobil-6-_jpg.rf.5afef69de925d56034321b4cecdf8915.jpg  \n",
            " extracting: valid/Mobil-64-_jpg.rf.4ed1fcea7f05571b60fb90df316f35cc.jpg  \n",
            " extracting: valid/Mobil-66-_jpg.rf.455cdffda85cf31b3803a0ed106efac8.jpg  \n",
            " extracting: valid/Mobil-70-_jpg.rf.ae0c561b0698471eff229cca4a7f1223.jpg  \n",
            " extracting: valid/Mobil-72-_jpg.rf.8169633d8bb5ed81babd7008ad627a1d.jpg  \n",
            " extracting: valid/Mobil-73-_jpg.rf.11f683fcc71ad015cc96e8c21c10c760.jpg  \n",
            " extracting: valid/Mobil-76-_jpg.rf.663a015eb5b519627e226a2e2e4db0e0.jpg  \n",
            " extracting: valid/Mobil-88-_jpg.rf.740ff3075d7342291aa91e734dd13280.jpg  \n",
            " extracting: valid/Mobil-90-_jpg.rf.4766a62a03edc15614e4a0f002254d79.jpg  \n",
            " extracting: valid/Mobil-99-_jpg.rf.23378977808ad9ffe5dc890aba649e46.jpg  \n",
            " extracting: valid/Motor-10-_jpg.rf.75f4ecac6cabb587b4942bfa5d857691.jpg  \n",
            " extracting: valid/Motor-112-_jpg.rf.650ad544e61cf2929f46ae267a9084d8.jpg  \n",
            " extracting: valid/Motor-116-_jpg.rf.6212964a1cd2248f7a444526ffd4be06.jpg  \n",
            " extracting: valid/Motor-131-_jpg.rf.dfbd15b5a497dc4a79da4c20b75e4f99.jpg  \n",
            " extracting: valid/Motor-134-_jpg.rf.cc62dfea06dff83ddbee577c40c1fc55.jpg  \n",
            " extracting: valid/Motor-142-_jpg.rf.bf0f27497748e29d881e0ee071950ae8.jpg  \n",
            " extracting: valid/Motor-144-_jpg.rf.bd632f9a106382598b87056baf34f5a3.jpg  \n",
            " extracting: valid/Motor-147-_jpg.rf.287bdaf43f082797400883e156ea0807.jpg  \n",
            " extracting: valid/Motor-153-_jpg.rf.2a3c3b5e0375acb296b5629eaa8f7229.jpg  \n",
            " extracting: valid/Motor-155-_jpg.rf.f45ece620041d3c42a662fd9af34770b.jpg  \n",
            " extracting: valid/Motor-161-_jpg.rf.239262411ee0c17dd7ba595c9fd35c69.jpg  \n",
            " extracting: valid/Motor-169-_jpg.rf.59c74b4acc5e1f28f9f71bc2e85938bd.jpg  \n",
            " extracting: valid/Motor-180-_jpg.rf.2f65e1285f4573b313b1a57f49185c17.jpg  \n",
            " extracting: valid/Motor-191-_jpg.rf.e41777a51e0b15e4683721d8b2d8bb45.jpg  \n",
            " extracting: valid/Motor-194-_jpg.rf.10d90a45010e103bec072dc3fa5d0652.jpg  \n",
            " extracting: valid/Motor-2-_jpg.rf.2fdbc36df5e4480bf69fff642c3e80a8.jpg  \n",
            " extracting: valid/Motor-204-_jpg.rf.3fd585ca50176aff825942167442cf2a.jpg  \n",
            " extracting: valid/Motor-207-_jpg.rf.5f849b442fdf8ab012d8f8d57d698f71.jpg  \n",
            " extracting: valid/Motor-211-_jpg.rf.987a606ddcda8f156c1baa37314cb6a0.jpg  \n",
            " extracting: valid/Motor-234-_jpg.rf.f677ae82a7b3f50f0fab5965d5363649.jpg  \n",
            " extracting: valid/Motor-244-_jpg.rf.e314c4d434aa3ce3e283c0fa46cfa073.jpg  \n",
            " extracting: valid/Motor-245-_jpg.rf.9ccd46335e396bd6e7c75344218fdbff.jpg  \n",
            " extracting: valid/Motor-255-_jpg.rf.527470d9f1c8ab3fc52508c9ceafa14f.jpg  \n",
            " extracting: valid/Motor-258-_jpg.rf.f23deeac642d65111db377c3b7dec463.jpg  \n",
            " extracting: valid/Motor-26-_jpg.rf.bb157b43cef1f008d06c66a91292d00f.jpg  \n",
            " extracting: valid/Motor-262-_jpg.rf.06fd1f18756b85262fa5f6873d29b64b.jpg  \n",
            " extracting: valid/Motor-269-_jpg.rf.db9a2f91f6a132b519a744dd546065a5.jpg  \n",
            " extracting: valid/Motor-280-_jpg.rf.d3edad8966d27e1cc5af756fdbe026ab.jpg  \n",
            " extracting: valid/Motor-286-_jpg.rf.8563ff1e0c72fc77de34aae3100fea18.jpg  \n",
            " extracting: valid/Motor-29-_jpg.rf.3c3167b1ce2297c6b5a801a1108609c8.jpg  \n",
            " extracting: valid/Motor-290-_jpg.rf.5b86b7a315347ad2b20eaea5d5d48703.jpg  \n",
            " extracting: valid/Motor-291-_jpg.rf.285f80c780523344aaaa78b482fb8314.jpg  \n",
            " extracting: valid/Motor-297-_jpg.rf.cbfb4737e3bbe64ff4b2722fc49ea432.jpg  \n",
            " extracting: valid/Motor-30-_jpg.rf.d8dce26973e6c5d3646b642c9eb50b95.jpg  \n",
            " extracting: valid/Motor-304-_jpg.rf.258e088ad966c3d8112524baee3d3adc.jpg  \n",
            " extracting: valid/Motor-305-_jpg.rf.c335b3fc5d5cdde81ba736543fa26bcc.jpg  \n",
            " extracting: valid/Motor-306-_jpg.rf.57f9de2a15ed483f87d7472d5034ca08.jpg  \n",
            " extracting: valid/Motor-307-_jpg.rf.556345e7a129e75adb64aebfba880c91.jpg  \n",
            " extracting: valid/Motor-310-_jpg.rf.e226a2885d9d8dab55b81f4f16169505.jpg  \n",
            " extracting: valid/Motor-319-_jpg.rf.c74d0d97f16ad26e39acd8efc54f3e41.jpg  \n",
            " extracting: valid/Motor-320-_jpg.rf.293f7f049341a4bd64dead9e9b49dd32.jpg  \n",
            " extracting: valid/Motor-326-_jpg.rf.fd58b4878f5eb5142911080ee9d491b8.jpg  \n",
            " extracting: valid/Motor-327-_jpg.rf.bcac4f5c85a7da82610a2e58e42a8689.jpg  \n",
            " extracting: valid/Motor-332-_jpg.rf.611b34c0b4e04b71f2085dc3864cbd9a.jpg  \n",
            " extracting: valid/Motor-333-_jpg.rf.3ab14e1c0e6286ec17125257350e01e2.jpg  \n",
            " extracting: valid/Motor-336-_jpg.rf.6dc74339a4c32de04a9213255c7494ad.jpg  \n",
            " extracting: valid/Motor-337-_jpg.rf.7878991518c24a06f5d6aaafe710beae.jpg  \n",
            " extracting: valid/Motor-338-_jpg.rf.7c8d1ccedf6f150c3bb73ac0522e22bc.jpg  \n",
            " extracting: valid/Motor-340-_jpg.rf.4e4486188fe5d1113851feb99e70d282.jpg  \n",
            " extracting: valid/Motor-344-_jpg.rf.6b4bef0a7ad172cf8889d13354602855.jpg  \n",
            " extracting: valid/Motor-347-_jpg.rf.133f48f266c21ed498563f8047179cba.jpg  \n",
            " extracting: valid/Motor-350-_jpg.rf.d625600f5dfe429e21f9e9104f35a52a.jpg  \n",
            " extracting: valid/Motor-358-_jpg.rf.3480dd1be01691e844bf6ed0a414dd84.jpg  \n",
            " extracting: valid/Motor-371-_jpg.rf.baca0518e4a1cbed657983ab5516a188.jpg  \n",
            " extracting: valid/Motor-372-_jpg.rf.4dac003eabff6ecfbe4cb423100a8ad0.jpg  \n",
            " extracting: valid/Motor-373-_jpg.rf.8554b52e22be4eb702ec2b64397df4c2.jpg  \n",
            " extracting: valid/Motor-374-_jpg.rf.8a5caa313bd5ed941b2c5071b62cf090.jpg  \n",
            " extracting: valid/Motor-376-_jpg.rf.722519352f80011a9de5b15e8d593fa0.jpg  \n",
            " extracting: valid/Motor-38-_jpg.rf.50c3a11e20b18a85c9e596d8d366603f.jpg  \n",
            " extracting: valid/Motor-41-_jpg.rf.bcf78982723bb97b8b5f1633b671125f.jpg  \n",
            " extracting: valid/Motor-45-_jpg.rf.4c44aca58b044097e22994ef26415af1.jpg  \n",
            " extracting: valid/Motor-55-_jpg.rf.d30665edc384defe11e9a04ccc451565.jpg  \n",
            " extracting: valid/Motor-57-_jpg.rf.7e71948926671cb0f37e0b7baf57b635.jpg  \n",
            " extracting: valid/Motor-6-_jpg.rf.debbe6f7ff78e128ed13fd3495b6de60.jpg  \n",
            " extracting: valid/Motor-65-_jpg.rf.ce2eec5c481cec2d4bec1def79a0ecc5.jpg  \n",
            " extracting: valid/Motor-70-_jpg.rf.1c5530dab2d5ad7b45b0672096d27406.jpg  \n",
            " extracting: valid/Motor-74-_jpg.rf.208d1ca07fc4a2769bc7ac394ad063c1.jpg  \n",
            " extracting: valid/Motor-75-_jpg.rf.276957587a317ccd9973a3a4e0f0cb36.jpg  \n",
            " extracting: valid/Motor-81-_jpg.rf.3a0eb8523ee9013322f64ff057fe23cb.jpg  \n",
            " extracting: valid/Motor-82-_jpg.rf.96514f286329f3e83b663eacd4b62e48.jpg  \n",
            " extracting: valid/Motor-85-_jpg.rf.16225c3d867bef8ffa6ca63c75db85a2.jpg  \n",
            " extracting: valid/Motor-9-_jpg.rf.482828b610db92ad8a84528679044879.jpg  \n",
            " extracting: valid/Motor-91-_jpg.rf.71975481422060eea4e15f0693515a72.jpg  \n",
            " extracting: valid/Motor-92-_jpg.rf.ad6de76839512ae9975ae9600485e88a.jpg  \n",
            " extracting: valid/Motor-99-_jpg.rf.be7537deaba6887decd0d9ca0355cbde.jpg  \n",
            " extracting: valid/PHOTO-2022-05-17-13-12-25_jpg.rf.ac3bf4f5444f752f7e776d8aee0936c4.jpg  \n",
            " extracting: valid/PHOTO-2022-05-17-13-12-27_jpg.rf.b2d95b74d6bc0d9f81bdb179c98de654.jpg  \n",
            " extracting: valid/PHOTO-2022-05-17-13-12-29-1-_jpg.rf.50eb7b5e41d12f6a31bf86ccf4b72e66.jpg  \n",
            " extracting: valid/PHOTO-2022-05-17-13-12-30_jpg.rf.9b56b7ea53b317844ea964fa976f6884.jpg  \n",
            " extracting: valid/PHOTO-2022-05-17-13-12-31-1-_jpg.rf.f4ded4a268695e44a147312201825763.jpg  \n",
            " extracting: valid/PHOTO-2022-05-17-13-12-32_jpg.rf.e264e2b543123de93f9a9abf3f14ffbd.jpg  \n",
            " extracting: valid/PHOTO-2022-05-17-13-12-33-1-_jpg.rf.bfcbc42a3d8f2797a32a1fde58af8a37.jpg  \n",
            " extracting: valid/PHOTO-2022-05-17-13-12-36_jpg.rf.8255be2da39143da9e87522d916ac4ad.jpg  \n",
            " extracting: valid/PHOTO-2022-05-17-16-44-13_jpg.rf.2324c308b71b77c6b2dea83d13267ed5.jpg  \n",
            " extracting: valid/PHOTO-2022-05-17-16-44-13_jpg.rf.24b54cf93552137f6366f1c5cf43123b.jpg  \n",
            " extracting: valid/PHOTO-2022-05-17-16-44-21_jpg.rf.62edb701f4e5d9d24f8d8209727a45c0.jpg  \n",
            " extracting: valid/PHOTO-2022-05-17-16-44-27_jpg.rf.ded4af928d109c9e5f9663f68e21d26f.jpg  \n",
            " extracting: valid/PHOTO-2022-05-17-16-44-28-1-_jpg.rf.709f02713144fecaf8d76114d737f8c1.jpg  \n",
            " extracting: valid/PHOTO-2022-05-17-16-44-30-1-_jpg.rf.74ca0e295dc794e08f05532b1fa7e469.jpg  \n",
            " extracting: valid/P_20211122_114525_jpg.rf.0b8d03fcab7e6bb8323bd3806fa25fbb.jpg  \n",
            " extracting: valid/P_20211122_114559_jpg.rf.d52b2daf5aa8885399527d20fb703437.jpg  \n",
            " extracting: valid/Pelat-1-_jpg.rf.dfef87c0a17c0d3debd077216dc430e7.jpg  \n",
            " extracting: valid/Pelat-104-_jpg.rf.de6af0b98d76cd5217e28ca342dd67cf.jpg  \n",
            " extracting: valid/Pelat-109-_jpg.rf.4067a854465170459e34b6b383c09963.jpg  \n",
            " extracting: valid/Pelat-120-_jpg.rf.456ac14df1b0eecdd69144dd2096ec07.jpg  \n",
            " extracting: valid/Pelat-124-_jpg.rf.3ca557c6f23a333c1674df81ac5b6d7d.jpg  \n",
            " extracting: valid/Pelat-127-_jpg.rf.b60d024e2c5ecb594af5375ffe927db5.jpg  \n",
            " extracting: valid/Pelat-14-_jpg.rf.557fe6ef820f22a504482e4cd8e8e7c6.jpg  \n",
            " extracting: valid/Pelat-145-_jpg.rf.2c5af0344692de803a01c5b3b695ea4a.jpg  \n",
            " extracting: valid/Pelat-150-_jpg.rf.961e6e44c232c677ff0e0510f01b8646.jpg  \n",
            " extracting: valid/Pelat-152-_jpg.rf.6bd4af6ab69980420f5fbb547b59f9a8.jpg  \n",
            " extracting: valid/Pelat-153-_jpg.rf.ab223d870dc3a70c8ce9582551fb5ab6.jpg  \n",
            " extracting: valid/Pelat-157-_jpg.rf.888c8785e07b5bee25e5426d37463fb9.jpg  \n",
            " extracting: valid/Pelat-160-_jpg.rf.d99339ba6b04c46a80160305b83eda82.jpg  \n",
            " extracting: valid/Pelat-165-_jpg.rf.c6a31fedad0dc60732de9891de2b3994.jpg  \n",
            " extracting: valid/Pelat-175-_jpg.rf.16351d48c506b22d1b80d6767d4ac17d.jpg  \n",
            " extracting: valid/Pelat-18-_jpg.rf.23839d3bd19dc2d45baeaedc796452ca.jpg  \n",
            " extracting: valid/Pelat-183-_jpg.rf.93d17b71d1458a987f0a4e259d1d963c.jpg  \n",
            " extracting: valid/Pelat-186-_jpg.rf.70c36d9a9a6a8cdd82a353538cc6b2b5.jpg  \n",
            " extracting: valid/Pelat-187-_jpg.rf.a2652916a08d6f6606f5df85beb75af1.jpg  \n",
            " extracting: valid/Pelat-19-_jpg.rf.f8eb098e48ac5f612512054cbfc08962.jpg  \n",
            " extracting: valid/Pelat-198-_jpg.rf.9236e5184c8b08aa119abcfef0af60b7.jpg  \n",
            " extracting: valid/Pelat-201-_jpg.rf.36737f80756eeced20445189518c6892.jpg  \n",
            " extracting: valid/Pelat-203-_jpg.rf.61b51f154f568c505f89883e155869b7.jpg  \n",
            " extracting: valid/Pelat-217-_jpg.rf.8a4dfc3343567e3a473d6e45d6d1dccb.jpg  \n",
            " extracting: valid/Pelat-219-_jpg.rf.004726f93fdd42c5df03efce9e6d3e03.jpg  \n",
            " extracting: valid/Pelat-226-_jpg.rf.038821a0682795c7f528d6effe2498fd.jpg  \n",
            " extracting: valid/Pelat-235-_jpg.rf.34025c126c0d594720c201ea9a02c916.jpg  \n",
            " extracting: valid/Pelat-236-_jpg.rf.79dfe75dc8f092be8f7d07e0ab067f56.jpg  \n",
            " extracting: valid/Pelat-237-_jpg.rf.c86bed1dc2dd6f43705219c9f173a3bf.jpg  \n",
            " extracting: valid/Pelat-239-_jpg.rf.f6c9d116645da546fcd6b0b30e90b660.jpg  \n",
            " extracting: valid/Pelat-24-_jpg.rf.4ef74c9bc2418a6d7b7b289dc12c319d.jpg  \n",
            " extracting: valid/Pelat-241-_jpg.rf.6edb110e0c5b7a9b73eb3659905b9c78.jpg  \n",
            " extracting: valid/Pelat-250-_jpg.rf.86b077cab1131d857d57e3dd5068ac57.jpg  \n",
            " extracting: valid/Pelat-258-_jpg.rf.2f8e6e4c4430e9eff20f770398b1e72e.jpg  \n",
            " extracting: valid/Pelat-259-_jpg.rf.c15b1e4d4877959443016ff14d5f5aa0.jpg  \n",
            " extracting: valid/Pelat-262-_jpg.rf.2a278abfd4210e0729d258fd182f4705.jpg  \n",
            " extracting: valid/Pelat-265-_jpg.rf.4362772a5be9d5af38575070c61fa332.jpg  \n",
            " extracting: valid/Pelat-268-_jpg.rf.372a00eb9e12c0cef3b4ec77cf0680e0.jpg  \n",
            " extracting: valid/Pelat-278-_jpg.rf.a61c47922c3cf111fa08e0fb02f3f1bf.jpg  \n",
            " extracting: valid/Pelat-281-_jpg.rf.fb1f11a531397815dc1243dc3544b6bd.jpg  \n",
            " extracting: valid/Pelat-283-_jpg.rf.691e5b70c6411306685f7812a241d004.jpg  \n",
            " extracting: valid/Pelat-29-_jpg.rf.48b156771823598e7029ad036c581107.jpg  \n",
            " extracting: valid/Pelat-292-_jpg.rf.d2c20fef8e9de5dd73ccd55492dc7294.jpg  \n",
            " extracting: valid/Pelat-296-_jpg.rf.46c333b17edac52bed5f3b50105c8efc.jpg  \n",
            " extracting: valid/Pelat-312-_jpg.rf.859a8ae32835783ed714fb518827977b.jpg  \n",
            " extracting: valid/Pelat-316-_jpg.rf.952eed41d579cc695b08b06573e6e70d.jpg  \n",
            " extracting: valid/Pelat-317-_jpg.rf.1c594b9b8c60e4ac3bbccf513fcd4e8f.jpg  \n",
            " extracting: valid/Pelat-319-_jpg.rf.98a2d5f5c643273335efd0c276b7e12e.jpg  \n",
            " extracting: valid/Pelat-323-_jpg.rf.b61fc94ebaea8a4c3b4e82733fc7bfac.jpg  \n",
            " extracting: valid/Pelat-326-_jpg.rf.ccd78f3902a7e6da49096f2d990df13e.jpg  \n",
            " extracting: valid/Pelat-330-_jpg.rf.b01d1db0e7d6babe3edcdcf9aefff7ad.jpg  \n",
            " extracting: valid/Pelat-334-_jpg.rf.c51ec1fed9e3b2df3f3eb0cde6969d96.jpg  \n",
            " extracting: valid/Pelat-335-_jpg.rf.e238d44392419880972db5fa11fbf118.jpg  \n",
            " extracting: valid/Pelat-336-_jpg.rf.fb9c0f238ab52bcb4e26b4bdd8a1c9c7.jpg  \n",
            " extracting: valid/Pelat-338-_jpg.rf.af0c4ffbedc52f0eb52b895df3c169a4.jpg  \n",
            " extracting: valid/Pelat-346-_jpg.rf.2c960d7ba34f18e1bce1af09bed09925.jpg  \n",
            " extracting: valid/Pelat-347-_jpg.rf.2374cc63944532ed286aeb6f80417f83.jpg  \n",
            " extracting: valid/Pelat-348-_jpg.rf.217c57c38c899f7b90132d19ece38e8d.jpg  \n",
            " extracting: valid/Pelat-353-_jpg.rf.0f9263f68af53fdb266d469fdc95d557.jpg  \n",
            " extracting: valid/Pelat-354-_jpg.rf.c64da703970873ec160798eabbce0980.jpg  \n",
            " extracting: valid/Pelat-37-_jpg.rf.4d8c14d49361b371657779bbd2f79997.jpg  \n",
            " extracting: valid/Pelat-372-_jpg.rf.742783c1973084b519b0d17935f1b7d0.jpg  \n",
            " extracting: valid/Pelat-375-_jpg.rf.883b7877e6b804cb0e60b1a793e214aa.jpg  \n",
            " extracting: valid/Pelat-42-_jpg.rf.615afc990596f2c304bedd1e73535a3c.jpg  \n",
            " extracting: valid/Pelat-53-_jpg.rf.eed7cd57d420262fad491e2c3c28be89.jpg  \n",
            " extracting: valid/Pelat-57-_jpg.rf.1c039d47839cd3dec20e304f96d2f50f.jpg  \n",
            " extracting: valid/Pelat-58-_jpg.rf.f30c699c5e538252cbf493e7f7f20c49.jpg  \n",
            " extracting: valid/Pelat-60-_jpg.rf.8b186e9dc0a8b5225083aa02fa828515.jpg  \n",
            " extracting: valid/Pelat-75-_jpg.rf.07ed74982acffcfeadd381f5ce935edb.jpg  \n",
            " extracting: valid/Pelat-8-_jpg.rf.a7614cc06bb8096edee6f7af4d0ee596.jpg  \n",
            " extracting: valid/Pelat-86-_jpg.rf.d1e6a48272c36bb2f035c2fc55e38549.jpg  \n",
            " extracting: valid/Pelat-91-_jpg.rf.55feb79d328a6fc30740e6d8982f09de.jpg  \n",
            " extracting: valid/Pelat-94-_jpg.rf.77fcc37ab4ef6f52f6db5a07d282fe41.jpg  \n",
            " extracting: valid/Pelat-98-_jpg.rf.3971ee9cd8012348992c85973fee711a.jpg  \n",
            " extracting: valid/Pelat-99-_jpg.rf.53485df9210ae3582025df8215032513.jpg  \n",
            " extracting: valid/Screenshot_20220517-135934_Gallery_jpg.rf.fc66d71eff4eee7e4eb5ae89746f911a.jpg  \n",
            " extracting: valid/Screenshot_20220517-135943_Gallery_jpg.rf.5b00b667fea354a040e2777c81438caf.jpg  \n",
            " extracting: valid/Screenshot_20220517-140130_Gallery_jpg.rf.94ec277c6c26f4a3ee0dbc7673853d28.jpg  \n",
            " extracting: valid/Screenshot_20220517-140300_Gallery_jpg.rf.5e7caac849640c912592a2577fa82e49.jpg  \n",
            " extracting: valid/Screenshot_20220517-140348_Gallery_jpg.rf.f89864a99f59637d5d09269fcc01a375.jpg  \n",
            " extracting: valid/Screenshot_20220517-140725_Gallery_jpg.rf.015b12a2dfa8e4e2d6c2723bfa6011ba.jpg  \n",
            " extracting: valid/Truk-1-_jpg.rf.0d53c39055a4313fa43417fb8fbd4079.jpg  \n",
            " extracting: valid/Truk-10-_jpg.rf.e69bf4306643049d7ccb0e3dfb615294.jpg  \n",
            " extracting: valid/Truk-101-_jpg.rf.3bf3df62658e9c72d692fffc79e655b6.jpg  \n",
            " extracting: valid/Truk-109-_jpg.rf.a2b643a36c166637741ecf6ddbda67cf.jpg  \n",
            " extracting: valid/Truk-115-_jpg.rf.d6f1de9e1914d59f101dd7f374663217.jpg  \n",
            " extracting: valid/Truk-116-_jpg.rf.a248f52b06f1a74012a9b518dbaca819.jpg  \n",
            " extracting: valid/Truk-119-_jpg.rf.88a4ffded020fbbc0a943a4ba41bdbaf.jpg  \n",
            " extracting: valid/Truk-121-_jpg.rf.6dc5f7dd6efd5b78ae2f56da6c714c41.jpg  \n",
            " extracting: valid/Truk-123-_jpg.rf.549cb1861bf28a9238b5e8090c311bb1.jpg  \n",
            " extracting: valid/Truk-125-_jpg.rf.1836edcc6c4656abf661a4f0ef94772c.jpg  \n",
            " extracting: valid/Truk-127-_jpg.rf.7c54660ae932bf353b02bc06dde8b9d8.jpg  \n",
            " extracting: valid/Truk-131-_jpg.rf.5a6add4237b384d28dc03eca80b810e2.jpg  \n",
            " extracting: valid/Truk-133-_jpg.rf.74354b393f69bc4b7794af7667bb6cf7.jpg  \n",
            " extracting: valid/Truk-136-_jpg.rf.565ff888a913ebf440cabd410f561470.jpg  \n",
            " extracting: valid/Truk-159-_jpg.rf.c5d48c0bd13cfa9db43fea83d835071b.jpg  \n",
            " extracting: valid/Truk-16-_jpg.rf.648f322f3afcc6a56a88a4bee9acadd0.jpg  \n",
            " extracting: valid/Truk-167-_jpg.rf.8c53fe2ff311295befe68179837bcd0a.jpg  \n",
            " extracting: valid/Truk-168-_jpg.rf.c81370d10470cb6fd645ca35d18967ee.jpg  \n",
            " extracting: valid/Truk-180-_jpg.rf.740793ff7e7197bbbfc442e5ae5c6dc0.jpg  \n",
            " extracting: valid/Truk-184-_jpg.rf.d2c745c0d50e9df08ef3d96e77358aee.jpg  \n",
            " extracting: valid/Truk-187-_jpg.rf.e9f93d9fcb80c1bab81eac60224ebb6b.jpg  \n",
            " extracting: valid/Truk-193-_jpg.rf.018ebb20fbb3cc51825fa6613af99424.jpg  \n",
            " extracting: valid/Truk-200-_jpg.rf.52e9c633e1917b535334c4288911e6d7.jpg  \n",
            " extracting: valid/Truk-202-_jpg.rf.8d207e94c9ccf73e2ebb7b69fbbfde75.jpg  \n",
            " extracting: valid/Truk-204-_jpg.rf.2a1c112c4762ca8ec7b08a838305e68c.jpg  \n",
            " extracting: valid/Truk-210-_jpg.rf.38a95b6431c7464561d86ce49ec218e5.jpg  \n",
            " extracting: valid/Truk-216-_jpg.rf.439212eb400b36f99ae21ea043e9e4c4.jpg  \n",
            " extracting: valid/Truk-221-_jpg.rf.b25dc559997f32ba3bb154140ce7df1e.jpg  \n",
            " extracting: valid/Truk-223-_jpg.rf.d615f74a140f235cc9861214729a2c85.jpg  \n",
            " extracting: valid/Truk-228-_jpg.rf.c03d88534e9aa573173b4ef902e94c7d.jpg  \n",
            " extracting: valid/Truk-232-_jpg.rf.1169d83da137bec0f40f69fa7a8b9b2e.jpg  \n",
            " extracting: valid/Truk-233-_jpg.rf.1b2163b866c3597a561413cc600f0912.jpg  \n",
            " extracting: valid/Truk-237-_jpg.rf.a8aadd9531aaa4c3572c660cb23637d1.jpg  \n",
            " extracting: valid/Truk-24-_jpg.rf.16a4b7e5290c2c383cdce162cfd07e18.jpg  \n",
            " extracting: valid/Truk-240-_jpg.rf.e756dd322568d6657328fc8e1333b688.jpg  \n",
            " extracting: valid/Truk-245-_jpg.rf.818a04c2c4bdb2f5b02dd0816a82f4c6.jpg  \n",
            " extracting: valid/Truk-246-_jpg.rf.a1cfcd14d61ee240bc9d6226372d3ef8.jpg  \n",
            " extracting: valid/Truk-267-_jpg.rf.6b8e928b7c89cae61b0bb105ddb88753.jpg  \n",
            " extracting: valid/Truk-269-_jpg.rf.b07f4380c31d3a4e2d5b441aff40f720.jpg  \n",
            " extracting: valid/Truk-273-_jpg.rf.1823d2ed3b24be42941ca5114ee36f0f.jpg  \n",
            " extracting: valid/Truk-274-_jpg.rf.5a2b4cb4a3f230c3ec2c35c71d5a155e.jpg  \n",
            " extracting: valid/Truk-281-_jpg.rf.c6671c404f50572c5647884b3035545d.jpg  \n",
            " extracting: valid/Truk-296-_jpg.rf.ce86dddc1113743eff1da8d2b79f15f3.jpg  \n",
            " extracting: valid/Truk-3-_jpg.rf.d90f9d9eb71902ff3a59662c6715e81f.jpg  \n",
            " extracting: valid/Truk-30-_jpg.rf.248bf10c8c5b27cf8ba00aaef47cd582.jpg  \n",
            " extracting: valid/Truk-309-_jpg.rf.2bd59d03740dc31b818206cb93304923.jpg  \n",
            " extracting: valid/Truk-313-_jpg.rf.1fe732d70e241ce20c84cab52f1d68c0.jpg  \n",
            " extracting: valid/Truk-316-_jpg.rf.13bfc04902c0274ec9c5188603babaa8.jpg  \n",
            " extracting: valid/Truk-323-_jpg.rf.f606da5b2de4334938ab092f8260cd6c.jpg  \n",
            " extracting: valid/Truk-324-_jpg.rf.d6507778085618e6782f1449f484e917.jpg  \n",
            " extracting: valid/Truk-33-_jpg.rf.128f8321d1ced49e05559bc4b092680d.jpg  \n",
            " extracting: valid/Truk-331-_jpg.rf.28a44bfd8b8125a38ca8824d3889cd45.jpg  \n",
            " extracting: valid/Truk-336-_jpg.rf.01a7639dc5f270ce79e4bea3328170a0.jpg  \n",
            " extracting: valid/Truk-339-_jpg.rf.5e86f9a5ca20130145f4955fc9fb3dec.jpg  \n",
            " extracting: valid/Truk-341-_jpg.rf.e8094a8c59405c59decc3a9cfa8a906a.jpg  \n",
            " extracting: valid/Truk-346-_jpg.rf.ce8f9b3a4713f3f63ca9566a57378104.jpg  \n",
            " extracting: valid/Truk-348-_jpg.rf.68103697d2228bf8d24363602b362267.jpg  \n",
            " extracting: valid/Truk-35-_jpg.rf.305019da0c1e90222955aaeaeda9b69b.jpg  \n",
            " extracting: valid/Truk-350-_jpg.rf.f11504bf3ae68ef7ccc129c52d3079dc.jpg  \n",
            " extracting: valid/Truk-354-_jpg.rf.cd662cf0b2708038a5fad7a119dfa76b.jpg  \n",
            " extracting: valid/Truk-368-_jpg.rf.02b803098a5537805159e83327aa49d9.jpg  \n",
            " extracting: valid/Truk-37-_jpg.rf.6d7309b4b5fdd44a43bbf01fb7c3a36f.jpg  \n",
            " extracting: valid/Truk-371-_jpg.rf.c1c856729892da3aada802a8c32a6ff2.jpg  \n",
            " extracting: valid/Truk-375-_jpg.rf.d6041d9ec02aeb161a32401b0731eab5.jpg  \n",
            " extracting: valid/Truk-4-_jpg.rf.98d002896ada169367d48ddb93a87191.jpg  \n",
            " extracting: valid/Truk-42-_jpg.rf.fbc2b66b902cd4985fcbd8a6de5e16cb.jpg  \n",
            " extracting: valid/Truk-49-_jpg.rf.0f85cbf06d67b78ac1c637eb0d791935.jpg  \n",
            " extracting: valid/Truk-55-_jpg.rf.13245139a2a9f97de89e788a3b84bb74.jpg  \n",
            " extracting: valid/Truk-62-_jpg.rf.84ab71e78232fe36677377969b3f9c34.jpg  \n",
            " extracting: valid/Truk-70-_jpg.rf.fe0010eada396627228c35c48f77e192.jpg  \n",
            " extracting: valid/Truk-71-_jpg.rf.39126d265539c7584e05672533452046.jpg  \n",
            " extracting: valid/Truk-72-_jpg.rf.5ab890dc737f5a3c7743c1bd7d92a137.jpg  \n",
            " extracting: valid/Truk-82-_jpg.rf.a01c8455bfc200559a82c63f39f93086.jpg  \n",
            " extracting: valid/Truk-93-_jpg.rf.ef72e5c5487d8208ac5ba90463eea9d0.jpg  \n",
            " extracting: valid/_annotations.coco.json  \n",
            " extracting: valid/adas_PNG_jpg.rf.0e7205e4bf66ca097469ad1e0a74b76b.jpg  \n",
            " extracting: valid/cutting-sticker-truck-canter-kombina_jpg.rf.6a83e608aef8be1bf81d2a8c0e7e0854.jpg  \n",
            " extracting: valid/dasdaqw_PNG_jpg.rf.e271cd18038a7010d30c74edb8b6c113.jpg  \n",
            " extracting: valid/e12as12_PNG_jpg.rf.1162a96a195ff65acbb27394b143b773.jpg  \n",
            " extracting: valid/easdqqw_PNG_jpg.rf.45d14027fd78cf2c66d0144dabfdf3cd.jpg  \n",
            " extracting: valid/eqweqw1_PNG_jpg.rf.600a698f7fb0deadbae54947b6cf49c7.jpg  \n",
            " extracting: valid/eqweqw21_PNG_jpg.rf.e24647e6993ab4768e000d9e5ba9bf87.jpg  \n",
            " extracting: valid/hanoi-vietnam-january-people-riding-motorbikes-busy-street-hanoi-vietnam-people-riding-motorbikes-busy-street-hanoi-120908376__flip_jpg.rf.8488a717f72ff9aa2752fa6b81398bf8.jpg  \n",
            " extracting: valid/ho-chi-minh-city-high-temperature-day-tired-face-extreme-weather-viet-nam-april-group-vietnamese-wear-glasses-mask-ride-146428580__flip_jpg.rf.7060873d4b9754dd69d66c1eb6005ece.jpg  \n",
            " extracting: valid/https___s3-ap-northeast-1-amazonaws-com_psh-ex-ftnikkei-3937bb4_images_5_4_8_1_15041845-4-eng-GB_8D8A8513_jpg.rf.a2c2b825c99c113391617a1826cd5201.jpg  \n",
            " extracting: valid/https___s3-ap-northeast-1-amazonaws-com_psh-ex-ftnikkei-3937bb4_images_7_6_3_9_1639367-10-eng-GB_1019N_Bike-in-SE-Asia__flip_jpg.rf.10488616797462cfe24e461a56c9dda7.jpg  \n",
            " extracting: valid/images293_jpg.rf.fcbc2163126041b6c044f96d40aed121.jpg  \n",
            " extracting: valid/images319_jpg.rf.a7c81194ed48a5cae839e780630405e5.jpg  \n",
            " extracting: valid/images375_jpg.rf.e82baaf0469b0927b08bfed8c2d70235.jpg  \n",
            " extracting: valid/images3_jpg.rf.7e8dfdcebd8d34955331926a0dd842af.jpg  \n",
            " extracting: valid/images405_jpg.rf.65574281d0c6169069e6046e04971846.jpg  \n",
            " extracting: valid/images56_jpg.rf.ccb457e0dfc5d05c53ab0deb3d784c0f.jpg  \n",
            " extracting: valid/images65_jpg.rf.5a79cff6dba3288a89ec229f71a7d883.jpg  \n",
            " extracting: valid/images66_jpg.rf.fb6e8409a5a56b394a6cf88842023877.jpg  \n",
            " extracting: valid/images78_jpg.rf.32c029af0d57ab367c53d30243af8312.jpg  \n",
            " extracting: valid/images80_jpg.rf.f2e89d0b06820e29e2a8704225d41b58.jpg  \n",
            " extracting: valid/images81_jpg.rf.7ea44006598d90112e203e2d76f3f8fa.jpg  \n",
            " extracting: valid/images86_jpg.rf.d3bd9fee88ce2f7c8801bda7da9aebd5.jpg  \n",
            " extracting: valid/img-p1651820217548-2_haxe3b_jpg.rf.c390a7dab1eca58d02353a362fe19531.jpg  \n",
            " extracting: valid/img-p1652159099741-1_yrdmem_jpg.rf.d6a504d7261f849a9047a3eabde147a3.jpg  \n",
            " extracting: valid/img-p1652170725870-2_ao0xxd_jpg.rf.f37d5fff815a1b7456b04f7dff8f24ca.jpg  \n",
            " extracting: valid/img-p1652234792788-2_x2ivdk_jpg.rf.4b160a0678718c79c7120d0358f3ce72.jpg  \n",
            " extracting: valid/img-p1652263017285-1_fli5yi_jpg.rf.e1fcf91424564f7dd1c09cc356bcc620.jpg  \n",
            " extracting: valid/img-p1652320270036-2_k8tanl_jpg.rf.c2d7aa98c2fa66ba29c5faac60c20f09.jpg  \n",
            " extracting: valid/img-p1652333486992-1_y6jdgz_jpg.rf.2b2a530cec6a60373d6cfa44c6c1f418.jpg  \n",
            " extracting: valid/img-p1652333486992-1_y6jdgz_jpg.rf.5b260ad95a9844bd00dd0fc211c3e47f.jpg  \n",
            " extracting: valid/img-p1652342497571-1_pbcwh9_jpg.rf.989a899b1403394db6059babbbbe515d.jpg  \n",
            " extracting: valid/img-p1652445794492-1_iyrvf7_jpg.rf.042c5179597b0997ecdf12ba84e8634f.jpg  \n",
            " extracting: valid/img-p1652446607682-1_vhyo46_jpg.rf.7710ab6427ea504a25c90c6f310c98d7.jpg  \n",
            " extracting: valid/img-p1652446607682-2_idxdcx_jpg.rf.fc999d5c3d001a6d0452e46c8f1c98bf.jpg  \n",
            " extracting: valid/img-p1652713533367-1_vt65ue_jpg.rf.a79db735caead675249d3ffa03c2a671.jpg  \n",
            " extracting: valid/img-p1652713533367-1_vt65ue_jpg.rf.bc4fd00473d0527637bdc7ed2b29be57.jpg  \n",
            " extracting: valid/img-p1652775611668-1_hydn6i_jpg.rf.035559364cc7845a58f5a5d571898379.jpg  \n",
            " extracting: valid/img-p1652857847718-1_icriyb_jpg.rf.a8b76bf8e4efe1175c1d96347415591a.jpg  \n",
            " extracting: valid/img-p1652875748731-1_k64hdi_jpg.rf.7b19584fc33f39bd4f58982adf035dd8.jpg  \n",
            " extracting: valid/img-p1652875748731-2_mhqg1n_jpg.rf.da18b1ed81c557566a8fffe3e7470e2d.jpg  \n",
            " extracting: valid/mobil-bekas-city-car-di-olx-dengan-jarak-tempuh-40000-45000-km-3_43_jpg.rf.c2117f071e7fd79032ca38e99b9e0109.jpg  \n",
            " extracting: valid/pelat-nomorjpg-20210714120744_jpg.rf.b26f105360c4f190804815c0d4f09b78.jpg  \n",
            " extracting: valid/plat-nomor-s-a2ec_jpg.rf.9cb423c57a108259156003c2785bc196.jpg  \n",
            " extracting: valid/wpryn5rhnpihyane2gjd_jpg.rf.0cbae41a5de640aef8fa1f8115ea443f.jpg  \n",
            " extracting: valid/x20211227030316-682-TYaqy-jpeg-pagespeed-ic-PT9HVDzR-P_jpg.rf.0f21423c75af7895cd08d301f70d14b7.jpg  \n",
            " extracting: valid/xPxvv_jpg.rf.8ec382af3cc4fa584879b771d39562fc.jpg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK73cnbNcMey",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cc65162-0eab-4feb-8e86-6f69ee0fe8e4"
      },
      "source": [
        "#fresh curl courtesy of roboflow.ai, outputing our dataset in Coco Json format\n",
        "\n",
        "!curl -L [YOUR-LINK-HERE] > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   888  100   888    0     0   1385      0 --:--:-- --:--:-- --:--:--  1385\n",
            "100 78.6M  100 78.6M    0     0  50.7M      0  0:00:01  0:00:01 --:--:--  111M\n",
            "Archive:  roboflow.zip\n",
            " extracting: README.dataset.txt      \n",
            " extracting: README.roboflow.txt     \n",
            "   creating: test/\n",
            " extracting: test/0b47311f426ff926578c9d738d683e76_jpg.rf.0b55f43ac16aa65c889558d8ea757072.jpg  \n",
            " extracting: test/1c0060ef868bdc326ce5e6389cb6732f_jpg.rf.9ce88078ea356949f4ab7ad9cfdfc62d.jpg  \n",
            " extracting: test/2f6fb003bb89cd401322a535acb42f65_jpg.rf.91ad9df05bd1f86bab67c8368ae5e4ad.jpg  \n",
            " extracting: test/410993714e325a1de3e394ffe860df3a_jpg.rf.519bf0fdbd5e38cd44cae1cfebc98536.jpg  \n",
            " extracting: test/4e3117459d759798537eb52cf5bf534d_jpg.rf.5b99421bf416463a8c75cfd07f8a68d1.jpg  \n",
            " extracting: test/5a35ba2ec3e0d0b2b12b1758a8ac29aa_jpg.rf.a907af85301c729635d6ab1c31eb31b2.jpg  \n",
            " extracting: test/654bb8835258b26c466b1c19893df451_jpg.rf.95aad22d4dd31ab256cb2bcff02a34dd.jpg  \n",
            " extracting: test/685b860d412b91f5d4f7f9e643b84452_jpg.rf.5ba8dc0b5d2585d01b28089debd42cd6.jpg  \n",
            " extracting: test/73a38a5c8f8f1b09f093f304660d5326_jpg.rf.2d2fa2f4b419d9f2a57fb82d38d8bc6b.jpg  \n",
            " extracting: test/749e9074a77f8d34d86e2218f26cdab4_jpg.rf.8079f8abd9f24ec16e76fcbf18489f46.jpg  \n",
            " extracting: test/7a34d8620235048917b28bcfd3b5572b_jpg.rf.71653deb6fe88ad472dabea12353373d.jpg  \n",
            " extracting: test/8ff752f9ed443e6e49d495abfceb2032_jpg.rf.c3e91277eea99c26328e39a6f0285189.jpg  \n",
            " extracting: test/IMG_0159_JPG.rf.1cf4f243b5072d63e492711720df35f7.jpg  \n",
            " extracting: test/IMG_0169_JPG.rf.b1530b71278953ad465d06863135c71e.jpg  \n",
            " extracting: test/IMG_0170_JPG.rf.6e336797b63833d78997207d352a44fc.jpg  \n",
            " extracting: test/_annotations.coco.json  \n",
            " extracting: test/a3863d0be6002c21b20ac88817b2c56f_jpg.rf.e421134b139d57e02e7df9468a35c1fb.jpg  \n",
            " extracting: test/b4ff4132c8c85da97d8bf9a2a4ed3e3d_jpg.rf.51d1d3e2f2ae5b116c7daf5a304e75ad.jpg  \n",
            " extracting: test/b526b661a33ff481231d1342aff2a266_jpg.rf.b63c85ea45c4e3a665915fddee8c76f9.jpg  \n",
            " extracting: test/b9402881fa580d0eb8b9b98845417550_jpg.rf.087d716cdfdd9cf2cb65b437af716d4d.jpg  \n",
            " extracting: test/c4943d83c06a12ad5e0399d19514a4ca_jpg.rf.8b0040b3b68009f6f700ea28fb1aa491.jpg  \n",
            " extracting: test/c5a012dfa72816098d23fc8baee67834_jpg.rf.e3f72193f30138545bf762265f30083f.jpg  \n",
            " extracting: test/cf4769d0586df6b3fb0dc618d9f8abe6_jpg.rf.326565beb891e3656f7083109897a48b.jpg  \n",
            " extracting: test/cfc306bf86176b92ffc1afbb98d7896f_jpg.rf.a3779da7c72dfa583f9fffa23c231beb.jpg  \n",
            " extracting: test/d7887071e972604ddf5940d8eb2702e7_jpg.rf.9e1760bfa031e0f1b9ec48b6c0448994.jpg  \n",
            " extracting: test/e0d38d159ad3a801d0304d7e275812cc_jpg.rf.fa0bb8160816a373df824349a24a11e7.jpg  \n",
            " extracting: test/e4147f3d8819fc5d67a9f72596bd9e47_jpg.rf.ff3718b0109da4fea85bf6ff5631104c.jpg  \n",
            " extracting: test/e4583d082076b2b549b3736ad1b193c9_jpg.rf.be7ed36bb2bee36cf4edad46fdd4ec75.jpg  \n",
            " extracting: test/f1a24b6bb778ee11ba33687415aa84f2_jpg.rf.6e35192bbbb13f887540067e07d5d660.jpg  \n",
            " extracting: test/fdcd6ada676799da8a870f58fdf548db_jpg.rf.54abced68347da874d25c5d3886d3c4a.jpg  \n",
            "   creating: train/\n",
            " extracting: train/00bc0cacffdebe6b11bdeec56f63ee49_jpg.rf.fbcc3af401eca6bf01b4d031af33c1fc.jpg  \n",
            " extracting: train/0115e4df73475b550e5c6f7a88b2474f_jpg.rf.c759321c26b9bc9c38b31cd49533d350.jpg  \n",
            " extracting: train/02f0931b536dfba10affc3231a3d64fb_jpg.rf.3a714622550c2311f7843cd103a50be3.jpg  \n",
            " extracting: train/0301b7f9ed4d5ba503fda79fc4370c29_jpg.rf.fbdf213f256c973bcb79f186728a898f.jpg  \n",
            " extracting: train/03886821377011fec599e8fa12d86e89_jpg.rf.bca01af1df978ad9092f057443798ad0.jpg  \n",
            " extracting: train/03d3ff4582c8125d69c19a72f846bec8_jpg.rf.c4c2b8da2df7fad6565ec5a1ab9453a2.jpg  \n",
            " extracting: train/040f2bcba5afce3afafdd5bbf36d2ca5_jpg.rf.6e3358605c2734735af18f31e571692c.jpg  \n",
            " extracting: train/04aed88a8d23cf27e47806eb23948495_jpg.rf.985c4b231ab28487d4345ab040afb94c.jpg  \n",
            " extracting: train/055b79dd8db4c43e1a23be6095aaf624_jpg.rf.67a8ff4aee8a2f00af03b3f98977c676.jpg  \n",
            " extracting: train/05de676d5078dc0a13796f3f627993ef_jpg.rf.0a8e65da4f29d2a28325d3f020988eaf.jpg  \n",
            " extracting: train/06770ce99d4866165c0dfb104179c361_jpg.rf.d8685d4639672391538d33e57ff87a85.jpg  \n",
            " extracting: train/0798bfb058da59d189c1bfadcf814f29_jpg.rf.4b02423be86fa6dc14a4913de966a5dd.jpg  \n",
            " extracting: train/0b4ba28f0c759a11750a6430649b52e3_jpg.rf.c840c64b42f1edd63fd63024fed5ec8b.jpg  \n",
            " extracting: train/0cf670506bf9e0fe587647cd62caa232_jpg.rf.411e40b679800ecff1e2c440035e3722.jpg  \n",
            " extracting: train/0d9dbf62d5ee42b92bf55197bba4254d_jpg.rf.d6c9eae5e5bed8f41ba7302bcd00064e.jpg  \n",
            " extracting: train/104ec0199cb67e1a359b1b0845ee66f3_jpg.rf.be5abecc546e16851c415aaaa6119d2d.jpg  \n",
            " extracting: train/13106bbc80a01cc413c2ab5052d2ec25_jpg.rf.c0f851bdf9bd534e5d972ecf341aedb6.jpg  \n",
            " extracting: train/1595777dfa66e954ae23655743e24809_jpg.rf.ce144eded98c26dadbeca8e80df31963.jpg  \n",
            " extracting: train/1728cd731489df8bb8e0396e178fe393_jpg.rf.19f2e7a6596a0e98b9279154f1a31075.jpg  \n",
            " extracting: train/1877a28e4c5f5c1ea68aca66f4e85d95_jpg.rf.263a83e7c95a2a7b3df541c43f3bd3f3.jpg  \n",
            " extracting: train/196829feb704a34a4e471155f14bdd80_jpg.rf.9490ff7a9097c948107e432f3934b128.jpg  \n",
            " extracting: train/1a530d578f3f0bf3497bfeff3d953025_jpg.rf.e666096a1e6aef9c410fe0a5caff68a4.jpg  \n",
            " extracting: train/1a8a4abcba7c4ead35c01f05b9fae8e5_jpg.rf.8e60639ed4cbd253966be89b5a242834.jpg  \n",
            " extracting: train/1b4ccdf7d5ff45dc6c3885243bde5af2_jpg.rf.3ad9dc5fdd86856e5dc10e776f695818.jpg  \n",
            " extracting: train/22e74efb18b2d88fba63d25a61bf5f97_jpg.rf.72cda26bc69e8611a023dea25871bb26.jpg  \n",
            " extracting: train/23988893ef7381fece6d1ef32ef5428f_jpg.rf.c5e09b6b2996b5453a95e7facd4b4683.jpg  \n",
            " extracting: train/239c409d5c09b493fed01a70a3cda4bc_jpg.rf.a745921b91958a16c18c92b259aca5ea.jpg  \n",
            " extracting: train/247f9cf35a263dc7dd7886b187fd5480_jpg.rf.d77e03ae61805408a2c3f81f2217d3ca.jpg  \n",
            " extracting: train/254f92b18b2a81f88b85e7aed3cabc61_jpg.rf.a5d3749856054f63addc3c8282336d11.jpg  \n",
            " extracting: train/26d663ab5ffbec49f9dc8e592982cfd4_jpg.rf.b18d279ba4125fd80a1d12ac0e771a97.jpg  \n",
            " extracting: train/285d7c487a4e20ad832a74acb527b77f_jpg.rf.8925934caf22a38a85af6fd60453f502.jpg  \n",
            " extracting: train/292b0ddcacad7de06a628980954b6993_jpg.rf.c44c0299e2b2a05ba93ceadcd8e8568a.jpg  \n",
            " extracting: train/2c32afd520cc8bf076dfa5b6e2e1c4c1_jpg.rf.e9ad14fa3330976595bbd5162e607641.jpg  \n",
            " extracting: train/2ee0fd0963465ba29d8f27c6e605c55d_jpg.rf.416ed5a06f9bae303c04fb48287f167f.jpg  \n",
            " extracting: train/2fe75c34fd54e960146fb8b0ad8b3fd6_jpg.rf.9b91df20f1a711da331d1878d5687f13.jpg  \n",
            " extracting: train/300f80826bbb7dc4bf83e148614f2f77_jpg.rf.4a030c3f3f66357883fd1b9ae35cb892.jpg  \n",
            " extracting: train/3057eba7e9b0221ddbdc96a01f39ab79_jpg.rf.99cea19d83ccb4944b34919888dd0b71.jpg  \n",
            " extracting: train/3091c9b25d76e9cbd0af83ced9f354e5_jpg.rf.a96c979a388355dec7d4f832c0027f12.jpg  \n",
            " extracting: train/31419854b103ca6becc4cc394c449e95_jpg.rf.11b00b871f708bbe4d1421a0d9bc9daa.jpg  \n",
            " extracting: train/3161933dffedf8a859d6623a99492c53_jpg.rf.c58eabf189045a84e3c4389cebbcb9ec.jpg  \n",
            " extracting: train/3474d785b1b21d68163f56aa00a92bc9_jpg.rf.6bd40b33320a982005920d6d2d680c64.jpg  \n",
            " extracting: train/34ad1966ae7a17d4502ca141413ed8d2_jpg.rf.537d7ed41b558d70e1324f7ca1852ae0.jpg  \n",
            " extracting: train/36066ba85572ce99198f1a21c2c8bbff_jpg.rf.0b8c6b6b4c05ac617ba42138acb75757.jpg  \n",
            " extracting: train/3730ef213ac6aad431475a9ab28f349a_jpg.rf.f5f1fbb4d67fe92ce0d9acaa098cf5ac.jpg  \n",
            " extracting: train/3796db002cba7265bd32b0161ddd9127_jpg.rf.d39211b0dcef15258c6b963af339174e.jpg  \n",
            " extracting: train/37fe05bcf7d8568a9e55b569afdbccbd_jpg.rf.cf1a8be3a1ab89adc512c7969c0f1858.jpg  \n",
            " extracting: train/383c2ed7bbe2d327ab55a871db497c33_jpg.rf.52c7e74ebf109fe309e4b5c4def80ab7.jpg  \n",
            " extracting: train/389b4c47568c78c44df11dbb1377ffea_jpg.rf.cf94bc4ad387c2217d8cdf5402adcc1b.jpg  \n",
            " extracting: train/38f26ee82e38d332b2a831aa47bd363b_jpg.rf.69b9f7a3e7a10d7cdea51d7d7f01ba63.jpg  \n",
            " extracting: train/3914be0cea4aa8a6bbd1081ec3b034a7_jpg.rf.683bc62edd79c5db6b8b1dffcefc8d3f.jpg  \n",
            " extracting: train/3bab0eaaeb63a2ac9ae4942df4006a25_jpg.rf.1e2bc93d96300515f87808e09a5dd9a0.jpg  \n",
            " extracting: train/3e8fb24addda1a0945bd6b7777bc4018_jpg.rf.ec3432947d47720924cbb0dbf51956ba.jpg  \n",
            " extracting: train/446e75de1ffefc2115e79696bcf0e357_jpg.rf.3515dc451efed9a872f9268f3e9eb744.jpg  \n",
            " extracting: train/4667110b61b16e786673ed6126ccc35d_jpg.rf.8dd3ddf202a5cb346771cb4461f82884.jpg  \n",
            " extracting: train/479459fe5c8213a84fd55ba82f2670b1_jpg.rf.f481d875b91a96ca7982bfb5ba10e167.jpg  \n",
            " extracting: train/47e842dd95735a11cf92c0ddf1161193_jpg.rf.fa045b4cdedb6dbeea6226d5e5d58a5c.jpg  \n",
            " extracting: train/4807629b8df9c7eb4366b7feccd72e6a_jpg.rf.7d7f1b6fcb45b82fca8e8d6ce7ae33a9.jpg  \n",
            " extracting: train/4894f034a55eaa9252cd261a62b11d27_jpg.rf.5821daba2605c369ab52a6c1d3485b2a.jpg  \n",
            " extracting: train/48d3c59a99b2b5a5b9f1eb7d5ba63b60_jpg.rf.4360a206e865320f4f5dddea12152bf6.jpg  \n",
            " extracting: train/48e115dcbf1b3a67ca47a75a92da3f33_jpg.rf.b7f219d6adc0b92d43dc62bd98ee752b.jpg  \n",
            " extracting: train/4939035108d04ee672570a7cc937e270_jpg.rf.6fade1d3dc27011193c2fa8b9c10bd12.jpg  \n",
            " extracting: train/49c2afbbe5726160b289f7c0c62cdace_jpg.rf.018249b80783dd42d0d23496d4830902.jpg  \n",
            " extracting: train/49d365236ee4fb6bd982b0f00bff007e_jpg.rf.a2679c37a0afa53ab1a9394ff0585f46.jpg  \n",
            " extracting: train/49f78dc9aaeadd0c76ed2def75c358f3_jpg.rf.06d058407b83ba70ad2e41656d9d2195.jpg  \n",
            " extracting: train/4ae38537a74c5ed10d5223f8066659fc_jpg.rf.b8e4020f3f188e6ebe715200d8db0c27.jpg  \n",
            " extracting: train/4bf38c062fa7b5796d15ba90d6c3a456_jpg.rf.ca8cb7f5c79fb302acc4a6bd81e0b9a6.jpg  \n",
            " extracting: train/4d6b667ecbd41ebd603b38848366d9d0_jpg.rf.e51e6ab1c441b8766bf8503333a69db9.jpg  \n",
            " extracting: train/4d7820ad9fb4fe69d5168e1d7317dd02_jpg.rf.877766bf8a749843720f86abf3056207.jpg  \n",
            " extracting: train/4de23afff63bc169b4ebe547a9c9b692_jpg.rf.3c9bf54ca2de480c19e30d7808e4a2f6.jpg  \n",
            " extracting: train/4eb630d4dd38528dacf72355caf5c06d_jpg.rf.192a83d78be33d7b7f4a5bdc1b47702f.jpg  \n",
            " extracting: train/53de0674524ae6d77bdfff48136dec2a_jpg.rf.e3110b74dc7e779b42cf28f66c70a5d5.jpg  \n",
            " extracting: train/54a90aab8c73562975cc560d51a9d2d1_jpg.rf.27c69714af4c78fdd6f390a4def1e4a3.jpg  \n",
            " extracting: train/5758322233deed7ae7adc23536db2a4f_jpg.rf.8999db6b1f2c3f65d582bc066a6c55c5.jpg  \n",
            " extracting: train/5825608dccde6544eef91822136079d0_jpg.rf.7c4ac226ecdf109b9b74f91cefc46dde.jpg  \n",
            " extracting: train/59727dce26aaa6100078810b61404069_jpg.rf.d0c247bc8da0897e492a48e773adf35c.jpg  \n",
            " extracting: train/5a8433ec79c881f84ef19a07dc73665d_jpg.rf.2f0c3c38d635f03ea39475fd078c3414.jpg  \n",
            " extracting: train/5cecd3b3946aac5c713a51e0bd4617c9_jpg.rf.b0e3d523923d0224d5f5faa66949b7aa.jpg  \n",
            " extracting: train/5e71cb8d41c333a18e799ef0004b040c_jpg.rf.57a1424a00d13826fe3e771dd404ceff.jpg  \n",
            " extracting: train/614811e933a680fd6535ac8bf06bf530_jpg.rf.ace44d36688dfecc17409089f7d0720f.jpg  \n",
            " extracting: train/614aadadb4a7f5b475b027b8e11398ee_jpg.rf.e3506223ffe7f4878bc357cdc1f33cd2.jpg  \n",
            " extracting: train/61567b97353acc18ba9e8aac0f111326_jpg.rf.69222b87f379416d71b28d07b4914777.jpg  \n",
            " extracting: train/6179b463c8f503445e213b706d2a4de5_jpg.rf.8882e7b1020797df38ea13e02e43a69c.jpg  \n",
            " extracting: train/6403b91d63799cb9b5531c47b195d088_jpg.rf.77da8d8e3bc7557ac1396d597f5759c5.jpg  \n",
            " extracting: train/6589f4cfb37439d7d276f0d70f7ee1f0_jpg.rf.8d4dabde24fa1a51f62ebf8ae0ce02e6.jpg  \n",
            " extracting: train/65ba27557c78850168b1df70a3ce4ff7_jpg.rf.223d0d2c45a4796a00809534807bfea2.jpg  \n",
            " extracting: train/66f3c2c7c10a9263de9c6e056ba5c1b9_jpg.rf.9e391887b9da6213f12999e1628558bb.jpg  \n",
            " extracting: train/673bcd0d44f495fbe9dd88d5cacfceb3_jpg.rf.4c5902b014a2bdaf3057a3c74b6a44a2.jpg  \n",
            " extracting: train/675619f2c8078824cfd182cec2eeba95_jpg.rf.223c4b81b8fa7e3bd7a24577a10a5382.jpg  \n",
            " extracting: train/699edbacbfee5e6d4d6d2189bc88990a_jpg.rf.26706a6cf9de8ec15a6bdb7e53e6173c.jpg  \n",
            " extracting: train/6ba74e310dd824af891d057d674cedb9_jpg.rf.d5ce8eb38bcd1353757d902b6c07c670.jpg  \n",
            " extracting: train/6bb6f7cb96bf37230681d12ff7882f61_jpg.rf.f367c0f54253444f9c2f8f8968a1a47f.jpg  \n",
            " extracting: train/6f0a888f9e5aed9516e336fd04723ce1_jpg.rf.284ac83a4d78d901e17b6ca1f8d6222a.jpg  \n",
            " extracting: train/6f0de9b594de9f9b92c6a20daa51a28a_jpg.rf.bc6c392807dacf7a8a84cae9c09acd03.jpg  \n",
            " extracting: train/759a86e63667ca033255c4ab438dd392_jpg.rf.7ce77a0061d42d49bf91a4329cafdc59.jpg  \n",
            " extracting: train/76d01bada90581f55f1ae64c062cafcf_jpg.rf.d8d268060aa9f6fd260d483b10ac6a04.jpg  \n",
            " extracting: train/76dbe2ccf986a2a0d399d3d8a47279ad_jpg.rf.581770ac7f3816d67c2431339bc65592.jpg  \n",
            " extracting: train/76e118acf05a8ebe06957f8882cc06aa_jpg.rf.355e39cef189edb061cf20d6e59d42db.jpg  \n",
            " extracting: train/79e744a68d6e6f83be0a9e8761ea66a4_jpg.rf.433e4079f552b8e2c261a6a3052f30cd.jpg  \n",
            " extracting: train/7df16cd59fb40e0691948cc805e4801b_jpg.rf.c439322b6c3c711ba67ace0c0f3ebffe.jpg  \n",
            " extracting: train/7ee8d13861bdc45e40a7cfe190a8d8a6_jpg.rf.67d658f56e627e74416bc18ec92107c2.jpg  \n",
            " extracting: train/81f5c542ffe0f9eae4df59d29acbcced_jpg.rf.99b5d8d7a1f3fa6cbb6e9ecfb5e3d8b3.jpg  \n",
            " extracting: train/859e7157c6d544236a67463c08169b6e_jpg.rf.bdb4426cf64b8f8c1e1d693a1df74b76.jpg  \n",
            " extracting: train/8678864272a0a04c4c65ca96324105b4_jpg.rf.90118317e342f59a5e18a9c460e72a99.jpg  \n",
            " extracting: train/871597c145446cf58c1c2dd7db988864_jpg.rf.6cecb51bef82f71cd395832fa16411ba.jpg  \n",
            " extracting: train/889c420fb266b8d0e817306110042bda_jpg.rf.02d22a79820be51228296021ad0b6bbb.jpg  \n",
            " extracting: train/8967433350d3b3043902603430fccaab_jpg.rf.0e119efea84f75200b18702781a169ba.jpg  \n",
            " extracting: train/8bb72e70f0560095885586deba37a524_jpg.rf.436c6acb4c9d0a040b6a86ad0a41e770.jpg  \n",
            " extracting: train/8d6f722eadc015a393bd490f9b7a85e6_jpg.rf.85a7f0c7d2d1b7ce90664ff35b84fe8d.jpg  \n",
            " extracting: train/8d796de64b9eed1ffd5ebe550d4ca807_jpg.rf.bcadbba8ab4a943a30062047dd9951be.jpg  \n",
            " extracting: train/8dd12470c30e3b265e8933a6fee7ad28_jpg.rf.a583ec04d3044992cfd9acbebea7aa95.jpg  \n",
            " extracting: train/8de03901c64a80070048ead3fb0d32bd_jpg.rf.d4cd4d7336cee96c7c01731c6f3b81cd.jpg  \n",
            " extracting: train/8f84f1945fd993facc3368d13345f333_jpg.rf.3286223477d0f45d03a6a9854b7ff4a6.jpg  \n",
            " extracting: train/8ff64b3f770bfe96bdffc629efd16460_jpg.rf.f14ad67cdd66b17692929139aef233d6.jpg  \n",
            " extracting: train/9146a6989dac08f1769e677064ebfb49_jpg.rf.21c3f74a60d73237ceb25280df5cebe8.jpg  \n",
            " extracting: train/92992ff9c823e0420bf17e71db9ef4ef_jpg.rf.73292c1560eefbd1a84212b43be8d424.jpg  \n",
            " extracting: train/93557fc861304f7753089c244bc1e33e_jpg.rf.15d07a278e4c1061b2d99a2b95ff9921.jpg  \n",
            " extracting: train/969daa72bd7804ea1212e191820249b0_jpg.rf.9ac5120ab4af0484ace560bea2c39a7c.jpg  \n",
            " extracting: train/97aeb1f9b745a929e9ac0848acb53a1a_jpg.rf.a37313f9380bde8e4827749f1dba6d7c.jpg  \n",
            " extracting: train/9962a4d44388b9008aa0f466e4f4052c_jpg.rf.faa4d33a45e46b53fcc8f751377a8160.jpg  \n",
            " extracting: train/998222d9c93f1640829d4f0032dbf3e8_jpg.rf.28adf4b8b45dc5d0011897ab15e9419f.jpg  \n",
            " extracting: train/99ee6574b2a7afc0bb06269bbcf49a4c_jpg.rf.64986b73afba1223e13eadbd9b0fdb27.jpg  \n",
            " extracting: train/9a6b61a6d3b3e3ecddc201b097aa02d1_jpg.rf.d5534a244c0a9972da49c08b89f83f75.jpg  \n",
            " extracting: train/9c153a9c9798dab948d4260eb109b315_jpg.rf.8db7f32aeb3c84a69b2a7d79b921fc5b.jpg  \n",
            " extracting: train/9c5fb0c3cfd7b334a247cd87c139e8e6_jpg.rf.588e9ea4bfffb48edc0f99b7af98c96f.jpg  \n",
            " extracting: train/9d776e74e90c4f8092b060dd7567e2f8_jpg.rf.b70c4c285edf5789719b8f7bddac3ddc.jpg  \n",
            " extracting: train/9e943906fba1ec89edfacb2dd7976504_jpg.rf.aa1f7ea2f8c95e89aa701d9f87056330.jpg  \n",
            " extracting: train/9fc54a45feb5b01db8f6828d181fb075_jpg.rf.04e7c11036b566a522bc317e86e5ab6a.jpg  \n",
            " extracting: train/IMG_0166_JPG.rf.f228ddaecf7848a0520e929807b35af4.jpg  \n",
            " extracting: train/IMG_0167_JPG.rf.661ad368ce42cadb9dc497ceaa07e777.jpg  \n",
            " extracting: train/IMG_0291_JPG.rf.a72d476f25b25f6ef3f768e5876c2a55.jpg  \n",
            " extracting: train/IMG_0292_JPG.rf.dae866a073c030671cc199d0d06353e4.jpg  \n",
            " extracting: train/IMG_0294_JPG.rf.b7ae411904ff022e80b90f6267535f05.jpg  \n",
            " extracting: train/IMG_0295_JPG.rf.8abd802272b965c843eb1ecbc8df4abc.jpg  \n",
            " extracting: train/IMG_0296_JPG.rf.818119ea873100bb120049c72da67cbd.jpg  \n",
            " extracting: train/IMG_0297_JPG.rf.2609f7e3ad4d54b19aafc0623f5a8510.jpg  \n",
            " extracting: train/IMG_0298_JPG.rf.388fb04c02f369a0c79a524343fe590c.jpg  \n",
            " extracting: train/IMG_0299_JPG.rf.7d92f1ba0929b7fc5e77848b80148fc6.jpg  \n",
            " extracting: train/IMG_0317_JPG.rf.b9135e07e62170150fc67bc1f25b0d3c.jpg  \n",
            " extracting: train/IMG_0318_JPG.rf.37a8faa6e2f4efc18f2113466c1ec320.jpg  \n",
            " extracting: train/_annotations.coco.json  \n",
            " extracting: train/a20eb4bb3cea2e394cfcf9ed969b628e_jpg.rf.9d2528623e7939a30ec82e76cac3df47.jpg  \n",
            " extracting: train/a4028b2361ce7ead654a86b07ac39d52_jpg.rf.03a20a2a674a95ceb6c61a5e531e8ca6.jpg  \n",
            " extracting: train/a4ebf4c268d80c4fe329331ea981b3a1_jpg.rf.d7e764e24afbdced1e4f8848f249bdfc.jpg  \n",
            " extracting: train/a5c65b40e0be3480c0ecfacaab399a87_jpg.rf.667ef27bf19775d48f8acf8dad04fa26.jpg  \n",
            " extracting: train/a8847f8fe8eaaa1c97bf83027a901760_jpg.rf.116b33357951f46fbbe0d5437561f61b.jpg  \n",
            " extracting: train/a932287da44b9dfacd0d16a5c1d27923_jpg.rf.b0950400898d51ce08945ad5c770ab03.jpg  \n",
            " extracting: train/a9768de3fceeeae2618f362870fb9a88_jpg.rf.055c7088ca1c11c42bcafa4950f2572f.jpg  \n",
            " extracting: train/a9987cf6cc5c6545818ec294d4a5bb9b_jpg.rf.21f51fbefe01648bbbb01e0d207c3843.jpg  \n",
            " extracting: train/b0f3d66c8be13f5f6aa25b67a06bdcfa_jpg.rf.30cc54e5f0d02160a2da3f6da04a9653.jpg  \n",
            " extracting: train/b3b002461f1c6b432e22964549767e5f_jpg.rf.6164bf4eadfd3dcb7f7ee2a2bd0764c2.jpg  \n",
            " extracting: train/b5102d7f9740eee7754ed268becb2163_jpg.rf.28a72d037ac692cc90b96708b1b05316.jpg  \n",
            " extracting: train/b5bcde459ca36f0d1f3c20e751336672_jpg.rf.0c6010e1e0afa0ff49d14eef51b5e6c8.jpg  \n",
            " extracting: train/b79ae5b70de58089ead6e32b235e30d3_jpg.rf.68c670de3208dc56613dc9b9f65ec934.jpg  \n",
            " extracting: train/b7a8c7de4fe1382d69f58ac97e819b5c_jpg.rf.d3b1cfbb0c618d6afff8ea3b96c4d331.jpg  \n",
            " extracting: train/bb54af2f0b83b174aecc29328c8fa001_jpg.rf.38630287afd7ffe84cd9468138ab7485.jpg  \n",
            " extracting: train/bc5decab88861286dcf78a367b4377cb_jpg.rf.c3e51d3ab678f7b49912e57cfd3d161c.jpg  \n",
            " extracting: train/beb11566e59775b61f0ca369952067cc_jpg.rf.726ac46a167828c2e34ad77f7abf895e.jpg  \n",
            " extracting: train/c0d68e012bb93c14bc333fc1d5e52621_jpg.rf.47fcf95dac60ca78902fc86cca7eab28.jpg  \n",
            " extracting: train/c3e9e81ba1540aae7961a4d8d96600ba_jpg.rf.deda5846f9437d81262d2e25f5808e36.jpg  \n",
            " extracting: train/c46bf04050a2a9323dfe563e8813602f_jpg.rf.634c5d0d551ab2b7c2554e4ce3c6aacb.jpg  \n",
            " extracting: train/c733616ab773817dd1a356dbbdf2ee33_jpg.rf.02fcb1d459e55b398bd4cc4edbd3bd10.jpg  \n",
            " extracting: train/c76c79e40bd9839a05237934cfa89ca3_jpg.rf.747f4292a1bb980bc392a787a773a0f1.jpg  \n",
            " extracting: train/c7890b749d14d3488066cbdfac4620fd_jpg.rf.eed3f658d1c9c65acfbcad5219f70716.jpg  \n",
            " extracting: train/ca869123d8a0cbcc6e54f4a445e5a78a_jpg.rf.de66695493176269696ee36a61dee1dc.jpg  \n",
            " extracting: train/cae099fe41d6aa30033d71e433c33c8d_jpg.rf.e346e0084281a8f6b63bbfeb576d1fc0.jpg  \n",
            " extracting: train/ce54969567273b9b8a275812ff56e16c_jpg.rf.af61be71f696438c30dc9bd87d299bd6.jpg  \n",
            " extracting: train/cf2784fa97151d5316b2961b1e62dc45_jpg.rf.d728eed31f107b29e913a6b2ad1f751a.jpg  \n",
            " extracting: train/d079f4e77b2445abceca7534356db743_jpg.rf.f7ee65ab8c16d3c9028443faaaf40ee2.jpg  \n",
            " extracting: train/d0cc2420bce5b14dfd39e55dc3737e57_jpg.rf.3914cdc1a02f2972d5316062da6f285f.jpg  \n",
            " extracting: train/d29148a2233950a7777285281cbfccff_jpg.rf.d23b4f180eb3b539d7ed88e2f4beb2cd.jpg  \n",
            " extracting: train/d33c33de41dbe1a95a43212c58fd12b7_jpg.rf.cdd968f5b7c71aa6ef1c732c4079c262.jpg  \n",
            " extracting: train/d3a4e1b8f13ef89f419251f5c5839d0d_jpg.rf.0c0623ed3bb8531690b2fbc7822d57bd.jpg  \n",
            " extracting: train/d415969922564f317be0d1433330626f_jpg.rf.1271853558336c8d9c5414b3a0466b8f.jpg  \n",
            " extracting: train/d494cb268ad7f9f55587de138edc1dc4_jpg.rf.b1bd99204b2ceacbda5bafa452a4d732.jpg  \n",
            " extracting: train/d67b5b9e900409b050dd9bd594f90709_jpg.rf.e07557fe78a4af8f4213b7c50edcc48e.jpg  \n",
            " extracting: train/d795f84f39716798482fb2937868ed8a_jpg.rf.57b7e9ee15d277b2694fdb94549a1487.jpg  \n",
            " extracting: train/d9acc69c5d57623cda22786e309201c9_jpg.rf.d37b5a883d97f31d33db5281c8ae0395.jpg  \n",
            " extracting: train/dd6b5c3cb2d7e77f38f1dfeb2bff0431_jpg.rf.f1dd1da676bf315e684a8e3a2ebbb82c.jpg  \n",
            " extracting: train/ddad9dc4d945006d66f5349d64498559_jpg.rf.cbac3a32273efcef96c08a2b0df10485.jpg  \n",
            " extracting: train/de60ba81aa78387928e4bdc11f3be301_jpg.rf.0cd8adb84fce0b83ee30a5fbdb4c1c4b.jpg  \n",
            " extracting: train/e40003d4bbcdac7196b9502bfe2fb6ed_jpg.rf.a92a3ed23c63f90ce84648a564f2a287.jpg  \n",
            " extracting: train/e6e3a2ff2c75970490079f00136885ad_jpg.rf.276c0ec51830ae8741a3e31c7f703638.jpg  \n",
            " extracting: train/e79deba8fe520409790b601ad61da4ee_jpg.rf.8cd55f2548d15a4c111f0a980d3ee4fe.jpg  \n",
            " extracting: train/e8480d7fb9881d8a0e88b7be4d103f6d_jpg.rf.eba2e44135388fd198939d843dca7e13.jpg  \n",
            " extracting: train/ea799d77875c399618c45cd9409f34ee_jpg.rf.077cbf5dc80bdc0bf0f59ddd6ce6f69e.jpg  \n",
            " extracting: train/eb9e7928e756c3cf9164e7afc08c4653_jpg.rf.77ace05280bcb7d839ab4cf9d586dfa2.jpg  \n",
            " extracting: train/ec4c30d88ecc70b6a3e76dbd9b17324a_jpg.rf.34d31473728f2b9a68bb71a3f40e1d6f.jpg  \n",
            " extracting: train/ec5ab1930d6aa16fff2582b48f82cada_jpg.rf.3164acc59bd3a1cade16f72b1f6e368a.jpg  \n",
            " extracting: train/edd285915356686fb53fb52c1ded0e53_jpg.rf.5104c70947989766361c9335d2f39d37.jpg  \n",
            " extracting: train/ef1d425fd5370fbf8b7adea43b755304_jpg.rf.4d4fe734367a2a5905da11a49184c767.jpg  \n",
            " extracting: train/f02d615907c77dc15f02bd1372e4398f_jpg.rf.714211d55651f47944d10b81622f1d39.jpg  \n",
            " extracting: train/f041d3171dfe3137390c85fc5437e447_jpg.rf.21a114abb3e64a6a241b6f7bdd0d8b9a.jpg  \n",
            " extracting: train/f1ea0167087976926d4fe0aa36b961ce_jpg.rf.245c4d4e37e289bbd69b90b60e6ee9bc.jpg  \n",
            " extracting: train/f2672cdc28767484b556da3ab6f1003e_jpg.rf.4397bb19b736490287e271bcf760ca16.jpg  \n",
            " extracting: train/f3302c754c6fd42130014199ee327d10_jpg.rf.0bef2494f0a7ebf9afda6b7688cf68b0.jpg  \n",
            " extracting: train/f3a5df526393445c6e2d38f66c1f5c27_jpg.rf.5c9ad833e2df809f6a0107ca7dd020ab.jpg  \n",
            " extracting: train/f52e1873b8583f8bf4f7ddf6e9649f07_jpg.rf.48248922519cd3c8f36539bc09dd8528.jpg  \n",
            " extracting: train/f587402be410b424bcbbac06e1dc6162_jpg.rf.a88d82401d5b97453bc047b92048ca39.jpg  \n",
            " extracting: train/f9a9a175f26d4b26bca3a5338cc1405e_jpg.rf.ec1a436f709ef7dc2e4f1fd3c9f6355e.jpg  \n",
            " extracting: train/fa3cf2724c1648a8822b59ac0759475f_jpg.rf.8b23c032ccc0fd6484f9d390cb6a2b9c.jpg  \n",
            " extracting: train/fa4e2b9a8cf58f405f69a56c662834f2_jpg.rf.9c9fb84a36bdfc518396a26a21758f9c.jpg  \n",
            " extracting: train/fb586797e8ad818c7e3e3a6411f73d84_jpg.rf.ad548be54dbd7087c07afbaa78746786.jpg  \n",
            " extracting: train/fc9d7bc0453cb3324406401c00224d30_jpg.rf.da31aaeddba327ec61dea2b7f515e62b.jpg  \n",
            "   creating: valid/\n",
            " extracting: valid/05ad7223827a29a8283f6c4b2490f52f_jpg.rf.5fb70e6e53b997c3015533194ea8e033.jpg  \n",
            " extracting: valid/0b2252c93c53e1b2e61d485b22328e2e_jpg.rf.78aea9d88ee5694eb75e7f05569e112a.jpg  \n",
            " extracting: valid/0c09b79cff39932c59ecc745dd827906_jpg.rf.a9966fa6e4e9a3da8246cd0e44c0e0d1.jpg  \n",
            " extracting: valid/0d9afc3d23392c3958f53d7fe71fd2f1_jpg.rf.38c69d3df99272f2d3c77c742ab1f50e.jpg  \n",
            " extracting: valid/15cc23c777b00d0e123f9df468f2852b_jpg.rf.a3f074f0d6beb76eb98cc6fa73ddce77.jpg  \n",
            " extracting: valid/18742c87a03866e042c5659ba04d1180_jpg.rf.ec481f84c7faf0dda7e20e721db5f89f.jpg  \n",
            " extracting: valid/1b7c1c9570e900f75eb974f99cbb3c60_jpg.rf.8f006641b9236815f6e4d16935747866.jpg  \n",
            " extracting: valid/1be2a621f309c7482e9a79ad5b23ecbe_jpg.rf.5cb426a7e2f8a4ef4c943f11bd62487b.jpg  \n",
            " extracting: valid/26fa37995fa5b18ec40e0a94e6d91104_jpg.rf.10d82beac7ac6234df91112c0276d4df.jpg  \n",
            " extracting: valid/302e7c10664be32b4fc000452149027c_jpg.rf.ec2e113c3ea11a78125c55887b60571f.jpg  \n",
            " extracting: valid/31b83afa654d5dd874c3f0111126ab7f_jpg.rf.755be19c63d3757e2127cc92d7b69869.jpg  \n",
            " extracting: valid/3312e3bb60e338e9c1a614f0f8960dd8_jpg.rf.effbdd6c0e43bd53a7e92240c0ba326b.jpg  \n",
            " extracting: valid/33b66ede234715fb46db40b33c4e26c1_jpg.rf.d59867e5d4f15a6cc37d2cc499b365d2.jpg  \n",
            " extracting: valid/3aafc2d38807dddd1b43a54cb70f500d_jpg.rf.7a1acfea51aff18b554e96c49beafb78.jpg  \n",
            " extracting: valid/3baf85c957b9d28a16c0b65cb2ef0d29_jpg.rf.ee68e051c8a61b8784b87686d828cf59.jpg  \n",
            " extracting: valid/3e0c67f38992fe16dfc163f7f5336263_jpg.rf.b541cee0030fd0edc7be9d4fed6a6abc.jpg  \n",
            " extracting: valid/424d6506342fa2471e71586675ed092c_jpg.rf.43baba77beb2f5588d5cc05ee7c081ec.jpg  \n",
            " extracting: valid/495019998442ddf85b59e387d4916cd3_jpg.rf.9d9d8ec43f8494e2bfe6603811f7b3de.jpg  \n",
            " extracting: valid/4b8f93069270a9f7bb523518a5088b9e_jpg.rf.ab3fbcd4d3542cb5bbb0b748053a358d.jpg  \n",
            " extracting: valid/55be99616328f83dcbfe8c18e1387c0e_jpg.rf.704f9d21a024a31afa058f00ea6d6ca9.jpg  \n",
            " extracting: valid/578029c06939a788cd5606ad17b49fb9_jpg.rf.6283a8b113fdfc84bf9f255a0df447c7.jpg  \n",
            " extracting: valid/57d1d1fb35ed875f9e770660bb03b6d7_jpg.rf.d3b0acfb689144d051a42d31205c791c.jpg  \n",
            " extracting: valid/5c19d3260762f5daa632d952bc0074d6_jpg.rf.9b21b95cd0d470a8c46ab298906e3745.jpg  \n",
            " extracting: valid/64061fd2e0e35bdf9ac4681eddf5fa2a_jpg.rf.7a9c55e842357fc0f8ed468afbdd4baa.jpg  \n",
            " extracting: valid/6859628a422c1b72be8b074841cd943e_jpg.rf.f580f9a20fdbf50ca1ab256112d11fb0.jpg  \n",
            " extracting: valid/6a41b6c8201604216ad196f842c6a2c6_jpg.rf.465cabf5502d8514f08087f183c3cb2a.jpg  \n",
            " extracting: valid/6e2dd4604b3a51d9be11b8809ed03803_jpg.rf.f6282009812141649ada9f73af2eee00.jpg  \n",
            " extracting: valid/73e6a751c50604d017541c11b28d8417_jpg.rf.81ee4214a166fd5de37da0bbfc5ef06c.jpg  \n",
            " extracting: valid/793c79d55c8a252b7a954d074b1d6498_jpg.rf.a9478a33f4491269886d3d92028cd059.jpg  \n",
            " extracting: valid/7e862b85e33cd247ed66447d129e5fb4_jpg.rf.d53dc427754d44718c33bb6291012ad2.jpg  \n",
            " extracting: valid/7e97f49e613a59a70b833e4c0b2c1c04_jpg.rf.e3d8cc08e136002cec4bf8350be37c47.jpg  \n",
            " extracting: valid/86afe95de5471af5cef08e6ae4d9acbb_jpg.rf.89e9e862697f76853ecd9142667e3aa7.jpg  \n",
            " extracting: valid/8ec14357f5f18fb98db86e0283623150_jpg.rf.dc1f65d43628062fda98946db19045ef.jpg  \n",
            " extracting: valid/9453c2097cb4ccc676e273939894b3da_jpg.rf.1b3941e5bbd87526c743197a542248ec.jpg  \n",
            " extracting: valid/97ed198b00b5491747d3b425df8e7096_jpg.rf.d4830d71ceb565084b77c6d7b7a09699.jpg  \n",
            " extracting: valid/IMG_0293_JPG.rf.f29eab19f33f4c8ef04f9188d7ff1de7.jpg  \n",
            " extracting: valid/IMG_0310_JPG.rf.6cf8e3d4550948ac9e5efafc66f1cdfd.jpg  \n",
            " extracting: valid/IMG_0311_JPG.rf.52d3ca104e59d1fcc846258e946e7dbd.jpg  \n",
            " extracting: valid/IMG_0319_JPG.rf.4ebd9c3d828dfa381411157d7b4ad4da.jpg  \n",
            " extracting: valid/IMG_0320_JPG.rf.63f3739202c30a04a1630bba0266fc4f.jpg  \n",
            " extracting: valid/_annotations.coco.json  \n",
            " extracting: valid/abd65798d9952a27e087710eb8bddf32_jpg.rf.99eb394f3994df8afcc2a5778016d1ec.jpg  \n",
            " extracting: valid/aec1aa6773dbbe004554f405cdef2bea_jpg.rf.748dcb4e54783f3bceb3c341d9eee5f1.jpg  \n",
            " extracting: valid/bb0de9761d16eee258ae09d8de32002c_jpg.rf.c11059695bd371034e76c84073775603.jpg  \n",
            " extracting: valid/c1f800417bc42263d141b5ed785e7707_jpg.rf.337b6ba78718cfc7228c7484c4a361f3.jpg  \n",
            " extracting: valid/c20ca9283ea51ac7707905894a7da703_jpg.rf.d23d9f998440d64312d949fdcdfa1b7d.jpg  \n",
            " extracting: valid/c5172afbdad90854b3d0f21a923c0c69_jpg.rf.f7da3947b94ff2b838d32b8fcd660104.jpg  \n",
            " extracting: valid/ca6484c259f286c5bdf1afefc868b753_jpg.rf.7aa1f1409074d5b0cbd19b20593cdcb5.jpg  \n",
            " extracting: valid/d114edc5cb4cae0ceb2f152afd15f57d_jpg.rf.047eea1174ccf45e4a09a9449a5611c0.jpg  \n",
            " extracting: valid/d3b9309d00a2b671407b918ea867a935_jpg.rf.cbc8557646c90e2b2764e2746a672acd.jpg  \n",
            " extracting: valid/d4f7caf01359b9a757c930140f746fad_jpg.rf.2b5cb1a63d242e69953a94e870bf8624.jpg  \n",
            " extracting: valid/d6e283a49b0395a6d5867c9e98e32045_jpg.rf.2571cdc4c5d218d1f8ecd4becc57c5ce.jpg  \n",
            " extracting: valid/d9ef98145d7d35393c75a51331a20e2c_jpg.rf.ff2352acde10b0f0eff169f22f55a1ce.jpg  \n",
            " extracting: valid/e1616dc9962fed075576ac4ea3553f51_jpg.rf.ad4a845557489e0b87666d3a34abd929.jpg  \n",
            " extracting: valid/e53bf8a0e692a4ccd5f1dc2bc19e7751_jpg.rf.181fa15089d35840f7c13edd8e22b1f5.jpg  \n",
            " extracting: valid/e7edc4f1b8d3cc1069b96d0358e066c9_jpg.rf.9dbe733e3efac3860d9ec4bf94e8674a.jpg  \n",
            " extracting: valid/ec418cafd39d7c5a69cc0642a08b2a08_jpg.rf.4d5b99fb671fd8cd28d64ed4f0293535.jpg  \n",
            " extracting: valid/eca42980852e6c5db10ee84aac23f9c6_jpg.rf.33b03eede8db8237276d8c962e735f2b.jpg  \n",
            " extracting: valid/fb7d97265a22bb1c1f908dadc6f9e7dc_jpg.rf.ebf5c65b740623772c9bd7490f81fc37.jpg  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nspgbsjTdSjZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "167808ae-2cc6-49b0-f749-96766aafa358"
      },
      "source": [
        "#let's take a look at our directory\n",
        "#notice the data came down in train, valid, test, splits - this is pre set during the dataset upload process\n",
        "%ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mMonk_Object_Detection\u001b[0m/  README.roboflow.txt  \u001b[01;34mtest\u001b[0m/   \u001b[01;34mvalid\u001b[0m/\n",
            "README.dataset.txt      \u001b[01;34msample_data\u001b[0m/         \u001b[01;34mtrain\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tZCaH-bdUnP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c7133f3-c74f-4915-83aa-99fd8d2e7d5d"
      },
      "source": [
        "#let's take a peak in train\n",
        "#jpg images and some coco json annotations\n",
        "%ls train"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0000147617-e4eb190337827f8bbbcc9317d-1_jpg.rf.1f9e5ec14aa27345b7997db3764c90e4.jpg\n",
            "0000147617-e4eb190337827f8bbbcc9317d-1_jpg.rf.2a7484bd2b0b636f518e38d3f65dbc66.jpg\n",
            "0000147617-e4eb190337827f8bbbcc9317d-1_jpg.rf.3d8042e54db73460b229cbac7b0d4eaf.jpg\n",
            "0000147617-e4eb190337827f8bbbcc9317d-1_jpg.rf.53512efb311e6ad82dfb3ba5956904a3.jpg\n",
            "0000147617-e4eb190337827f8bbbcc9317d-1_jpg.rf.5a1bf7c5fab4aee519ae7bab6c355862.jpg\n",
            "0000147617-e4eb190337827f8bbbcc9317d_jpg.rf.339066048621cbee362d66a73a60681f.jpg\n",
            "0000147617-e4eb190337827f8bbbcc9317d_jpg.rf.619f670367ea014370dbf790ed4d54cf.jpg\n",
            "0000147617-e4eb190337827f8bbbcc9317d_jpg.rf.6776d9b59d7f761781f100061dd3b75d.jpg\n",
            "0000147617-e4eb190337827f8bbbcc9317d_jpg.rf.8c43c881f65a44f2778e12bf834ecf60.jpg\n",
            "0000161190-eff4a7d6440628a6ed58e9d9a_jpg.rf.14bc640dcfdecb2e7a1e146f14a77b88.jpg\n",
            "0000161190-eff4a7d6440628a6ed58e9d9a_jpg.rf.1d8308d28f9977c018a8cb71e8a868da.jpg\n",
            "0000161190-eff4a7d6440628a6ed58e9d9a_jpg.rf.93caefb47f9c7574d516d45f32dd4399.jpg\n",
            "0000161190-eff4a7d6440628a6ed58e9d9a_jpg.rf.9a6f7ed81e1e9c219758fc236305b3d7.jpg\n",
            "0000161190-eff4a7d6440628a6ed58e9d9a_jpg.rf.c05196d001b91e9b9f2e21fd494596cf.jpg\n",
            "002998700_1416392386-SHDX_1_jpg.rf.e6efe38a44e69e4ef3f4038937a6537e.jpg\n",
            "002998700_1416392386-SHDX_1_jpg.rf.eabc1392a123f26b2ece2a49064596a1.jpg\n",
            "-008A4A1E-D0C3-4640-A49D-A4F2835BF13A-png_jpg.rf.f3a120d82ef366ce59a451e262ff45ff.jpg\n",
            "-00CD1618-10B8-4662-941C-41605A309144-png_jpg.rf.bf8e46bba27ffc8a9bc92a61fe2df9c3.jpg\n",
            "010222-002539-1-1-0-cam1_jpg.rf.275b1e47a1876d7e3655afd03fcf411d.jpg\n",
            "010222-004041-1-1-0-cam1_jpg.rf.c71858f3566808ed2689f41a5b9d0288.jpg\n",
            "010222-004146-1-1-0-cam1_jpg.rf.d50cceb3c84b36ad77647a94c3955277.jpg\n",
            "010222-004617-1-1-0-cam1_jpg.rf.124b764b73ae2c348537d9d54cb6802b.jpg\n",
            "010222-004734-1-1-0-cam1_jpg.rf.a19baff78edd2e92d6dbc688e01893b6.jpg\n",
            "010222-004823-1-1-0-cam1_jpg.rf.d7033dc7f3b9a62a348fae569cf898c0.jpg\n",
            "010222-005140-1-1-0-cam1_jpg.rf.9b2ce0699ceb63815eb3ba4ff51aeb41.jpg\n",
            "010222-005740-1-1-0-cam1_jpg.rf.4890a9c9a60407f3c5a0ea274eb7579b.jpg\n",
            "010222-010331-1-1-0-cam1_jpg.rf.ec6f4620f714ff75fa9575a1b00bc30c.jpg\n",
            "010222-010351-1-1-0-cam1_jpg.rf.9dd067df1e14f4cc66a9c4f194b0e2dd.jpg\n",
            "010222-010357-1-1-0-cam1_jpg.rf.32844eb14371704ab842d1ad0e1e0e67.jpg\n",
            "010222-010912-1-1-0-cam1_jpg.rf.ea95a2d38736f4d506d1aefa1fdd16f8.jpg\n",
            "010222-011020-1-1-0-cam1_jpg.rf.03c1ced4f62ae7ba4aeabaddd7c57920.jpg\n",
            "010222-011221-1-1-0-cam1_jpg.rf.450e1d63006d6f08625f80c2259f26fd.jpg\n",
            "010222-012154-1-1-0-cam1_jpg.rf.fcfc6f696e17b95d48e9ff4828e7b7b1.jpg\n",
            "010222-013147-1-1-0-cam1_jpg.rf.9955033cdb98724d73bf4d68b4b750b5.jpg\n",
            "010222-013155-1-1-0-cam1_jpg.rf.08ccd4870d798ff1e4f7321dd0c00d91.jpg\n",
            "010222-013247-1-1-0-cam1_jpg.rf.210efb778e60193b17beb32ba4ed4ee1.jpg\n",
            "010222-013315-1-1-0-cam1_jpg.rf.2e98beb608f935d3b1cb98757be74e79.jpg\n",
            "010222-013629-1-1-0-cam1_jpg.rf.0bc9bf3759fc680864a1326ae6864c4a.jpg\n",
            "010222-014202-1-1-0-cam1_jpg.rf.73c80da0d3fd531229bbc4894907768f.jpg\n",
            "010222-014603-1-1-0-cam1_jpg.rf.f5a81db37b02ed67cdabde7cf875a2cf.jpg\n",
            "010222-015017-1-1-0-cam1_jpg.rf.20eff431c865112961da31ce0724d799.jpg\n",
            "010222-015309-1-1-0-cam1_jpg.rf.76f08f564a7536935289f01839f13746.jpg\n",
            "010222-015346-1-1-0-cam1_jpg.rf.ad5b9f3fb6d786ddc6d0b69b5aa01fe3.jpg\n",
            "010222-015441-1-1-0-cam1_jpg.rf.b11db02a8b9d811d88bc2ff23c695741.jpg\n",
            "010222-015521-1-1-0-cam1_jpg.rf.f24b3fa57d73de514af1bd60b55c706f.jpg\n",
            "010222-015725-1-1-0-cam1_jpg.rf.1e3c966b53c7c2f20c03eaa50ea14813.jpg\n",
            "010222-015808-1-1-0-cam1_jpg.rf.71017da80ec4e2fabf0295ad850481b3.jpg\n",
            "010222-015834-1-1-0-cam1_jpg.rf.d0c631e50ba832e373227d65f846a27b.jpg\n",
            "010222-015835-1-1-0-cam1_jpg.rf.d90ed6c893171c16a80468bbab98f974.jpg\n",
            "010222-020028-1-1-0-cam1_jpg.rf.d838eebed12251259995dba104940c4c.jpg\n",
            "010222-020224-1-1-0-cam1_jpg.rf.027c4a801f89029671e5e56a8db76af8.jpg\n",
            "010222-020855-1-1-0-cam1_jpg.rf.1503e2d9b725523b13867ab434c2302e.jpg\n",
            "010222-020934-1-1-0-cam1_jpg.rf.525601cde48125141f533991784fc99a.jpg\n",
            "010222-021116-1-1-0-cam1_jpg.rf.e16d916c86c4adabcb1f1e1a769b9b3d.jpg\n",
            "010222-021533-1-1-0-cam1_jpg.rf.7e4cdd81e841c267f1c6af3cc4cce9f0.jpg\n",
            "010222-021555-1-1-0-cam1_jpg.rf.7abbeb183864c739824be6ceed1b46e1.jpg\n",
            "010222-021737-1-1-0-cam1_jpg.rf.d28bca11c2642783ce300c549f8a35cd.jpg\n",
            "010222-021901-1-1-0-cam1_jpg.rf.4bf89b45d5d39222e2898fe80d89b67e.jpg\n",
            "010222-022128-1-1-0-cam1_jpg.rf.685446fc77dcd2da32326afd4ae660d6.jpg\n",
            "010222-023150-1-1-0-cam1_jpg.rf.5713a3f5325683c8966bcdfe0c1453ec.jpg\n",
            "010222-023252-1-1-0-cam1_jpg.rf.3235175f043b1744c282f48aa7879fcc.jpg\n",
            "010222-023349-1-1-0-cam1_jpg.rf.d001cbd6281551f2b528a7f373df8225.jpg\n",
            "010222-023622-1-1-0-cam1_jpg.rf.1bb1ae1297c8e1ff2df09e11ab713ab2.jpg\n",
            "010222-023656-1-1-0-cam1_jpg.rf.74b427bb433ce9bf5fae2136464543bd.jpg\n",
            "010222-024002-1-1-0-cam1_jpg.rf.5ebe8bde8990375d2402707653813be4.jpg\n",
            "010222-024005-1-1-0-cam1_jpg.rf.e7121d69a1c9ce07cab7352b0d7f28b8.jpg\n",
            "010222-024326-1-1-0-cam1_jpg.rf.22e3bfc662690a7051b841deaedc8baf.jpg\n",
            "010222-024328-1-1-0-cam1_jpg.rf.cca354a81695244cbbd62fdaaa83d373.jpg\n",
            "010222-024913-1-1-0-cam1_jpg.rf.503fca1f3ea87fbba7958adfd6ff5f52.jpg\n",
            "010222-024914-1-1-0-cam1_jpg.rf.140fcad89daddb37ff84746bcb3c581f.jpg\n",
            "010222-025424-1-1-0-cam1_jpg.rf.47fa1384954f152518ebfde552752c90.jpg\n",
            "010222-025529-1-1-0-cam1_jpg.rf.93165de943d97eb7929097bebc7cc183.jpg\n",
            "010222-025656-1-1-0-cam1_jpg.rf.b4d7f9cf1b86bd342250bbc60ad30e44.jpg\n",
            "010222-025740-1-1-0-cam1_jpg.rf.a7af4994a358a8c79701642379648e8a.jpg\n",
            "010222-025741-1-1-0-cam1_jpg.rf.42f091a5c62bd136150d848855646c6a.jpg\n",
            "010222-030016-1-1-0-cam1_jpg.rf.90fe2a173a819fa89bf38802ef2e5a3c.jpg\n",
            "010222-030029-1-1-0-cam1_jpg.rf.8c32fec52f7e2b8cb3c3aea27d6b72aa.jpg\n",
            "010222-030132-1-1-0-cam1_jpg.rf.205f6eb74d1d642fe0b44273d698fb90.jpg\n",
            "010222-030249-1-1-0-cam1_jpg.rf.a9e29b203cb5276eecf6bc2bbea6d08a.jpg\n",
            "010222-030443-1-1-0-cam1_jpg.rf.2b7151f876970c732b485081b2cc52e2.jpg\n",
            "010222-030805-1-1-0-cam1_jpg.rf.fafd08b4426c744dbe8ddb170d7e99b0.jpg\n",
            "010222-031222-1-1-0-cam1_jpg.rf.3c81327b1abcc1d8e9fe5e84c551cdba.jpg\n",
            "010222-031604-1-1-0-cam1_jpg.rf.92acaddd51a441216a831fe17485e93f.jpg\n",
            "010222-032510-1-1-0-cam1_jpg.rf.0ded8ca98b795a77d403ae6d406b32ff.jpg\n",
            "010222-032940-1-1-0-cam1_jpg.rf.089c3fa436bd103d65c918b4ee8d4b71.jpg\n",
            "010222-033135-1-1-0-cam1_jpg.rf.91d7ce8ffd58888c0dab47cfd4559fbc.jpg\n",
            "010222-033303-1-1-0-cam1_jpg.rf.e83b87d175d7c12054f2b3cb20b2b72b.jpg\n",
            "010222-033557-1-1-0-cam1_jpg.rf.d89638d12ac1fcd5b86030ab0e6119fc.jpg\n",
            "010222-034522-1-1-0-cam1_jpg.rf.73eb827aa6cab0a475b1f28c0be11a30.jpg\n",
            "010222-035244-1-1-0-cam1_jpg.rf.063a4793f5af27332dce51d91f6170c9.jpg\n",
            "010222-035249-1-1-0-cam1_jpg.rf.33ae8037bd33375ecbab0454b911aade.jpg\n",
            "010222-040051-1-1-0-cam1_jpg.rf.2d2dc9035ad3d2640449a439ed490ba4.jpg\n",
            "010222-040125-1-1-0-cam1_jpg.rf.0d25b09eb11b2fe0d4d5fce7812faa45.jpg\n",
            "010222-040542-1-1-0-cam1_jpg.rf.af05d4656dadaa928d9ae18879881a30.jpg\n",
            "010222-040730-1-1-0-cam1_jpg.rf.6301250a0580c78f4b4f22a74b66dfbb.jpg\n",
            "010222-040853-1-1-0-cam1_jpg.rf.bf9dd888315a9113583ca8237fd7eff9.jpg\n",
            "010222-042026-1-1-0-cam1_jpg.rf.6c4e1477bd05f693ef9c3f2efeebbc9f.jpg\n",
            "010222-042027-1-1-0-cam1_jpg.rf.2c7eae45e5c91bb5f8c97067aaa54203.jpg\n",
            "010222-043404-1-1-0-cam1_jpg.rf.340eb777f300226540d74e710caab7c1.jpg\n",
            "010222-043449-1-1-0-cam1_jpg.rf.be776b1fbb54ff5aebb9c4ff4b2aaf4b.jpg\n",
            "010222-044350-1-1-0-cam1_jpg.rf.df778714230165edd89a632a1ed260b7.jpg\n",
            "010222-045145-1-1-0-cam1_jpg.rf.28ded7b285533f0f4d7a40fde9787dc6.jpg\n",
            "010222-045525-1-1-0-cam1_jpg.rf.434cd047423937d689ee5dc5f5d7e790.jpg\n",
            "010222-050628-1-1-0-cam1_jpg.rf.9fe1d820cb739aa1e4b1c841efdb4aca.jpg\n",
            "010222-052228-1-1-0-cam1_jpg.rf.3feda3172c5fae4c4caad3de9cca03bf.jpg\n",
            "010222-053844-1-1-0-cam1_jpg.rf.9f80ec398800f9eaf9c34b17d836337c.jpg\n",
            "010222-055337-1-1-0-cam1_jpg.rf.631962cc9645957701952f829c219fa3.jpg\n",
            "010222-061035-1-1-0-cam1_jpg.rf.143e4a0c74d941154e9ce8e6486de566.jpg\n",
            "010222-071158-1-1-0-cam1_jpg.rf.1d660a6bb893590d7aa5bc1da9e9c0f6.jpg\n",
            "010222-075809-1-1-0-cam1_jpg.rf.4d03d6f5e8ead43280e15909c7148691.jpg\n",
            "010222-082503-1-1-0-cam1_jpg.rf.e77a4da05997e4e3495c2a899b4c6d51.jpg\n",
            "010222-084559-1-1-0-cam1_jpg.rf.90f1a4bbb9cfc6e02d2720d2bc217b91.jpg\n",
            "010222-084713-1-1-0-cam1_jpg.rf.3364db6ff07ca8f64132a0f03109e205.jpg\n",
            "010222-091527-1-1-0-cam1_jpg.rf.7a981b47b87ceb7abbb15735ca1a8de1.jpg\n",
            "010222-103837-1-1-0-cam1_jpg.rf.cc7d0840bddef7b7a26caec18410a028.jpg\n",
            "010222-114651-1-1-0-cam1_jpg.rf.a231658130701caaf85fe2f0228eed21.jpg\n",
            "010222-115647-1-1-0-cam1_jpg.rf.6608a2a0d0dc6396891b1bc63a301438.jpg\n",
            "010222-120410-1-1-0-cam1_jpg.rf.e3b9ac5f9de102ae3337c775b938b9ed.jpg\n",
            "010222-124007-1-1-0-cam1_jpg.rf.793c3c8620419d274d0917c2aaad2883.jpg\n",
            "010222-131335-1-1-0-cam1_jpg.rf.707500db7f2c12a03b195b5608e4c573.jpg\n",
            "010222-132245-1-1-0-cam1_jpg.rf.7f5aca017b83a054181cd22711b7ba5a.jpg\n",
            "010222-133132-1-1-0-cam1_jpg.rf.230f390776bd2b3f992fa5a651f87d94.jpg\n",
            "010222-133534-1-1-0-cam1_jpg.rf.e79e33b94d98627ce1b4a8443be18446.jpg\n",
            "010222-133859-1-1-0-cam1_jpg.rf.405e48d18ea87250cc93eb1477074adf.jpg\n",
            "010222-134430-1-1-0-cam1_jpg.rf.385db608e0a3c0948900635f3b663ca6.jpg\n",
            "010222-135337-1-1-0-cam1_jpg.rf.bd167e2e668cfba27b718404a93d1e4f.jpg\n",
            "010222-140424-1-1-0-cam1_jpg.rf.b9e5244fa09a7d0f9d0deb1dcb81ff08.jpg\n",
            "010222-141526-1-1-0-cam1_jpg.rf.17d503b335d7b4354339cf51b9adeba2.jpg\n",
            "010222-143244-1-1-0-cam1_jpg.rf.6a93fa9fad6d172c80d92d1575bf9f88.jpg\n",
            "010222-144521-1-1-0-cam1_jpg.rf.4ef3318c00cec307f14dab7e8084cffd.jpg\n",
            "010222-145302-1-1-0-cam1_jpg.rf.08e3ccd71c12ee0d42d1332bdd98663c.jpg\n",
            "010222-145407-1-1-0-cam1_jpg.rf.04610be3d9293ed28023bd740984f481.jpg\n",
            "010222-145821-1-1-0-cam1_jpg.rf.5a85dd55f06e5590fc1060fbfe5f2173.jpg\n",
            "010222-153602-1-1-0-cam1_jpg.rf.18cba12a26ec8551acdd51469deea69c.jpg\n",
            "010222-162701-1-1-0-cam1_jpg.rf.5a70eead2169ba085668a84b42b06292.jpg\n",
            "010222-171935-1-1-0-cam1_jpg.rf.13bb008233a21da039a8e9f2ad5a4b7c.jpg\n",
            "010222-172611-1-1-0-cam1_jpg.rf.90b5650c68c2cb671633e66a757e4bb4.jpg\n",
            "010222-173017-1-1-0-cam1_jpg.rf.bd799c950d7344889afd049b042e9a63.jpg\n",
            "010222-173627-1-1-0-cam1_jpg.rf.e4681d4ce240d802354b28c6dedcf41b.jpg\n",
            "010222-173914-1-1-0-cam1_jpg.rf.0afc1ae0a897da35dd2a0b9a84cda736.jpg\n",
            "010222-174615-1-1-0-cam1_jpg.rf.4d7765e13072f3b9df2aebf0c8c1797b.jpg\n",
            "010222-174950-1-1-0-cam1_jpg.rf.2175f70978e1f483960acc10860c0b54.jpg\n",
            "010222-174951-1-1-0-cam1_jpg.rf.b142fe64e2b9bcb6bc31a4d7836094ac.jpg\n",
            "010222-181544-1-1-0-cam1_jpg.rf.b0ebad50aa4b95d6eb2ebca5725b6f2c.jpg\n",
            "010222-183601-1-1-0-cam1_jpg.rf.7927908525071b549744c6d3ea27429c.jpg\n",
            "010222-184341-1-1-0-cam1_jpg.rf.70d8a63594ddb0f652399e1ead5818e5.jpg\n",
            "010222-184528-1-1-0-cam1_jpg.rf.52509b1e61024e43cd29937be15a8d72.jpg\n",
            "010222-193442-1-1-0-cam1_jpg.rf.eec7124662d8a728fd731aacf1b63586.jpg\n",
            "010222-193449-1-1-0-cam1_jpg.rf.014ebbc12c2fd6567b6c18a84004b28d.jpg\n",
            "010222-193452-1-1-0-cam1_jpg.rf.5dc232a28e92ff1f7e5f83893a03cb0a.jpg\n",
            "010222-193453-1-1-0-cam1_jpg.rf.accf80d0fbd0308ea0a152ae897b6a36.jpg\n",
            "010222-210506-1-1-0-cam1_jpg.rf.ed3a3f6cee773c3061debc31b7217e26.jpg\n",
            "010222-231252-1-1-0-cam1_jpg.rf.bec48202e00385029e337d5e02406b95.jpg\n",
            "010222-233659-1-1-0-cam1_jpg.rf.59551094a41acecac11a893e2a0742e7.jpg\n",
            "010222-234724-1-1-0-cam1_jpg.rf.e645dcdaee700174c89d76de44913fbb.jpg\n",
            "-010CF27A-7EE3-4612-B311-61C641E550F5-png_jpg.rf.44e4ecbc8d73710f8147877ea8ac9de4.jpg\n",
            "013877-1-lg_jpg.rf.479e71f8add0e7200abd21f51bdbe24e.jpg\n",
            "013877-1-lg_jpg.rf.5d96b86b5421020f2eb9e901cd302161.jpg\n",
            "013877-1-lg_jpg.rf.9d24666e63a54c75e2045d7ae003a182.jpg\n",
            "-015C8F67-D57B-40D2-A8D4-6717E7D78918-png_jpg.rf.6fb9a4349bcbfe4b555ad4cdeeece115.jpg\n",
            "018_jpg.rf.bf99ea76baf5e44cb4da33b3d4fbf6e9.jpg\n",
            "-01F94235-2804-400F-91B7-D9862145A299-png_jpg.rf.8beaa7828953ee8cf4ec3b64fe42c978.jpg\n",
            "01-image_1509470240_59f8b0204ebdf_jpg.rf.f2b9ad8c7a24cfcbf69700012dd729bc.jpg\n",
            "020222-021035-1-1-0-cam1_jpg.rf.ac26f677db653d9e42a6e96179707584.jpg\n",
            "020222-021924-1-1-0-cam1_jpg.rf.15e8f69d4e5bd7e6038c3f664db13e97.jpg\n",
            "020222-022732-1-1-0-cam1_jpg.rf.498519f238bfef6f9455a9dd8e3d8be9.jpg\n",
            "020222-023249-1-1-0-cam1_jpg.rf.463689cde6414be8b30267821ff5bef5.jpg\n",
            "020222-023945-1-1-0-cam1_jpg.rf.7fc345fa58d7a9c5eab10166d9bc8dee.jpg\n",
            "020222-024342-1-1-0-cam1_jpg.rf.a7373a9b1be1a71201dd78a04cec7801.jpg\n",
            "020222-024359-1-1-0-cam1_jpg.rf.55740de65eb98456f3983ee40c9e0513.jpg\n",
            "020222-024440-1-1-0-cam1_jpg.rf.8ff284c1a8083c166d79d354a552cd4e.jpg\n",
            "020222-025036-1-1-0-cam1_jpg.rf.85446c8aac3b55e9afa8abd957b644dd.jpg\n",
            "020222-025419-1-1-0-cam1_jpg.rf.c2e686164464a22dde5935b75d5a40fb.jpg\n",
            "020222-025602-1-1-0-cam1_jpg.rf.b29d32c1150000448d0f1c97d4de714a.jpg\n",
            "020222-025948-1-1-0-cam1_jpg.rf.31fa1b441add8a296a0521d869c2499b.jpg\n",
            "020222-031508-1-1-0-cam1_jpg.rf.b50d18556e2ef9c77ed8813e7472d687.jpg\n",
            "020222-031556-1-1-0-cam1_jpg.rf.1667dce8bfe51acc1e70b956b73b40b5.jpg\n",
            "020222-031654-1-1-0-cam1_jpg.rf.772e1d45de4eecd6ff207d858f985f6e.jpg\n",
            "020222-031834-1-1-0-cam1_jpg.rf.e4d0fdff2f0cb823f3bd5ad0972785c8.jpg\n",
            "020222-031836-1-1-0-cam1_jpg.rf.ab6daf4c5fd01e6e3ab0fc6671f656cc.jpg\n",
            "020222-032853-1-1-0-cam1_jpg.rf.8bbe6132f5fe4828ba73244e22d5cf8c.jpg\n",
            "020222-033320-1-1-0-cam1_jpg.rf.f3733fb093bc512c88ede5a47a38425b.jpg\n",
            "020222-033622-1-1-0-cam1_jpg.rf.b31c3c98db1a600c1af8778274d217f4.jpg\n",
            "020222-034302-1-1-0-cam1_jpg.rf.116fa4535ae301079680dcbd24cf22d9.jpg\n",
            "020222-034735-1-1-0-cam1_jpg.rf.9b74e34e9d8920ea624f7304d904c569.jpg\n",
            "020222-034826-1-1-0-cam1_jpg.rf.3911b3d2075de0ea8ebe086400076694.jpg\n",
            "020222-034936-1-1-0-cam1_jpg.rf.f415860d9be3963de6d8c4352e68b6d1.jpg\n",
            "020222-035122-1-1-0-cam1_jpg.rf.995162a0ea5d1d18185bf08602570fc1.jpg\n",
            "020222-035214-1-1-0-cam1_jpg.rf.de1f77f9da1ebc0324dfcd64101c4f91.jpg\n",
            "020222-035235-1-1-0-cam1_jpg.rf.e8a551e1fffe3e33934b09534c91d2cf.jpg\n",
            "020222-040611-1-1-0-cam1_jpg.rf.efff6dfdedd9892b48415f031d7c14ab.jpg\n",
            "020222-041159-1-1-0-cam1_jpg.rf.81dfe7bbbe2748fd714c18fad3d0db6b.jpg\n",
            "020222-041614-1-1-0-cam1_jpg.rf.a4bf3bdb29bf263fc6114f123bf21158.jpg\n",
            "020222-041615-1-1-0-cam1_jpg.rf.64a1f62c3e87a5e05517a43e3ea837a8.jpg\n",
            "020222-042756-1-1-0-cam1_jpg.rf.27732f011114f7d90dd8a919d430711d.jpg\n",
            "020222-043029-1-1-0-cam1_jpg.rf.29e9de9d04584bb929532e655623d8e1.jpg\n",
            "020222-043143-1-1-0-cam1_jpg.rf.e7feb0c04cc21398e3006e7a0faf33ce.jpg\n",
            "020222-043144-1-1-0-cam1_jpg.rf.02029ad24af540e1daa75389c64ca708.jpg\n",
            "020222-043824-1-1-0-cam1_jpg.rf.c8df14a2f01a2b114f3646dd39b0841c.jpg\n",
            "020222-043825-1-1-0-cam1_jpg.rf.43e37b08f0bcf9bcc5213b5dcb67ed09.jpg\n",
            "020222-043826-1-1-0-cam1_jpg.rf.f230978a33ebc2bd7a8d0f35a4bcc93a.jpg\n",
            "020222-043828-1-1-0-cam1_jpg.rf.160e5bf8e568c33715436598e54b65f1.jpg\n",
            "020222-044255-1-1-0-cam1_jpg.rf.4a8fd6d711b12cc266a03655086a352a.jpg\n",
            "020222-050123-1-1-0-cam1_jpg.rf.b0844f4680c5a4f20f26ba240670dc68.jpg\n",
            "020222-050742-1-1-0-cam1_jpg.rf.88469c3aa06696e1cd32f8846d6eca62.jpg\n",
            "020222-053714-1-1-0-cam1_jpg.rf.4e1ce86cae09503d61baabdca99ed73c.jpg\n",
            "020222-063610-1-1-0-cam1_jpg.rf.3112cf12997bc1144b08ec562f30fe26.jpg\n",
            "020222-070451-1-1-0-cam1_jpg.rf.e00e2726063a52d3d2c0fc1cfab57b28.jpg\n",
            "020222-071133-1-1-0-cam1_jpg.rf.15cc78cde9f9d7666f5fe8279c7342ae.jpg\n",
            "020222-094534-1-1-0-cam1_jpg.rf.86d4e32a3d826ac77c6e5213d524c09c.jpg\n",
            "020222-123047-1-1-0-cam1_jpg.rf.ad9f1f46357ef0c6553fc61a46886171.jpg\n",
            "020222-130721-1-1-0-cam1_jpg.rf.cb36965f96fbda3ec8a82547f25c006a.jpg\n",
            "020222-132328-1-1-0-cam1_jpg.rf.2cc0cc9dc0ea85c8cf1765dc1407c7e9.jpg\n",
            "020222-145354-1-1-0-cam1_jpg.rf.84c200c2a4b69aca9daa52950e98d85f.jpg\n",
            "020222-145517-1-1-0-cam1_jpg.rf.77a0aaa82ad034e4a2a14313c8dd0655.jpg\n",
            "020222-181413-1-1-0-cam1_jpg.rf.9381fe08b02f95192b97812a5bdd89a6.jpg\n",
            "020222-184009-1-1-0-cam1_jpg.rf.b32e32e0d2915f624bfdbb23f0741021.jpg\n",
            "020222-190315-1-1-0-cam1_jpg.rf.f17ad5ecf75ea4899ff16f20cea504cd.jpg\n",
            "020222-190804-1-1-0-cam1_jpg.rf.90ae18ed754f96ae147544b5ce82fc9d.jpg\n",
            "020222-193916-1-1-0-cam1_jpg.rf.3806e0442ca8434c8466ec6543a0c866.jpg\n",
            "020222-211724-1-1-0-cam1_jpg.rf.a63fc41afb928fb070b354c41520b0af.jpg\n",
            "020222-211739-1-1-0-cam1_jpg.rf.cf645bc2670b9c1bce89fef524c7e8ac.jpg\n",
            "020222-220717-1-1-0-cam1_jpg.rf.b38c919f522b3037cb834a5ff7767f7a.jpg\n",
            "020222-223937-1-1-0-cam1_jpg.rf.b95af2b9fe3c7c1880ff3dbb9123d28f.jpg\n",
            "020222-224744-1-1-0-cam1_jpg.rf.fa6c7035ca6391a1e23cd7e637b2a80d.jpg\n",
            "020222-231610-1-1-0-cam1_jpg.rf.bb8308a631ba84a55f7d13381ee41e0d.jpg\n",
            "020222-233555-1-1-0-cam1_jpg.rf.6cc2dc4bdd500f88beb960fd2036f76d.jpg\n",
            "020222-234631-1-1-0-cam1_jpg.rf.c525e167d73c2e33f459e2ad52db30e3.jpg\n",
            "-02DECFAF-5069-46D2-A619-C27992E88BFD-png_jpg.rf.cd2ec9c4e1d19f90f61dbfe37d0df461.jpg\n",
            "-0378D390-5AE2-4D09-84BB-387E850F5E5A-png_jpg.rf.78aec99c036a22c752e345a1cd41e4ba.jpg\n",
            "0386_jpg.rf.1f541561550671d0ea4dba14f89cf43a.jpg\n",
            "0387_jpg.rf.013670d743f51c73851b721e3d5d17f6.jpg\n",
            "0388_jpg.rf.dda23b6c744a811fa30f71f547c38c3e.jpg\n",
            "0389_jpg.rf.8b7d26396de4678e3d5973e09faaf01c.jpg\n",
            "0390_jpg.rf.23ef3ab5ec676c8819d8ff146656a772.jpg\n",
            "0391_jpg.rf.478856cce0d6bb7e0325bf7cdc605888.jpg\n",
            "0392_jpg.rf.3e07c847f72b9b92c3e39e6e9c75e829.jpg\n",
            "0393_jpg.rf.1c2c367383d811427f601a332bd2965b.jpg\n",
            "0395_jpg.rf.4c412ab84dadda99ce0f1197451c49dd.jpg\n",
            "0396_jpg.rf.376d12409b9f54a64e007897e5b7adcd.jpg\n",
            "0398_jpg.rf.4aec16b35447a6cd867fee9a42acf6dc.jpg\n",
            "0399_jpg.rf.c3e36de262df824f23662923b97114ad.jpg\n",
            "0400_jpg.rf.af7b99f77e81d71a3f68391ca6a29712.jpg\n",
            "0401_jpg.rf.f0c87b35472845bdd518313275c0e58e.jpg\n",
            "0402_jpg.rf.c69c7f2b1dc03cd5d77e03213a8aac3e.jpg\n",
            "0403_jpg.rf.029907cb93785ae0a343aec6c888c1fa.jpg\n",
            "0405_jpg.rf.ca06346c0079eb6ddd610a1a581ffd7d.jpg\n",
            "0406_jpg.rf.a6dab6519f8464264b60d8dabb96016f.jpg\n",
            "0408_jpg.rf.4a75174a451666a7f92ed98316c7c9f0.jpg\n",
            "0410_jpg.rf.93312418e045c05bcf70dab078d5221f.jpg\n",
            "0412_jpg.rf.0ab1182acd9e25d1b47a30751a6af7b6.jpg\n",
            "0414_jpg.rf.4c86d06de9e36d008274bfd061647d8a.jpg\n",
            "0416_jpg.rf.c8a31f5115882626e42ef26f6761ad4d.jpg\n",
            "0419_jpg.rf.ae2f0398917374b1612bbb66fb56f136.jpg\n",
            "0420_jpg.rf.af54fcd9c9bef503c3b743d184c964a3.jpg\n",
            "0421_jpg.rf.7bd3f21511e3eb217570d2aa10a615a8.jpg\n",
            "0422_jpg.rf.26f9014da35fb9c57693fe84042401db.jpg\n",
            "0423_jpg.rf.393df3fe9400f166243da8b86fadc855.jpg\n",
            "0425_jpg.rf.e5c3c2d788eceaba9747773797845439.jpg\n",
            "0427_jpg.rf.0ffcd671f7d27625d467f17ce963b394.jpg\n",
            "0429_jpg.rf.f3d983b0bc94011b0782cf3a9a53d8c8.jpg\n",
            "0430_jpg.rf.4089e77d93e8aea8b233491fd791a7b6.jpg\n",
            "0431_jpg.rf.916129830ba000317c36549bbec37fe9.jpg\n",
            "0433_jpg.rf.8efeb50771182ebd7b5324efea387724.jpg\n",
            "0434_jpg.rf.61c51467fa693252936720ff27e2d516.jpg\n",
            "0436_jpg.rf.3566e5e6db9e4c4657cced40c65757cb.jpg\n",
            "0438_jpg.rf.f856ca46b039a3ff05c4370f7b679bb4.jpg\n",
            "0439_jpg.rf.b24325c1c6627707540f691bb929938c.jpg\n",
            "0440_jpg.rf.16a6a952e10f7485ef532c9d95303da3.jpg\n",
            "0441_jpg.rf.ae605a38de96104c74aba6e7baac0273.jpg\n",
            "0442_jpg.rf.30a02d67a0df3a272d87c6abf8031c63.jpg\n",
            "0443_jpg.rf.cfeb8fdf6de8fc006c79d79fb7dff5e1.jpg\n",
            "0445_jpg.rf.af53c74a690072a6e4df645e8eee8155.jpg\n",
            "0446_jpg.rf.33e689a46d927836fa9819ca7ec3918e.jpg\n",
            "0447_jpg.rf.17378ff1ba5700a17bbe7322660c54c5.jpg\n",
            "0448_jpg.rf.d727c06b1a31a589ce58a45bbd33e150.jpg\n",
            "0449_jpg.rf.09624ab211ade6258960cef836636ecc.jpg\n",
            "0450_jpg.rf.30ab677014bb25ab5d3759b4e1129f37.jpg\n",
            "0451_jpg.rf.377d99c11e41ff23a4476d4e22b38d88.jpg\n",
            "0453_jpg.rf.860cd6332af0cd3db3b8d52773c84eeb.jpg\n",
            "0454_jpg.rf.1256adb07447ba03515083b6c865daa9.jpg\n",
            "0455_jpg.rf.852e531ecfaa51b52bae301a6e9d310d.jpg\n",
            "0456_jpg.rf.d3b662b7c29d44a3a10f086b5518daed.jpg\n",
            "0457_jpg.rf.2a20dad749c6fcedd8e41656161796a3.jpg\n",
            "0458_jpg.rf.e4fb020a659ee6f3863b6c4512373c3e.jpg\n",
            "0459_jpg.rf.02a49f245f751ebe6e32137a837fa773.jpg\n",
            "0460_jpg.rf.37ae02d783e546a13be692352a7b4821.jpg\n",
            "0462_jpg.rf.c3ab3d81d732a5b01b6c483734031daa.jpg\n",
            "0463_jpg.rf.f6fce942fdc5e6c4cba058f207865ba5.jpg\n",
            "0464_jpg.rf.00948ebdeb313ea6e78bbd9d32c50d59.jpg\n",
            "0465_jpg.rf.2370d52d64fd1e6e24977be58e74d4df.jpg\n",
            "0466_jpg.rf.2eb0afe87992cde146d584f931240428.jpg\n",
            "0468_jpg.rf.e18b77eae3028d6fd0d689375f3a812a.jpg\n",
            "0469_jpg.rf.89abdac344574e392fa9ff1968f7bcfc.jpg\n",
            "-046E9840-F025-4749-B3AB-19402B34E739-png_jpg.rf.b8ce1b032e7a0666bba4c90906b28c40.jpg\n",
            "0472_jpg.rf.1663e730dedf8321c59a22a193d7a519.jpg\n",
            "0474_jpg.rf.d3358e317b9aa74db4f0814c12151236.jpg\n",
            "0475_jpg.rf.cf84922aef78a317778456563ba69372.jpg\n",
            "0476_jpg.rf.6cf40f34220ecfcbb455590769201162.jpg\n",
            "0477_jpg.rf.d07cac553cd64542bb406363b036f3a7.jpg\n",
            "0478_jpg.rf.c39538c7a5088531b465da6ea414b6a0.jpg\n",
            "0479_jpg.rf.f7d2135ade629b4a42ea76e4c8908fe6.jpg\n",
            "0480_jpg.rf.647c6a63ea6e5da37c45f3f587c988fc.jpg\n",
            "0481_jpg.rf.831b83d79e0ce8b0407b48850bce7c1c.jpg\n",
            "0482_jpg.rf.5a2fc86c4198ceb9c30b511e1cf14590.jpg\n",
            "0483_jpg.rf.5a7445e1c4b6ab9cf338aff02d4a8f58.jpg\n",
            "0485_jpg.rf.7481729aa91b7b6cfae22cd3a2325813.jpg\n",
            "0486_jpg.rf.afbb0de2107edf7cee94ce24e6cc1afc.jpg\n",
            "0487_jpg.rf.d97f4c807f645d0fa19423d112a93acf.jpg\n",
            "0490_jpg.rf.3bf32ea9beebde8f0c78e1386e26c3f6.jpg\n",
            "0491_jpg.rf.912d4347c1e055db20d6a31efcd38ebb.jpg\n",
            "0492_jpg.rf.aae1ae91219debf79778aff570cf75ab.jpg\n",
            "0493_jpg.rf.a63ff98beed88f2f9f513264e53853ae.jpg\n",
            "0496_jpg.rf.34fbe615815ce7a26474812ace78b7f2.jpg\n",
            "0498_jpg.rf.7d93452a3f1f4c81463ca0da8a18b37d.jpg\n",
            "0499_jpg.rf.d36c00cbc4ed7eac55e13369d6df47f1.jpg\n",
            "-04F496E7-ACB5-4B10-AC65-F836C0DD5B53-png_jpg.rf.828615ae2389c73aa170a7e48d2ed208.jpg\n",
            "0500_jpg.rf.79a3829a5291522481b25192a99b65da.jpg\n",
            "0502_jpg.rf.a884d7a79dc37d9e64612c409bcfa48d.jpg\n",
            "0503_jpg.rf.1c7da5f1e6ce7e0194e8a0e5385cf937.jpg\n",
            "0504_jpg.rf.6a6307e55700a4ddb4c2b0a07d41c6e6.jpg\n",
            "0506_jpg.rf.6e1c00031c4372dbcb2cd886b512cd19.jpg\n",
            "0508_jpg.rf.dfe9531a34167bf76d0a3292616ba61b.jpg\n",
            "0509_jpg.rf.cf2a231eb1f16553764b369f58db840f.jpg\n",
            "0511_jpg.rf.c3ad7752f0e454888ab5b690cb92f51c.jpg\n",
            "0513_jpg.rf.e8305f5476e6694292eb577d13e45a5b.jpg\n",
            "0515_jpg.rf.a348a4d6243802b471d03df9a3c72394.jpg\n",
            "0516_jpg.rf.6d52d85f8d255613b7e8d2cd85206114.jpg\n",
            "0517_jpg.rf.aaf362280b93570611ea80a833ccb147.jpg\n",
            "0520_jpg.rf.20b9ed55d87997b30540afe65d719f70.jpg\n",
            "0521_jpg.rf.2f26bb53327e9e31bf978e661f4c5ada.jpg\n",
            "0523_jpg.rf.10b72d16c4c1ec1dd1e4f2b69284f6de.jpg\n",
            "0524_jpg.rf.00ab2f18510df1579f9bf38e0e8c7825.jpg\n",
            "0525_jpg.rf.11b52edfcf0729f1a3822f984dab6c18.jpg\n",
            "0527_jpg.rf.2fa3c88e7d59b4e080d1a85103cc6209.jpg\n",
            "0528_jpg.rf.94043303e489bf9d7b0cafc17bdfb6b3.jpg\n",
            "0529_jpg.rf.549583f6e1da19ba12c503d3d08723ae.jpg\n",
            "0530_jpg.rf.b80dd6403dd6a2913b727738d9cc480a.jpg\n",
            "0531_jpg.rf.98a8117d5f872d43a6e4090b527a7ba1.jpg\n",
            "0532_jpg.rf.70e1f3a543d204bd4ade3c6d22bd1684.jpg\n",
            "0533_jpg.rf.fa64060de4582a4237afd89055cdc753.jpg\n",
            "0534_jpg.rf.56cef66b7ebd8ef12192c2c7190b24ee.jpg\n",
            "0536_jpg.rf.89455251f1719e50d378796a6188f795.jpg\n",
            "0539_jpg.rf.c4f030266bfc3f6c0f48fdca24e8b42f.jpg\n",
            "0540_jpg.rf.aba46007841b282c49b4037396bec9b9.jpg\n",
            "0543_jpg.rf.0010b1cfd13c8fd01c34a1a024907e89.jpg\n",
            "0544_jpg.rf.ed3eab654f47e5843bcb50d1c85c8ade.jpg\n",
            "0545_jpg.rf.bb3e915cee7b0a219296ff56db64be18.jpg\n",
            "0546_jpg.rf.73a20f3e277e63ea6a5f7d144a97ac8b.jpg\n",
            "0547_jpg.rf.0c33d024bc40517e614791994208bc15.jpg\n",
            "0548_jpg.rf.7b4069633c56603405b0c8eba1e03d88.jpg\n",
            "0550_jpg.rf.95ff218c3bd9063edee48277a6b02b2c.jpg\n",
            "0551_jpg.rf.7812e5ffecf548de583f5fa451525964.jpg\n",
            "0552534da9e2aeb5af5d4061777bbe44-1_jpg.rf.7b1b476b8a1db5f17d212cadc7d23370.jpg\n",
            "0552534da9e2aeb5af5d4061777bbe44-1_jpg.rf.b75482a94d2a71dbcc9c3af113acd6d3.jpg\n",
            "0552534da9e2aeb5af5d4061777bbe44-1_jpg.rf.e2f76ac09333b4efc3d801bf34e78884.jpg\n",
            "0552534da9e2aeb5af5d4061777bbe44_jpg.rf.2e56b3c42e74fb8ac68648dfb314f594.jpg\n",
            "0552534da9e2aeb5af5d4061777bbe44_jpg.rf.53a91b3074ba7927700ed4ec9db0fd69.jpg\n",
            "0552534da9e2aeb5af5d4061777bbe44_jpg.rf.d02fcbb3664e1e7c94fd137f450e1a93.jpg\n",
            "0552_jpg.rf.eddf964caafb45d4dcad26c6c3f59f4b.jpg\n",
            "0553_jpg.rf.23014894f30b58f2bcf6e0ae505b4f2d.jpg\n",
            "0554_jpg.rf.f665b5c4419fd131aad1f92cc8439d82.jpg\n",
            "0557_jpg.rf.a5ba9b941905942ba2dcb742332376f8.jpg\n",
            "0558_jpg.rf.9166de1739d93303c0b9dfd76486341d.jpg\n",
            "0562_jpg.rf.432f2b79dd98bf4a74b6c1e1af930515.jpg\n",
            "0563_jpg.rf.41765d7c8aa988753e9c9912ee6f4350.jpg\n",
            "0564_jpg.rf.73fcb7159887bc8dbb36f1c0c5968154.jpg\n",
            "0565_jpg.rf.cff77244215dad8f2390430c12c68755.jpg\n",
            "0566_jpg.rf.c0fbb5f444d19b5f636a4496d2d3e800.jpg\n",
            "0567_jpg.rf.cadc533aef6ac06150241c03f394a59b.jpg\n",
            "0569_jpg.rf.7a526d243a4b1f9616fd0adac97ad792.jpg\n",
            "0570_jpg.rf.5e94915eae0ccbdf8aec247c7eef3701.jpg\n",
            "0572_jpg.rf.ac3a599f0fbcc64bbfa0448cc96b3840.jpg\n",
            "-0573F94C-289D-4503-A571-94C6C8C5674C-png_jpg.rf.719d3afb3b1ecb6e992719cbf5f32b5d.jpg\n",
            "0573_jpg.rf.c80c81721edd360724815b3be73513c0.jpg\n",
            "0574_jpg.rf.8c8b4636e9e0a89d0d5c0a099d829d9c.jpg\n",
            "0575_jpg.rf.e943f043e617ca995f6be438e014a2c1.jpg\n",
            "0576_jpg.rf.ddb57427ef67fe07038f1ce443154b7f.jpg\n",
            "0577_jpg.rf.f05fc7c37517679cbfbfb33a0d35d994.jpg\n",
            "0578_jpg.rf.d2c91ba3c7873fadaa85faca6979ae23.jpg\n",
            "0580_jpg.rf.76a10f831bdb3e28ab7672c865c056ff.jpg\n",
            "0582_jpg.rf.7925bc33ba11ebc6df99ba0b60dd2ba3.jpg\n",
            "0583_jpg.rf.fe31637127bb483f8064b7c66c03899e.jpg\n",
            "0584_jpg.rf.bb79dfb34710af05e1ab7685fde4489b.jpg\n",
            "0585_jpg.rf.66c5edfa20fe58a8311c1a909391be87.jpg\n",
            "0586_jpg.rf.dcf53c7473820267833b187f23c6a9e4.jpg\n",
            "0587_jpg.rf.3956a6e6ad0bb137085f4296f93387c2.jpg\n",
            "0588_jpg.rf.d78ec1c47778be6230638e91015172ec.jpg\n",
            "0592_jpg.rf.4bcbba9456564c5fa7894312db359571.jpg\n",
            "0593_jpg.rf.49c99e004c4b3238b6a20ff0626805a0.jpg\n",
            "0594_jpg.rf.dc7cf63b890bb324b45e0639eec8c065.jpg\n",
            "0595_jpg.rf.9fe0c26ca43e081f6b27f005804862ad.jpg\n",
            "0597_jpg.rf.eb099b4e45fa0242f79be4976aa95332.jpg\n",
            "0600_jpg.rf.b765015775677f31316d589fafd508fd.jpg\n",
            "0604_jpg.rf.b52132c5db6f5c2de218893099197e01.jpg\n",
            "0605_jpg.rf.39c4a25819da097dd6b2bc9ebf0249f0.jpg\n",
            "0606_jpg.rf.5c25686c59837e4e7b59684c7e0b9cd9.jpg\n",
            "0608_jpg.rf.c28e02e2d3e405e7d84697a8c2e5e5a1.jpg\n",
            "0611_jpg.rf.124185e26577569f1ca467925bb3bef4.jpg\n",
            "0613_jpg.rf.c4eb635279f3f6f5d8a05445f6c2e4dc.jpg\n",
            "0614_jpg.rf.18a3fa82007f0c0f8d889ff70f85a0bd.jpg\n",
            "0615_jpg.rf.0db1aacfa4695d8f57c7d4671d60f246.jpg\n",
            "0617_jpg.rf.f0c8bd4462a325f720ad406102e7050f.jpg\n",
            "0619_jpg.rf.533e1bbadf790b313e62ec061d486716.jpg\n",
            "0621_jpg.rf.0b0e0df96a03d848d9030d50599cb6fb.jpg\n",
            "0622_jpg.rf.a714392a8ae8fafd3b0c044fe447c98b.jpg\n",
            "0623_jpg.rf.7a7b89034bbdd53846583de67d3aa641.jpg\n",
            "0624_jpg.rf.823701e2556c322a01b2e811a787c041.jpg\n",
            "0625_jpg.rf.0e47937280b3d5ce05a04ead72bae1ad.jpg\n",
            "0626_jpg.rf.e11300b4ff9953b7fbddccf359e8378c.jpg\n",
            "0627_jpg.rf.d4313f3fe763507074c3c58d83416bf9.jpg\n",
            "0628_jpg.rf.20fb4d9808302836e3c364f8522e2148.jpg\n",
            "0629_jpg.rf.a654dc98dcf0e796a7ffbddd225b4659.jpg\n",
            "0631_jpg.rf.33fc8a88e2d3e7ab4f2752a8c152f131.jpg\n",
            "0632_jpg.rf.8c147fd4c298c535280651b8ba6dcd12.jpg\n",
            "0633_jpg.rf.78b9fbb14877fb1f40358f6c9baa0e8c.jpg\n",
            "0635_jpg.rf.54039bd74735c5512e9e2e8e21c1428a.jpg\n",
            "0636_jpg.rf.904871ada818e01be12ae7116e79081b.jpg\n",
            "0637_jpg.rf.7dfbd5a5ef3b8aaa040e421e9a781b78.jpg\n",
            "0639_jpg.rf.855eb540b7a0f2de97fb649a1ec84abe.jpg\n",
            "0640_jpg.rf.5e02fceb575847bd5b93ae4b3ae09898.jpg\n",
            "0642_jpg.rf.3fb9906048df73d40302963b0c54e850.jpg\n",
            "0643_jpg.rf.87d416d333f314db8e6edfb3a88cea44.jpg\n",
            "0644_jpg.rf.61390e2f6af39b92b366f13aa2eca70a.jpg\n",
            "0646_jpg.rf.9ecbad402120327c206829b12d69f48f.jpg\n",
            "0647_jpg.rf.feb6bdab3a53a052a7683c3a65642b72.jpg\n",
            "0648_jpg.rf.0f0e07940e8d6921eb0c7f473dca3f69.jpg\n",
            "0649_jpg.rf.0dbf180aa9189297eecdba497fdb6d3e.jpg\n",
            "0651_jpg.rf.aa24f3370aae78c9d69eeffa98ebad87.jpg\n",
            "0653_jpg.rf.baaf9add04f1b5c3c706f15d37f08f03.jpg\n",
            "0654_jpg.rf.3894522ab6086d9d26f5e429fd542538.jpg\n",
            "0656_jpg.rf.e29afd6f4158eada7f641090d5770d19.jpg\n",
            "0657_jpg.rf.514b146380a7e7181ae61c3473c9d8a4.jpg\n",
            "0658_jpg.rf.2e2287fa19e33068878a0b315bbea74e.jpg\n",
            "0659_jpg.rf.e03e87a66bf318710230522594e895c9.jpg\n",
            "0660_jpg.rf.252b9561c91e2312cbe838d88b0001a9.jpg\n",
            "0661_jpg.rf.3f83d4c603e8c5bf56f04084ea97cb40.jpg\n",
            "0662_jpg.rf.2186e7dca471b02565e4aa5d8fb5f32c.jpg\n",
            "0663_jpg.rf.ca7cf6a48cfdb18970d9a95d1da98558.jpg\n",
            "0664_jpg.rf.002edb4ba25279d6211792153663ac52.jpg\n",
            "0665_jpg.rf.7cc3ec090bac68bfb7cf4af43357d54a.jpg\n",
            "0666_jpg.rf.94ff05d93590406a7f1f219a034bce5f.jpg\n",
            "0667_jpg.rf.9caec3c1af34e1dea01c0e1f1ed68d3e.jpg\n",
            "0668_jpg.rf.209f3ac47795825997ec71ccd4c98637.jpg\n",
            "0670_jpg.rf.c482fb591999e36391bdd3923c92870e.jpg\n",
            "0671_jpg.rf.62571da1ba83f093361f1869654b7125.jpg\n",
            "0672_jpg.rf.f3cfd2cd3e3c079d0501559fd5ca37a9.jpg\n",
            "0674_jpg.rf.08e7092481507f0bc0b6da9955bc36df.jpg\n",
            "0675_jpg.rf.0c86e92d4ce655a36f8834d6d3b942f7.jpg\n",
            "0676_jpg.rf.f16589e9a6248244d65740296dcb963e.jpg\n",
            "0678_jpg.rf.35fb3f64a9a04cf61fda0dee12dda1cb.jpg\n",
            "0679_jpg.rf.1f64ddc491dd9038731abfa18acfa41e.jpg\n",
            "0681_jpg.rf.4a7723355a5a50228181b7e892c4c34e.jpg\n",
            "0684_jpg.rf.bd4d020ba5df61abb7aca2ef53f5dba8.jpg\n",
            "0686_jpg.rf.81da5c5f45a519b47524f22173678f95.jpg\n",
            "0687_jpg.rf.ea9c09a6461097b96b810b5e3f5e8201.jpg\n",
            "0691_jpg.rf.c6976bd6df9050485d8c8fad71382105.jpg\n",
            "0692_jpg.rf.c6ce418dea3441a530afd91025aa835c.jpg\n",
            "0694_jpg.rf.b11d664e4f068c37c446868582d639e8.jpg\n",
            "0697_jpg.rf.fceb9e1ab934a8b5a01156c92a75e57c.jpg\n",
            "0698_jpg.rf.ac84dbb187d98fffb735de8ef9159205.jpg\n",
            "0700_jpg.rf.da5b2a37f8967e61871b1cd11682a6c3.jpg\n",
            "070122-114121-1-1-0-337158203125-cam1_jpg.rf.124563521c290d8b6638fac6b95e5f7d.jpg\n",
            "070122-114725-1-1-0-34423828125-cam1_jpg.rf.777949059c7253b874fc9140947db72b.jpg\n",
            "070122-114820-1-1-0-236328125-cam1_jpg.rf.e6837a265ab0e04944e401f7bad61f90.jpg\n",
            "070122-115726-1-1-0-36962890625-cam1_jpg.rf.3113f1c4607ee6a007e36dd872134f41.jpg\n",
            "070122-120237-1-1-0-2088623046875-cam1_jpg.rf.082cb08c966a52faee6873bb29c16bff.jpg\n",
            "070122-120755-1-1-0-1822509765625-cam1_jpg.rf.914a61c322b13b149ac6827267dc8e15.jpg\n",
            "070122-120831-1-1-0-28759765625-cam1_jpg.rf.407fe4659f053876e22fd2da01800866.jpg\n",
            "070122-121601-1-1-0-28125-cam1_jpg.rf.6b549800bf61e16c15353367285eeb73.jpg\n",
            "070122-123753-1-1-0-2578125-cam1_jpg.rf.09794b5a507092b434cc4145bd06cce2.jpg\n",
            "070122-123920-1-1-0-32177734375-cam1_jpg.rf.ce6cc001bc70c673ec45798475534d18.jpg\n",
            "070122-124615-1-1-0-364013671875-cam1_jpg.rf.94014006441a99f6886b7fbfc8dfb437.jpg\n",
            "070122-131526-1-1-0-1993408203125-cam1_jpg.rf.568fc743c2ac3e8332bdb80768b819ed.jpg\n",
            "070122-133303-1-1-0-28515625-cam1_jpg.rf.da8d28b93581d564e2dd405850d4fb0f.jpg\n",
            "070122-133828-1-1-0-34375-cam1_jpg.rf.3a3db86a5f7e53a24eb6fcbb0fbd391f.jpg\n",
            "070122-134439-1-1-0-301025390625-cam1_jpg.rf.bec78ec08b6a5a723a553a61839e41fb.jpg\n",
            "070122-135053-1-1-0-33984375-cam1_jpg.rf.f012018f2351868a5ccb1ccf81523a12.jpg\n",
            "070122-135111-1-1-0-295166015625-cam1_jpg.rf.483544a6178690c445f4da11d2aa12ca.jpg\n",
            "070122-135539-1-1-0-346923828125-cam1_jpg.rf.5282c1d78f6567421637cf9697c4f542.jpg\n",
            "070122-135605-1-1-0-468017578125-cam1_jpg.rf.bd2885611385ffb8ae426c25f580eed8.jpg\n",
            "070122-135733-1-1-0-4248046875-cam1_jpg.rf.c02626d198d139a30a641734d4afd14d.jpg\n",
            "070122-135940-1-1-0-410400390625-cam1_jpg.rf.da05b9c07b94b0597d9251f4c2c4ea8c.jpg\n",
            "070122-141826-1-1-0-340576171875-cam1_jpg.rf.f85af2b955b45a0a0c3bc0a5f9dd200a.jpg\n",
            "070122-145137-1-1-0-177734375-cam1_jpg.rf.074b0cac6145d091fbd74a7a1c160a98.jpg\n",
            "070122-145950-1-1-0-49267578125-cam1_jpg.rf.b2023b0157c131785ff983ed158a509d.jpg\n",
            "070122-150227-1-1-0-28466796875-cam1_jpg.rf.d82d359c36f9250f4d2f4ccccb7350fe.jpg\n",
            "070122-151533-1-1-0-22607421875-cam1_jpg.rf.aca46882c6eb0bd22866e5ab01da208c.jpg\n",
            "070122-151707-1-1-0-35302734375-cam1_jpg.rf.12b40888720d03e5be7539f5bee3b2ee.jpg\n",
            "070122-152326-1-1-0-302490234375-cam1_jpg.rf.21710fd7bae3620407404c6b6645a393.jpg\n",
            "070122-152356-1-1-0-2191162109375-cam1_jpg.rf.e5542049d98c884e9e56aa7dc7a2b686.jpg\n",
            "070122-152439-1-1-0-31884765625-cam1_jpg.rf.b1153ae62aa0d21b8693ce7390026918.jpg\n",
            "070222-210530-1-1-0-cam1_jpg.rf.988032406c0f0c4e31a0e1ba89867107.jpg\n",
            "070222-221510-1-1-0-cam1_jpg.rf.03d5982edf8ef423e9f46acce6afcabe.jpg\n",
            "070222-221621-1-1-0-cam1_jpg.rf.ba419034375eeae624619bdb3384c4e1.jpg\n",
            "070222-221720-1-1-0-cam1_jpg.rf.9d032ea848aa33f057faed270020066a.jpg\n",
            "070222-224248-1-1-0-cam1_jpg.rf.23d73a58ed06483a689785a560ab28ff.jpg\n",
            "070222-224344-1-1-0-cam1_jpg.rf.81c75ab7e7123fcfac5e0d0eebd1ecad.jpg\n",
            "0704_jpg.rf.263ade730dc0e89274189f0e34a97ad9.jpg\n",
            "0705_jpg.rf.2e049224ff46e50b52042c4a853ed419.jpg\n",
            "0706_jpg.rf.098f2322ff24901ea03d8898dee363c8.jpg\n",
            "0707_jpg.rf.35844dfecb6ec3003b795cc4b4109e5d.jpg\n",
            "0708_jpg.rf.98db892e06b02973a60de5c820025b7c.jpg\n",
            "0709_jpg.rf.c1f4ef76e564f9876fc7fee0360ea70c.jpg\n",
            "0710_jpg.rf.942f8d86d42b3c7bc11e431e6dcd5630.jpg\n",
            "0711_jpg.rf.cbf2109963578732067b183083636dd6.jpg\n",
            "0713_jpg.rf.449d9e00e781e024f3dc3c93f68e8628.jpg\n",
            "0716_jpg.rf.2e8b1b970b286f27178d73b2ee8e70d1.jpg\n",
            "0718_jpg.rf.cc8eca44209c8b1e0059a3dbaab04436.jpg\n",
            "0719_jpg.rf.65c5d23f8b7a0f489fa67ec9e630c5d5.jpg\n",
            "0720_jpg.rf.fec5fd0f5f3c384be54612ea8f7b99ef.jpg\n",
            "0721_jpg.rf.d7b2237cbe5375f2bac398fd884303c5.jpg\n",
            "0722_jpg.rf.c4ce28d8ccf4201d17894668df1c70f7.jpg\n",
            "0725_jpg.rf.10fff8cec356eace86e0746f3fa37dc1.jpg\n",
            "0729_jpg.rf.54aa86017e62b83cfd6b9b69bea6b335.jpg\n",
            "0730_jpg.rf.aa32d3b88a05afc20f4af03eaf67ebdc.jpg\n",
            "0731_jpg.rf.c8cbf1d0d5c185af55c869b6fe54718b.jpg\n",
            "0732_jpg.rf.c573cd35f7efcd5c17a844b31738750d.jpg\n",
            "0734_jpg.rf.302627d75bb606bdaf1983dcf34fa04d.jpg\n",
            "0735_jpg.rf.e1fd09e98a338c1f18a600db7ecd79b2.jpg\n",
            "0736_jpg.rf.6a92ebff549d7db54c50ee814b818d8d.jpg\n",
            "0737_jpg.rf.30846fe29cbcac9f104e7717ac2d882e.jpg\n",
            "0738_jpg.rf.ce535b7e6fc52b10eb8467c3efcad5d7.jpg\n",
            "0740_jpg.rf.e71c934333e616a9d356c541b09fef75.jpg\n",
            "0741_jpg.rf.6b6fa5d439629bbfef356c631440d132.jpg\n",
            "0742_jpg.rf.e9dfc95a18aea89aeb0edd4c43e9e125.jpg\n",
            "0743_jpg.rf.a13de188a0793a6447821e893ee7a572.jpg\n",
            "0745_jpg.rf.88b882c26d399cdcb9b1871a63f5de23.jpg\n",
            "0746_jpg.rf.e4e7d9e624aab1627f1300459fe8516f.jpg\n",
            "0748_jpg.rf.102e1abdfa10592d081f1f18eb0444ec.jpg\n",
            "0749_jpg.rf.71786222715ab9e352dfcf17e8073ec5.jpg\n",
            "0751_jpg.rf.5c3fad34978abfd4dc1733b062ae163c.jpg\n",
            "0752_jpg.rf.4ed6b65c908eb39d8a954070f73c929b.jpg\n",
            "0753_jpg.rf.f55696c62838bf9b538315ad7482dfec.jpg\n",
            "0754_jpg.rf.5494c476b1db22178c18e0319a7975d5.jpg\n",
            "0756_jpg.rf.4b13b3832f56735e0e6296026de31cfb.jpg\n",
            "0757_jpg.rf.0a58b261af19f46e8c1aa17800ab974f.jpg\n",
            "0762_jpg.rf.0451020eddf883fe59aac1f7eeb07fde.jpg\n",
            "0763_jpg.rf.2695f5fb137abbc5df4e51fb8602428b.jpg\n",
            "0764_jpg.rf.b9308227a9fdcee4ddb0529aef975eaf.jpg\n",
            "0765_jpg.rf.edfe06d878501ef6d048120cbaddd423.jpg\n",
            "0766_jpg.rf.7900a44debb721951f42bdb1b6bb4e85.jpg\n",
            "077006000_1466184933-kepala_kuning-1_jpg.rf.11f8ed419e031c3ad52a5b66c5bb5918.jpg\n",
            "077006000_1466184933-kepala_kuning-1_jpg.rf.ebea26191105a2b17964568dcbdcc2e5.jpg\n",
            "077006000_1466184933-kepala_kuning_jpg.rf.a7234b7de3e0b5505741bac0efeb818c.jpg\n",
            "077006000_1466184933-kepala_kuning_jpg.rf.bc7723a58ddbfa7e94358063e86839ee.jpg\n",
            "077006000_1466184933-kepala_kuning_jpg.rf.cacde3425181b01ef3affe3adb148082.jpg\n",
            "077006000_1466184933-kepala_kuning_jpg.rf.d1bf3d76bfd89960bea3051b0b92ec6d.jpg\n",
            "077006000_1466184933-kepala_kuning_jpg.rf.f265cbfe3e567855d89b22db8d8f7ba7.jpg\n",
            "0771_jpg.rf.8afe6ccde8b564f5ec2ef0b564483d10.jpg\n",
            "0772_jpg.rf.f57a086af3140a5f9caab830540d0380.jpg\n",
            "0773_jpg.rf.4067b41b3bf7d8e891f0a2fb9c117a9e.jpg\n",
            "0774_jpg.rf.8cf40d08c1d5ca13ee9f71cb2bee72a0.jpg\n",
            "0776_jpg.rf.c7d90773626838b9a584ca8eb335d87a.jpg\n",
            "0777_jpg.rf.437569541e52971b9cf6d64bb8b4a097.jpg\n",
            "0778_jpg.rf.3aba00caaef9db29a28f5266b48cb5b7.jpg\n",
            "0779_jpg.rf.5e340f137cca8e145584e6d1acd2df4c.jpg\n",
            "0783_jpg.rf.fc25f4bac40079d211bc1947066e29d2.jpg\n",
            "0784_jpg.rf.3d5326c5f1b52bb87447fecd5822db0b.jpg\n",
            "0785_jpg.rf.1e5bf878b995842dae82b88e9880eab8.jpg\n",
            "0786_jpg.rf.0f40ea6a7c08a17193ef0361db5dd517.jpg\n",
            "0787_jpg.rf.11b432ad37b3a450f84180540ed7fcd7.jpg\n",
            "0788_jpg.rf.78f03e237fc49a023138a5e044672b2f.jpg\n",
            "0790_jpg.rf.70aca959766c67c127a7388ef9bd5109.jpg\n",
            "0792_jpg.rf.6290bb088b0733d1f8749d937d906e22.jpg\n",
            "0793_jpg.rf.5dcbde75ed52fd3f11114951acb9a344.jpg\n",
            "0794_jpg.rf.3883eab074db87dc50c15228b94354f0.jpg\n",
            "0795_jpg.rf.85fc083ca89f918d6ab4a76956de649e.jpg\n",
            "0796_jpg.rf.9e139a1aed65909e6cb9573abc14b0ae.jpg\n",
            "0797_jpg.rf.1d6642ecb4ab65d351c8dfdb7bbbde83.jpg\n",
            "0800_jpg.rf.bbdf5e63ac18a48601918cb83969b77b.jpg\n",
            "0801_jpg.rf.a7a8f0c6eb0ee63978886fb50242274c.jpg\n",
            "080222-001830-1-1-0-cam1_jpg.rf.8493831fc886d93ca61e3bcdf521620e.jpg\n",
            "080222-013049-1-1-0-cam1_jpg.rf.62f46b0b5f86977002100f47a2fba34d.jpg\n",
            "080222-020505-1-1-0-cam1_jpg.rf.7c3ab4ce54ede9fe480c6695cb2a2ad5.jpg\n",
            "080222-022552-1-1-0-cam1_jpg.rf.07e06e047580e9d47a99ebebd6a15e51.jpg\n",
            "080222-022633-1-1-0-cam1_jpg.rf.de93c8a930bdc7369b5bc6e7913557f1.jpg\n",
            "080222-025127-1-1-0-cam1_jpg.rf.60ed32f0cc5bfde871666cfda1fb8ae9.jpg\n",
            "080222-032127-1-1-0-cam1_jpg.rf.c588f0b0db9b62cc80230a73acc824e5.jpg\n",
            "080222-040050-1-1-0-cam1_jpg.rf.ae2ea73ad4701854f48d813018abc204.jpg\n",
            "080222-040646-1-1-0-cam1_jpg.rf.8475b04cf94c66a19855d500bc32045d.jpg\n",
            "080222-045500-1-1-0-cam1_jpg.rf.bb328bbdd3fad08baa24c3a66ec175dd.jpg\n",
            "080222-052141-1-1-0-cam1_jpg.rf.b5ff6ba11264a079cc369d7427d5778a.jpg\n",
            "080222-060736-1-1-0-cam1_jpg.rf.0432d561b4fe3ff42427a688a270dddb.jpg\n",
            "080222-062906-1-1-0-cam1_jpg.rf.da256aea42f9248c03eef6fc69f7580d.jpg\n",
            "080222-063003-1-1-0-cam1_jpg.rf.5c30188ccd7e16347d33897c7e296cd2.jpg\n",
            "080222-063152-1-1-0-cam1_jpg.rf.b8871ea872b7a16831b3387b6100fdc0.jpg\n",
            "080222-064125-1-1-0-cam1_jpg.rf.49d8faa9f17a20f4e4284b196e24d842.jpg\n",
            "080222-065540-1-1-0-cam1_jpg.rf.d5a74757941cc7c7ca1e596b3ded0f2a.jpg\n",
            "080222-072550-1-1-0-cam1_jpg.rf.51dfb30410e619a2a48ec7031ab9a54f.jpg\n",
            "080222-072757-1-1-0-cam1_jpg.rf.d093e1fdd1753f2594b23dfe35abd087.jpg\n",
            "080222-075451-1-1-0-cam1_jpg.rf.207541802fc9963765915e2acd37774e.jpg\n",
            "080222-082020-1-1-0-cam1_jpg.rf.12e3cdccb7f86b638b67e055e0fe4ddc.jpg\n",
            "080222-085722-1-1-0-cam1_jpg.rf.6f63b7cec52d521483a115073dc36979.jpg\n",
            "080222-102926-1-1-0-cam1_jpg.rf.2fe083bd777ef446154eb817042c4718.jpg\n",
            "080222-103828-1-1-0-cam1_jpg.rf.899e7b64afdc290e06489a246fc576be.jpg\n",
            "080222-124101-1-1-0-cam1_jpg.rf.dabe64430555f612bd3895f0765cec12.jpg\n",
            "080222-133326-1-1-0-cam1_jpg.rf.a2feb84e87f22e476267290a86769fe2.jpg\n",
            "080222-141740-1-1-0-cam1_jpg.rf.29ff1c5dcbbf4e9cf8a4eebccba38b32.jpg\n",
            "080222-144506-1-1-0-cam1_jpg.rf.930e5cc25b0dcb29239993e038685c2a.jpg\n",
            "080222-145633-1-1-0-cam1_jpg.rf.1bf521de3631643ecbecb3ce46bf4f3b.jpg\n",
            "080222-145636-1-1-0-cam1_jpg.rf.faa83ccafae1cf39092876039e46f597.jpg\n",
            "080222-150212-1-1-0-cam1_jpg.rf.69ec7f57b613eb7f55705970a8f62771.jpg\n",
            "080222-150411-1-1-0-cam1_jpg.rf.0ae1b4d7ab009ad319b14b83ddd131a9.jpg\n",
            "080222-150528-1-1-0-cam1_jpg.rf.53296447023c956fbef1f35f1b4d3f33.jpg\n",
            "080222-150955-1-1-0-cam1_jpg.rf.f00e3ae7b9d7e12faf06a866e2665e70.jpg\n",
            "080222-151114-1-1-0-cam1_jpg.rf.64166da28889a7bc4396120405681a65.jpg\n",
            "080222-151220-1-1-0-cam1_jpg.rf.539ba5ba6b7ba5b45dba89de02c5af14.jpg\n",
            "080222-154530-1-1-0-cam1_jpg.rf.c9693da6aa4c5712d3d0be11da3f413a.jpg\n",
            "080222-154640-1-1-0-cam1_jpg.rf.b57fb3374e14683edbc4d7a7e051aff1.jpg\n",
            "080222-161136-1-1-0-cam1_jpg.rf.b635056a595a14111a3be48f82e70c59.jpg\n",
            "080222-161232-1-1-0-cam1_jpg.rf.62e63284da8192b8437ea2a308f3f95c.jpg\n",
            "080222-164934-1-1-0-cam1_jpg.rf.21799f927daf818b90bf5903b6910dd1.jpg\n",
            "080222-165830-1-1-0-cam1_jpg.rf.f9ee7033ccbd9801d0bfc67ea87a0ddf.jpg\n",
            "080222-165834-1-1-0-cam1_jpg.rf.eb55322426947c6cce982123a1bb4129.jpg\n",
            "080222-170012-1-1-0-cam1_jpg.rf.298e45373520d7065054e61db4a491a8.jpg\n",
            "080222-170204-1-1-0-cam1_jpg.rf.41ded0ff4613dbfbc671e193d753a078.jpg\n",
            "080222-170956-1-1-0-cam1_jpg.rf.a860d2d21932a0b2f5a59c2d0ce9ada1.jpg\n",
            "080222-171555-1-1-0-cam1_jpg.rf.a67d52e89b54ba80039b892e3953649f.jpg\n",
            "080222-172443-1-1-0-cam1_jpg.rf.988bb306c20f70d46d0724b962484e08.jpg\n",
            "080222-172444-1-1-0-cam1_jpg.rf.3f5d1f652aca3099c4c286b84226189e.jpg\n",
            "080222-172617-1-1-0-cam1_jpg.rf.35a7fa8f2d8e0d71dd3a3056969ce7c3.jpg\n",
            "080222-172645-1-1-0-cam1_jpg.rf.e0e1659fb68f106b361c094e05cd5d67.jpg\n",
            "080222-172749-1-1-0-cam1_jpg.rf.e34f6d9faf62d0d78580fa3b8ec8c826.jpg\n",
            "080222-173155-1-1-0-cam1_jpg.rf.8e1e6c0d9b87e13aab6568ee5d806ad4.jpg\n",
            "080222-173446-1-1-0-cam1_jpg.rf.173f8de89a0e454750a6f36735c3278f.jpg\n",
            "080222-175017-1-1-0-cam1_jpg.rf.726b2b10c6e3641398b95f0f09c96eb2.jpg\n",
            "080222-175019-1-1-0-cam1_jpg.rf.f54be31b60f59e3c69e3d597dae156dc.jpg\n",
            "080222-180316-1-1-0-cam1_jpg.rf.c712aa9baa69f5ea9895c8567981ac8a.jpg\n",
            "080222-180811-1-1-0-cam1_jpg.rf.690504eb26cfc00d3b3c73301446787c.jpg\n",
            "080222-182446-1-1-0-cam1_jpg.rf.0b4c36eaa21766b3af33b8b1466f09b5.jpg\n",
            "080222-184318-1-1-0-cam1_jpg.rf.21f50c5f982fa427d5aac41c31cc20fb.jpg\n",
            "080222-184458-1-1-0-cam1_jpg.rf.626574194094380b7faf06c54c7e7bbb.jpg\n",
            "080222-185325-1-1-0-cam1_jpg.rf.7c7ad13d78827fd6ee537fad0e6555b8.jpg\n",
            "080222-185733-1-1-0-cam1_jpg.rf.71a9b798fbb4cb5c14a05c4c5ab1c289.jpg\n",
            "080222-190145-1-1-0-cam1_jpg.rf.b1b60e8e76cbe6bba59c3d697fc2e93d.jpg\n",
            "080222-192737-1-1-0-cam1_jpg.rf.547ade18ab49a42ba6a88d2913de24bb.jpg\n",
            "080222-200722-1-1-0-cam1_jpg.rf.d91a0d00a823a1ec5f5f29ce47491b79.jpg\n",
            "080222-202123-1-1-0-cam1_jpg.rf.db29a442765e8e63028412dbd461a5fc.jpg\n",
            "080222-202322-1-1-0-cam1_jpg.rf.97e76331609de7435fdd26208834a43d.jpg\n",
            "080222-203453-1-1-0-cam1_jpg.rf.a7f9f29fb97a980bba2d1de041bf9381.jpg\n",
            "080222-203754-1-1-0-cam1_jpg.rf.6518069a81d49bcfd8c603f44359050c.jpg\n",
            "080222-205206-1-1-0-cam1_jpg.rf.32539df062678d831566a0de7e533308.jpg\n",
            "080222-205929-1-1-0-cam1_jpg.rf.2bde65c631ab371ba173e2ff64ee0b69.jpg\n",
            "080222-214158-1-1-0-cam1_jpg.rf.f37691b15cda25b28d2bc40f16006c91.jpg\n",
            "080222-221120-1-1-0-cam1_jpg.rf.48ed79379ad2a0b5d1162828b49929e4.jpg\n",
            "080222-221510-1-1-0-cam1_jpg.rf.7943eb0883eaad2efa014046857ef91d.jpg\n",
            "080222-221739-1-1-0-cam1_jpg.rf.32343211fde12084e8d610dcd07da3c1.jpg\n",
            "080222-223708-1-1-0-cam1_jpg.rf.01f29f35f8420fe2ec13b5a7490e769d.jpg\n",
            "080222-225938-1-1-0-cam1_jpg.rf.3a6238591cf991184f10c94cda803005.jpg\n",
            "080222-230553-1-1-0-cam1_jpg.rf.4b6882f585c2bc1bef4068df6643f2c0.jpg\n",
            "080222-233740-1-1-0-cam1_jpg.rf.c3bc8f9257d47a4030abb859989f6414.jpg\n",
            "080222-234028-1-1-0-cam1_jpg.rf.8b7cb33c56ca8de2669d5ca6b484b8e3.jpg\n",
            "080222-234412-1-1-0-cam1_jpg.rf.2f40723d64d24a864feb89e7eada48e7.jpg\n",
            "0802_jpg.rf.000e7235a914dbf797737d084c872523.jpg\n",
            "0804_jpg.rf.544c582453506211f2ceb1b3abcf123b.jpg\n",
            "0805_jpg.rf.c5d313c151c61a100f850898ad941203.jpg\n",
            "0806_jpg.rf.d2af8815be4fa617d61b2fcb5ebe194c.jpg\n",
            "0808_jpg.rf.3b4184d3dc5667a63c55b66030e83037.jpg\n",
            "0809_jpg.rf.e104e91cd6102b12bf1708f31657ed54.jpg\n",
            "0810_jpg.rf.d4a5971ea57274c8db58c4351f813330.jpg\n",
            "0814_jpg.rf.8398079ac1f0414ca74db48ac6636a9f.jpg\n",
            "0815_jpg.rf.0f06af8021aa2d42f0fe816edb6f0404.jpg\n",
            "0816_jpg.rf.c4bd859490b5fefc1727661c316ced1b.jpg\n",
            "0818_jpg.rf.b1961a9e8e5c61aa7514a71d6f21259b.jpg\n",
            "-081E069C-5653-4461-A454-77BE153E5731-png_jpg.rf.90b918d8cab7b5fe5572517a68adc312.jpg\n",
            "0820_jpg.rf.a5450384c4104a7630ae4cf1c1f134ca.jpg\n",
            "0821_jpg.rf.0b6ca6cd1134f2f278bffbb647015426.jpg\n",
            "0823_jpg.rf.b39dbf97469e5cd8bb392a67b05dfe0b.jpg\n",
            "0824_jpg.rf.ee2fc0a1e654eb85534a10bbd47cbd75.jpg\n",
            "0825_jpg.rf.4a1c3743933589d0bbd3be8426b6ee4b.jpg\n",
            "0826_jpg.rf.2e8b5f368e358f70ed8a10fdf9bf5ee4.jpg\n",
            "-08F946D6-9D13-4360-B805-495C5CA6C0FA-png_jpg.rf.b0fd8e1501afc8a4797b721a1ab121f0.jpg\n",
            "090222-001509-1-1-0-cam1_jpg.rf.e9cc378f839f1b37d07cf8830adcbad5.jpg\n",
            "090222-001523-1-1-0-cam1_jpg.rf.2af5a1f4a08a629c001b520402f2747c.jpg\n",
            "090222-001840-1-1-0-cam1_jpg.rf.322de4f3a8922c2d9b70050950f82447.jpg\n",
            "090222-003349-1-1-0-cam1_jpg.rf.f595e13342a3de858226cb20ec9f1c03.jpg\n",
            "090222-003546-1-1-0-cam1_jpg.rf.92832dc7a44ec9b1661207140b421a60.jpg\n",
            "090222-004356-1-1-0-cam1_jpg.rf.f9bbf3ab8bed90d7ccc063b79c51a36c.jpg\n",
            "090222-005536-1-1-0-cam1_jpg.rf.1d80609165dc37b6a385e04f744bad88.jpg\n",
            "090222-010036-1-1-0-cam1_jpg.rf.52a3074945005fb5c5b7aaceaa70a8e9.jpg\n",
            "090222-010817-1-1-0-cam1_jpg.rf.27e74df8047dfff6278c09662e3681fa.jpg\n",
            "090222-011450-1-1-0-cam1_jpg.rf.4581a8d2e4add95068433516fe2f2b48.jpg\n",
            "090222-011940-1-1-0-cam1_jpg.rf.6f86abc088b5b571658b43f29baa4a4c.jpg\n",
            "090222-011958-1-1-0-cam1_jpg.rf.c7e5b745ab60e2bc70f79202b3d63ec5.jpg\n",
            "090222-012351-1-1-0-cam1_jpg.rf.dd4525707328f11da4fb2343c2b97ccd.jpg\n",
            "090222-013457-1-1-0-cam1_jpg.rf.d616e6aba936a0ed19146ca24a27e2eb.jpg\n",
            "090222-013516-1-1-0-cam1_jpg.rf.9341890cd3a5f461dc743c0480a35e16.jpg\n",
            "090222-013538-1-1-0-cam1_jpg.rf.f8010089c83381e97efadda0c4291e4d.jpg\n",
            "090222-013541-1-1-0-cam1_jpg.rf.628ffc01dd7c50c927e766603cfce300.jpg\n",
            "090222-013901-1-1-0-cam1_jpg.rf.a2169e0c43ffcb5aec2c47e569e9a605.jpg\n",
            "090222-013944-1-1-0-cam1_jpg.rf.20f8584b7c445785d33be3e93773894d.jpg\n",
            "090222-014737-1-1-0-cam1_jpg.rf.88ece7b1dc6e55e7fc0f8ec08ae6108b.jpg\n",
            "090222-015103-1-1-0-cam1_jpg.rf.0dbcab316f97202420a77b64ffe12063.jpg\n",
            "090222-015614-1-1-0-cam1_jpg.rf.3bd54cfd0df89a71f9008e8c3fad5e1d.jpg\n",
            "090222-020144-1-1-0-cam1_jpg.rf.efe85bc04d608d161d8e512e4a275ea4.jpg\n",
            "090222-020421-1-1-0-cam1_jpg.rf.321160f6562121fc2c55742e016bf16a.jpg\n",
            "090222-020548-1-1-0-cam1_jpg.rf.c68e06c7da3e841d3726ccf05fac816b.jpg\n",
            "090222-020709-1-1-0-cam1_jpg.rf.9f6ebb2b1ad4b15f4fe02e06859e48de.jpg\n",
            "090222-021150-1-1-0-cam1_jpg.rf.3e77da664ce194a940d2996cfc3c4184.jpg\n",
            "090222-021242-1-1-0-cam1_jpg.rf.ea4647c44230b27b632bf491fd135edc.jpg\n",
            "090222-021304-1-1-0-cam1_jpg.rf.9390d963f116a3fc5c6424427e94c030.jpg\n",
            "090222-022338-1-1-0-cam1_jpg.rf.ca2d9dc17127748b23855fdb0cfaf7b1.jpg\n",
            "090222-022752-1-1-0-cam1_jpg.rf.fc557b43ebd87a465469114b722bb3de.jpg\n",
            "090222-022920-1-1-0-cam1_jpg.rf.745ff82d153e74affd8078c5915dc80f.jpg\n",
            "090222-025039-1-1-0-cam1_jpg.rf.42cabe9c2fda75825be15fdb8e3ab7b1.jpg\n",
            "090222-030600-1-1-0-cam1_jpg.rf.e0b1aa2ed7caa5c9788b2077af171564.jpg\n",
            "090222-030928-1-1-0-cam1_jpg.rf.76c808e796c628a25f55d46af88d6031.jpg\n",
            "090222-033738-1-1-0-cam1_jpg.rf.512ef5d2ad2f10957f922f68851e6c51.jpg\n",
            "090222-034850-1-1-0-cam1_jpg.rf.cdd15759ddb962bc752a13d1f79717ce.jpg\n",
            "090222-042214-1-1-0-cam1_jpg.rf.f9720ca0d5c6036ea23876e4a4658fe1.jpg\n",
            "090222-042242-1-1-0-cam1_jpg.rf.5655c25e9d85bc4e731c392211dc585c.jpg\n",
            "090222-050002-1-1-0-cam1_jpg.rf.8bf2af2a38ec32a17f6cc542a42dcc2c.jpg\n",
            "090222-051233-1-1-0-cam1_jpg.rf.c0b290f06fd816f11aadb9d4ccba48b9.jpg\n",
            "090222-052147-1-1-0-cam1_jpg.rf.6d2f388c490c6314f6a95d5478a82b75.jpg\n",
            "090222-053417-1-1-0-cam1_jpg.rf.878188db782fe8c4e01ca72301d577c6.jpg\n",
            "090222-053950-1-1-0-cam1_jpg.rf.57a8977997ef7960a5ed3bbe7c08f633.jpg\n",
            "090222-054159-1-1-0-cam1_jpg.rf.7792c41d39266fcf949dfb5910756722.jpg\n",
            "090222-054257-1-1-0-cam1_jpg.rf.c85245598c329f96fb83e9b2f88d1173.jpg\n",
            "090222-054303-1-1-0-cam1_jpg.rf.36695de8c38eeb75906a13af326a5da4.jpg\n",
            "090222-054547-1-1-0-cam1_jpg.rf.3c32f14de381e4b4b6423865b6831b73.jpg\n",
            "090222-054633-1-1-0-cam1_jpg.rf.1d72f54f3431782893fc1f5b95d7f8e6.jpg\n",
            "090222-055012-1-1-0-cam1_jpg.rf.bda11152402d6b76bcb88d58b4786e9b.jpg\n",
            "090222-055030-1-1-0-cam1_jpg.rf.a348646222d6eefb4898978d265234e7.jpg\n",
            "090222-055047-1-1-0-cam1_jpg.rf.fa4fa724e0a44e7c24f4ff41d72da6e9.jpg\n",
            "090222-055217-1-1-0-cam1_jpg.rf.cfad80764f94d95a8259faf4f43ad395.jpg\n",
            "090222-055230-1-1-0-cam1_jpg.rf.b7db2bc143ac977348f84f757d014ba0.jpg\n",
            "090222-055620-1-1-0-cam1_jpg.rf.934613ab1b9fbd28e1642193927a687f.jpg\n",
            "090222-055836-1-1-0-cam1_jpg.rf.f8712c769c2866a28631fb5b2aa049d1.jpg\n",
            "090222-060215-1-1-0-cam1_jpg.rf.cbf4511aa2d587f951e802275c1622c1.jpg\n",
            "090222-060239-1-1-0-cam1_jpg.rf.155d58fe85d22f7897a6134fa8bb834e.jpg\n",
            "090222-060933-1-1-0-cam1_jpg.rf.c2c2c7210f7efb3053c75e1b33aeb9c0.jpg\n",
            "090222-061006-1-1-0-cam1_jpg.rf.3a9675df6222d34c90287770b87f64a5.jpg\n",
            "090222-061134-1-1-0-cam1_jpg.rf.9df5b917442caf45f1dd91ebc3e16ee9.jpg\n",
            "090222-061244-1-1-0-cam1_jpg.rf.7dc76d72dca0999f75a25caacb56da81.jpg\n",
            "090222-061916-1-1-0-cam1_jpg.rf.5b49b1806791f51a5fd32f80f875a542.jpg\n",
            "090222-062347-1-1-0-cam1_jpg.rf.2af9e52fe12d12d66b16541868ad2fbb.jpg\n",
            "090222-062423-1-1-0-cam1_jpg.rf.aaa798aac19bd760ab0dc916c319007a.jpg\n",
            "090222-062609-1-1-0-cam1_jpg.rf.bcc298cf7eec3cb0d409c714a56d9d91.jpg\n",
            "090222-062818-1-1-0-cam1_jpg.rf.0f3c690b2610239fabdc08937b1c37ce.jpg\n",
            "090222-062939-1-1-0-cam1_jpg.rf.265bd9e46fdd6610cb3768b3ddd8f05b.jpg\n",
            "090222-062958-1-1-0-cam1_jpg.rf.bf5393346858b10946286882b773ebd9.jpg\n",
            "090222-063252-1-1-0-cam1_jpg.rf.981a9dc601c815c956ee8a53d4040e57.jpg\n",
            "090222-063542-1-1-0-cam1_jpg.rf.7945fe00cbf919cfbf7a86f94baf181d.jpg\n",
            "090222-065326-1-1-0-cam1_jpg.rf.4e8d9ecb007cdadae383f5a3e3ee8d38.jpg\n",
            "090222-065707-1-1-0-cam1_jpg.rf.e3af9cfeddb2b242a006a77f86b42201.jpg\n",
            "090222-065844-1-1-0-cam1_jpg.rf.15b46192bd8b6d9abbd7149c06a2d6be.jpg\n",
            "090222-070408-1-1-0-cam1_jpg.rf.6f879240f149a7cb123e584aa9f7fb84.jpg\n",
            "090222-070424-1-1-0-cam1_jpg.rf.aa186efed7606bfc5ada0c10e45774f6.jpg\n",
            "090222-070538-1-1-0-cam1_jpg.rf.c66a8392b32c8eb31c23fae2254d220b.jpg\n",
            "090222-071013-1-1-0-cam1_jpg.rf.08e24d5bd4ce9232adc35e5954cda0c3.jpg\n",
            "090222-071346-1-1-0-cam1_jpg.rf.3050d58989ed2c4e8b75f62635e00727.jpg\n",
            "090222-072012-1-1-0-cam1_jpg.rf.cc7328b31292bb4891cd93775219858b.jpg\n",
            "090222-072629-1-1-0-cam1_jpg.rf.7973566f188078802408e0058b25f389.jpg\n",
            "090222-073341-1-1-0-cam1_jpg.rf.fe632606ae410f64066584cbe5a1acf8.jpg\n",
            "090222-073727-1-1-0-cam1_jpg.rf.0263f5ab154f9596c2d04d0cfd6862a5.jpg\n",
            "090222-074139-1-1-0-cam1_jpg.rf.a0f4b9222dbbcf83ec036188e93351e2.jpg\n",
            "090222-074706-1-1-0-cam1_jpg.rf.d6f1844bc740bb39a8ad1359fd480510.jpg\n",
            "090222-074951-1-1-0-cam1_jpg.rf.0b9008afabf9c8096c1f3389b5438427.jpg\n",
            "090222-080349-1-1-0-cam1_jpg.rf.da6f5762b2985a5c190a80684d29f1fa.jpg\n",
            "090222-082148-1-1-0-cam1_jpg.rf.db740bb6abc98e384a764ba9f7ac560b.jpg\n",
            "090222-083334-1-1-0-cam1_jpg.rf.7c54613d42bd0f07a67b8066c73c4eb6.jpg\n",
            "090222-083359-1-1-0-cam1_jpg.rf.75636241b396880b393dd12595086cfc.jpg\n",
            "090222-083441-1-1-0-cam1_jpg.rf.213237842a97dc8b14a564f9f16ea42a.jpg\n",
            "090222-083737-1-1-0-cam1_jpg.rf.df96ca96f59f347899616572af328c4a.jpg\n",
            "090222-090931-1-1-0-cam1_jpg.rf.0be0b0c08ee8455a02a5394d337ee7fc.jpg\n",
            "090222-091626-1-1-0-cam1_jpg.rf.0b9359d3b817c79276bd9c9e2f564754.jpg\n",
            "090222-093208-1-1-0-cam1_jpg.rf.45bbaf78b8e8b832bee0cc0ab39b57c3.jpg\n",
            "090222-104649-1-1-0-cam1_jpg.rf.3f814a26064ec8cbb9d1ff06d002e444.jpg\n",
            "090222-105034-1-1-0-cam1_jpg.rf.5a6db7a2d55b5574fd9f2c614747076a.jpg\n",
            "090222-113140-1-1-0-cam1_jpg.rf.a805f577084d78bf111ee0be606b6e8a.jpg\n",
            "090222-113859-1-1-0-cam1_jpg.rf.2e223a932412de9cfd7b62fdcafa5e9a.jpg\n",
            "090222-120147-1-1-0-cam1_jpg.rf.feb44a4723d3a9807383dcc5fc76ca14.jpg\n",
            "090222-121811-1-1-0-cam1_jpg.rf.a8d68a5e3ba821be7f0e9fb22683d664.jpg\n",
            "090222-122829-1-1-0-cam1_jpg.rf.ab8f96f9f3768e0947202af6eb9f65ba.jpg\n",
            "090222-123135-1-1-0-cam1_jpg.rf.9b244c64bcf385b9836e8e8db9c7f385.jpg\n",
            "090222-123356-1-1-0-cam1_jpg.rf.90af0e3cc38f3ea28d9f08bdaf531a41.jpg\n",
            "090222-123939-1-1-0-cam1_jpg.rf.8225a984b0bb0e8adc5a39342c4523bf.jpg\n",
            "090222-124724-1-1-0-cam1_jpg.rf.2d419565a8a8a3aaff816c73a8f8f584.jpg\n",
            "090222-132100-1-1-0-cam1_jpg.rf.ef5d1ef86706d53eef060e164fc9a97e.jpg\n",
            "090222-132727-1-1-0-cam1_jpg.rf.04e4e945e966766deca0580c624d4241.jpg\n",
            "090222-133101-1-1-0-cam1_jpg.rf.827003e0025b4adf5621d335085f3b68.jpg\n",
            "090222-133547-1-1-0-cam1_jpg.rf.0a75ae4922893e3e3786c2ddb2af1ab3.jpg\n",
            "090222-134417-1-1-0-cam1_jpg.rf.0f22986b7e69cafef9cda35699f2f4cd.jpg\n",
            "090222-134722-1-1-0-cam1_jpg.rf.fbeec4472ee81a22de346e7fa74f23d6.jpg\n",
            "090222-135123-1-1-0-cam1_jpg.rf.f06e79c3e7cec5b51e78aab8b096a79e.jpg\n",
            "090222-135241-1-1-0-cam1_jpg.rf.12ba2b0df97f28ead6244803bec86c45.jpg\n",
            "090222-135302-1-1-0-cam1_jpg.rf.4b68774810fbc6895c113a45964d244e.jpg\n",
            "090222-135306-1-1-0-cam1_jpg.rf.b6b8ef421bb99275d7f82fc74554f168.jpg\n",
            "090222-135843-1-1-0-cam1_jpg.rf.aa8876df4804ff63c5d0b3bb705b6391.jpg\n",
            "-0ACAD937-70A4-46F0-8E49-0CAE6F942CF2-png_jpg.rf.3d83a55531df64b83bff7adac9d40ea6.jpg\n",
            "-0AD5F45D-45CE-4BCD-A9B7-76764AA51A9B-png_jpg.rf.5ea9c426727b76420d2ef8609f9b97af.jpg\n",
            "-0B43DB53-2377-4D6D-B5B8-60CBBAB90F88-png_jpg.rf.2d2f81c3b62eccc35071bebcdef9ffd9.jpg\n",
            "-0EA5B2D5-C63C-45B2-9048-072293BBA378-png_jpg.rf.edc2aad83a4ea06c418d257b1b761828.jpg\n",
            "-0FB0E465-1451-4618-84CD-1A1A88293B08-png_jpg.rf.432c91a5dd40106a3acbec2fd7d28945.jpg\n",
            "100171_jpg.rf.0054153345fd6408fe6c2d7d911b1326.jpg\n",
            "101-E-4604-PS-09-17_jpeg_jpg.rf.ca79444adefc28eedbaa14a9d50e25a8.jpg\n",
            "-101F7188-06B4-4FC2-B9FF-123C60B06606-png_jpg.rf.1267435e6058bbf91cd7092f14d73454.jpg\n",
            "102685_jpg.rf.2d1d865bd03172d48149bfd9b701796c.jpg\n",
            "102_jpg.rf.2fcab21d45e6ef13fe6239ad8b4631d2.jpg\n",
            "103773_jpg.rf.dcb09c0420f8f15296fb4f865c9b23f4.jpg\n",
            "103-E-6387-PL-04-20_jpeg_jpg.rf.51a5afc07036271930e68e03ad98013a.jpg\n",
            "104-E-4939-PAE-07-21_jpeg_jpg.rf.3a08cc1a01cd86bb765d01ccbcc38df5.jpg\n",
            "104_jpg.rf.db466e52c41c9b0f5fb694d6bb4f2c97.jpg\n",
            "-1058CFB8-55AA-4270-937C-FAB55C49F17A-png_jpg.rf.d31a36544c0de816dc193d8733d9a130.jpg\n",
            "105_jpg.rf.62fd2abe6410b38b071c3fa73375063b.jpg\n",
            "106985_0_jpg.rf.0890d35103f39b0142a621d031858afc.jpg\n",
            "106985_0_jpg.rf.afced2f3f55a77e668dbc9c17e68b681.jpg\n",
            "106_jpg.rf.ae2cfeee5112b3713edf6cc0282b1cd3.jpg\n",
            "107-E-4145-QZ-12-20_jpeg_jpg.rf.92d5f02bb18485a65dacf8ce0e5f5253.jpg\n",
            "108-E-5860-ST-03-21_jpeg_jpg.rf.970b3d008dde0d61cdda5394a8be1ede.jpg\n",
            "109-E-4026-SL-02-20_jpg.rf.4af8f799a39a93b02c3e33dae21d8a46.jpg\n",
            "109_jpg.rf.105b2d6c8a83f2b26513fd9e041c7166.jpg\n",
            "110222-064911-1-1-0-cam1_jpg.rf.64b9ce22ba21f3e35b107fb7054259aa.jpg\n",
            "110222-064951-1-1-0-cam1_jpg.rf.e4430dd2dc110bba80fc0cc47d035242.jpg\n",
            "110222-065419-1-1-0-cam1_jpg.rf.14b61c1606dcc192d36cb8a00dfeeb42.jpg\n",
            "110222-065439-1-1-0-cam1_jpg.rf.7b348eddf8af000c926e438677924407.jpg\n",
            "110222-065840-1-1-0-cam1_jpg.rf.18cea302acba5fce3685dda1b86b2fde.jpg\n",
            "110222-070113-1-1-0-cam1_jpg.rf.e348d1f96d832a7efbc9ce76f3e29a9f.jpg\n",
            "110222-070128-1-1-0-cam1_jpg.rf.726573886c1fba8f3c0a79e4767d625b.jpg\n",
            "110222-070734-1-1-0-cam1_jpg.rf.81547eaa44484af9380616edc26145f0.jpg\n",
            "110222-070840-1-1-0-cam1_jpg.rf.0461f5535d4eaac280a5b025dd0b0ffe.jpg\n",
            "110222-070931-1-1-0-cam1_jpg.rf.04fd860f0f595244f089f320e744daff.jpg\n",
            "110222-071644-1-1-0-cam1_jpg.rf.4dc46d8d0ee6f8df8cf5fcefa74895bf.jpg\n",
            "110222-071955-1-1-0-cam1_jpg.rf.82b2d1580584f410cb584a4ff39a11e3.jpg\n",
            "110222-072449-1-1-0-cam1_jpg.rf.8d30f1ed4f78105f0b847d7312035403.jpg\n",
            "110222-073343-1-1-0-cam1_jpg.rf.4d96969251e208ba7f4861cdeb49bcd9.jpg\n",
            "110222-073356-1-1-0-cam1_jpg.rf.19760cdb19e5d2dee75b9e6e1944619c.jpg\n",
            "110222-073456-1-1-0-cam1_jpg.rf.b111f9a380a878e01f06bbf52cc980ea.jpg\n",
            "110222-073501-1-1-0-cam1_jpg.rf.2431245062a8068198454ddb8e7f59f4.jpg\n",
            "110222-073909-1-1-0-cam1_jpg.rf.0b3e6e3ac2c0e5456ac3607d6e581501.jpg\n",
            "110222-074149-1-1-0-cam1_jpg.rf.8b24c64f6ef2d7b3f38bd8cb1e35a7d6.jpg\n",
            "110222-074901-1-1-0-cam1_jpg.rf.b57de3eaab4719328f6f02d1b9f13710.jpg\n",
            "110222-074915-1-1-0-cam1_jpg.rf.5b586a91f67e316c31bc08e976a5bee2.jpg\n",
            "110222-075133-1-1-0-cam1_jpg.rf.9046874dbb114e4e85fb799bd7cf1fa9.jpg\n",
            "110222-075406-1-1-0-cam1_jpg.rf.a9ff08b95f0c20701a13e36b4114bbd0.jpg\n",
            "110222-075743-1-1-0-cam1_jpg.rf.c71d9f9e2d929139185cb011ecdb59d0.jpg\n",
            "110222-075907-1-1-0-cam1_jpg.rf.0a89a494657f65a4ab1b3972776c0e75.jpg\n",
            "110222-083512-1-1-0-cam1_jpg.rf.707c58360765f5954a024c00fa691d1d.jpg\n",
            "110222-090136-1-1-0-cam1_jpg.rf.fd0520fe6d52675a2a8fc134eef45b17.jpg\n",
            "110222-090601-1-1-0-cam1_jpg.rf.cb43fbd1fb4e57ad53abea6e447c2c12.jpg\n",
            "110222-093335-1-1-0-cam1_jpg.rf.5b2221762e05ce1c8fd275890e8a0ce8.jpg\n",
            "110222-093934-1-1-0-cam1_jpg.rf.3cff769f7d0eb9e6234505d8751aa310.jpg\n",
            "110222-100934-1-1-0-cam1_jpg.rf.3f610b675d416b030d8e1bc968e92148.jpg\n",
            "110222-101427-1-1-0-cam1_jpg.rf.b413efea1fbedc380c658c2dc057f8a8.jpg\n",
            "110222-113727-1-1-0-cam1_jpg.rf.98a72d4c409b33003890daa0d6146670.jpg\n",
            "110222-122234-1-1-0-cam1_jpg.rf.a40213ef5b8c56e335c21ccfb5d859f6.jpg\n",
            "110222-122342-1-1-0-cam1_jpg.rf.c815109d2f4421b9b9767266eca4abe2.jpg\n",
            "110222-131014-1-1-0-cam1_jpg.rf.925442fe175c33932f87070165927ab0.jpg\n",
            "110222-132733-1-1-0-cam1_jpg.rf.099a1db99dac444af23e953b74cf7297.jpg\n",
            "110222-142459-1-1-0-cam1_jpg.rf.cb989fa78314eeda975bed524b55b623.jpg\n",
            "110222-144006-1-1-0-cam1_jpg.rf.cf739ccd383043605aad6063d89caf51.jpg\n",
            "110222-144153-1-1-0-cam1_jpg.rf.8e1574ba8d625f817d216dce4adab6d3.jpg\n",
            "110222-144545-1-1-0-cam1_jpg.rf.4d310863f311ce99a5e7db014462b4e8.jpg\n",
            "110222-144612-1-1-0-cam1_jpg.rf.95137cbc0a906b966bc372fc83e44482.jpg\n",
            "110222-145003-1-1-0-cam1_jpg.rf.d516ca6a6ce96942b8ccf322d25aa0b6.jpg\n",
            "110222-145136-1-1-0-cam1_jpg.rf.12a82609be987345dde5dc52f96d4338.jpg\n",
            "110222-145154-1-1-0-cam1_jpg.rf.81f04967c1bd9ec3d2c6aef87cbeef92.jpg\n",
            "110222-145747-1-1-0-cam1_jpg.rf.c0707d51f1a9a3852a76a566bf918e5b.jpg\n",
            "110222-150115-1-1-0-cam1_jpg.rf.76f0747fd949077422de1db9dd9f6242.jpg\n",
            "110222-150944-1-1-0-cam1_jpg.rf.8a93505b623d18ab7f4719ed6e88bd63.jpg\n",
            "110222-151118-1-1-0-cam1_jpg.rf.e070988ad8d2b27215be19fb0618d2c9.jpg\n",
            "110222-151841-1-1-0-cam1_jpg.rf.57f93051530539413e5d733cb1e22409.jpg\n",
            "110222-152253-1-1-0-cam1_jpg.rf.8dd0380ec571915155530834874234d9.jpg\n",
            "110222-152544-1-1-0-cam1_jpg.rf.bf54de3d36de55fce63d2079858f8f43.jpg\n",
            "110222-152604-1-1-0-cam1_jpg.rf.c6c50d4ff65d24097fe9fdd887593fbc.jpg\n",
            "110222-153148-1-1-0-cam1_jpg.rf.f2c7dcd12c835edc936744c0ed444311.jpg\n",
            "110222-153202-1-1-0-cam1_jpg.rf.d0ac6cb9da5acd18b793aaea4c388971.jpg\n",
            "110222-153318-1-1-0-cam1_jpg.rf.b28c1efe2b62dd7a8dea08b2c9d2cb8c.jpg\n",
            "110222-153521-1-1-0-cam1_jpg.rf.165ff645418b0388c3dfff06ce233fe8.jpg\n",
            "110222-153638-1-1-0-cam1_jpg.rf.85907319f91f5af24d5cec09a3c42872.jpg\n",
            "110222-154104-1-1-0-cam1_jpg.rf.1c7e84b1273dedc00dbf908263fd52a0.jpg\n",
            "110222-154345-1-1-0-cam1_jpg.rf.4c7df98034024693f6b6ffc127132724.jpg\n",
            "110222-154419-1-1-0-cam1_jpg.rf.74df4b2cb08a280105a1089189e60a8e.jpg\n",
            "110222-154737-1-1-0-cam1_jpg.rf.37a7f22a548702bf4be72dd80e817e10.jpg\n",
            "110222-154800-1-1-0-cam1_jpg.rf.f36a5d6e56cd7df9638cc3e4f6b9c731.jpg\n",
            "110222-155325-1-1-0-cam1_jpg.rf.1e97aa281de0bee52d020ce65bdd8499.jpg\n",
            "110222-155834-1-1-0-cam1_jpg.rf.489dfdb95253329ebd2140e12e5ea7bf.jpg\n",
            "110222-160834-1-1-0-cam1_jpg.rf.551d9f5d54a2b25b98242891e1e0b5c9.jpg\n",
            "110222-161039-1-1-0-cam1_jpg.rf.7dc3ca48ae340e61135d6284cd6159c8.jpg\n",
            "110222-161104-1-1-0-cam1_jpg.rf.a1ee87dec173d038587e411c7f27ac5f.jpg\n",
            "110222-162632-1-1-0-cam1_jpg.rf.705bde0ca11110f2e66b03b2cf8beebd.jpg\n",
            "110222-162746-1-1-0-cam1_jpg.rf.c25ba43ddf8998d68f7963d4249a835c.jpg\n",
            "110222-163231-1-1-0-cam1_jpg.rf.42adfeef5883ef97c1b1fb355e9ebb43.jpg\n",
            "110222-163416-1-1-0-cam1_jpg.rf.8a6dfd2547bb9f400d5175f974c4de6c.jpg\n",
            "110222-164029-1-1-0-cam1_jpg.rf.73570f7d1fc785e9644ee567e689134d.jpg\n",
            "110222-170551-1-1-0-cam1_jpg.rf.1d2bc3731994cd33acd78a2e1d8cc1d1.jpg\n",
            "110222-170609-1-1-0-cam1_jpg.rf.449338756f8a993e9fad2a97add85cd8.jpg\n",
            "110222-170935-1-1-0-cam1_jpg.rf.635dfcb32b4404dcaa311588e75665cb.jpg\n",
            "110222-171535-1-1-0-cam1_jpg.rf.b9fabd44b212754997a2e5a90077c21e.jpg\n",
            "110222-173735-1-1-0-cam1_jpg.rf.70f95625004fb839daee5b7da7132aa3.jpg\n",
            "110222-174611-1-1-0-cam1_jpg.rf.d5a5106f895dd6486196a75dbc068626.jpg\n",
            "110222-184148-1-1-0-cam1_jpg.rf.01d4650248f0d747960d092b6a0ab313.jpg\n",
            "110222-185417-1-1-0-cam1_jpg.rf.c34418991434a3872e675da637daf044.jpg\n",
            "110222-190255-1-1-0-cam1_jpg.rf.ecd42c8c79524d7baffa657b62290c87.jpg\n",
            "110222-190458-1-1-0-cam1_jpg.rf.5a6c94af0c428a29d647fef180e6ab40.jpg\n",
            "110222-190626-1-1-0-cam1_jpg.rf.0849b84a9068f7319b9f90ebc753c9f3.jpg\n",
            "110222-201435-1-1-0-cam1_jpg.rf.ca64303bf5f96862c2873e3b94c72eee.jpg\n",
            "110222-204913-1-1-0-cam1_jpg.rf.405e786a3cfa6a47bd3f453a14cf839f.jpg\n",
            "110222-205236-1-1-0-cam1_jpg.rf.fbbf7471a3ac4bdbc0ba391bb722fc80.jpg\n",
            "110222-214851-1-1-0-cam1_jpg.rf.4d10c5279221b99b8e78641e59652489.jpg\n",
            "110222-215822-1-1-0-cam1_jpg.rf.0115ecb98c4d072d06143f73aa1fda68.jpg\n",
            "110222-220228-1-1-0-cam1_jpg.rf.35918670399b48453ebd39e7616ed6c9.jpg\n",
            "110222-231846-1-1-0-cam1_jpg.rf.4c8b3b56df2ff063adcb45049401c00d.jpg\n",
            "110222-232900-1-1-0-cam1_jpg.rf.55a2fe0991d5b0acd88e26c06373c42c.jpg\n",
            "110222-234203-1-1-0-cam1_jpg.rf.dfb7c769a86325d915991b06a4e6bf2a.jpg\n",
            "110222-234633-1-1-0-cam1_jpg.rf.2404171669e94727c32a15ce2bc5182d.jpg\n",
            "110_jpg.rf.e35d935a0b1c5ebd5fbf379e396ecfaf.jpg\n",
            "111104_jpg.rf.d4637c4b19c7327b76c330707c82981e.jpg\n",
            "111-E-6810-IX-05-20_jpg.rf.345e88124d496aca94aabaeb4ab073ef.jpg\n",
            "-1121F9BD-6C24-47D6-937E-DC2AB1906098-png_jpg.rf.c038f7aa1d1517bc2ee2597203c89d53.jpg\n",
            "112_jpg.rf.14a7e1aa6e0c1ec64fa141b828cb406a.jpg\n",
            "113-E-2283-RG-10-10_jpg.rf.b94fc5b78c45732beb5615c8ae759fb5.jpg\n",
            "114_jpg.rf.42ba33465a97880032425ed214109fab.jpg\n",
            "11546_Sb4733_14_jpg.rf.5f15426089500383e12847f03dbe7b2f.jpg\n",
            "116_jpg.rf.693ec4f22c0d97576f43a62354854729.jpg\n",
            "1-1871163958-Yamaha-R15-Plat-G-Pekalongan-Surat-Lengkap-Hidup-Panjang-Motor_jpg.rf.2636c3c37a60f1ae5d4f9c15f700e689.jpg\n",
            "118_jpg.rf.5236a880edf1c9e8c22b30c4c9d3654a.jpg\n",
            "119092_jpg.rf.6b539293e3691bdb8be62b2b89119d86.jpg\n",
            "11__flip_jpg.rf.90769017307a9523daa204a449d91b04.jpg\n",
            "11_jpg.rf.6c8687ad22b4d4a4dcbecd0a1374b0c5.jpg\n",
            "120222-015616-1-1-0-cam1_jpg.rf.79278277dc8695ba847178b2a35b9a1c.jpg\n",
            "120222-021626-1-1-0-cam1_jpg.rf.a5be5cc895c55b1bf2277655445ab2c8.jpg\n",
            "120222-023703-1-1-0-cam1_jpg.rf.5e63d66d5cfd59ae27616ec30b201d39.jpg\n",
            "120222-031653-1-1-0-cam1_jpg.rf.9b14767420841b18888b89996e8c9e94.jpg\n",
            "120222-033819-1-1-0-cam1_jpg.rf.af20cd35de5a0d24aa893cf054e6b269.jpg\n",
            "120222-041314-1-1-0-cam1_jpg.rf.6f2242d0fe43dd085d90573f65b5544d.jpg\n",
            "120222-053124-1-1-0-cam1_jpg.rf.eadebd190dd1dbdeb4a80ee6380f2a23.jpg\n",
            "120222-054655-1-1-0-cam1_jpg.rf.f58c773f985176b57521f75237bbdf2a.jpg\n",
            "120222-055111-1-1-0-cam1_jpg.rf.b09a84ea46732a2decc5adb331c29079.jpg\n",
            "120222-061035-1-1-0-cam1_jpg.rf.9fe51d287219c8025bc479eff72f051b.jpg\n",
            "120222-061846-1-1-0-cam1_jpg.rf.01e64a240c0eb71257c34d78c513a4ae.jpg\n",
            "120222-062210-1-1-0-cam1_jpg.rf.395d88166ef28eaad622d061bda45b31.jpg\n",
            "120222-064220-1-1-0-cam1_jpg.rf.495425e6d81758bf4e9cd9d23ff9b560.jpg\n",
            "120222-070549-1-1-0-cam1_jpg.rf.53057957480be5e3b5d9fc7b17fd5886.jpg\n",
            "120222-070717-1-1-0-cam1_jpg.rf.25ef440c0d27d89d9586b0afc4d689d6.jpg\n",
            "120222-070908-1-1-0-cam1_jpg.rf.63e3bfdf24864e0b5320e4f35aad6cd5.jpg\n",
            "120222-073435-1-1-0-cam1_jpg.rf.e5a2145e09e854924eb2a3ea4f0a466f.jpg\n",
            "120222-074024-1-1-0-cam1_jpg.rf.9927167ec2af165ca4957fd713caf6b8.jpg\n",
            "120222-074156-1-1-0-cam1_jpg.rf.7b0e30262d5d0f14d4d92c9ba865ef57.jpg\n",
            "120222-074421-1-1-0-cam1_jpg.rf.687b722fc86879a217e3ecac6295c956.jpg\n",
            "120222-075121-1-1-0-cam1_jpg.rf.f8cacc8ba3a4ac107c1616a99c934df6.jpg\n",
            "120222-081034-1-1-0-cam1_jpg.rf.213a851b166960da8c52d3cbe6ca1035.jpg\n",
            "120222-081057-1-1-0-cam1_jpg.rf.eec66e35f3e7b08df8377531291c4b27.jpg\n",
            "120222-082242-1-1-0-cam1_jpg.rf.b565dba413f7da743e13beebe0c71665.jpg\n",
            "120222-083609-1-1-0-cam1_jpg.rf.0736dd4d47619a45356810c505b4dc16.jpg\n",
            "120222-083816-1-1-0-cam1_jpg.rf.2a34e5338da58d7348732893c8eef879.jpg\n",
            "120222-094641-1-1-0-cam1_jpg.rf.0609830dd2884e460514f55534991463.jpg\n",
            "120222-111329-1-1-0-cam1_jpg.rf.47b711646a0fef3a4d56f25d61e99221.jpg\n",
            "120222-115655-1-1-0-cam1_jpg.rf.b2ed176d8f791dc511a34326af171a97.jpg\n",
            "120222-120955-1-1-0-cam1_jpg.rf.cf4cee892be287e3a05124a9d548fe65.jpg\n",
            "120222-123336-1-1-0-cam1_jpg.rf.11aea2a04ff9ac1214369b5f4b9e8567.jpg\n",
            "120222-124452-1-1-0-cam1_jpg.rf.fde3c47b705875259c04a394631e383b.jpg\n",
            "120222-131446-1-1-0-cam1_jpg.rf.8fb5617fdef8f759ab90b725bbac6632.jpg\n",
            "120222-134656-1-1-0-cam1_jpg.rf.2087bcf521f88d2f9ef9946e46962bc5.jpg\n",
            "120222-135859-1-1-0-cam1_jpg.rf.eeb1030773df3d7536f00fe54f085e53.jpg\n",
            "120222-143655-1-1-0-cam1_jpg.rf.bb207c73bfa0b477de4e5be282c8cf2c.jpg\n",
            "120222-144610-1-1-0-cam1_jpg.rf.35f5d02cd8b92754ca8e8e79f5f05e14.jpg\n",
            "120222-150727-1-1-0-cam1_jpg.rf.07405e14b09687cfc6e8ff9ee4ddd22a.jpg\n",
            "120222-152107-1-1-0-cam1_jpg.rf.94bb7ceab4c04cbfdb306685e70c4ac0.jpg\n",
            "120222-152145-1-1-0-cam1_jpg.rf.b5f534d16218d26e67a1f04d4b9e8e6f.jpg\n",
            "120222-153506-1-1-0-cam1_jpg.rf.38505e5f5f742f0d1dcd3695978df717.jpg\n",
            "120222-153923-1-1-0-cam1_jpg.rf.a5dec1524e68a10ef63b53c7378c23b6.jpg\n",
            "120222-154137-1-1-0-cam1_jpg.rf.92f386292667cbd3e6e1e7510392c004.jpg\n",
            "120222-154956-1-1-0-cam1_jpg.rf.e9c5aaff15892fc62c446a859b9ad58f.jpg\n",
            "120222-155805-1-1-0-cam1_jpg.rf.1c8623e6956afae535acdb2d58bfeab0.jpg\n",
            "120222-155825-1-1-0-cam1_jpg.rf.bf65ce4ee7264961c62a4ae951001b53.jpg\n",
            "120222-160139-1-1-0-cam1_jpg.rf.cb9b88d27412c8ad767270ae97368d02.jpg\n",
            "120222-161328-1-1-0-cam1_jpg.rf.f4e49946d03267d85d8f983f68db7c47.jpg\n",
            "120222-162535-1-1-0-cam1_jpg.rf.0701467a0c190d99856a2921ce79da22.jpg\n",
            "120222-163956-1-1-0-cam1_jpg.rf.e57e5b4f018bba2f192776e4d340ca68.jpg\n",
            "120222-164130-1-1-0-cam1_jpg.rf.9d9c393bc833665d80eca4741f2de13b.jpg\n",
            "120222-164533-1-1-0-cam1_jpg.rf.e300c195d4e8c6c785041085cac45523.jpg\n",
            "120222-164715-1-1-0-cam1_jpg.rf.fbb0ef0383f16d508af541e235423c04.jpg\n",
            "120222-165731-1-1-0-cam1_jpg.rf.20aa0a58ae8a3ba659294639b43d21a9.jpg\n",
            "120222-165853-1-1-0-cam1_jpg.rf.84bfb5c243c8361a319418f8ad8dc123.jpg\n",
            "120222-165933-1-1-0-cam1_jpg.rf.9f3c9527786d36156ff42499615d064d.jpg\n",
            "120222-170928-1-1-0-cam1_jpg.rf.6ce7c69358b5bea04c6475f1651feeaf.jpg\n",
            "120222-171110-1-1-0-cam1_jpg.rf.5f7d96bc1f572873ff74086354ca6266.jpg\n",
            "120222-171851-1-1-0-cam1_jpg.rf.e4f5e5e4aa1f5226c238270007fd9762.jpg\n",
            "120222-172215-1-1-0-cam1_jpg.rf.7ebd26408c015a11cfb89b1e54f98dbe.jpg\n",
            "120222-172711-1-1-0-cam1_jpg.rf.bd0d72c0911685e201b85f1a27248c1c.jpg\n",
            "120222-173844-1-1-0-cam1_jpg.rf.2ae5c0838c220c74d478e27011f5fed2.jpg\n",
            "120222-174640-1-1-0-cam1_jpg.rf.d9a0fc7d6b28d60d9d3bf86678169d95.jpg\n",
            "120222-175018-1-1-0-cam1_jpg.rf.aa8d197c7b53c7d12fb35b329072c560.jpg\n",
            "120222-175820-1-1-0-cam1_jpg.rf.bf020a9e81f6cb312e283be617f8bed7.jpg\n",
            "120222-185238-1-1-0-cam1_jpg.rf.46200a128bcc763461fcfccdc19e5bb1.jpg\n",
            "120222-192453-1-1-0-cam1_jpg.rf.d0661139532331d36219570ed0414c33.jpg\n",
            "120222-201212-1-1-0-cam1_jpg.rf.6d379ba1c015a67f6bf9943651b4d214.jpg\n",
            "120222-224223-1-1-0-cam1_jpg.rf.c550b25e7949ef8cb928d8eae5a7ca28.jpg\n",
            "120222-234634-1-1-0-cam1_jpg.rf.48003bac9931138564c8871ccae5f845.jpg\n",
            "120222-235013-1-1-0-cam1_jpg.rf.b07eb0f547f569b29f6394cb3b406400.jpg\n",
            "1-2109219950-Motor-Yamaha-Mio-Soul-GT-Second-Tahun-2012-Plat-T-Karawang-Jawa-Barat_jpg.rf.0ab4d28bae2bdec9d60351d2291e1d26.jpg\n",
            "1211192truk1780x390_jpg.rf.3fb8e33c2d5fefb24360e6ef353e7b71.jpg\n",
            "1211192truk1780x390_jpg.rf.41a0ecf3bc1fc4858d749836e6a33deb.jpg\n",
            "1211192truk1780x390_jpg.rf.8a4ebd1f1971662d3bf7e441ec44c325.jpg\n",
            "121_jpg.rf.b51e3b6b26b171fcf6bb8c2c61fe255b.jpg\n",
            "122235898-ho-chi-minh-city-viet-nam-april-26-vietnamese-woman-wear-face-mask-to-sun-protection-ride-bicycle-un__flip_jpg.rf.d5c7d8961c0fb24249e7a54e30b59718.jpg\n",
            "122-E-3206-PAO-06-22_jpeg_jpg.rf.d56416bbec8c8b12b861d51946c1b558.jpg\n",
            "122_jpg.rf.47aaa838a578e7cf3891f3fbd31f0f4b.jpg\n",
            "1231231_PNG_jpg.rf.486da7da79cd3dca8ce642a283f94809.jpg\n",
            "123-E-4603-PAE-07-21_jpeg_jpg.rf.114609d384ddc4d1f8119bcc7323bf44.jpg\n",
            "123_jpg.rf.548181a5b327e922047f40ab91a6ffa2.jpg\n",
            "124-E-4564-RRR-11-21_jpg.rf.cfd2d4fc3b78a69b50a32359afa4f4e4.jpg\n",
            "125-E-4172-QB-11-22_jpeg_jpg.rf.0fd1f97d9fe0da02a84a26ec685dff9b.jpg\n",
            "125-E-4172-QB-11-22_jpeg_jpg.rf.3af9ac768fb0ca532b1c67106f10b4cc.jpg\n",
            "125_jpg.rf.0215b5b588b2d9f43183d4917771e457.jpg\n",
            "126-E-3453-TN-06-22_jpeg_jpg.rf.7daf9409a7dc5977e78277ca0c59cbb1.jpg\n",
            "126_jpg.rf.aa5f9ec91b74c7c94a84e4f8cbf0b8a2.jpg\n",
            "127-E-6932-TW-05-18_jpg.rf.e8fa8dd60b764cf44e2d9d04658703d9.jpg\n",
            "127_jpg.rf.fad8cec768e8dcb9f7e67c284574a5d0.jpg\n",
            "128887_jpg.rf.4f8c6e59bad9609ac90076ba8a9fb0e2.jpg\n",
            "128_jpg.rf.c808171a99ff7b2e3c445efbdcccff4a.jpg\n",
            "12988780_MTAwMC03OTUtYTcxNGRiOGUwZQ_jpg.rf.3434f2abe8c850028ec744a9afd53d7b.jpg\n",
            "12988780_MTAwMC03OTUtYTcxNGRiOGUwZQ_jpg.rf.716a785deca6ae78bfd93793bc85b953.jpg\n",
            "129-E-6410-TX-06-18_jpeg_jpg.rf.a01ff788e6c1c53450b1f9bbb550e683.jpg\n",
            "-12D2734F-0757-4B08-9819-D3704009B312-png_jpg.rf.4e58df75b4bc8dfe184a0f865ebb3587.jpg\n",
            "-12D4A1A7-14ED-4777-BC81-494D863072FC-png_jpg.rf.6a0a8d2f0f39c53a2a6bdb1682ca0f52.jpg\n",
            "12easd12_PNG_jpg.rf.4fac2b2f65a83e2472ec9ac66a92b10e.jpg\n",
            "12_jpg.rf.dce7d93025cb31b2c7cc85d15b3a7226.jpg\n",
            "130222-013139-1-1-0-cam1_jpg.rf.65925a46447954d2b92a61957b769122.jpg\n",
            "130222-014742-1-1-0-cam1_jpg.rf.1dcc9ff5287f4af95de0329675eacdd2.jpg\n",
            "130222-023116-1-1-0-cam1_jpg.rf.65b9e507673c11b8769df4f481b53dfe.jpg\n",
            "130222-035712-1-1-0-cam1_jpg.rf.0873e1b3af9cc241e24864e79e5a3553.jpg\n",
            "130222-063727-1-1-0-cam1_jpg.rf.b985a1b9335239193809ac261307348b.jpg\n",
            "130222-070013-1-1-0-cam1_jpg.rf.397681eb944f8b8246c8b6298e6d12be.jpg\n",
            "130222-070520-1-1-0-cam1_jpg.rf.bcfa2631774364622b1df4cbfa34726a.jpg\n",
            "130222-073155-1-1-0-cam1_jpg.rf.4e5f7fa9d86d224a249c6372665f7fb2.jpg\n",
            "130222-073247-1-1-0-cam1_jpg.rf.fcf138426633c0ae1903b064eda28bfd.jpg\n",
            "130222-073654-1-1-0-cam1_jpg.rf.01a0a2c747fd60aa866fe83adbe120bd.jpg\n",
            "130222-073742-1-1-0-cam1_jpg.rf.44e4d3a3312a36cb0faedfa9b9a5e313.jpg\n",
            "130222-073748-1-1-0-cam1_jpg.rf.b04cb0aab82c76a3f1f6e9dd224ddd57.jpg\n",
            "130222-073810-1-1-0-cam1_jpg.rf.e638775f6fe4c201abd8f18450266ded.jpg\n",
            "130222-074746-1-1-0-cam1_jpg.rf.eb4ed11ee6c045e2539ad2ac0c8df2dd.jpg\n",
            "130222-075142-1-1-0-cam1_jpg.rf.68933a4514cef8ee50f52581ee0c40cd.jpg\n",
            "130222-080419-1-1-0-cam1_jpg.rf.9f1dedc6652cf982a8e49024aff766db.jpg\n",
            "130222-080719-1-1-0-cam1_jpg.rf.2b186781721e82b61bb0a259bc91ba4e.jpg\n",
            "130222-082934-1-1-0-cam1_jpg.rf.4f0d208a345ddae7600a36eb904e1835.jpg\n",
            "130222-091146-1-1-0-cam1_jpg.rf.9dd988f141a1292fa6c5d5e38c232814.jpg\n",
            "130222-091730-1-1-0-cam1_jpg.rf.9953c90c8da951973154a9e4ad3c9d5f.jpg\n",
            "130222-093356-1-1-0-cam1_jpg.rf.599e86ee0a674abe88f5c92e8e95a9ef.jpg\n",
            "130222-100929-1-1-0-cam1_jpg.rf.41478e40a72b0b40fbee3f5beb66d46d.jpg\n",
            "130222-123412-1-1-0-cam1_jpg.rf.e87b0e8973be29119c06d49e17ba8376.jpg\n",
            "130222-133230-1-1-0-cam1_jpg.rf.cf97456f1388f0da406dd1e3317829c1.jpg\n",
            "130222-133650-1-1-0-cam1_jpg.rf.9e8d29dc17fbd25905741e183bcf891a.jpg\n",
            "130222-135203-1-1-0-cam1_jpg.rf.df230f5009268b963541cf99bea82d8e.jpg\n",
            "130222-135434-1-1-0-cam1_jpg.rf.e9eb1878a4921144228c4c284f6c6c89.jpg\n",
            "130222-140051-1-1-0-cam1_jpg.rf.290495c2c47ee5fedf0fda5b0e3cc61b.jpg\n",
            "130222-140122-1-1-0-cam1_jpg.rf.1b23acdf7d72bde64d686d6f42d45316.jpg\n",
            "130222-144044-1-1-0-cam1_jpg.rf.6e1028e22220380d1014efac89819d33.jpg\n",
            "130222-144913-1-1-0-cam1_jpg.rf.0f0257edd05681eb2e86d242bd8fdcca.jpg\n",
            "130222-153439-1-1-0-cam1_jpg.rf.b031f23e85033cac23a8ef8ff244500e.jpg\n",
            "130222-153830-1-1-0-cam1_jpg.rf.4932dc713becb2cbff9e0e5520d15add.jpg\n",
            "130222-154102-1-1-0-cam1_jpg.rf.da646bfebd5c56d95226f3f87c5fc05f.jpg\n",
            "130222-154153-1-1-0-cam1_jpg.rf.02964f904066739f956521d53661a8fd.jpg\n",
            "130222-155916-1-1-0-cam1_jpg.rf.631013230f2bde6719aee2b485acb712.jpg\n",
            "130222-161042-1-1-0-cam1_jpg.rf.79fcdd360763a0bd954a01c287dde9d2.jpg\n",
            "130222-163606-1-1-0-cam1_jpg.rf.fcfc6280c1dcf8e052816c0a6f87c556.jpg\n",
            "130222-165320-1-1-0-cam1_jpg.rf.b85c0540dbde90551f6850c9dd9282e2.jpg\n",
            "130222-172534-1-1-0-cam1_jpg.rf.70bd3142238cc2f4e48bdb8909d1f63d.jpg\n",
            "130222-172544-1-1-0-cam1_jpg.rf.3c102327a19a005d5d522343c3e761eb.jpg\n",
            "130222-173016-1-1-0-cam1_jpg.rf.7796d3c11a32e86afe9e451a8c7314f8.jpg\n",
            "130222-173444-1-1-0-cam1_jpg.rf.93746a0d5f9b87c2074d612a6a1ba4f8.jpg\n",
            "130222-174241-1-1-0-cam1_jpg.rf.c46988c9d344b11edb4205735ea0186b.jpg\n",
            "130222-184903-1-1-0-cam1_jpg.rf.1bbf814a476af182f4a1ef9e68ca1d46.jpg\n",
            "130222-201744-1-1-0-cam1_jpg.rf.56d5599f0c5ef7a92149fb11e6427a9f.jpg\n",
            "130222-204748-1-1-0-cam1_jpg.rf.253ea011bdfe916745cb46ae1e97d3b3.jpg\n",
            "130222-215033-1-1-0-cam1_jpg.rf.ed2ad82e2d2f759c744d0e68ca971dd9.jpg\n",
            "130222-222715-1-1-0-cam1_jpg.rf.e60ff46bd755fd971ab0cae55ef1f6e0.jpg\n",
            "130222-222738-1-1-0-cam1_jpg.rf.9038147590c184de215ce459d5ee150e.jpg\n",
            "130222-233954-1-1-0-cam1_jpg.rf.b1235f9f44142649ec4fc2981534a242.jpg\n",
            "130222-234540-1-1-0-cam1_jpg.rf.443939c5ddd64fdee4527507b92d3694.jpg\n",
            "13193_jpg.rf.0948a6688bbb2cc5a84696f676bb1f91.jpg\n",
            "131-E-5789-QD-12-18_jpg.rf.ffe6a28c642475a28e8a01322904043b.jpg\n",
            "131_jpg.rf.37d549791da74da78fb08004ddcf186e.jpg\n",
            "132_jpg.rf.d815830678b47cc6a033714f38b0fd2f.jpg\n",
            "134-E-2194-Q-07-18_jpeg_jpg.rf.fc6b7b986ca830b0307eb43cb524c929.jpg\n",
            "134_jpg.rf.17c2fd2e9610ee1a0097e1717fa2d3c4.jpg\n",
            "135-E-4721-SJ-11-20_jpeg_jpg.rf.a325ab4548a01317fe850b094dc6bd00.jpg\n",
            "135_jpg.rf.905d00f17121ce8ad27b3f90fb7331e4.jpg\n",
            "13685839-hanoi-vietnam-february-19-traffic-on-hanoi-street-hanoi-vietnam-february-19-2011-in-hanoi-vietnam_jpg.rf.e56ed8d646a50dec8df345def2f745d7.jpg\n",
            "136-E-3916-P-05-21_jpg.rf.d28f78c2c7542378f10c7059612522b9.jpg\n",
            "136_jpg.rf.1fb323a984c503fb827589a75121b50a.jpg\n",
            "137-E-4958-QS-05-20_jpg.rf.3a24377399ca725e9d12ac57ae96d539.jpg\n",
            "138-E-4746-PAI-12-21_jpg.rf.aa95485a6c450286bb33d5ffc0772cb2.jpg\n",
            "138_jpg.rf.ab248b7a79ec99cd03eaf111613e7191.jpg\n",
            "139345_jpg.rf.50c739a18c4371e618a7c0e146e9eb5f.jpg\n",
            "139-E-5515-QG-04-19_jpg.rf.bc79ea894e857e3eb70792e94c0e10ce.jpg\n",
            "139_jpg.rf.f5958df192cf2c406586b9eaa90e4041.jpg\n",
            "13_jpeg_jpg.rf.4afdafb0e9761525aac79c3c560d46ba.jpg\n",
            "13-Kode-Plat-Kendaraan-Kota-Administrasi-Jakarta-Pusat-_jpg.rf.f6eba7fc5beadb30f4989e74c3b08277.jpg\n",
            "140222-000702-1-1-0-cam1_jpg.rf.83991023e453e7037fc0e822f454b604.jpg\n",
            "140222-005453-1-1-0-cam1_jpg.rf.b808c137fae06863fd3b98fd78740ea1.jpg\n",
            "140222-011519-1-1-0-cam1_jpg.rf.b01251c6f295e5c19f9b93bca0381ad6.jpg\n",
            "140222-014402-1-1-0-cam1_jpg.rf.63c059ce5b6e7dea93bb9d7668812aa0.jpg\n",
            "140222-020456-1-1-0-cam1_jpg.rf.01f1648af87637d74d70b414ef7b2f24.jpg\n",
            "140222-024313-1-1-0-cam1_jpg.rf.e9b7ac134ed0120c5604b21c887635ee.jpg\n",
            "140222-030208-1-1-0-cam1_jpg.rf.e4960721df62f81f5060281581d7443c.jpg\n",
            "140222-034239-1-1-0-cam1_jpg.rf.bf1c515e5e1ac5f68252da92d5c4cf17.jpg\n",
            "140222-041004-1-1-0-cam1_jpg.rf.f918fc15f160edf2fefecb6166db6bde.jpg\n",
            "140222-042538-1-1-0-cam1_jpg.rf.136e23c23e78fc03ac319a8e259f1159.jpg\n",
            "140222-042854-1-1-0-cam1_jpg.rf.bdb97f235972f3a33a36ac71974b425d.jpg\n",
            "140222-043005-1-1-0-cam1_jpg.rf.756d08076f44690eb0ceb4096979aeae.jpg\n",
            "140222-043823-1-1-0-cam1_jpg.rf.e458957ba5737be5d699b78f92088d3d.jpg\n",
            "140222-044726-1-1-0-cam1_jpg.rf.c74dbe1f55bbd26c03d5eeca39b948a9.jpg\n",
            "140222-044933-1-1-0-cam1_jpg.rf.bf7176ab1296ebf0a23e555a3acc4e6a.jpg\n",
            "140222-055830-1-1-0-cam1_jpg.rf.17b3489c25d9de7cc382db1a18e6a8ea.jpg\n",
            "140222-060504-1-1-0-cam1_jpg.rf.b08b86258b52f73df7946accb2b65f87.jpg\n",
            "140222-060601-1-1-0-cam1_jpg.rf.d45cc355d2b92e7067e161d0340cb480.jpg\n",
            "140222-060612-1-1-0-cam1_jpg.rf.ec15cd510812ed82c5ccb76e0c3618cc.jpg\n",
            "140222-060634-1-1-0-cam1_jpg.rf.62ed49a57992bc61502f9407f661794b.jpg\n",
            "140222-060809-1-1-0-cam1_jpg.rf.2ec38de69f4fd40bc666060435db367d.jpg\n",
            "140222-060840-1-1-0-cam1_jpg.rf.61ceb9041a2f9a1c4c5777c51abc457e.jpg\n",
            "140222-060911-1-1-0-cam1_jpg.rf.8ea075e608a89f8f7824232a448fdf90.jpg\n",
            "140222-061011-1-1-0-cam1_jpg.rf.d6223a0abf6a0da96bc25dcc6fc542e1.jpg\n",
            "140222-061122-1-1-0-cam1_jpg.rf.afea26f5e9b32b88e1d800df538e84eb.jpg\n",
            "140222-061310-1-1-0-cam1_jpg.rf.0648ab004b4176c08b94f1011ee9e4da.jpg\n",
            "140222-061510-1-1-0-cam1_jpg.rf.25a64d3019ebba0b7d3a93f92ea157f1.jpg\n",
            "140222-061525-1-1-0-cam1_jpg.rf.fa3a8e9876232f0ed662b5a2e3717041.jpg\n",
            "140222-062413-1-1-0-cam1_jpg.rf.bae9b1665855d06f27417343a1dcce0b.jpg\n",
            "140222-062639-1-1-0-cam1_jpg.rf.3208ecabe46d7aafb9acfe4928949d31.jpg\n",
            "140222-062652-1-1-0-cam1_jpg.rf.69b332b0021562c81b91b54809b025b9.jpg\n",
            "140222-062950-1-1-0-cam1_jpg.rf.6ed2c5a3e4e2665cb95013a4105d6885.jpg\n",
            "140222-063044-1-1-0-cam1_jpg.rf.efa9d0656be8f4d7353454cd781703d1.jpg\n",
            "140222-063239-1-1-0-cam1_jpg.rf.09c2b69c52719b06dc9cb423e196c54b.jpg\n",
            "140222-063341-1-1-0-cam1_jpg.rf.22c8a73517e6b07aed56c61b25ecd767.jpg\n",
            "140222-063853-1-1-0-cam1_jpg.rf.322bc6423096bcdc9caaec3f56702953.jpg\n",
            "140222-063922-1-1-0-cam1_jpg.rf.0982bf6e7fac97a4cd6658068e703bf5.jpg\n",
            "140222-064012-1-1-0-cam1_jpg.rf.decb74996725695828f3268d78f7ecda.jpg\n",
            "140222-064643-1-1-0-cam1_jpg.rf.b25ed08eab7128b8b60bb30718e48e7a.jpg\n",
            "140222-065949-1-1-0-cam1_jpg.rf.af3a39b879683ad476a982638270e67d.jpg\n",
            "140222-070157-1-1-0-cam1_jpg.rf.3918ba7ce9ead23fefb2649e5894ea26.jpg\n",
            "140222-070217-1-1-0-cam1_jpg.rf.2ec7ecf4005aa4e17d06fed797069d72.jpg\n",
            "140222-070301-1-1-0-cam1_jpg.rf.0cf6e2faeb39dc58e2a351175778e7f7.jpg\n",
            "140222-070424-1-1-0-cam1_jpg.rf.2378993a65653a8f19bc5318341c4b75.jpg\n",
            "140222-070442-1-1-0-cam1_jpg.rf.565b63fa259998637a0afef6a260e9b6.jpg\n",
            "140222-070531-1-1-0-cam1_jpg.rf.c3ae39eebf6e6a06d02520517639edb8.jpg\n",
            "140222-070612-1-1-0-cam1_jpg.rf.7674a76d38b010a9693e4e6ec65518c1.jpg\n",
            "140222-070924-1-1-0-cam1_jpg.rf.74ffeb12e417c08b1783e8fb68ffa252.jpg\n",
            "140222-071037-1-1-0-cam1_jpg.rf.403abc08d53fce6c9ed534732f05cabe.jpg\n",
            "140222-071112-1-1-0-cam1_jpg.rf.d41249b37e93e672fa91850cd6a0ebe8.jpg\n",
            "140222-071357-1-1-0-cam1_jpg.rf.3a84134537b51284a4f2fa5b1fcb156b.jpg\n",
            "140222-071559-1-1-0-cam1_jpg.rf.30abc520c8f84eb0a6a1444280595db5.jpg\n",
            "140222-072010-1-1-0-cam1_jpg.rf.60f5069b273e69fcf3a37604d15b10f9.jpg\n",
            "140222-072321-1-1-0-cam1_jpg.rf.e18be1cdd9530082f5418347acf6923e.jpg\n",
            "140222-072446-1-1-0-cam1_jpg.rf.02a85b2767c47f86d4fa1d14c382b2b1.jpg\n",
            "140222-073115-1-1-0-cam1_jpg.rf.522ce6fb6d77a1f45a2e31bca9de0371.jpg\n",
            "140222-074020-1-1-0-cam1_jpg.rf.2600cdff1708c061668bdebdc923b500.jpg\n",
            "140222-074433-1-1-0-cam1_jpg.rf.779c9b828940da1781c45f088858840e.jpg\n",
            "140222-075442-1-1-0-cam1_jpg.rf.6cf5f69dc139e7c30b101f609c513f8d.jpg\n",
            "140222-080936-1-1-0-cam1_jpg.rf.384249afc6a9a7ee514144673fe1a75e.jpg\n",
            "140222-082150-1-1-0-cam1_jpg.rf.9016aa8b7ff3a108973adf932c10b79a.jpg\n",
            "140222-084425-1-1-0-cam1_jpg.rf.db0a51d4c9ef7f220120c32f165c021a.jpg\n",
            "140222-084528-1-1-0-cam1_jpg.rf.f0389a45429e43e14b162d839fcad494.jpg\n",
            "140222-084802-1-1-0-cam1_jpg.rf.76e2491eaad55f878dc9c86082c0c056.jpg\n",
            "140222-090353-1-1-0-cam1_jpg.rf.8305a0391d2f605eb56a5e1aa142fa09.jpg\n",
            "140222-091424-1-1-0-cam1_jpg.rf.9ba79f84f2cebe08862242c94ce3e14f.jpg\n",
            "140222-091701-1-1-0-cam1_jpg.rf.508989b7617aea91f965b9c67fb0fa9f.jpg\n",
            "140222-093735-1-1-0-cam1_jpg.rf.2176275ad59f9aced522242f2c6cebcd.jpg\n",
            "140222-113901-1-1-0-cam1_jpg.rf.96185db3078427f9da0ef7d5d17acdfb.jpg\n",
            "140222-114635-1-1-0-cam1_jpg.rf.208a2e4fad2733c43bf7a5f312c4dc5a.jpg\n",
            "140222-115107-1-1-0-cam1_jpg.rf.21c79892f98d0d928c0681c35fd13635.jpg\n",
            "140222-121257-1-1-0-cam1_jpg.rf.fabae1b18a90c45aa848d2f442e990c6.jpg\n",
            "140222-121848-1-1-0-cam1_jpg.rf.0d202d3a56027575a0a37e9b31996881.jpg\n",
            "140222-122544-1-1-0-cam1_jpg.rf.6ac8f6b91ea1419631f768b8294d2745.jpg\n",
            "140222-123501-1-1-0-cam1_jpg.rf.3c90e26a448186330ea26b82aa5ec692.jpg\n",
            "140222-124232-1-1-0-cam1_jpg.rf.59c6d061d587be968f0b0e85b069b905.jpg\n",
            "140222-125141-1-1-0-cam1_jpg.rf.a05e086196bbc12b12e42ef7d6fd6252.jpg\n",
            "140222-130351-1-1-0-cam1_jpg.rf.c4d37c14190652b42438af7cb3689241.jpg\n",
            "140222-131836-1-1-0-cam1_jpg.rf.787d745b5feef3ae1d10bd02522be282.jpg\n",
            "140222-132257-1-1-0-cam1_jpg.rf.bf9b9ed0a09ddf8a1460f9e7e79670ab.jpg\n",
            "140222-133342-1-1-0-cam1_jpg.rf.17f63e323bf93d02a52d8a19db89dc25.jpg\n",
            "140222-133431-1-1-0-cam1_jpg.rf.60f43f3b2b9564e925ab12ef3090d360.jpg\n",
            "140222-134555-1-1-0-cam1_jpg.rf.c1d3e51f546b48e4f44dabeb974dc6eb.jpg\n",
            "140222-135031-1-1-0-cam1_jpg.rf.b0aa8b223f269068ca650360730c67e4.jpg\n",
            "140222-135212-1-1-0-cam1_jpg.rf.26e8d2a26f2a1ad9ff351cf87c99e570.jpg\n",
            "140222-135535-1-1-0-cam1_jpg.rf.886c4a2c45d5419c11a2534a58221c81.jpg\n",
            "140222-135619-1-1-0-cam1_jpg.rf.66b1d818993f737e64ee7a704c7538ce.jpg\n",
            "140222-135639-1-1-0-cam1_jpg.rf.fac15a8f989b8e009453595d4794b908.jpg\n",
            "140222-135913-1-1-0-cam1_jpg.rf.3a3778163f0bfbe09623c93df03dec8a.jpg\n",
            "140222-140149-1-1-0-cam1_jpg.rf.af930533c138af569158892a5f4dc405.jpg\n",
            "140222-140340-1-1-0-cam1_jpg.rf.fb7e1a0c943cc3f462dfabbcae78786a.jpg\n",
            "140222-140522-1-1-0-cam1_jpg.rf.8c93f652bdfe9f3582648f33a0008f12.jpg\n",
            "140222-140916-1-1-0-cam1_jpg.rf.7a7d1812e3d0b17726753fa417990076.jpg\n",
            "140222-141214-1-1-0-cam1_jpg.rf.085914298f4754041122e161dc42e968.jpg\n",
            "140222-142030-1-1-0-cam1_jpg.rf.c9dea60fda3a82fd95a339e3abde3148.jpg\n",
            "140222-142032-1-1-0-cam1_jpg.rf.eaa52e9b13d659bf09494a7d30cc3644.jpg\n",
            "140222-142548-1-1-0-cam1_jpg.rf.3f04fb7e030b4482c946f5ebd1ebfb35.jpg\n",
            "140222-144234-1-1-0-cam1_jpg.rf.770346f486b64f1699aaf29ed33c61e8.jpg\n",
            "140222-144251-1-1-0-cam1_jpg.rf.554af048b2c11ccd4007e86fa441fdb8.jpg\n",
            "140222-144439-1-1-0-cam1_jpg.rf.c035c7168f1e5f2212739de5c45d76e4.jpg\n",
            "140222-144638-1-1-0-cam1_jpg.rf.03b0f400cca5ccd60e8ab638a32538a4.jpg\n",
            "140222-144653-1-1-0-cam1_jpg.rf.d93444e9d0da00020701c3e246aebf5e.jpg\n",
            "140222-144812-1-1-0-cam1_jpg.rf.a19cb7cc576b753d8928053f05a93c52.jpg\n",
            "140222-144936-1-1-0-cam1_jpg.rf.3e5d10a8e56d16f36f66aca6cdb523fe.jpg\n",
            "140222-145030-1-1-0-cam1_jpg.rf.0a5d5fd5e3477387fab68d8507c1ea96.jpg\n",
            "140222-145140-1-1-0-cam1_jpg.rf.0249f86e3f23dff112747a954d3b4f26.jpg\n",
            "140222-145237-1-1-0-cam1_jpg.rf.1f951eba428086c59c95b55950027d22.jpg\n",
            "140222-145302-1-1-0-cam1_jpg.rf.ece1d0e2172331e61f4edeb885d38164.jpg\n",
            "140222-145411-1-1-0-cam1_jpg.rf.b5342aafeb483f81bea02d1f08bf86f6.jpg\n",
            "140222-145803-1-1-0-cam1_jpg.rf.df96ec0377c7e9d18a5849a267bbc89a.jpg\n",
            "140222-145815-1-1-0-cam1_jpg.rf.ff765988e2315600bcdeac4cfcb70d6c.jpg\n",
            "140222-150051-1-1-0-cam1_jpg.rf.8eb3ac7f874f36ba0d172e7395d63c84.jpg\n",
            "140222-150216-1-1-0-cam1_jpg.rf.a9eeec71a20d7e7923a0093b6f7be9d6.jpg\n",
            "140222-150233-1-1-0-cam1_jpg.rf.04527cb17d73577c1dd2353e47e28f98.jpg\n",
            "140222-150559-1-1-0-cam1_jpg.rf.ed39c72b2c0029201872aae8402ed180.jpg\n",
            "140222-151105-1-1-0-cam1_jpg.rf.604edf2c546aa58a6e955ffa8c2862e8.jpg\n",
            "140222-151402-1-1-0-cam1_jpg.rf.7429a51a70e9e2e0263fd966c3c52b68.jpg\n",
            "140222-151906-1-1-0-cam1_jpg.rf.d4a292c13ea4cb61d6d43a9068981c7b.jpg\n",
            "140222-151916-1-1-0-cam1_jpg.rf.d3d2bf95ddbac5cd27bf842a119e0c20.jpg\n",
            "140222-152222-1-1-0-cam1_jpg.rf.a85dc3dd4f6b6d561969dd9b9fdb03c7.jpg\n",
            "140222-152230-1-1-0-cam1_jpg.rf.b063f7d8886ae1af09a50de3d5e02ea9.jpg\n",
            "140222-152654-1-1-0-cam1_jpg.rf.9ec9e1a3568d52121dfe0c595a85891f.jpg\n",
            "140222-152730-1-1-0-cam1_jpg.rf.7e0eb3602df254377bc6861b02ed388a.jpg\n",
            "140222-152746-1-1-0-cam1_jpg.rf.627cd2c66252c2384a00666fc602c0c9.jpg\n",
            "140222-152929-1-1-0-cam1_jpg.rf.e563ef1748b54f6f29cd7a33d813d7ca.jpg\n",
            "140222-152946-1-1-0-cam1_jpg.rf.33bda986dcc4879474258ccc2c91f40c.jpg\n",
            "140222-153210-1-1-0-cam1_jpg.rf.26db43bfdf8ae3964cf0b6f95836f031.jpg\n",
            "140222-153234-1-1-0-cam1_jpg.rf.d35641307ff8ee959162a25d620e7b3d.jpg\n",
            "140222-153237-1-1-0-cam1_jpg.rf.d09b5dd8de0ac2aea23835cf2abfba1c.jpg\n",
            "140222-153313-1-1-0-cam1_jpg.rf.75191744c4001a7be5d234d8f754c13d.jpg\n",
            "140222-153331-1-1-0-cam1_jpg.rf.802a638333adf62f1b9cb26263b72ce9.jpg\n",
            "140222-153347-1-1-0-cam1_jpg.rf.23f6012df17b4712d43d9ec303c22079.jpg\n",
            "140222-153717-1-1-0-cam1_jpg.rf.ec9f3af6bd97e29d602048b7cdd1ec2e.jpg\n",
            "140222-153916-1-1-0-cam1_jpg.rf.63abda420b6ff062877673396d9f1ca2.jpg\n",
            "140222-153956-1-1-0-cam1_jpg.rf.179888baff8837323a59dfcd6f2177e8.jpg\n",
            "140222-154300-1-1-0-cam1_jpg.rf.48518b9feb06776ed54baccce58ffa32.jpg\n",
            "140222-154450-1-1-0-cam1_jpg.rf.4baef410682a2920abf3b57479673c37.jpg\n",
            "140222-154538-1-1-0-cam1_jpg.rf.3c197ff65934137d999384e23e9b5666.jpg\n",
            "140222-154559-1-1-0-cam1_jpg.rf.2a7e1b3e7c8f92de143c457167dd7543.jpg\n",
            "140222-154628-1-1-0-cam1_jpg.rf.24d4d22dae879c45d30526fd3360b054.jpg\n",
            "140222-154803-1-1-0-cam1_jpg.rf.6b460973b32c4d3f8840b8ffea6a153a.jpg\n",
            "140222-154824-1-1-0-cam1_jpg.rf.0962af4e9d14c8f23d78392c04ce90db.jpg\n",
            "140222-154847-1-1-0-cam1_jpg.rf.f59f0e92d20c56418230972ba6df9a47.jpg\n",
            "140222-155032-1-1-0-cam1_jpg.rf.03f069adc5a54f5b208647f095a1b801.jpg\n",
            "140222-155115-1-1-0-cam1_jpg.rf.c556bf51dda4816a3ed359e1027e5d7e.jpg\n",
            "140222-155258-1-1-0-cam1_jpg.rf.891d6ff6341ede5fe931d417a7cfde17.jpg\n",
            "140222-155259-1-1-0-cam1_jpg.rf.977536674b9524da805bde07cacf14de.jpg\n",
            "140222-155744-1-1-0-cam1_jpg.rf.8d7e62641ff5cc3e8efe446b77743f6c.jpg\n",
            "140222-155838-1-1-0-cam1_jpg.rf.0f4c8bb4a16a33f642aded2f716b4316.jpg\n",
            "140222-160000-1-1-0-cam1_jpg.rf.1afd395fd51d19fed4c9aaba5199bea7.jpg\n",
            "140222-160256-1-1-0-cam1_jpg.rf.4baa2a0d462a5781f23a77fb6d909f0b.jpg\n",
            "140222-160422-1-1-0-cam1_jpg.rf.f62eba6bc3e6e933bc3faee606f04e8c.jpg\n",
            "140222-160426-1-1-0-cam1_jpg.rf.610a367ae56dc461346904b070f32f6f.jpg\n",
            "140222-160920-1-1-0-cam1_jpg.rf.0da3652e0e31911eb4dc46b295b98ce1.jpg\n",
            "140222-161048-1-1-0-cam1_jpg.rf.8c66f5c9f7e576805b2a9ba408a364fa.jpg\n",
            "140222-161603-1-1-0-cam1_jpg.rf.2ed1eecffb3dc234034549004c0a6e7a.jpg\n",
            "140222-161731-1-1-0-cam1_jpg.rf.53448216a2a159ee1d4ee57074693f4d.jpg\n",
            "140222-161929-1-1-0-cam1_jpg.rf.1ee18264934295c2991d90a2f854968a.jpg\n",
            "140222-161956-1-1-0-cam1_jpg.rf.bb5ac55c362d9a41d898e5cbfec8d191.jpg\n",
            "140222-162018-1-1-0-cam1_jpg.rf.8bd8eb8dd406acd7d18c0f15e0a6441f.jpg\n",
            "140222-162524-1-1-0-cam1_jpg.rf.f294fb6d5b1a2914556fa974d3f7364b.jpg\n",
            "140222-162549-1-1-0-cam1_jpg.rf.f4a5e8d9a4cd309294deaedcfc393af2.jpg\n",
            "140222-162819-1-1-0-cam1_jpg.rf.e3cfce6fe2fd8111dbfca750c0c78aad.jpg\n",
            "140222-162842-1-1-0-cam1_jpg.rf.17358d04ee656e280a47505897e4ea3b.jpg\n",
            "140222-163821-1-1-0-cam1_jpg.rf.a7747c377811965c2481f8a03f98949b.jpg\n",
            "140222-164237-1-1-0-cam1_jpg.rf.43a20812a9aca3939d9952070a981f1c.jpg\n",
            "140222-164346-1-1-0-cam1_jpg.rf.5762679ace4b2ccc34e5d6dc9e2cc9ee.jpg\n",
            "140222-164430-1-1-0-cam1_jpg.rf.5f371ce05c2977ed2f7354250b7197c3.jpg\n",
            "140222-164445-1-1-0-cam1_jpg.rf.2f85ac9d579b0a4bc4f1628ee25ac1af.jpg\n",
            "140222-164546-1-1-0-cam1_jpg.rf.52847f50589017ad781d38db3378f36e.jpg\n",
            "140222-164650-1-1-0-cam1_jpg.rf.ad2b95300720c1c18a87cbe58fa6d3e2.jpg\n",
            "140222-164912-1-1-0-cam1_jpg.rf.22f307e7ca26f1cf72d512f77c140dab.jpg\n",
            "140222-165020-1-1-0-cam1_jpg.rf.c4b105dc5e09f5dc2f2369671a6182d6.jpg\n",
            "140222-165726-1-1-0-cam1_jpg.rf.772cabef933428aa87c682996a370baf.jpg\n",
            "140222-165803-1-1-0-cam1_jpg.rf.582a6adfa3c0842f9a983eefc1dd22bb.jpg\n",
            "140222-170349-1-1-0-cam1_jpg.rf.4d66b6cd9567c29cf9c30f69bda079b7.jpg\n",
            "140222-170401-1-1-0-cam1_jpg.rf.f43f2fbe371429a7ff09c9abf3a0e1ba.jpg\n",
            "140222-170451-1-1-0-cam1_jpg.rf.a9abd24442a482d645c2839bc8b5d662.jpg\n",
            "140222-170517-1-1-0-cam1_jpg.rf.d3e6cf683bb0391429f4d61c5791b08e.jpg\n",
            "140222-170625-1-1-0-cam1_jpg.rf.957591968f69c512bd8ee0afdab2fca1.jpg\n",
            "140222-170734-1-1-0-cam1_jpg.rf.ea0ac583365d3f82e46c964efe48fb29.jpg\n",
            "140222-170740-1-1-0-cam1_jpg.rf.b729643cacde28307b1629ff30ecebb1.jpg\n",
            "140222-171034-1-1-0-cam1_jpg.rf.919d0fcaca6e71072c58d16234138f4d.jpg\n",
            "140222-171518-1-1-0-cam1_jpg.rf.14f0ca19c7cf0c1e3af4edc144e0b3a0.jpg\n",
            "140222-171519-1-1-0-cam1_jpg.rf.a388b8ae602c91b48077d490f4c98c5e.jpg\n",
            "140222-171733-1-1-0-cam1_jpg.rf.3d5b4f66a0b5791d1aee5a18f296eda5.jpg\n",
            "140222-171837-1-1-0-cam1_jpg.rf.411db1ed6ac5eec9b80ce6297159c92e.jpg\n",
            "140222-172211-1-1-0-cam1_jpg.rf.8f54ccaa2e5a9d19d1f4020ed45b5683.jpg\n",
            "140222-172351-1-1-0-cam1_jpg.rf.d7d7d3493fafe306d64ae04296d8fab7.jpg\n",
            "140222-172749-1-1-0-cam1_jpg.rf.f95c46b481c076ebeddccd7e0be77828.jpg\n",
            "140222-172804-1-1-0-cam1_jpg.rf.a6451da5e8f69fe3a16246d1a9671fd2.jpg\n",
            "140222-172921-1-1-0-cam1_jpg.rf.f08e94908e324769ac8d5bf5363443d2.jpg\n",
            "140222-173003-1-1-0-cam1_jpg.rf.c7200a5fc7c8e0b6e686c2e36cb1eae1.jpg\n",
            "140222-173014-1-1-0-cam1_jpg.rf.3632b7f6b7bfcff66de28a2dabbb060d.jpg\n",
            "140222-175045-1-1-0-cam1_jpg.rf.aed26b6d35d1c874322b4ff34fbfec98.jpg\n",
            "140222-175253-1-1-0-cam1_jpg.rf.bbbf78fd0bf152495d9bbeeebd757046.jpg\n",
            "140222-175734-1-1-0-cam1_jpg.rf.2de324aee9a6f96cd6a351565bff9a6e.jpg\n",
            "140222-175933-1-1-0-cam1_jpg.rf.1e24a30ae600aa4d9b07d08393e4d2d4.jpg\n",
            "140222-180409-1-1-0-cam1_jpg.rf.717553f377d5d24ed068c5bfda324a85.jpg\n",
            "140222-181612-1-1-0-cam1_jpg.rf.492216828a2212dac158a26f0fa158e4.jpg\n",
            "140222-182236-1-1-0-cam1_jpg.rf.01f876088a84d5aad604886a4ee8ad30.jpg\n",
            "140222-182351-1-1-0-cam1_jpg.rf.6ec3b1510f5393d6c75a3e0577954c7f.jpg\n",
            "140222-184024-1-1-0-cam1_jpg.rf.a083801a9ff89ce18ca4ffa0d24550e2.jpg\n",
            "140-E-5997-QP-01-20_jpeg_jpg.rf.c662bb4387cfbedf2f1738053c3342e2.jpg\n",
            "140_jpg.rf.59758d7e36b3fc8fd94c7dc6d137a3eb.jpg\n",
            "141-E-3860-PAK-02-22_jpeg_jpg.rf.48e71de5e15ec0fbed7f00b0060adc63.jpg\n",
            "142-E-3229-SQ-11-18_jpeg_jpg.rf.c28044983b165044b3dd90a5dca6c614.jpg\n",
            "142_jpg.rf.e77b24e1e66dc7c8a200f993f131fb8e.jpg\n",
            "143-E-5279-SD-12-21_jpg.rf.ee1be814ca9a3c885a452663f9286781.jpg\n",
            "143_jpg.rf.0e2f913d2e6951e1d8d19d0959e6bd24.jpg\n",
            "144-E-3063-RS-07-22_jpeg_jpg.rf.15f1bb3f3475cc403896fc2d698abc2e.jpg\n",
            "144_jpg.rf.0d83186a192a3ada98777264ffccb245.jpg\n",
            "145185_jpg.rf.4cc4cadedb3b3e20700a2d4ab6d70e7f.jpg\n",
            "145195_jpg.rf.113981917a6d201745412ff3c09d95d3.jpg\n",
            "145512_jpg.rf.052a73732843e193497ba2e00bacde42.jpg\n",
            "145-E-2035-SO-07-20_jpeg_jpg.rf.45d7e05108c24592530707ffb6559b91.jpg\n",
            "145_jpg.rf.c861d4a39dde53c6369068ec246df580.jpg\n",
            "146072_jpg.rf.b7e2ff8d98dbde2cce858db724f2398f.jpg\n",
            "146-E-3485-SZ-09-10_jpeg_jpg.rf.9c499fb860b6f42b3cd333674ce52f28.jpg\n",
            "147_jpg.rf.2c967265ca26ae587dfeae4de7e1382e.jpg\n",
            "14931_1100209_6-1_jpg.rf.307db77ac5de570c4b675b5424f18017.jpg\n",
            "14931_1100209_6-1_jpg.rf.7993bd366d91e6bd3997f34061286b59.jpg\n",
            "14931_1100209_7-1_jpg.rf.37cdb1065f9f6a54c189feb4ffe3a101.jpg\n",
            "14931_1100209_7-1_jpg.rf.5bdd987293eb5a2af33781809d2a5849.jpg\n",
            "14931_1100209_7-1_jpg.rf.b4fddbdce38c9b006c70f233f20239dc.jpg\n",
            "149-E-4217-TT-01-18_jpeg_jpg.rf.c31a39d918afaa66f6754bbe4f9a4d4e.jpg\n",
            "14-E-1129-RP-07-18_jpg.rf.ef6417f9c46df213c0aa3b14bd020991.jpg\n",
            "14_jpg.rf.3571783dce03bcd66ac3e4216f583478.jpg\n",
            "14-Kode-Plat-Kendaraan-Kota-Administrasi-Jakarta-Selatan-_jpg.rf.dde90083263cdfdfb49cad6393d8bbaf.jpg\n",
            "1505422968_6299099020660_jpg.rf.835c4b01ee1dab727f2ac46fa2bbccbc.jpg\n",
            "1505422968_6299099020660_jpg.rf.b9f3033692594236c8151370db616fbc.jpg\n",
            "150-E-6686-PAI-01-22_jpg.rf.33a801b8d1c6f2c0f27fe22479bcae24.jpg\n",
            "1517432936821_jpg.rf.19f9110750e2e3c1947ce2c50b66c73b.jpg\n",
            "1517432936821_jpg.rf.570707754eac60438002e6e112df95dd.jpg\n",
            "1517432936821_jpg.rf.c73f61144da99844e91c0c86d2cdbe19.jpg\n",
            "152_jpg.rf.661d08437e0a913ccbeef6e1fac2c8bd.jpg\n",
            "153019_jpg.rf.d493237423da7fceb7c2e42d8cec3ea6.jpg\n",
            "155229_jpg.rf.701e93103457d8f7585626734ef51a22.jpg\n",
            "155828_jpg.rf.7bab059b15bcdd6d8b1f0fdf507f65a1.jpg\n",
            "1-559737181-Honda-Beat-eco-2018-Surat-Lengkap-Pajak-Hidup-Plat-T-Karawang_jpg.rf.062499c8f5227245c56afc77bc320d97.jpg\n",
            "155_jpg.rf.0a3f4561daff7950b281f088721d45bb.jpg\n",
            "156277_jpg.rf.269048f41474622c3866c75cb82787d7.jpg\n",
            "-156F82DF-5099-4AEA-8574-19720B40C034-png_jpg.rf.5d5496ab1e53a525e051968785cef92b.jpg\n",
            "156_jpg.rf.27bd168b5af38aec5a39bc6bedb2bb94.jpg\n",
            "1574233981_ets2_03894_jpg.rf.18bbe17c06a6ffe86b0f301741390596.jpg\n",
            "1574233981_ets2_03894_jpg.rf.368efd0e4443ff642ebeede0451d5900.jpg\n",
            "1574233981_ets2_03894_jpg.rf.ec17578f9eb3251920cf79141edf11e7.jpg\n",
            "157_jpg.rf.45e7ef7b7c5983155a25b5571db2a181.jpg\n",
            "1-583354530-Daihatsu-Xenia-xi-Tahun-2009-Warna-Hitam-Mulus-Plat-AA-Magelang-Bisa-Kredit-Ma_jpg.rf.c601fd94ceed15d1d819f1bb9532171f.jpg\n",
            "158_jpg.rf.98f507867b4f91d339026d5d35c43069.jpg\n",
            "-15D32EAC-AC48-4D31-BEFC-BB6539C96CAC-png_jpg.rf.1212546aa3ef51056057ce45eff545a7.jpg\n",
            "15-E-3088-PAK-02-22_jpg.rf.4ee01a2482c966be53549fb9d9f5ce26.jpg\n",
            "-15F66BCC-7D1B-4C04-82EF-C560EC4C612E-png_jpg.rf.a79683f3a4853d7cfeb95c06cc681d31.jpg\n",
            "15_jpeg_jpg.rf.44a2c41c36ae445628278f3339acfdbc.jpg\n",
            "15_jpg.rf.4ef8a168149694a55e25d67b815091c0.jpg\n",
            "16012-colt-jual-mobil-mitsubishi-can_jpg.rf.9cfbe129d883fe8f72adf0804aa99d86.jpg\n",
            "16012-colt-jual-mobil-mitsubishi-can_jpg.rf.e747164b2dd4aa58d2fac604848d2221.jpg\n",
            "160_jpg.rf.76b13a3d4dee59f47894deee48584b4b.jpg\n",
            "1622779784_0_daihatsu-ayla-type-d-plus-10-manual-tahun-2019-plat-r-purwokerto_jpg.rf.51812df6cbef037de04dd6bb240afd79.jpg\n",
            "162_jpg.rf.4823472414993f3af8c4fdb6be0236d6.jpg\n",
            "164486_jpg.rf.b47b592da08f8e3197c880d21e1229bb.jpg\n",
            "16482_1806189169446_jpg.rf.5c44be444317275668c4c629c0f20b2e.jpg\n",
            "16482_1806189169446_jpg.rf.90267a05aebeaac2530e52477eda8c83.jpg\n",
            "16482_1806189169446_jpg.rf.aab2bbab79a6f2fbb1abe08593ef1e80.jpg\n",
            "16482_3666418146613_jpg.rf.0b180e0ea0e583d34647205828a9aaa4.jpg\n",
            "16482_4786988467249_jpg.rf.126a4dc1f3d53c628e732d59bab36a25.jpg\n",
            "16482_4786988467249_jpg.rf.64ad52ac75cdbcd0e2329b430643fe1b.jpg\n",
            "16482_4786988467249_jpg.rf.e381490f25fd7df35bed4fc5a21928b0.jpg\n",
            "16482_6538366098693_jpg.rf.995d692593fab5e97db30dcd6f8b265d.jpg\n",
            "16482_6538366098693_jpg.rf.d2fa8449eae79fa3c86397d8310e4375.jpg\n",
            "16482_6538366098693_jpg.rf.edec367a981217125d08fe87f87529e4.jpg\n",
            "165_jpg.rf.5fe52810c33f399af6c27a2b3982d56c.jpg\n",
            "166_jpg.rf.18dacd38a0c999be82ea685cd3de3cd0.jpg\n",
            "167_jpg.rf.f4e4645a3e9b9c00dd82f551c826e2ed.jpg\n",
            "168329_jpg.rf.8e6becf61f06540fef4c25257caf148c.jpg\n",
            "-169AB8C1-EECA-451A-9C5D-346D21D26E08-png_jpg.rf.0f73fdd825c909e1e436280e2ffa30b9.jpg\n",
            "169_jpg.rf.73f1406cac682690e1a665d5d75c80d5.jpg\n",
            "16-E-3598-PAD-09-21_jpg.rf.54a79c02a75912eb60d10d53d038b884.jpg\n",
            "170-E-3913-QS-04-20_jpeg_jpg.rf.7a695215aa05f5c55073953402279d4a.jpg\n",
            "-1719DE15-BCDC-404A-8470-386AAD8717B4-png_jpg.rf.d667b3cbd59a2f52034ea98b952d63aa.jpg\n",
            "171-E-5605-QZ-12-20_jpeg_jpg.rf.64b6016dfe7cc3dbda9d923824982743.jpg\n",
            "171_jpg.rf.e052264a35c56fa726722ef901fe0bd1.jpg\n",
            "172-E-6526-QX-11-20_jpg.rf.afbc4a08c1078d50e8bbac1c922c76c8.jpg\n",
            "172_jpg.rf.0ab11f34a93b685374b1975f045bcb44.jpg\n",
            "173_jpg.rf.789f51fc4a440ba2af60aa554f80f498.jpg\n",
            "175-E-6962-PAA-02-21_jpeg_jpg.rf.52149bfbc4a72fd7d85fa758104d6e7e.jpg\n",
            "177_jpg.rf.478f8d515423cd2e47605f1d82327558.jpg\n",
            "17828_5789ACS01_1-1_jpg.rf.0241557a1b1d2674b393d701815c9578.jpg\n",
            "17828_5789ACS01_1-1_jpg.rf.2470ec5303a061fd58c86f09e1d3c0f4.jpg\n",
            "17828_5789ACS01_1-1_jpg.rf.4085bfa38ac5e431aa0c60719526a5c1.jpg\n",
            "17828_5789ACS01_1-1_jpg.rf.4f0f65b67e9d5cae7815b3b9cb06b3b4.jpg\n",
            "17828_5789ACS01_1-1_jpg.rf.a07d7a4db3033fb8147aaeafb81769a5.jpg\n",
            "17828_5789ACS01_1-1_jpg.rf.d21f3d742814b133b7848230e78c9823.jpg\n",
            "17828_5789ACS01_2_jpg.rf.b933508056ba5f8324aadf423dcd3175.jpg\n",
            "17828_5789AHS01_17-1_jpg.rf.1ddba7307a38a665196c4b22c0580969.jpg\n",
            "17828_5789AHS01_17-1_jpg.rf.22754b549d15b80816287c12734b7fe8.jpg\n",
            "17828_5789AHS01_17-1_jpg.rf.d03fd02cdfea8d448c0c6aa0e6221b75.jpg\n",
            "17828_5789AHS01_17-1_jpg.rf.eaf2fba97f626f27302d91977c6ffa88.jpg\n",
            "17828_5789AHS01_17-1_jpg.rf.f7c2de0eb02be72ca72aa7da3583b614.jpg\n",
            "17828_5993AFS01_2_jpg.rf.44086e5d55680d9624c21297fc2c6edc.jpg\n",
            "17828_5993AFS01_2_jpg.rf.c97c4a128637674206572a965f77da95.jpg\n",
            "17828_5993AFS01_3_jpg.rf.8540e900244bfe8accad4877d8cff6bb.jpg\n",
            "17828_5993AFS01_3_jpg.rf.d96c92ecbb1a328d3725b4f9f0cc1815.jpg\n",
            "17828_6137AFS01_11_jpg.rf.f6617a975fc22779424ed723465807d8.jpg\n",
            "17882_jpg.rf.4c44963b61c96789d610f54341acb809.jpg\n",
            "178_jpg.rf.7e3bad3aa39c48c9feebc3b9b3657b20.jpg\n",
            "179-E-3934-PAI-12-21_jpg.rf.d67e51b153388f87ff1a263f98194781.jpg\n",
            "17-E-4172-QC-11-18_jpg.rf.7184f4eca0493ab84a5c5bb3ac2d3748.jpg\n",
            "17-E-4172-QC-11-18_jpg.rf.d67380a2044a02ce449e73f10645e1b3.jpg\n",
            "17_jpeg_jpg.rf.345ab9c9ea578cf221ce97097997b8fc.jpg\n",
            "17_jpg.rf.af9d129931dec4c4dd9c6782902485dc.jpg\n",
            "180366280-e1436462668706_jpg.rf.bc70f3af2fa99a5374445c4b4913630c.jpg\n",
            "180-E-3646-RL-05-20_jpeg_jpg.rf.b68e0645da8932230e5dd10029a13e78.jpg\n",
            "182-E-3996-RS-08-17_jpeg_jpg.rf.28cdde7df786ea5ad5ba6650d0c01afa.jpg\n",
            "183-E-5266-TS-12-22_jpg.rf.387e9d7f1cad750f689234a4619dd49b.jpg\n",
            "183_jpg.rf.65794d716f0ea5aebb8f7f47b916b3c7.jpg\n",
            "184-08_jpg.rf.c5f6af72a4f2607e2bd38dd70879e86e.jpg\n",
            "184-E-6595-TO-10-22_jpeg_jpg.rf.e0488abffd04e91560b2a552211114c8.jpg\n",
            "186136_jpg.rf.583df43bd6b64256c08397f804817b35.jpg\n",
            "186805_jpg.rf.a196df46b49c853fa80e3a933def1467.jpg\n",
            "188317_jpg.rf.0f0b27b3f03f43680b71076bc90b49a6.jpg\n",
            "189_jpg.rf.1864b71057e0ae2e998140e42f484b61.jpg\n",
            "18-E-3865-PAF-08-21_jpeg_jpg.rf.bae2c57bcb0cc97570a422b59a5f2c38.jpg\n",
            "-18F5C8FC-327E-42BB-8A5F-C7DAE694A63C-png_jpg.rf.821c5e2eed3b96b87d44b81e36691c76.jpg\n",
            "190997_jpg.rf.88471886642585ce88798115b9420f21.jpg\n",
            "190_jpg.rf.60d3d7cc2cd12fc5a5eeebcad7fe5e37.jpg\n",
            "191-E-3690-ZV-02-20_jpg.rf.08d4a2d38bf4109d5a0462da094a9939.jpg\n",
            "191_jpg.rf.ecbe2050d06e19d169e9e587fd1fbfd1.jpg\n",
            "-192C4A31-07E9-4438-9D0D-63CF545747C8-png_jpg.rf.b1d7db599f246a4ad96a2a49cae5c82f.jpg\n",
            "193027_jpg.rf.ec39a3ccf0f986c03f24436ba2e5430a.jpg\n",
            "193056_jpg.rf.788f8a85ae591191614c110bb01a76ce.jpg\n",
            "194129_jpg.rf.ffe3838efe5b517434c6a280be19503b.jpg\n",
            "194_jpg.rf.509f08b4e2e69df40b51c3d9ec2b0f79.jpg\n",
            "19575a5n4f_jpg.rf.2a181fceac1ae1d0efa9cfb5c15f4d06.jpg\n",
            "19575a5n4f_jpg.rf.60583f274c780e4197324ebd0ccab225.jpg\n",
            "19575a5n4f_jpg.rf.694208ca610c1463297fbd29f62d50a2.jpg\n",
            "195-E-2110-QP-12-19_jpeg_jpg.rf.90617b36eb692800001a53f12fa8e005.jpg\n",
            "195_jpg.rf.11358877ca7197ec8be085ac8270c43e.jpg\n",
            "196_jpg.rf.67c7db404d3347292e4241af5902eea7.jpg\n",
            "197-E-6375-OC-06-22_jpg.rf.158e32de73ffff0392dbf397cb01cd01.jpg\n",
            "1990-mitsubishi-fuso-fk-flatbed-dump_jpg.rf.fe5c10ac622250a072f46428ae8e032f.jpg\n",
            "1995-mitsubishi-fuso-fe4-15ft-box-tr_jpg.rf.a513d1c579b35f83c60aa420b73ff1a3.jpg\n",
            "1999-mitsubishi-fuso-fg-beverage-tru_jpg.rf.6dfb894ba60602339a89bf847282f6a0.jpg\n",
            "199_jpg.rf.4b7170440440cdd1e077a7570d7e94bc.jpg\n",
            "19-E-6179-SH-09-14_jpeg_jpg.rf.dd96a9c57ca6216713abc5c00d990512.jpg\n",
            "19_jpeg_jpg.rf.3061e447d89a83174bc72b992c189b39.jpg\n",
            "19_jpg.rf.f47804d944e4e239d6461251bdde6c05.jpg\n",
            "-1B0238BF-B78A-469B-8D8F-6601591EA89C-png_jpg.rf.62582a5b204a4645a8e7f93a8894f46b.jpg\n",
            "-1CFE9E26-1C67-40EF-BBDB-72A77E5ACBF3-png_jpg.rf.00f4930736c912bb5927ac3900368286.jpg\n",
            "-1D16C086-C64D-4CAB-AD95-E31F5FEB5461-png_jpg.rf.4187eda688d52aec371fe5046fa042e2.jpg\n",
            "-1D3ACB8E-DC65-44CE-857A-8518EDEF7A09-png_jpg.rf.5d0a3103e37c8c80e8a9bd4185c44c26.jpg\n",
            "-1E060058-A56A-4311-B732-3ADEA1E80274-png_jpg.rf.05d98760718dd91c9182c0220bf7f9bf.jpg\n",
            "-1E0BFB6E-30D8-4FA3-B325-FD010ACDB292-png_jpg.rf.0825e1b8e687f05eda11ec37c247083a.jpg\n",
            "-1E32D45B-FDE0-4D64-B7EF-71F9B74AFAF3-png_jpg.rf.653858d85d5e71493b261fa1cea8b95e.jpg\n",
            "1-E-3977-QM-09-19_jpeg_jpg.rf.552229650f32184b016521f5883be533.jpg\n",
            "1-E-3977-QM-09-19_jpeg_jpg.rf.ffe7138e8ded8cdfe0ed37e4cb74e231.jpg\n",
            "-1E770B3E-CAB3-4BE5-ACDF-7EBF876CA5F0-png_jpg.rf.4d705c51ad097d134957fa6a8fc73583.jpg\n",
            "-1EE5CA55-C89F-4985-8D4E-A56DBD1A1E96-png_jpg.rf.ce4804a2ec206b93a8ea1a22f81d5de0.jpg\n",
            "-1F999A49-2799-4FBC-811D-D10A165F8B02-png_jpg.rf.cbcf941f32f35956304ab0d4b8f19605.jpg\n",
            "2005-mitsubishi-fuso-fm260-18ft-dies-3_jpg.rf.1dfb5889b5d989e3c637a85d2bb0bd7a.jpg\n",
            "2007-Mitsubishi-Fuso-Fighter-FK600_5_jpg.rf.94c46d4a7e9434c60b39f84a1335f431.jpg\n",
            "2007-Mitsubishi-Fuso-Fighter-FK600_5_jpg.rf.cd10d33602c3a07e4edac6caeca20a9f.jpg\n",
            "2007-mitsubishi-fuso-fk200-24ft-box-1_jpg.rf.2980512b55029db13fb51b6bccb2984e.jpg\n",
            "2007-mitsubishi-fuso-fk200-24ft-box-1_jpg.rf.954c0bf1a65bd3fb2e8fb27a017322f4.jpg\n",
            "2007-mitsubishi-fuso-fk200-24ft-box-1_jpg.rf.b557d5c44876a506abef8cdba13f8c9a.jpg\n",
            "2007-mitsubishi-fuso-fk200-24ft-box-1_jpg.rf.e1e4ea842329e0baf4c61bb3b1a192be.jpg\n",
            "2007-mitsubishi-fuso-fk200-24ft-box-1_jpg.rf.f81050d1a62b85066e856b176542dafd.jpg\n",
            "2007-mitsubishi-fuso-fk200-24ft-box-_jpg.rf.1243cf51167c55b5ed04de9db0c1695d.jpg\n",
            "2007-mitsubishi-fuso-fk200-24ft-box-_jpg.rf.90d03afb9109d05fdcc3091c886e0f7c.jpg\n",
            "2007-mitsubishi-fuso-fk200-24ft-box-_jpg.rf.b028002455c5ef3c3267bb47570532c1.jpg\n",
            "2007-mitsubishi-fuso-fk200-24ft-box-_jpg.rf.e5f149a6ff225f0cbfff4ad06e47b2da.jpg\n",
            "2007-mitsubishi-fuso-fm260-26-box-tr_jpg.rf.0bc3e9b02089af2081b3a2334123353b.jpg\n",
            "2007-mitsubishi-fuso-fm260-26-box-tr_jpg.rf.66acb42e381185bb922ac80c6071452e.jpg\n",
            "2007-mitsubishi-fuso-fm260-26-box-tr_jpg.rf.8ad7c770216461551d0e9f1d5659bfc1.jpg\n",
            "2007-mitsubishi-fuso-fm260-26-box-tr_jpg.rf.a8fc9d53f5b9e6bcb38fcf4da5823e7b.jpg\n",
            "2007-mitsubishi-fuso-fm260-26-box-tr_jpg.rf.ff09234ebc708ef12d64e2b10bd87e15.jpg\n",
            "2008-mitsubishi-fuso-wrecker-tow-tru-1_jpg.rf.28546116af919b52853e3f35fd37df24.jpg\n",
            "2008-mitsubishi-fuso-wrecker-tow-tru-1_jpg.rf.7984cf6a2bdf6b0175052228658a0809.jpg\n",
            "2008-mitsubishi-fuso-wrecker-tow-tru-1_jpg.rf.f6e08b47a56e6d6a5e81efa455d6466b.jpg\n",
            "2008-mitsubishi-fuso-wrecker-tow-tru_jpg.rf.c24d7b9bde572544affb25955c76e366.jpg\n",
            "2008-mitsubishi-fuso-wrecker-tow-tru_jpg.rf.db72f89872a57519cba7875b5fd86074.jpg\n",
            "2009-Mitsubishi-Canter-mini-dump-tru_jpg.rf.8862c497fff13a80506b8fc413d8081b.jpg\n",
            "2009-Mitsubishi-Canter-mini-dump-tru_jpg.rf.d39b7a19d550b8b85f7dc18547cc7d01.jpg\n",
            "2009-Mitsubishi-Fighter-FM600_573533_jpg.rf.18609e04b9792b4ba6744f6fd082cbe1.jpg\n",
            "2009-Mitsubishi-Fighter-FM600_573533_jpg.rf.50a006ff0e7ac66eaa92b4962d60b01b.jpg\n",
            "2010-mitsubishi-fuso-26-ft-box-truck-1_jpg.rf.767b694798966d3264100e9d98979941.jpg\n",
            "2010-mitsubishi-fuso-26-ft-box-truck-1_jpg.rf.942e0403bf6755296e11cec277bb8d9d.jpg\n",
            "2010-mitsubishi-fuso-26-ft-box-truck-1_jpg.rf.b1b78da843f81863e911067d227a58d1.jpg\n",
            "2010-mitsubishi-fuso-26-ft-box-truck-1_jpg.rf.e662c7c69b710f38d6a645e9f074360e.jpg\n",
            "2010-mitsubishi-fuso-26-ft-box-truck_jpg.rf.4802fdf2523f6c21cf9dfe91418911e8.jpg\n",
            "2010-mitsubishi-fuso-26-ft-box-truck_jpg.rf.61f5c54cdbd4130986dca6211ad29956.jpg\n",
            "2010-mitsubishi-fuso-26-ft-box-truck_jpg.rf.ad87da9c93b2c74fb0ea8fa893f8055d.jpg\n",
            "2010-mitsubishi-fuso-fe145-12ft-box-_jpg.rf.45421b6754ea04223df4c22a75140490.jpg\n",
            "2010-mitsubishi-fuso-fe145-12ft-box-_jpg.rf.a4b78d6af27baebd48e2e7b3df92f9c9.jpg\n",
            "2010-mitsubishi-fuso-fe145-12ft-box-_jpg.rf.b2672a85bcd8512d6b2c960db59e0572.jpg\n",
            "2010-mitsubishi-fuso-fe145-12ft-box-_jpg.rf.dbf8827d740d345375d6d525c0bd6b08.jpg\n",
            "20121009_123807_jpg.rf.681fde8e386537cad362145a03349058.jpg\n",
            "20121009_123807_jpg.rf.ce475f42cc2f953490ef17da2184b996.jpg\n",
            "20121009_123807_jpg.rf.f5074949cd8e7c9676c1cc348f6c8891.jpg\n",
            "2012-mitsubishi-fuso-canter-fe160-du-1_jpg.rf.0fdef5168f9bf62c805932e31a13fc4b.jpg\n",
            "2012-mitsubishi-fuso-canter-fe160-du-1_jpg.rf.221f67b1c1d2d34498253f1f2c7fdafc.jpg\n",
            "2012-mitsubishi-fuso-canter-fe160-du-1_jpg.rf.5f6727824f063ce642c7d5e098e307cf.jpg\n",
            "2012-mitsubishi-fuso-canter-fe160-du-1_jpg.rf.6c3dfe19c11e1f6f3424dcdc32a906bd.jpg\n",
            "2012-mitsubishi-fuso-canter-fe160-du_jpg.rf.c3b4ccd6c8d7282326a711bc61e65209.jpg\n",
            "2012-mitsubishi-fuso-fe160-16ft-dump-1_jpg.rf.99107357f51c14a6b8860f8de41c22af.jpg\n",
            "2012-mitsubishi-fuso-fe160-16ft-dump-1_jpg.rf.ce7d0caf45ee6a62d4aad50b05223543.jpg\n",
            "2012-mitsubishi-fuso-fe160-16ft-dump-1_jpg.rf.f38b9fa9f3f76fbf3e49fdf88d14e0a1.jpg\n",
            "2012-mitsubishi-fuso-fe160-16ft-dump-2_jpg.rf.b1dee9eb360b98cbf155e3a333687e3b.jpg\n",
            "2012-mitsubishi-fuso-fe160-16ft-dump-2_jpg.rf.df7bfb772b760b4c1976d0ff7eb62f73.jpg\n",
            "2012-mitsubishi-fuso-fe160-16ft-dump-2_jpg.rf.f7ea5d4c994cb2109cab076a98089338.jpg\n",
            "2012-mitsubishi-fuso-fe160-16ft-dump_jpg.rf.19ff455c0461e8b6c302e5bf6a3650e8.jpg\n",
            "2012-mitsubishi-fuso-fe160-16ft-dump_jpg.rf.3104527037abfc5ff8bb2efe900566c4.jpg\n",
            "2012-mitsubishi-fuso-fe160-16ft-dump_jpg.rf.b13f0318c32efdf433669d9546321fa9.jpg\n",
            "2012-mitsubishi-fuso-fe160-16ft-dump_jpg.rf.cddac9a6e72dfb590e0500bc96fb32ac.jpg\n",
            "2012-mitsubishi-fuso-fe160-16ft-dump_jpg.rf.d045223f85a1c7b5684a1c124c601976.jpg\n",
            "2012-mitsubishi-fuso-fe160-16ft-dump_jpg.rf.e7b0efa540c07df0b83bd3240d4a2032.jpg\n",
            "2013-Fuso-Canter-4x4-1-1_jpg.rf.0139dc00ddd0b3af8ff527ad14504b0f.jpg\n",
            "2013-Fuso-Canter-4x4-1-1_jpg.rf.182ce5f62a405c4ef5b797b62a5eb1bc.jpg\n",
            "2013-Fuso-Canter-4x4-1-1_jpg.rf.6027f9c96155f5ef9c47d73cac4b9b4e.jpg\n",
            "2013-Fuso-Canter-4x4-1-1_jpg.rf.c65ddc24df5f610017fba167e3590615.jpg\n",
            "2013-Mitsubishi-18ft-Refrigerated-Va_jpg.rf.c49b3b38047446f88acab4aa943c17d5.jpg\n",
            "2013-Mitsubishi-Fuso-Canter-7C15-PBU_jpg.rf.25f44e379cf7dc2afce8372d55b3e295.jpg\n",
            "2013-Mitsubishi-Fuso-Canter-7C15-PBU_jpg.rf.687c010e22c70c15b9d4c15c4785ff9a.jpg\n",
            "2013-Mitsubishi-Fuso-Canter-7C15-PBU_jpg.rf.e9a0a2e61d65c676a92c625c3df84401.jpg\n",
            "2013-mitsubishi-fuso-fe160-20-box-tr_jpg.rf.01ccf09f83402954001cedc6fc70a2f5.jpg\n",
            "2013-mitsubishi-fuso-fe160-20-box-tr_jpg.rf.0bf406e3239d7ec71ed39ce7ca09f6b5.jpg\n",
            "2013-mitsubishi-fuso-fe160-20-box-tr_jpg.rf.691da95ac1222fdc8fdcc843214474e5.jpg\n",
            "2013-mitsubishi-fuso-fe160-20-box-tr_jpg.rf.6c818267e4f6cd3482266373c42ee1ae.jpg\n",
            "2013-mitsubishi-fuso-fe160-20-box-tr_jpg.rf.7829adee1c574116702d6867d16c0174.jpg\n",
            "2014-mitsubishi-canter-truck-7mnuxba_jpg.rf.44193493ad76a1aa0825643fa5aab7f5.jpg\n",
            "2014-mitsubishi-canter-truck-7mnuxba_jpg.rf.86e3d3d5edc91843942bcf938b20ad4b.jpg\n",
            "2014-mitsubishi-canter-truck-7mnuxba_jpg.rf.97c7ba6e4728f55177072f2fae71754a.jpg\n",
            "2014-mitsubishi-canter-truck-7mnuxba_jpg.rf.bc1bfc5f3ff5f7b31302733044f0133d.jpg\n",
            "2014-mitsubishi-canter-truck-ugikpwq_jpg.rf.379a1afa8c853fa0c219a86a0aa9a765.jpg\n",
            "2014-mitsubishi-canter-truck-ugikpwq_jpg.rf.cc2b0e4a953861f103adecd6216ed4b2.jpg\n",
            "2014-mitsubishi-fuso-fe160-14-feet-b_jpg.rf.49dd8d97ea730e70fe2599d2b4d64ab4.jpg\n",
            "2014-mitsubishi-fuso-fe160-14-feet-b_jpg.rf.d0e2c0b9b5b1d2070e010333509d9889.jpg\n",
            "2014-mitsubishi-fuso-fe160-14-feet-b_jpg.rf.f8c1ef3543d17c90b21a76eed730c8a1.jpg\n",
            "2015-Mitsubishi-Fuso-Canter-7C15-4x2-1_jpg.rf.852c7cac588e76924e69f8e2e6787d23.jpg\n",
            "2015-Mitsubishi-Fuso-Canter-7C15-4x2_jpg.rf.5badbb18bbdbb88456dbdde157b761f7.jpg\n",
            "2015-Mitsubishi-Fuso-Canter-7C15-4x2_jpg.rf.6a4e5da1c08923f188ed258f00078372.jpg\n",
            "2015-mitsubishi-fuso-fe180-dual-tech_jpg.rf.b1011c8d723b55df729194cae5382195.jpg\n",
            "2015-mitsubishi-fuso-fe180-dual-tech_jpg.rf.cbb10037e85621630235b20c75d2cd2a.jpg\n",
            "2015-mitsubishi-fuso-fe180-dual-tech_jpg.rf.d4bfe89dfc2d76b482b9389295ce4e74.jpg\n",
            "2015-mitsubishi-fuso-fe180-dual-tech_jpg.rf.dd121a7700fa0c5881c5b22f9a995333.jpg\n",
            "20170325_115955_HDRw_1u_jpg.rf.786dcdb36c240532e4a762b7ec016ee6.jpg\n",
            "20170325_115955_HDRw_1u_jpg.rf.99965881331d32b9a39195e0ea058908.jpg\n",
            "201707170712_fuso-1024x512_jpg.rf.033e1320c6e0aa3dc1e87053b25d890d.jpg\n",
            "201707170712_fuso-1024x512_jpg.rf.0bb1dd12c64ef92bafb78823560499af.jpg\n",
            "201707170712_fuso-1024x512_jpg.rf.deef60b2d02b20070a778ff08965481b.jpg\n",
            "201707170712_fuso-1024x512_jpg.rf.f9422f414df631b8ccda41330c0df272.jpg\n",
            "201707170712_fuso_jpg.rf.6b6b929011adb7bb857ff4eb40b51854.jpg\n",
            "201707170712_fuso_jpg.rf.ada21acb98997ed4dedaf3b7f410f493.jpg\n",
            "20170820170831fuso-1-1024x674_jpg.rf.c484baba3f5edcc9a8ebf944a56125b9.jpg\n",
            "20170820170831fuso-1-1024x674_jpg.rf.d2303a5c7fb7e0757818c2b064f2171f.jpg\n",
            "20171210_212912_jpg.rf.03615682c2f9059638b4c28945a2b492.jpg\n",
            "20171211_084300_jpg.rf.e5a64783bb6a242f5bdf5b5d1d8124c5.jpg\n",
            "20171211_110642_jpg.rf.bdd3d666db9b4c82a92f3169c7b7cd92.jpg\n",
            "20171211_110651_jpg.rf.ea56c6d50955a4b4bc508951800d0d9e.jpg\n",
            "20171211_110659_jpg.rf.7ba33c09a5a3664c00202eb4fdbc2c95.jpg\n",
            "20171211_110711_jpg.rf.feb4554a78c57904b5f501b6593dc14c.jpg\n",
            "20171211_154917_jpg.rf.6cc1d4a04d37593c59ab8fb5750e96e0.jpg\n",
            "20171211_154939_jpg.rf.b000e6d375a4eb9a2fbb02f1803a15a8.jpg\n",
            "20171211_160434_jpg.rf.398d463a83a44558b27a78fc19a47392.jpg\n",
            "20171212_073402_jpg.rf.1e44a49a19ea334dd9bdc852659b8fa1.jpg\n",
            "20171212_073415_jpg.rf.4835aea07c1106a48fc078bad7775ff0.jpg\n",
            "20171212_073435_jpg.rf.d824cfb527dc96b5594f387c1d082c65.jpg\n",
            "20171212_100546_jpg.rf.42b716f428e0bcbd8dc8cb85976f9bee.jpg\n",
            "20171212_100708_jpg.rf.ebefb49bd73fd0022940c86f9f48b3e7.jpg\n",
            "20171212_124357_jpg.rf.4347819a00c8394b05b915635c8cb29d.jpg\n",
            "20171212_124415_jpg.rf.2ad1beb1cf57cfcc1d64a0881c1a8ea4.jpg\n",
            "20171212_124449_jpg.rf.5fb92abb46bd88db73dfea8cbbf1e062.jpg\n",
            "20171212_141155_jpg.rf.2e6bc22d92623862d4a56cbc0a9315a3.jpg\n",
            "20171212_141203_jpg.rf.f841665e245831a73cc551e278fbe667.jpg\n",
            "20171212_142228_jpg.rf.45862eff32b58985cd48a8f0fcecb1cb.jpg\n",
            "20171212_142243_jpg.rf.9ef012ab1af4937913cace7050885ebe.jpg\n",
            "20171212_142342_jpg.rf.4281cdbeccb2b7ea8f0e6ae661f3e7ee.jpg\n",
            "20171214_091545_jpg.rf.766f6caf471f9bc34d6846501b8065ce.jpg\n",
            "20171214_121617_jpg.rf.a889caa2c45d06c476509a491290b8da.jpg\n",
            "20171214_121636_jpg.rf.78097f208066d2ab19639cdddfc429da.jpg\n",
            "2017-Mitsubishi-Super-Great-Cargo-Du_jpg.rf.2407cbbcd07d4e99e4daa0698e9df319.jpg\n",
            "2017-Mitsubishi-Super-Great-Cargo-Du_jpg.rf.d71dd43f704ee3f3334cd8f279b16f51.jpg\n",
            "20180925_133619_jpg.rf.129d2673f3f0c11d337b687c6fa826b4.jpg\n",
            "20180925_133619_jpg.rf.7e0f99a7b0761c2f46faa900af4bbfca.jpg\n",
            "20180925_133619_jpg.rf.c158407cfad350cc7b758369512a4f51.jpg\n",
            "2020-09-19-16-41-50-1100x674_jpg.rf.25bc60f9155c5c775c709ce32be809e9.jpg\n",
            "2020-09-19-16-41-50-1100x674_jpg.rf.6bbe7dfe12f740e5fafe89da4ff10e3a.jpg\n",
            "2020-09-19-16-41-50-1100x674_jpg.rf.d62a8e219e51ff4acff547ea4b1d3f43.jpg\n",
            "20211122_114011_jpg.rf.f5f36253300b956c159ea71f1ea74d2c.jpg\n",
            "20211122_114029_jpg.rf.e0359cd04f2b569cabc380758d933f96.jpg\n",
            "20211122_114037_jpg.rf.0ebd650b9fca3743078b4068ef7ce8bc.jpg\n",
            "20211122_114133_jpg.rf.6841dc4facb5d628d4966ae7ab776d52.jpg\n",
            "20211122_114142_jpg.rf.a186c9cc6f9c19e2490ac2bc8517a4e0.jpg\n",
            "20211122_114201_jpg.rf.aabdaec0c8afddadf0abfab81b1acd01.jpg\n",
            "20211122_114210_jpg.rf.e473bd0a28b3fe78748b4f3f1dce57ff.jpg\n",
            "20211122_114224_jpg.rf.8005d4006d0c86ef96f9995627d4c915.jpg\n",
            "20211122_114233_jpg.rf.f9106108a9ad61b408e6986036079707.jpg\n",
            "20211122_114245_jpg.rf.200d8bb466800a008f1b1519cf5da7df.jpg\n",
            "20211122_114305_jpg.rf.155433ec16245bf4d3d1e7d75aca60fd.jpg\n",
            "20211122_114320_jpg.rf.87a9cd5171aa1191cdb19d19d38a1887.jpg\n",
            "20211122_114325_jpg.rf.1e474afe70974940d6018017c15df494.jpg\n",
            "20211122_114332_jpg.rf.3da83ca087bda54bc71c40bbada63135.jpg\n",
            "20211122_114344_jpg.rf.b685162c1d20e13d14ead937b514e229.jpg\n",
            "20211122_114352_jpg.rf.1d9857e809cfdb417233c788f66d1e41.jpg\n",
            "20211122_114406_jpg.rf.96060c57f9390a729fd7fe8efa0a28a6.jpg\n",
            "20211122_114415_jpg.rf.028aaf2892390f7ba6cb904f25012899.jpg\n",
            "20211122_114429_jpg.rf.8d51e3c322bfef55a301d0bb27910238.jpg\n",
            "20211122_114435_jpg.rf.0633c4553b0cd794331c1bc6a705b029.jpg\n",
            "20211122_114453_jpg.rf.2479bf2af97361b8c89083d8451b2b20.jpg\n",
            "20211122_114501_jpg.rf.758d8d331331eb70330b69ef597b92b4.jpg\n",
            "20211122_114507_jpg.rf.d79e0c61552eb1067d67d92fd7aa3078.jpg\n",
            "20211122_114513_jpg.rf.c2209c42aff92cff36f2382b4b49b354.jpg\n",
            "20211122_114527_jpg.rf.8a7511ec75dac7f216961f00e006c2bc.jpg\n",
            "20211122_114541_jpg.rf.fc23879083b4f25cde435d86effaaebf.jpg\n",
            "20211122_114604_jpg.rf.18ceadd799c6769a534966acd253f58b.jpg\n",
            "20211122_114618_jpg.rf.ffea546ab58176813d4cc92a5b9299e2.jpg\n",
            "20211122_114638_jpg.rf.374974e0caec8ed675ef032372fd063f.jpg\n",
            "20211122_114649_jpg.rf.85bc1afcb49b21badf21927fe249fcf0.jpg\n",
            "2021-fuso-fe180-steel-dumptruck-oran_jpg.rf.becc739cadfee4c9f6b8b533cebd2857.jpg\n",
            "2021-fuso-fe180-steel-dumptruck-oran_jpg.rf.fcf9c9d98148b7e9308169ac4be1f5d8.jpg\n",
            "2021-fuso-fe180-steel-dumptruck-west_jpg.rf.387fe1b6510aed371b62dc3712399ac3.jpg\n",
            "2021-fuso-fe180-steel-dumptruck-west_jpg.rf.d06f04e246e4459620d0cd9befda2d8a.jpg\n",
            "2021-fuso-fe180-steel-dumptruck-west_jpg.rf.e87be9e6b3b16c9faa9abe56a9d14d3a.jpg\n",
            "2022-05-15-09_46_24-20220514_111222-mp4-VLC-media-player_jpg.rf.c2ba27d69b3df631d02e6fe6d6a246f0.jpg\n",
            "2022-05-15-09_48_38-20220514_111222-mp4-VLC-media-player_jpg.rf.77c44b0a565aedacffc5649f0fbc53b0.jpg\n",
            "2022-05-15-09_48_38-20220514_111222-mp4-VLC-media-player_jpg.rf.eb759da72c113b4a1c70e01f05646f3e.jpg\n",
            "2022-05-15-09_50_17-20220514_111222-mp4-VLC-media-player_jpg.rf.0ea7967ec2d245a389fd79c50cdbf978.jpg\n",
            "2022-05-15-09_52_11-20220514_111222-mp4-VLC-media-player_jpg.rf.06c94a5f3fb3fe05def7f8be0aa2f293.jpg\n",
            "2022-05-15-09_52_11-20220514_111222-mp4-VLC-media-player_jpg.rf.531f72ba7719153186d34948c4254697.jpg\n",
            "2022-05-15-09_53_43-20220514_111222-mp4-VLC-media-player_jpg.rf.2670fa5ffcf5c064f3e13a5322858cd8.jpg\n",
            "2022-05-15-09_53_43-20220514_111222-mp4-VLC-media-player_jpg.rf.c4215931818dc3e4db09ad48f6145013.jpg\n",
            "2022-05-15-09_54_24-20220514_111222-mp4-VLC-media-player_jpg.rf.5bb8c6d2f8c72b4920ca176ae47b7e3d.jpg\n",
            "2022-05-15-09_54_44-20220514_111222-mp4-VLC-media-player_jpg.rf.ba05033693e9810edba5af0c48831003.jpg\n",
            "2022-05-15-09_54_44-20220514_111222-mp4-VLC-media-player_jpg.rf.e495bccab64604ff1c6635b11604c3d7.jpg\n",
            "2022-05-15-09_57_15-20220514_111222-mp4-VLC-media-player_jpg.rf.1897f32c64b0964ad08f8f54819a3545.jpg\n",
            "2022-05-15-09_59_08-20220514_111444-mp4-VLC-media-player_jpg.rf.c7f51f120f0749c0e1113f489cfc6203.jpg\n",
            "2022-05-15-09_59_25-20220514_111444-mp4-VLC-media-player_jpg.rf.0a4efd38601c2c5cacc3ffcd2e037d3c.jpg\n",
            "2022-05-15-09_59_25-20220514_111444-mp4-VLC-media-player_jpg.rf.f5d97a399a24f8d9515950b4bb77e767.jpg\n",
            "2022-05-15-09_59_54-20220514_111444-mp4-VLC-media-player_jpg.rf.cde9991fdc01d75eacd198e928c5e367.jpg\n",
            "2022-05-15-10_00_02-20220514_111444-mp4-VLC-media-player_jpg.rf.882ea3c328854f2e7385cdc6d882c9e6.jpg\n",
            "2022-05-15-10_01_25-20220514_111444-mp4-VLC-media-player_jpg.rf.3406ad3ae429814b7ee59968f07598ed.jpg\n",
            "2022-05-15-10_02_30-20220514_112722-mp4-VLC-media-player_jpg.rf.eee64784d77e1b8647e8f0469303632c.jpg\n",
            "2022-05-15-10_02_45-20220514_112722-mp4-VLC-media-player_jpg.rf.41c7b7e9d5235b36ee67e9bbac8a1dba.jpg\n",
            "2022-05-15-10_02_50-20220514_112722-mp4-VLC-media-player_jpg.rf.c51ea26de3a35ab3838de0ca4cb881d4.jpg\n",
            "2022-05-15-10_03_02-20220514_112722-mp4-VLC-media-player_jpg.rf.28ac2d1b4327ee4dbf20bb81486f0800.jpg\n",
            "2022-05-15-10_03_02-20220514_112722-mp4-VLC-media-player_jpg.rf.aaa26219a8e6b8324c24dc3e00144709.jpg\n",
            "2022-05-15-10_03_23-20220514_112722-mp4-VLC-media-player_jpg.rf.4029051356e708b714e52d565e36fb47.jpg\n",
            "2022-05-15-10_03_33-20220514_112722-mp4-VLC-media-player_jpg.rf.760f48dfe607af620ae0dc990a4bc217.jpg\n",
            "2022-05-15-10_03_33-20220514_112722-mp4-VLC-media-player_jpg.rf.a42a2a05c1fb7a0470823bb2c1f527d7.jpg\n",
            "2022-05-15-10_03_50-20220514_112722-mp4-VLC-media-player_jpg.rf.6829eafe47ccbd186b505e219efdba80.jpg\n",
            "2022-05-15-10_03_50-20220514_112722-mp4-VLC-media-player_jpg.rf.898dc71fc7309d72a9f8e6b662d5ec09.jpg\n",
            "2022-05-15-10_03_58-20220514_112722-mp4-VLC-media-player_jpg.rf.4194b23444fd6c71bdb65b85ad6cedd3.jpg\n",
            "2022-05-15-10_03_58-20220514_112722-mp4-VLC-media-player_jpg.rf.6836685da3cb36cff2f51827577f3d34.jpg\n",
            "2022-05-15-10_04_08-20220514_112722-mp4-VLC-media-player_jpg.rf.0a3b46ea3bf8028c24583213b6dd6da5.jpg\n",
            "2022-05-15-10_04_08-20220514_112722-mp4-VLC-media-player_jpg.rf.d5dafefeadbf2b53560161e066bc1521.jpg\n",
            "2022-05-15-10_04_52-20220514_112722-mp4-VLC-media-player_jpg.rf.dd1d344251f306c11ee148b6e0e5302b.jpg\n",
            "2022-05-15-10_06_45-20220514_112722-mp4-VLC-media-player_jpg.rf.627c5d20a023ee181c2af1a0ae675867.jpg\n",
            "2022-05-15-10_06_59-20220514_112722-mp4-VLC-media-player_jpg.rf.6890f9251221941003c41c2daa9bbad1.jpg\n",
            "2022-05-15-10_07_49-20220514_112722-mp4-VLC-media-player_jpg.rf.acaf9d54ee29fcb889fef21d7e15a9a5.jpg\n",
            "2022-05-15-10_07_59-20220514_112722-mp4-VLC-media-player_jpg.rf.da6ec858fb9647011bdc345223a76ae6.jpg\n",
            "2022-05-15-10_08_10-20220514_112722-mp4-VLC-media-player_jpg.rf.47ae9b3d69f5c3ac0927dfa4dfdf5c62.jpg\n",
            "2022-05-15-10_09_03-20220514_112722-mp4-VLC-media-player_jpg.rf.d7b0deb6756fd6667a0b6c2a79665f71.jpg\n",
            "2022-05-15-10_09_46-20220514_112722-mp4-VLC-media-player_jpg.rf.420186e77eb6f2c1c14db25810940e58.jpg\n",
            "2022-05-15-10_09_57-20220514_112722-mp4-VLC-media-player_jpg.rf.9f0502e04f7e1c9a4f54f191944ce77c.jpg\n",
            "2022-05-15-10_11_17-20220514_112722-mp4-VLC-media-player_jpg.rf.46b0e32f19a9e4a75b2157dcf94a61a7.jpg\n",
            "2022-05-15-10_11_38-20220514_112722-mp4-VLC-media-player_jpg.rf.3c7d4aed18cbe5ae66f22de20662a627.jpg\n",
            "2022-05-15-10_12_01-20220514_112722-mp4-VLC-media-player_jpg.rf.3a30700ba3b3fa9768d7a237d43461cd.jpg\n",
            "2022-05-15-10_12_18-20220514_112722-mp4-VLC-media-player_jpg.rf.dc6c94a4bbcd0262233fabaabcd21896.jpg\n",
            "2022-05-15-10_13_49-20220514_112722-mp4-VLC-media-player_jpg.rf.47eb0f1d2c000e764d7792c57d2d17c4.jpg\n",
            "20220515_135912_jpg.rf.47ce77cf6cfeedaa49ae3a7fd857185c.jpg\n",
            "20220515_140122_jpg.rf.bbe39defb55e032b10b080a3599e3d48.jpg\n",
            "20220515_151534_jpg.rf.14700259fb1fce57b9705ce1d44cfcb5.jpg\n",
            "20220515_151534_jpg.rf.7d0a311993c91d3fdfa73311491f023a.jpg\n",
            "20220515_151751_jpg.rf.bcd9ceea602abce0e7cffb80e87150b6.jpg\n",
            "20220515_152005_jpg.rf.df228556d49041186eb39a7457d20d56.jpg\n",
            "20220515_152659_jpg.rf.12c893390f235ca7ee41c70b3945bced.jpg\n",
            "20220515_153146_jpg.rf.6b5a8b71c26abfd0977e2fcd2eea50b3.jpg\n",
            "20220515_202107-1-_jpg.rf.02b8cd2cff23b97d2ea289ec30bf0e03.jpg\n",
            "20220515_202107-1-_jpg.rf.b4ec2424a393b759530589b2323936b5.jpg\n",
            "20220515_202120-1-_jpg.rf.370519b6eaf37c1d18a6541748f60325.jpg\n",
            "20220516_095815_jpg.rf.58f404f7af49b2f05ce3501df3f9436a.jpg\n",
            "20220516_102400_jpg.rf.3a6e4fc3d2676804029b22ba710827f1.jpg\n",
            "20220516_102424_jpg.rf.7bc052dbe5f1300815c5bb8129c5b794.jpg\n",
            "20220516_103850_jpg.rf.224e7a74877261a524cefacc94f2e2f4.jpg\n",
            "20220516_104623_jpg.rf.9595eec1f2c0c00cb8f50ade1cc9bbf6.jpg\n",
            "20220516_120444_jpg.rf.4c77ac31d596eb6ffd8ec80f1fb78f0d.jpg\n",
            "20220516_143612_jpg.rf.5c864280df2f08d6c58e71c83cb10020.jpg\n",
            "20220516_143723_jpg.rf.2085689b1b5600bc5dc8680551d8aeb3.jpg\n",
            "20220516_144206_jpg.rf.49a09ec1acb5ba8fd5cc5ae7a3420ab7.jpg\n",
            "20220516_144302_jpg.rf.36b0d0739d72283b183a6ccb44bfce7c.jpg\n",
            "20220516_144322_jpg.rf.31cf61e91151a9f041f236852cb699a5.jpg\n",
            "20220516_144322_jpg.rf.7917c7e91ac647379264e489c5a91069.jpg\n",
            "20220516_144343_jpg.rf.0db9d9db7970c66c3a4d2663694e78f0.jpg\n",
            "20220516_144343_jpg.rf.1bfc76d76411cb5a1e8fe75a430faacb.jpg\n",
            "20220516_144602_jpg.rf.5eb0310b56ebbf05f1eee92d419a45ea.jpg\n",
            "20220516_144602_jpg.rf.76f597107f01ff770788c83172b0a84b.jpg\n",
            "20220516_144604_jpg.rf.0f6b6190171fd38e945ed94ddd64c370.jpg\n",
            "20220516_144654_jpg.rf.52bc46218b22bbe0addebf76499c2eb3.jpg\n",
            "20220516_144744_jpg.rf.1f695a46b36593ddc83c5a922a98aed4.jpg\n",
            "20220516_144744_jpg.rf.a4575382a3d97161a604097ea713a1f1.jpg\n",
            "20220516_144755_jpg.rf.25e970c73013254d372439d89994e21e.jpg\n",
            "20220516_144755_jpg.rf.beb54a05fd088a4fe4fcc64464643337.jpg\n",
            "20220516_144848_jpg.rf.23eac6be27e861491d0bfb974feb0551.jpg\n",
            "20220516_144852_jpg.rf.5128a077df4f9ad9bb6d1e87c1a96a26.jpg\n",
            "20220516_145103_jpg.rf.a0010bae4f69d6d9861e99becd9eae63.jpg\n",
            "20220516_145103_jpg.rf.b0e9ae3d35aa5e06af490b88792f4588.jpg\n",
            "20220516_145147_jpg.rf.ca63fbc248e8c40b29c2c76ecaa8b547.jpg\n",
            "20220516_145209_jpg.rf.53581a5c8eac57e0f0ba950056403405.jpg\n",
            "20220516_145209_jpg.rf.70f189bf832020ea62119416d688eb3d.jpg\n",
            "20220516_145254_jpg.rf.26df6d7e70e34e6adef700da39ada576.jpg\n",
            "20220516_145254_jpg.rf.657bec559d65e464e5a844ae8ba0ffd4.jpg\n",
            "20220516_145440_jpg.rf.d6557d3b2d49c6c2ac1e085d3ca95469.jpg\n",
            "20220516_145507_jpg.rf.f57e3604824142d7d3ca60961bf35c64.jpg\n",
            "20220516_145536_jpg.rf.4b5fda0fc39fc48bb02ed9b9e86170eb.jpg\n",
            "20220516_145613_jpg.rf.037884b042eca7d1e927913ed3971cfa.jpg\n",
            "20220516_145800_jpg.rf.a4f5639495ed8d5de8a27e7f4c98e31f.jpg\n",
            "20220516_145800_jpg.rf.ef591b97a880957124e02e50656b0337.jpg\n",
            "20220516_145804_jpg.rf.43874b32374fbde1204ce802120bb14d.jpg\n",
            "20220516_145804_jpg.rf.4ea1fa08c5ceff81400218cc897dc1d6.jpg\n",
            "20220516_145849_jpg.rf.665f9e1099e263cf1a30797c08e9c01d.jpg\n",
            "20220516_145849_jpg.rf.99b0f92815f83e7c3aaf7d0164ef64dd.jpg\n",
            "20220516_145908_jpg.rf.cefb3dcbeaf6ab7ec415bd1b9e01c711.jpg\n",
            "20220517_123134_jpg.rf.8bb1835006123a42db681a6e10c1c357.jpg\n",
            "20220517_123234_jpg.rf.e137cd70d90556bc92b6b12a24ae3674.jpg\n",
            "20220517_123409_jpg.rf.6c1489aaef795671a783300bacab2bad.jpg\n",
            "20220517_123417_jpg.rf.7f2fd6f32032f331301ccf03ab37d7c3.jpg\n",
            "20220517_123427_jpg.rf.6b98c17ca186c84fbcd24144d8fdc852.jpg\n",
            "20220517_123452_jpg.rf.310fa31332c6dc2877a0a79a03cfe8b9.jpg\n",
            "20220517_123452_jpg.rf.aaa29bac9a091c8c45a18f8bf806e21d.jpg\n",
            "20220517_123506_jpg.rf.697fd32a5abe4816434ddf83a8f78cab.jpg\n",
            "20220517_123506_jpg.rf.ec0e3ed5553e49c95b906c7d1a4bb8c8.jpg\n",
            "20220517_123511_jpg.rf.21755ae0532d817cad195bde6520f03a.jpg\n",
            "20220517_123511_jpg.rf.c9720f76c97a450390e677d505d58b12.jpg\n",
            "20220517_123527_jpg.rf.2626affc643f44849217724975cab914.jpg\n",
            "20220517_123527_jpg.rf.6737519d2f4d91a9e286f75e42fb222d.jpg\n",
            "20220517_123534_jpg.rf.1ca67f62f1c4ed1a266bb880bd28a529.jpg\n",
            "20220517_123546_jpg.rf.5d345dd752501be784504928497b6b6e.jpg\n",
            "20220517_123558_jpg.rf.8bb611f7e6ba881d63bd59227faa5744.jpg\n",
            "20220517_123601_jpg.rf.cf951e605c92aaa8ad61d7af5d78ba4a.jpg\n",
            "20220517_123608_jpg.rf.74e3584000abbaeed20bd2416d4b9a06.jpg\n",
            "20220517_123612_jpg.rf.80517c7b4908b9c97ebf7063a8353b0d.jpg\n",
            "20220517_123619_jpg.rf.256b521df13ad27652e145b0236945c5.jpg\n",
            "20220517_123904_jpg.rf.c6d0eb7e4e336015db498b53fd1eff36.jpg\n",
            "20220517_123913_jpg.rf.0f7ee762674a34319ccf544759b0916f.jpg\n",
            "20220517_124020_jpg.rf.1d5088ebb6ea8c376091c770ce14d6e6.jpg\n",
            "20220517_124032_jpg.rf.849c266563d5e424a4c6598187735d12.jpg\n",
            "20220517_124111_jpg.rf.e7696664127285e00e7335da33c46c6c.jpg\n",
            "20220517_124127_jpg.rf.cda5b09a36c2a91c78b721e2a9fa1c75.jpg\n",
            "20220517_124132_jpg.rf.7d4f5645b1bd4a7a363f1f8f7fadb845.jpg\n",
            "20220517_124140_jpg.rf.aa60d3989f41b32ec1199382c90dc1e3.jpg\n",
            "20220517_124145_jpg.rf.2b17b9a5306cb609f734f77e913c9678.jpg\n",
            "20220517_124604_jpg.rf.ddb5d990fa4f4eaf7fe1d8a4db5d620d.jpg\n",
            "20220517_124614_jpg.rf.6be8140249a3c2a0e88d9cd2a634441c.jpg\n",
            "20220517_124627_jpg.rf.182398aea79871223df93d076845c449.jpg\n",
            "20220517_124640_jpg.rf.81472f500697d5f739a5dae1c061ac9e.jpg\n",
            "20220517_124655_jpg.rf.6211caa17af486a05b6b9baef186438a.jpg\n",
            "20220517_124658_jpg.rf.5ed16f551d7dd881daa7d566e29391d9.jpg\n",
            "20220517_124708_jpg.rf.f4389845a64a38697ac73b0f53bc912e.jpg\n",
            "20220517_124711_jpg.rf.5a7234ed5bc3d28e6af1e940a2c6d374.jpg\n",
            "20220517_124930_jpg.rf.a9878087141ff39bc9141e22140df578.jpg\n",
            "20220517_124933_jpg.rf.60cbefff338bb6f835bfade0adc7019c.jpg\n",
            "20220517_124937_jpg.rf.4d00df1933bedf9097731bb7b3be8e19.jpg\n",
            "20220517_124959_jpg.rf.93777442b36ae139fbae61853fb38bf9.jpg\n",
            "20220517_125005_jpg.rf.38941645ef4bd648bfc30456017e628d.jpg\n",
            "20220517_125005_jpg.rf.a0f0259d68996fcc5f3a988340bff862.jpg\n",
            "20220517_132137_jpg.rf.9cc7ea8846c701b1a0da93487581d824.jpg\n",
            "20220517_132137_jpg.rf.bfa62f0a1beabfca232dc311a36ab7ac.jpg\n",
            "20220517_132148_jpg.rf.adae64cac94b477f1d7c3cb625a8e0ac.jpg\n",
            "20220517_132153_jpg.rf.ea52d25068ec1c74996e78980406796b.jpg\n",
            "20220912_15_1159286_L_jpg.rf.1a24e3672b9830e2d6e77903ef3aa58b.jpg\n",
            "203-E-3071-TC-10-21_jpg.rf.3b8a5be9adee3cba5045e4b5a8cb4541.jpg\n",
            "204_jpg.rf.7cee5168f68598aa1f37d46eaaa1051f.jpg\n",
            "205_jpg.rf.cf42521632b147aae2942c077a9bfef3.jpg\n",
            "206_jpg.rf.ec3182170ee08bf9266f8d76de00fd98.jpg\n",
            "207_jpg.rf.0bd05634e7cea5788c43a5d95705a1b1.jpg\n",
            "208696_jpg.rf.ec4b2941cf2929b5dd808bd8c68bf861.jpg\n",
            "209491_jpg.rf.6d5bc89016963c81f2df05476b900644.jpg\n",
            "209_jpg.rf.51f3b0d722571e283115b7ce15a110ea.jpg\n",
            "20_jpeg_jpg.rf.276ae6e1c80e29f2a2b8bf399c96e983.jpg\n",
            "210_jpg.rf.048de7928e11f4cb7629e1d0e86a2ed8.jpg\n",
            "211_jpg.rf.d8e67ad96284c0f058c85e3ffffb6821.jpg\n",
            "212390_jpg.rf.246d576a1ee7efa431e3809b846ce07b.jpg\n",
            "212_jpg.rf.4188aece6e5a4dd3587f9ea56fdda8c2.jpg\n",
            "2-1307437574-Honda-Brio-Putih-AT-Type-E-2016-Warna-Putih-Bekas-Plat-AD-Klaten-Klaten_jpg.rf.1ce2ad9b26c6946e17225b4323b9c26e.jpg\n",
            "213_jpg.rf.12dd7161f808e900406653c971a3bf89.jpg\n",
            "21452_NT130964_2-1_jpg.rf.1059e81689b01064d8b5e4b47d2c7d8a.jpg\n",
            "21452_NT130964_2-1_jpg.rf.1e27d1dc40ea2e41f4f0c64a8b8bb2e0.jpg\n",
            "21452_NT130964_2-1_jpg.rf.481bc1132976203e2a9585baa402e19d.jpg\n",
            "21452_NT130964_2-1_jpg.rf.93577aa8aebdae15a767e2520f269ade.jpg\n",
            "21452_NT789-1_19-1_jpg.rf.2feb6fa3290b05bbe8033ec42307c68a.jpg\n",
            "21452_NT789-1_19-1_jpg.rf.9edd3d9c62921866459191e77c26a636.jpg\n",
            "21452_NT789-1_19-1_jpg.rf.abd66884627442169bb9568ca4a134d3.jpg\n",
            "21452_NT789-1_19-1_jpg.rf.afec65ea5572453ec96dcc8adafdf807.jpg\n",
            "215_jpg.rf.41d9dacc26ba685335a352b6e55a2d05.jpg\n",
            "216_jpg.rf.75e999e27db3d460dfe90503a650b1b9.jpg\n",
            "218014_jpg.rf.b00c4696bf469ca175d063d5e71276c6.jpg\n",
            "2182_jpg.rf.b0e9c5e71955d208e3b60586052c8a10.jpg\n",
            "219222_jpg.rf.049768c8885830d6675342c300df65e0.jpg\n",
            "219_jpg.rf.dc33b699c1b37213bd7dce98918da55a.jpg\n",
            "21_jpeg_jpg.rf.95a6ab316ad6e043b890542baf5634d0.jpg\n",
            "221_jpg.rf.3e2d10b7d61751159e4fd353028b0cd4.jpg\n",
            "-2229E395-534F-4F69-9F9B-80628BD8D5AC-png_jpg.rf.353804f41f47ed2b20850db9d101e3a7.jpg\n",
            "222_jpg.rf.3b9b28afdf24619fcaf3e6b2ef0224f9.jpg\n",
            "2234_jpg.rf.5249bbd34b4c910a3495c3a087ff47e0.jpg\n",
            "2234_jpg.rf.7658531f55c9bffd787d1595235e1c3b.jpg\n",
            "223_jpg.rf.ef741e355e12eb7965cc6c799c3e2bc0.jpg\n",
            "224_jpg.rf.9971ec5770caf72f5ea3a2807d76653f.jpg\n",
            "225_jpg.rf.1cb520c565a9ce934885d0787fd99a3e.jpg\n",
            "226-E-5148-OI-06-13_jpg.rf.5e298cf37bb27c6a68515afcd193d93a.jpg\n",
            "228_jpg.rf.8454407f093c3787341715f9a0bc4572.jpg\n",
            "229_jpg.rf.c036fc58808769bb62d4614dff5ae2f3.jpg\n",
            "-22C97EA9-A33B-4CCD-941C-5A2130410D29-png_jpg.rf.7a7d15839202f6616cd7aac8406692a5.jpg\n",
            "-22D2C682-3978-442F-B081-82D1DC552928-png_jpg.rf.91ef9f0e558d9c34cca364ee45a6ccd8.jpg\n",
            "22_jpeg_jpg.rf.7805ffe3a5a806fa1d08f662ee6a4924.jpg\n",
            "22_jpg.rf.ac72d48230134c6630a21b980418956f.jpg\n",
            "231_jpg.rf.3393800a7f4789cb7452e47cbdcafdca.jpg\n",
            "-232CA389-A176-4AB7-A513-8D2D5E477CC2-png_jpg.rf.57777c86bb0db2ce1581e3cf484e5570.jpg\n",
            "232_jpg.rf.3613056773a83b612753e03fabccc4d0.jpg\n",
            "233916005_6a02c11c_9248_4e5b_8386_34007ee612e8_823_1266_jpg.rf.b524c1efa62e087d836f65eabd4f3e3b.jpg\n",
            "233-E-3407-PAB-03-21_jpg.rf.33410342166a623ea52caca093443ff1.jpg\n",
            "233_jpg.rf.71b31ef034240fd7f856b0e1f2a574c4.jpg\n",
            "235_jpg.rf.1921fccc6968d1d2abbc21f8670f92f3.jpg\n",
            "-23705E7A-1279-43E7-B20A-CE37ADAB61DD-png_jpg.rf.a0858f774592575bc40bdfbbae3f2d32.jpg\n",
            "239_jpg.rf.59c3e79ef5da446eaa5149fe87c6a4c3.jpg\n",
            "23-E-2694-SI-09-19_jpg.rf.847a425cccbe9aa45e8c931b5710baf9.jpg\n",
            "23_jpg.rf.56c528d88e41d02c4eb3297d7418058c.jpg\n",
            "23-Kode-Plat-Kendaraan-Kota-Yogyakarta-_jpg.rf.51f8901c6c22d92a859b1af375d2b011.jpg\n",
            "240_jpg.rf.01a600aabf36de3a88b646a2587cb4ca.jpg\n",
            "241_jpg.rf.410a661fe245581e048c6cd27dc278fe.jpg\n",
            "242150_jpg.rf.a3e4c15bc45a94130f921381efe69f5f.jpg\n",
            "243_jpg.rf.0754fb2aa62471e1927b01c81bd98611.jpg\n",
            "244_jpg.rf.1c50ab95e0d0a801666a1f68f133cccf.jpg\n",
            "245-E-6941-PAP-08-22_jpeg_jpg.rf.fdb9d8ef7d7f023f55b731c110b9eaf1.jpg\n",
            "245_jpg.rf.7d523b7a0d5713d14a4bb036dec6135a.jpg\n",
            "2465_da8fe53a59ef60c6eb3ea78b89ee30c_jpg.rf.61f5bb87ec6ac06b815f3469a81943d1.jpg\n",
            "2465_da8fe53a59ef60c6eb3ea78b89ee30c_jpg.rf.8466404ff243b5c089e0bfcd0a982cad.jpg\n",
            "2465_da8fe53a59ef60c6eb3ea78b89ee30c_jpg.rf.b550bf6ec76bf12cdbd5921f8bbaf24a.jpg\n",
            "2465_da8fe53a59ef60c6eb3ea78b89ee30c_jpg.rf.f3b6b14b5dd1c2793fcd525023ff59aa.jpg\n",
            "246_jpg.rf.d1bbdb6874bf251f1d99891d61dc5e5f.jpg\n",
            "248526_jpg.rf.cbfa076e5690802b8d2e218219833a8f.jpg\n",
            "248-E-4212-SS-01-21_jpeg_jpg.rf.eca98b68171099555b21a29642165373.jpg\n",
            "24-E-6520-PAC-05-21_jpeg_jpg.rf.dad4711665dc69f509829df2ed4bd40b.jpg\n",
            "-24FFED69-CE70-43C8-8E00-90684987BD32-png_jpg.rf.8e4c643761cf5b5e6ded4d5b30e856f4.jpg\n",
            "24_jpg.rf.644c4b1cabd8b3597779a2c1d5bf4f01.jpg\n",
            "250150_jpg.rf.dd0ea6652a8130314ffbdf091d7a0f09.jpg\n",
            "250-E-6031-ST-03-21_jpeg_jpg.rf.d0f424c4502dd9eec2a0a82bd496e46f.jpg\n",
            "251327_jpg.rf.00e98209d426acf987ef53461dcba68a.jpg\n",
            "25195-ets2-fuso-fu-v1-5-ets2-1-40_jpg.rf.00b28cc850f5e79b4d8748bab99428fe.jpg\n",
            "25195-ets2-fuso-fu-v1-5-ets2-1-40_jpg.rf.4c0afe4106d49bf45e63ec11fb94e2ad.jpg\n",
            "25195-ets2-fuso-fu-v1-5-ets2-1-40_jpg.rf.4ca0184c0dee13f7496b35f0a9091678.jpg\n",
            "25195-ets2-fuso-fu-v1-5-ets2-1-40_jpg.rf.92628638fc5f449ea792c61867388eb0.jpg\n",
            "25195-ets2-fuso-fu-v1-5-ets2-1-40_jpg.rf.d92c3feee72c83833cb759b113edfb82.jpg\n",
            "-251A7DC4-47FA-45BF-8F18-8C933578D147-png_jpg.rf.320d7d9c7857d3f0e10953ce955456d5.jpg\n",
            "251-E-3008-SM-05-20_jpeg_jpg.rf.83e8c5416a3b6ce0077a3ff404117ae5.jpg\n",
            "251_jpg.rf.420793729b63348d7bcdfc2be2b3c40e.jpg\n",
            "-2526BBBE-6B96-49DC-94B9-880E133FA549-png_jpg.rf.aa2a1ccd9b92b40d119c9f7dd00c10ad.jpg\n",
            "2530355363_287ac9442d_b_jpg.rf.f02155870f75b7fe6c14c05b4caae2fb.jpg\n",
            "25397-colt-fe-truk-mitsubishi-colt-d_jpg.rf.0262cdc38cc79b423ed7754af29fab7e.jpg\n",
            "25397-colt-fe-truk-mitsubishi-colt-d_jpg.rf.9ed615cf682f1310febd61dac8879aa7.jpg\n",
            "25397-colt-fe-truk-mitsubishi-colt-d_jpg.rf.e16027d4aa9603646a3610f82ef762c9.jpg\n",
            "253-E-2212-TZ-07-18_jpeg_jpg.rf.4fb5ab224de6f74dcc09ba6174927bdf.jpg\n",
            "253_jpg.rf.79c50d0ef8694d44eb664be91438f2e1.jpg\n",
            "255-E-6527-OD-02-20_jpeg_jpg.rf.8dd2351aa32b58d8f5f8252a9541e6e5.jpg\n",
            "257927_jpg.rf.ab7e76ddb4f75aea2663dfe92e403f34.jpg\n",
            "257-E-4553-QT-06-20_jpg.rf.019d80f91317d61dc75f5bdaf0b8ca25.jpg\n",
            "257_jpg.rf.5604c2570bf825aacc345ffa33f030ef.jpg\n",
            "2_57_jpg.rf.99dd06878fd6ef80ea87d99463189906.jpg\n",
            "258179_jpg.rf.e11d3211196c831fa8149884337cc370.jpg\n",
            "258-E-2895-NB-10-13_jpg.rf.9d52b2e2927da5be404a2c32ff0d767d.jpg\n",
            "25994-colt-fe-jual-truk-engkel-fe-71_jpg.rf.550578cd2d5be4675bed5470dcd9bb88.jpg\n",
            "25994-colt-fe-jual-truk-engkel-fe-71_jpg.rf.939ff6d74545a81a37176aafea56b6c7.jpg\n",
            "25994-colt-fe-jual-truk-engkel-fe-71_jpg.rf.f9155faeb8fe8cbca07a03f8f2b53e6a.jpg\n",
            "259-E-3154-QO-11-19_jpeg_jpg.rf.fb5ac8baf50f1601265474c39b6a317f.jpg\n",
            "259_jpg.rf.ad49299eaaf3cc23b5ebcaca257bb1bd.jpg\n",
            "25-E-2101-PAD-06-21_jpeg_jpg.rf.0ac4d17ed4756c0a0c14562f9dfa0d86.jpg\n",
            "260-E-4250-SU-04-21_jpeg_jpg.rf.a20e29b07dc57816b519d7bcc4c88c00.jpg\n",
            "260_jpg.rf.b37f1c6047792eb091068d8ea43ce270.jpg\n",
            "26135_jpg.rf.17aa0f23a20a3adc0c1c89abd8facc9b.jpg\n",
            "261-E-4991-TP-09-17_jpg.rf.6b0c1a94dcbba2dbc5988980f22d27b1.jpg\n",
            "262-E-3465-SL-02-20_jpg.rf.6c7a3abf7e9575df4178a631d0fd139f.jpg\n",
            "262_jpg.rf.e279fad8c298cc4c973f938369b96530.jpg\n",
            "263-E-6631-TO-08-21_jpg.rf.2d27cbd5f654b98cd9f0ded143c1ad98.jpg\n",
            "263_jpg.rf.c0009ef3f77f4e0ac0b25f9609d2d469.jpg\n",
            "264441_jpg.rf.c12720ed857a68091a4598eae7369553.jpg\n",
            "264675_jpg.rf.c1e65ed16d430345c6fee6f82d040923.jpg\n",
            "264-E-2458-SV-05-16_jpeg_jpg.rf.15ec620af85ca3768daf24ca9f72a6ff.jpg\n",
            "265-E-3984-TZ-07-21_jpg.rf.03ed8990e911e33eede07b6eb88466bd.jpg\n",
            "265_jpg.rf.3866750c19d947dccd20fda183cb6a6a.jpg\n",
            "266-E-4299-SZ-09-21_jpeg_jpg.rf.42533122b6b8223d51250c40c6e2f7c7.jpg\n",
            "266_jpg.rf.6ca580da529394d0c39714d32ccf61f5.jpg\n",
            "267-E-2747-TS-12-17_jpg.rf.7f30924a1a928d1f71010e08b549d8a7.jpg\n",
            "267_jpg.rf.9a88aa5afe1b6161f6b8dc876a2a730d.jpg\n",
            "268-E-6752-SN-04-18_jpeg_jpg.rf.0484a39d7bd54edd3b9174b2903bbebd.jpg\n",
            "269660_jpg.rf.9bfae51d9ad4c0b96cb82d1ed2cbb3ae.jpg\n",
            "269-E-2101-TJ-02-22_jpg.rf.603603040ec0996b4b116ad27a2118c3.jpg\n",
            "269_jpg.rf.6a71e0a35d7d050a516bde586679913c.jpg\n",
            "-26A61E03-2530-485D-8D3C-0D6EEAA17019-png_jpg.rf.81fe43950702326cb243f4a101948c50.jpg\n",
            "26_jpg.rf.af68ffd953d7e245f270784b3a3b06ee.jpg\n",
            "270672_jpg.rf.228e81132aaf2a81ae59e0eadbf0a304.jpg\n",
            "270_jpg.rf.caab8d0688b47485459306bc0c15fd0e.jpg\n",
            "271-E-2381-PAH-10-21_jpeg_jpg.rf.488c4f95a9e291f93d241f290f69cd77.jpg\n",
            "272-E-1677-PE-02-21_jpeg_jpg.rf.2ed816f36afe98f0ad521fa4d1dcb218.jpg\n",
            "273-E-6078-RM-09-22_jpeg_jpg.rf.a6839a7a290e28edb0d29f0c64cec915.jpg\n",
            "273_jpg.rf.6b36a27ca8890f01e7a696c7302497bc.jpg\n",
            "274-E-4558-SH-08-18_jpeg_jpg.rf.fd906ca35974e73fe3ca756ebbe36ac6.jpg\n",
            "274_jpg.rf.28b71d84f2834c552b8481d8a6ceeea8.jpg\n",
            "275-E-4986-SO-10-20_jpg.rf.86cbe345e3de6c9a107a8949ebe3cdfb.jpg\n",
            "275__flip_jpg.rf.a6f020af5e4170c4006aa1fd158f51e8.jpg\n",
            "275__flip_jpg.rf.e33de4c09983b225b8aa0a67a1a797a6.jpg\n",
            "276086_jpg.rf.852aa943294c2df157989d8792d8be8d.jpg\n",
            "276520_jpg.rf.23aebd2157326d2cde7d09006a96e640.jpg\n",
            "276-E-2810-PAD-05-21_jpeg_jpg.rf.d96246a6cae5aefedaaceef78ffdbc13.jpg\n",
            "276__flip_jpg.rf.a2ed6b49cd003f2d7874a0c2500d56d9.jpg\n",
            "277-E-6802-PAH-11-21_jpg.rf.83fe067d6e9404458eb241e1e9f2f65a.jpg\n",
            "277_jpg.rf.0629d6b3662673085f868d2e3e2910ae.jpg\n",
            "2788_1807600_1_jpg.rf.7c442cb4b590cfd8692b016c0cdf0da8.jpg\n",
            "2788_1807600_1_jpg.rf.dd57e72adec4651f3f546053bd4eea27.jpg\n",
            "278-E-4568-TCK-12-17_jpeg_jpg.rf.5b0efc3e130061ade4819d1c06bfdc8b.jpg\n",
            "278__flip_jpg.rf.58dc39560cde20d98f716aad913fb99d.jpg\n",
            "278_jpg.rf.120f979f2c19f4249b618c196071dd5b.jpg\n",
            "279_jpg.rf.4a07ea16f9faf3f3b2be2b9aed9f31c0.jpg\n",
            "27-E-3524-PAG-09-21_jpeg_jpg.rf.5ce83cbf7eefbd219aea06a047832dd8.jpg\n",
            "27-E-3524-PAG-09-21_jpeg_jpg.rf.a0179ab1914d80c3fecb174a22c89006.jpg\n",
            "27_jpg.rf.2d4ccde4ea046fca8003750050435619.jpg\n",
            "280708_jpg.rf.3f16bbd0f8a7a70444d5addd8d877491.jpg\n",
            "280933_jpg.rf.1ad0a439fdee1d133889b8e763ef49f5.jpg\n",
            "280-E-4813-PL-04-20_jpeg_jpg.rf.89b79d275a8ed0f8553d3b2989a17397.jpg\n",
            "280_jpg.rf.fc71d2ad85a21e8a89d6168cbaab8b7a.jpg\n",
            "281-E-5503-TI-02-20_jpeg_jpg.rf.7a737820ab7c896da9834346e4d9ebc7.jpg\n",
            "281__flip_jpg.rf.0a41f8420c57420076d18f40b1ee0349.jpg\n",
            "281_jpg.rf.a7673a3d75c552dfb6c8b66c5c256b5c.jpg\n",
            "281_jpg.rf.d24ab90829d3aa8264b50e14763a5e9b.jpg\n",
            "282474_jpg.rf.5388278143664ccd2a5a0553eabbfa06.jpg\n",
            "282948_jpg.rf.b7659d354d1bdd80887722f073fe9ac8.jpg\n",
            "282__flip_jpg.rf.5e1b66f870c9e4141b357aa828d38306.jpg\n",
            "282_jpg.rf.514b2281f02b51472c7888794f393e72.jpg\n",
            "282_jpg.rf.ed49393d349f5a539e86b58fe0adbfa6.jpg\n",
            "283040_jpg.rf.fe2b2651fcb2a9f607f6338f732d872c.jpg\n",
            "283794_jpg.rf.e6381acc012996f41f236102cdc8e5ec.jpg\n",
            "283_jpg.rf.a39d254565ebedd41eae7b9bb0d38f0c.jpg\n",
            "283_jpg.rf.f632e2d2bb4f6424313ffdb5bbabda5c.jpg\n",
            "285152_jpg.rf.c45844858cb78f3fc841cd853a264c79.jpg\n",
            "285-E-5515-QT-06-20_jpeg_jpg.rf.9b633c730eb6b255c9f6a49ce91fcc5b.jpg\n",
            "286973_jpg.rf.b58f1bf0ed379323a7662bb7ba690bd9.jpg\n",
            "287-E-6272-PAJ-02-22_jpeg_jpg.rf.f58448c287b4c8fa8e85b3f1e4e0a8a1.jpg\n",
            "288-E-2747-QQ-01-20_jpeg_jpg.rf.8f2fd889e0f02c6415279547072fac94.jpg\n",
            "288__flip_jpg.rf.fa510a6c3b0cba3b25dfefe7aa413955.jpg\n",
            "289-E-6810-TX-06-18_jpeg_jpg.rf.7393fbc50fec7f81d5418702ce74de7d.jpg\n",
            "289_jpg.rf.2f07d752c4f5c8b0c2a684fdf80fcf28.jpg\n",
            "289_jpg.rf.40b533b2463665e487d9447ac0ac2d13.jpg\n",
            "289_jpg.rf.9e0c2ed286657ae50725c90364fce370.jpg\n",
            "28-E-2393-TT-01-18_jpeg_jpg.rf.2905c2320fb0b1c116261d60eb87849f.jpg\n",
            "290_jpg.rf.957a7274de9a978eea32c0310d029dad.jpg\n",
            "29174_jpg.rf.7961248d9edeba3f1f5c6f60ab103ece.jpg\n",
            "291-E-3496-RW-04-19_jpeg_jpg.rf.278b686b763e9afb3c166bc3e6222493.jpg\n",
            "291_jpg.rf.78a351a11b7137ce803f185dac3e7b1c.jpg\n",
            "291_jpg.rf.f1d7fa39216e8ac420c99c88e47d4efd.jpg\n",
            "292846_jpg.rf.f91653444e183f27e2c3d1d80f011ff2.jpg\n",
            "292-E-4890-QE-01-19_jpeg_jpg.rf.018bd1763add838137693d183b8cb8c3.jpg\n",
            "292_jpg.rf.56792d17c1785f745abb5dd44312604a.jpg\n",
            "293-E-2509-OW-09-20_jpg.rf.816f6e1b9f9f32f5314a177496396151.jpg\n",
            "293__flip_jpg.rf.73fabc7ed7e54525a6a962fdfac8b231.jpg\n",
            "294-E-2381-QAA-10-22_jpeg_jpg.rf.10c9775fc3b838bcc55ea431ba16ef04.jpg\n",
            "294__flip_jpg.rf.dad4d81e0e0fe7b59bb8bc8a1ce6c483.jpg\n",
            "295-E-6919-TM-06-17_jpg.rf.f9ae43d8e4def59aa07e68b53fef1f30.jpg\n",
            "295_jpg.rf.e981fe1521a3690d1201f569c2899faf.jpg\n",
            "297_jpg.rf.d8f0e3a509f2fc483454a5a7bbf5f6fb.jpg\n",
            "298-E-5944-TK-04-22_jpeg_jpg.rf.08d15e2cf2a592abb44fdd99e3b287f7.jpg\n",
            "298_jpg.rf.c78231d4d300671f9484c15093b2571a.jpg\n",
            "299-E-5051-SD-03-18_jpeg_jpg.rf.0127cc54956d3be999ac345813a8d19c.jpg\n",
            "299__flip_jpg.rf.67e510a4bb17d9ad4a9b506ac32fff14.jpg\n",
            "299__flip_jpg.rf.7a828349ef9057f202f7cbd7e5dc5c8a.jpg\n",
            "29-E-3978-SC-12-21_jpeg_jpg.rf.07a5ee06c408946fca629a8261e94345.jpg\n",
            "-2AE9E484-CD7E-45FB-BD22-3EB7588C1224-png_jpg.rf.1bbe47ebf56692b6e7bc5aa7a1a42a1a.jpg\n",
            "-2BFD91FB-F08F-448D-B649-ADF70A001E37-png_jpg.rf.f697fa915a3105fd49d88f37317bd9e5.jpg\n",
            "-2CC30CC7-5872-41C8-80F9-549219177A84-png_jpg.rf.3895da64d904190c2cb83473d15cb441.jpg\n",
            "-2CED9A70-376F-4C6E-9D0F-7670A652C145-png_jpg.rf.28cdee7290807fd5aeec4091d2e9aff8.jpg\n",
            "-2D2D8602-E497-4B46-B4B3-5C7594A43411-png_jpg.rf.c4eb1fd717c79fd22ca9c7f64fdb1336.jpg\n",
            "-2D839168-D231-4DD7-8B9D-7C814EE1566B-png_jpg.rf.938319271bf1e8de0f4cbf2fa7104530.jpg\n",
            "-2DA4F282-79BF-479B-8C38-E863DBF1AA9D-png_jpg.rf.d54dca43d0d792f018512bccedb096ed.jpg\n",
            "2e1asdasd_PNG_jpg.rf.0631020da8512ec6896b8141b3d943d2.jpg\n",
            "2e1dasdas_PNG_jpg.rf.680b581e3da372df09d6b2da27c9ebc7.jpg\n",
            "-2E501F36-DA04-4BD8-AB75-602E05110FC0-png_jpg.rf.1a59a532d8985cbe8538efb538610798.jpg\n",
            "-2F4A4C5D-FCC3-4EFB-926F-17C298CC2970-png_jpg.rf.01ba4ac38e22faae491243eb919eab6e.jpg\n",
            "300-E-5105-OD-12-21_jpg.rf.91c59dba9380c14bdb9015a835473a11.jpg\n",
            "300__flip_jpg.rf.b4a28b8315bc9ea3b3ac6d79e74688e1.jpg\n",
            "300_jpg.rf.2c45faab3d223fa8b8cc2f248928f5fe.jpg\n",
            "300_jpg.rf.3db0d48c04b7ca70c46ba034561e0ec6.jpg\n",
            "301-E-6893-PAD-06-21_jpeg_jpg.rf.ff1303149a6effb352ec6dc8bdee9594.jpg\n",
            "301_jpg.rf.007e7e1c257fcea0483f6a0d034ffb86.jpg\n",
            "302-E-3922-OI-05-19_jpg.rf.884871d0d82eaaaa2bb5f2df6a1e438c.jpg\n",
            "302_jpg.rf.c9054fa032c6b2297dadc0f795a48db9.jpg\n",
            "30364-1_jpg.rf.2147f01957d5d0aeab15d5c2f2b36a2a.jpg\n",
            "30364-1_jpg.rf.37dee55403818a6a9b063b69e754d005.jpg\n",
            "30364-1_jpg.rf.48d4e034edcd92ccdfbfcef2e3b71e4c.jpg\n",
            "303-E-6888-SC-11-21_jpg.rf.9122b8168ef5c3f7c053fc6fc0453da5.jpg\n",
            "303_jpg.rf.326065010c77de49d7e691b89af83bc7.jpg\n",
            "303_jpg.rf.c00476a63e3a858c9c908fa7f201f343.jpg\n",
            "3040974006_jpg.rf.00b08731018f55d58a8be792ceac7870.jpg\n",
            "3040974006_jpg.rf.10e3636a4b362a9fdba26e0ee90b3a08.jpg\n",
            "3040974006_jpg.rf.955002bec719ca09633a5c6bb7d22df8.jpg\n",
            "304-E-5381-PAB-03-21_jpeg_jpg.rf.ede30c21c6a605dfc05f2207ee72bc62.jpg\n",
            "304__flip_jpg.rf.9bf8f5f49e84af01641e3cb941a3b36b.jpg\n",
            "304_jpg.rf.588e0977b9fe6a96defd2f408a31ecaa.jpg\n",
            "304_jpg.rf.89e84f14f93f1d9fde5b2179eb6f4c07.jpg\n",
            "3059_en_43493_17596_fuso_canter_fg4x_jpg.rf.1eef2b4206e99f22d2e416a30b7ee83c.jpg\n",
            "3059_en_43493_17596_fuso_canter_fg4x_jpg.rf.c725a99a722ee3ae508941dfaff11862.jpg\n",
            "3059_en_43493_17596_fuso_canter_fg4x_jpg.rf.ea8dde60998cbac2acd047234b1e42a5.jpg\n",
            "305_jpg.rf.659453c28356f3728b0343f2001bd775.jpg\n",
            "305_jpg.rf.fa2f29ae096805dab6f146c4be946e19.jpg\n",
            "306616_jpg.rf.9f4afe7bbf13b558dd8c152aa95e41be.jpg\n",
            "306-E-3270-SJ-08-22_jpeg_jpg.rf.42a6f0310d58dfb4f7ac03d13e919367.jpg\n",
            "306_jpg.rf.e7529764f9c7385d1b5e33a29832d323.jpg\n",
            "306_jpg.rf.ee87338eb81feb8716cbf56a3618ed1e.jpg\n",
            "307-E-4238-QC-11-18_jpeg_jpg.rf.9b75af32c28550cdfa53bd28c9b75a74.jpg\n",
            "307__flip_jpg.rf.c0ede904b5511523d662c2acdf674edf.jpg\n",
            "307_jpg.rf.1c497f990e201e6151a879aef1769eee.jpg\n",
            "307_jpg.rf.aab5e6c1a67d0832e6a861507fa80687.jpg\n",
            "309098_jpg.rf.2613d221b84c94dcee33fbf1903db5e7.jpg\n",
            "309-E-6140-OX-11-20_jpg.rf.72c3eee8ab5aa482ec4e74f82a9f3a9b.jpg\n",
            "309_jpg.rf.2dd748abde9bb298ab586acc301c10b2.jpg\n",
            "-30D0614E-5268-4BF4-8D73-D219A9746EC6-png_jpg.rf.4b2be5d04689502d5c87d7f8e26ec659.jpg\n",
            "-30F90B85-6947-452B-A85F-E8696249B7A1-png_jpg.rf.ac7f03032d8326ca01f9c2761da4e77d.jpg\n",
            "310__flip_jpg.rf.a936700492f417271c8f979da8f59f85.jpg\n",
            "310_jpg.rf.8ff4f41cf36670e97a302fb00b16f7c0.jpg\n",
            "311-E-3593-TF-10-19_jpg.rf.4bed425b8f02a52935e00f831072b02a.jpg\n",
            "311_jpg.rf.0bba914f74c9f8edf79f374582ce5c4b.jpg\n",
            "311_jpg.rf.a32c95c54a8eec8e0e62ccf991d7cd07.jpg\n",
            "311_jpg.rf.e9c22b8e7ecd7eb58db1af4d15de4344.jpg\n",
            "312250_jpg.rf.9dbabb27fe3a18969f46aeefd7859544.jpg\n",
            "312easda_PNG_jpg.rf.ca40efd6750596ae78bfbdf50be7bdb7.jpg\n",
            "312__flip_jpg.rf.625128038c345f5e63c1e025090fa07b.jpg\n",
            "312_jpg.rf.cc9d2481795e7ba939fb75d7cde4cdbd.jpg\n",
            "312_jpg.rf.d92b0eaa38656b40299d1810b6ee220f.jpg\n",
            "313-E-5971-TO-08-22_jpg.rf.52b7f4fbc2836653530c24bed53bd390.jpg\n",
            "313_jpg.rf.475c0f5d33527571319607228839f7f7.jpg\n",
            "314-E-3016-SB-10-18_jpeg_jpg.rf.3e57eb0322d4830e444325b7b444f98e.jpg\n",
            "314__flip_jpg.rf.7e7f00ccc0601a8d4d5c6c1cf05bc7e5.jpg\n",
            "315947_jpg.rf.40560dd79d78e1db0da59467e3190544.jpg\n",
            "315_jpg.rf.513aa0a6328ec01fb7655d550d760172.jpg\n",
            "-3163ca687f_jpg.rf.2697059ad27cd8d53944ae3e7ad7a4de.jpg\n",
            "-3163ca687f_jpg.rf.8227bd7a15f7f0e42361570888f472ed.jpg\n",
            "-3163ca687f_jpg.rf.8d19f396e28cc4f4a79874e13f7c13c5.jpg\n",
            "-3163ca687f_jpg.rf.e4f85482941997ced5ee8efd1679d971.jpg\n",
            "3-1650482375-Yamaha-Motor-Fino-Premium-Tahun-2016-Plat-T-Karawang-Pajak-Jalan-Motor-Siap-Paka_jpg.rf.fbee5189a84c511e12bc3b08c7dc3074.jpg\n",
            "316_jpg.rf.736eccaed3847037b1b8e5640bea555a.jpg\n",
            "317185_jpg.rf.4b50377223498301de7c08ceda1eca16.jpg\n",
            "3173ec56-a792-47ff-9b18-79fc37729b95_jpg.rf.41fdac473b573448454abec7ea056b6b.jpg\n",
            "3173ec56-a792-47ff-9b18-79fc37729b95_jpg.rf.ea358523dec0b3e0d7c209e7cdd80428.jpg\n",
            "317-E-5064-SE-05-19_jpeg_jpg.rf.280773696efce96a11a3dc884a232787.jpg\n",
            "317__flip_jpg.rf.33a2fed8ee39ac861e3ee704dc001f0b.jpg\n",
            "317_jpg.rf.2552e8014a6ac1d511119746a19863c1.jpg\n",
            "317_jpg.rf.e623d351c8e6e866427043cb79636c77.jpg\n",
            "318__flip_jpg.rf.acee03aa63fd73c49f6257d4f3d858b3.jpg\n",
            "318_jpg.rf.8891a22072a11366db71472419f2238e.jpg\n",
            "318_jpg.rf.f3aefd5123720d4f301264a03a89d25c.jpg\n",
            "319-E-3547-RR-06-12_jpg.rf.c8cf3bd5ac47553f20a9b74d3e429110.jpg\n",
            "319_jpg.rf.606f7dda1988164c4daf0da1352380b4.jpg\n",
            "319_jpg.rf.9f6e7b4335902252407cb95a70dd9e7f.jpg\n",
            "-31A39D7C-DC0F-4C2E-9CC8-74C1BCC9C660-png_jpg.rf.c41b46ac5656a54b30d5d5e8b7617117.jpg\n",
            "31-E-5235-RO-11-16_jpg.rf.440da1266e457f17f5d2c057dca254f3.jpg\n",
            "31_jpg.rf.45b1318d9fd10983d3beec3e4c989f6d.jpg\n",
            "320-E-3796-PY-05-20_jpg.rf.96a0ae346e40de076413d9779944fc38.jpg\n",
            "320__flip_jpg.rf.d847db1005a1fa278cf503a2fecb8ff0.jpg\n",
            "320_jpg.rf.43b6fc24b7d2a5f5b742332cb76c193f.jpg\n",
            "321-E-3255-TN-12-20_jpg.rf.64bd27b2f5171abd0dc8b266800dcd57.jpg\n",
            "321_jpg.rf.39537770e88e5a49c436c106790ccd15.jpg\n",
            "322-E-8767-TG-11-22_jpg.rf.669117853717596c5d59808126bd17c9.jpg\n",
            "322_jpg.rf.5a8677dee8a3d90684af99f59c5d682b.jpg\n",
            "322_jpg.rf.cf0e8a854c884b23fb1f3f6dec1bc4f5.jpg\n",
            "323-E-4886-TM-06-22_jpeg_jpg.rf.8d3339013e722ed01aea597542ed95a1.jpg\n",
            "323_jpg.rf.87eeca1170bb66e716a446a0e3b45ba1.jpg\n",
            "323_jpg.rf.9a70a1d0b23b269bc1c4f85c6cc8a441.jpg\n",
            "32455_44329_230732_jpg.rf.8bd96c47c552ee84b868382af637b6a5.jpg\n",
            "32455_44329_230732_jpg.rf.a9c0819da80944cc17457c46692fc1cc.jpg\n",
            "324-E-5854-PAP-08-22_jpeg_jpg.rf.52a0d97e4113251550bcb5020ebb26f7.jpg\n",
            "324_jpg.rf.a4ee3cb9070157c5bf1807c754d51d95.jpg\n",
            "325841_jpg.rf.98f84dd119fd79646b86553047a273af.jpg\n",
            "325-E-2634-QG-03-19_jpeg_jpg.rf.01d94b9977d6356f14dc6b5d3088477c.jpg\n",
            "325_jpg.rf.152bddf0f63f4e7089d41148790b1301.jpg\n",
            "326-E-3758-RW-04-18_jpeg_jpg.rf.19761559c2bd4606faed41a665ef5ead.jpg\n",
            "326__flip_jpg.rf.d4d995d401735da0a8c4f021a6938815.jpg\n",
            "327-E-5071-SS-01-21_jpg.rf.15c7c20849c20a5f12342c7ce7c1ef1d.jpg\n",
            "327_jpg.rf.2691980234d5f55b936410c9e8bd2eba.jpg\n",
            "328789_jpg.rf.22094f644205c85b4707e4ddd2b3b6cc.jpg\n",
            "328_jpg.rf.187059b84bc5d185b9fbb6acb686edc7.jpg\n",
            "328_jpg.rf.b70e97e1dfaaca7dce3e93022cd2e617.jpg\n",
            "328_jpg.rf.bea1faa1bea708089f3c07242aa2c0a5.jpg\n",
            "329220_jpg.rf.64e3ae09d56fb377a65661cd7f081b69.jpg\n",
            "329-E-5078-QF-02-19_jpeg_jpg.rf.457342a9a171acb6cbed4ec23cd486fb.jpg\n",
            "329_jpg.rf.e0103ee597ea82a548ebe3122bdb1899.jpg\n",
            "32_jpg.rf.5fb8291c870957fa2388c16876b25e3e.jpg\n",
            "330-E-5869-PAA-02-21_jpg.rf.7c453f01684a73339570026a7571f683.jpg\n",
            "330__flip_jpg.rf.c1c44d4b5b00ee934dfdf624ca2bba29.jpg\n",
            "330_jpg.rf.68ab31634e491b64b4c240fcb0c80379.jpg\n",
            "331995_jpg.rf.88b7bb5358a51b31d1ffdc8b41f55f64.jpg\n",
            "331-E-2843-HB-08-21_jpeg_jpg.rf.60650b1b434c3d888c9c297ce2ed6072.jpg\n",
            "331_jpg.rf.320c0a8f34bc850b81080af4177d8f62.jpg\n",
            "332-E-4876-Q-08-18_jpg.rf.6a34c98fe3ea1deb46d3927a38813273.jpg\n",
            "332__flip_jpg.rf.fdbd63f67038d830dddd8e2b2ab31408.jpg\n",
            "332_jpg.rf.23fccba9796eee56e1117c7340339cda.jpg\n",
            "333847_jpg.rf.1a7ea8008bac87cff4c6edc69e4196d7.jpg\n",
            "333879_jpg.rf.0a85be2a67ecbd7834ba8ddef387b70a.jpg\n",
            "333991_jpg.rf.911939cad41e6bef9875618792fcde13.jpg\n",
            "333__flip_jpg.rf.f409574c4754c4921fb86841ac2fc29f.jpg\n",
            "333_jpg.rf.4690fc681ff719c17936201845c6fe85.jpg\n",
            "333_jpg.rf.5975acf04e328e1f012181231c1f53eb.jpg\n",
            "334-E-5195-PL-04-20_jpeg_jpg.rf.0fb6ea95d6abf419b2ed28963c1df4a2.jpg\n",
            "33564bdf916af91988b51c38883f1841_jpg.rf.46e0fddbbd4bcbc98d70815fa67d3af7.jpg\n",
            "33564bdf916af91988b51c38883f1841_jpg.rf.d12a5f745ff3cba6086a0ee3804327a3.jpg\n",
            "33564bdf916af91988b51c38883f1841_jpg.rf.d889b26e92aeafabf89d072c077a282d.jpg\n",
            "33564bdf916af91988b51c38883f1841_jpg.rf.dad1e76ac90f26eace814ae77827906e.jpg\n",
            "33564bdf916af91988b51c38883f1841_jpg.rf.f816a4e2b4e75ac8668700293e7e9f68.jpg\n",
            "335-E-3405-PAH-10-21_jpeg_jpg.rf.176ae5c35751c1742a06e097f938f749.jpg\n",
            "335_jpg.rf.f63e06e248b0f5853ac052319cfc94d9.jpg\n",
            "336-E-2909-TP-12-21_jpeg_jpg.rf.572998bfdfae2bc13f830b3ece0288bc.jpg\n",
            "-3372F3CB-7432-4FE7-B9BB-DFB5D1FC3CD4-png_jpg.rf.631b1aec69740d4dd3d75c54cb9740d5.jpg\n",
            "338-E-3851-PAI-12-21_jpeg_jpg.rf.06bab7bab0ef5db087731bcaa78fa254.jpg\n",
            "339664_jpg.rf.0852f592ee168bf304bb6f889efd9586.jpg\n",
            "339_jpg.rf.fc1e3178e30b4d4d641fa1764bc32f63.jpg\n",
            "33-E-5216-TI-11-21_jpeg_jpg.rf.4b02d42400228a30ed0e8b7d3d9a57b7.jpg\n",
            "3403092507_jpg.rf.e176c4dd0236748491ff64e63551df5f.jpg\n",
            "340-E-4235-RP-01-22_jpeg_jpg.rf.a728490bb7935924c91db3eb6addc982.jpg\n",
            "340_jpg.rf.92ff725c6a6e52a9cab2c20443b79196.jpg\n",
            "342-E-2544-QD-11-18_jpeg_jpg.rf.55b5a022941e9caf3da5862f4805aa62.jpg\n",
            "343-E-6894-SB-11-19_jpeg_jpg.rf.52e932a58350ff75570239f73e90b4be.jpg\n",
            "344339_jpg.rf.eee2b1e9cfaa750292ac02bbaa7b2f17.jpg\n",
            "34456_jpg.rf.bab7c5c3477e55f16f2cef690bbd4de9.jpg\n",
            "-344A5C5C-CF3A-48B7-BE2F-7373A99B6465-png_jpg.rf.170d1a494fd844bfb1a0ceecc3410ec8.jpg\n",
            "344-E-6393-TZ-07-18_jpeg_jpg.rf.cc252fef998dcad5540e0878491bd93d.jpg\n",
            "345-E-2047-SF-05-19_jpeg_jpg.rf.f009585a6b232ad6f2a59da3d289ffc6.jpg\n",
            "345_jpg.rf.c36e1f93ad21d712cf7227964e01b749.jpg\n",
            "346_jpg.rf.e60f28c9ae6b3747b20e6d4d8b582c6c.jpg\n",
            "347-E-6765-PAD-06-21_jpeg_jpg.rf.b3e3b8d2af6d798beab43053bbfa8372.jpg\n",
            "347_jpg.rf.9607da75870b83f99ea7f59b0b8b1b5c.jpg\n",
            "348157_jpg.rf.baaac7537651ec871be47b94a53fbc21.jpg\n",
            "348_jpg.rf.afb8a6e9a4addc8932ecb89a9dcefc8b.jpg\n",
            "349172_jpg.rf.c00b9d9c477086007fd7d8f01dec7c53.jpg\n",
            "34_jpg.rf.7ba71ad43b43f6068db00710c78f72e9.jpg\n",
            "350_jpg.rf.d694e08d58a40fc19309db5a42aa1ed4.jpg\n",
            "352-E-5053-RG-09-20_jpeg_jpg.rf.75464c899bb8bcb2bda6fc84e56f4b2b.jpg\n",
            "352_jpg.rf.3f16aca9fd524faacab1c911ecc61477.jpg\n",
            "3534274-foto-camion_jpg.rf.0b5fa7ebd3b9db08122cce67f6be4150.jpg\n",
            "353-E-6270-SM-06-20_jpeg_jpg.rf.cac16cba33b40d02ec808f615512bfd0.jpg\n",
            "354-E-6250-PAJ-02-22_jpeg_jpg.rf.aea9a0c0e4d73954dc00ef7e0e71e61c.jpg\n",
            "354_jpg.rf.a8e112762be7f160d694727cafc30ccb.jpg\n",
            "355833_jpg.rf.921ef114aeebee52640866f210839b87.jpg\n",
            "355-E-6547-PAF-09-21_jpeg_jpg.rf.9fecf9e84169a75023b8760dc38f54b6.jpg\n",
            "355_jpg.rf.d75739c408daa9ae0cd075caf7022ffc.jpg\n",
            "356-E-6225-SJ-11-19_jpeg_jpg.rf.8432bb2ff5d6a02d3047010bfb7d1882.jpg\n",
            "-3571FC71-85E8-4968-8882-3A4B92AC8388-png_jpg.rf.562df79f7ae5f66c2f2d2698afc7cc89.jpg\n",
            "3_58_jpg.rf.c99481226912e5f2e3f75d5cae3514b5.jpg\n",
            "359-E-6270-OZ-01-21_jpg.rf.8a0af35739a46feeb3d98168ad697ee7.jpg\n",
            "-35C8F869-003E-4989-ADF3-F79D890A8FE4-png_jpg.rf.a752ab0b0a979c1a2c47579ad8772023.jpg\n",
            "35_jpg.rf.d397d989f3d6419c6316af8161a3cef2.jpg\n",
            "360006_jpg.rf.a8bc4197e97da4be85b2664a12430b3b.jpg\n",
            "36038_47874_245202_jpg.rf.650cba0cbf5c5146752f07e49e701cf8.jpg\n",
            "36038_47874_245202_jpg.rf.adaeaf32e58e6dad9186001c27bdfe28.jpg\n",
            "36038_47874_245202_jpg.rf.b36b7c1caff0a953db40b9f10da9cca0.jpg\n",
            "360-E-4690-PAL-04-22_jpg.rf.70780d968c3488d1887658ad4e944924.jpg\n",
            "360_jpg.rf.63e1b6be882c8b9c83f596e811f278a9.jpg\n",
            "361936_jpg.rf.9c0ab779748af1647348728216063b64.jpg\n",
            "361-E-3193-PS-08-17_jpeg_jpg.rf.0a73e7e8aa29edcf0670c23d5be6f049.jpg\n",
            "362394__flip_jpg.rf.bf4c39cd0b2fc0620c7c45f300f43409.jpg\n",
            "3626_2211076_1_jpg.rf.0128699f2171dcefa60e9b27ac38e9cd.jpg\n",
            "3626_2211076_1_jpg.rf.27a27a3543c6b5592b2a75e728730763.jpg\n",
            "3626_2211076_1_jpg.rf.577503b4765163bb4b5f4733d33c5706.jpg\n",
            "3626_2211076_1_jpg.rf.7aeb98f642dcfcf8fc4b1f60c5a62540.jpg\n",
            "362-E-6525-SF-09-21_jpeg_jpg.rf.ba7774d6ed6f080dff92f5ff348fc1d1.jpg\n",
            "362_jpg.rf.d8d8946e9f1be1b50a49c36cbfc9b8f2.jpg\n",
            "363-E-6263-RU-07-20_jpg.rf.8c6f74fc6281b233e7fc325fc7b333ea.jpg\n",
            "36481_48360_248248_jpg.rf.0c9a2b9acad1f41a4649c1170df7d321.jpg\n",
            "36481_48360_248248_jpg.rf.33e989386cca16239bb4c07993c71749.jpg\n",
            "36481_48360_248248_jpg.rf.b7e772da8eada9a0741476cb84736331.jpg\n",
            "36481_48360_248248_jpg.rf.f06e2061c8d22bf5eb77c1df5d29b206.jpg\n",
            "36484_48363_248254_jpg.rf.39cd8e1f8a345c5abeb84af29d66f048.jpg\n",
            "36484_48363_248254_jpg.rf.533885b70a52d521b16032285fd15b13.jpg\n",
            "36484_48363_248254_jpg.rf.80ad7c9eeba3a075746ed1a200c14988.jpg\n",
            "36484_48363_248254_jpg.rf.d3b10f4d7e302a5a11e75545324ff082.jpg\n",
            "36486_48365_248258_jpg.rf.6606f48e7e3d6d2af938c95d68beb392.jpg\n",
            "36486_48365_248258_jpg.rf.c0388131d5a12418da9276c8601ea4d5.jpg\n",
            "36486_48365_248258_jpg.rf.ce2db18d72a1b92786e8a8d2e3396ec5.jpg\n",
            "364-E-6528-P-11-18_jpeg_jpg.rf.c2da374c42f977327f484a599de7ff5d.jpg\n",
            "364_jpg.rf.5b3cb94d90859bb83131bfbb3c577e96.jpg\n",
            "3-655x370-1-655x370_jpg.rf.5f35c0238a8b1b78e5faad3b8dde4575.jpg\n",
            "366_jpg.rf.cdd265a8004dfc2b4920990e30f8b83d.jpg\n",
            "3671090417_jpg.rf.3a3167d6cdc8533d6c0c620b853e671a.jpg\n",
            "367_jpg.rf.9d959f41c3bcaaa51d0960d561047f0e.jpg\n",
            "368_jpg.rf.87803fcf32bf0ffe88042d975b1c90f6.jpg\n",
            "369_jpg.rf.e159f859d329c6baa6cc84f91b6765d6.jpg\n",
            "370_jpg.rf.85de763c2834b80c3c26d2bbc887677c.jpg\n",
            "373_jpg.rf.9024d3a0e86e24042739fa464577bb05.jpg\n",
            "374_jpg.rf.1e3afe414879c10809fd0a114d3ff038.jpg\n",
            "-375329E9-678F-4B48-AED2-472A7ED60D19-png_jpg.rf.a25e738569c44cd5f6228fa604f5ab9f.jpg\n",
            "375_jpg.rf.a3e0beaf39ade369198c1a5dc1d1ca03.jpg\n",
            "378100_jpg.rf.b702a566d2910806ac3df953d6fa109f.jpg\n",
            "378950_jpg.rf.4fb33732c59232f0b18116222cf0744c.jpg\n",
            "378_jpg.rf.1b566dc2880165e4f5356a7cc6bc6232.jpg\n",
            "379_jpg.rf.de5f899008b515e065a7d373c08f6d59.jpg\n",
            "37-E-4127-QI-05-19_jpg.rf.a77c2d69c404928cfd0cbc233fe96dc4.jpg\n",
            "-37EAFDFC-4667-4A10-98F7-3C9FB6EC7912-png_jpg.rf.261983d58340efd0a6a8f1e552730e3d.jpg\n",
            "37_jpg.rf.e417f8a8d96cebf5cb1704f458a04d4f.jpg\n",
            "380_jpg.rf.cb9c79d94b59a20e55ec8676fde52131.jpg\n",
            "381_jpg.rf.bd1833804d5c891c67943a4c9dc5c7c2.jpg\n",
            "38263_50139_258320_jpg.rf.9c6c5b161e7dbbfdb09f10503986008b.jpg\n",
            "-3827C0BE-B55D-4ADE-9938-9DC7D50A32DD-png_jpg.rf.131a62b45f089bce5e015b51d4b63f23.jpg\n",
            "387_jpg.rf.8eab2bee6c07c66be964b28098c0157c.jpg\n",
            "389_jpg.rf.6fed82f5b1704eded3f13e1da484347d.jpg\n",
            "38-E-3747-RE-08-15_jpeg_jpg.rf.387983e9f03998b562b124a070551b24.jpg\n",
            "38_jpg.rf.e6d3f1bcaa8d02341df7a9fe1185e2ed.jpg\n",
            "390_jpg.rf.b1df27877574a4bca8ee22ed4b2e1340.jpg\n",
            "391_jpg.rf.0f9234b24ab9e2a02d81f855e9adbed1.jpg\n",
            "-3923D79E-9339-4D23-97E0-76DC2B526C3C-png_jpg.rf.bbeb12dbd71214036a1da4812efc889f.jpg\n",
            "393_jpg.rf.3aca41788cbe9ac2c00f6240e2f43964.jpg\n",
            "-3947B75C-299F-46E6-84AF-947CB4AE712E-png_jpg.rf.9b8590e0c16e3c6fe6ae6eaa7ce32c54.jpg\n",
            "39489_jpg.rf.6ff5790a4e5e886f1e18936c7623c63d.jpg\n",
            "-394F92E4-59B2-4B85-9170-F782BC3DC244-png_jpg.rf.46424e1eaf3caa8f9cb5e65fadce226b.jpg\n",
            "394_jpg.rf.34044d2211610f387d7144ba0f81b6c6.jpg\n",
            "396_jpg.rf.03e9f0b68d664c91b62d56988a264854.jpg\n",
            "398674_jpg.rf.244146c7325e4daab0198b3dfc726870.jpg\n",
            "39878_jpg.rf.d0c4f6bb86666285405e3f4ad6ea7d71.jpg\n",
            "-398D11E1-12E9-4FE1-83DA-198B0C1A0D9D-png_jpg.rf.06a7e34c48dd4dc276724174a23f9f92.jpg\n",
            "-39CA14CD-A783-4F15-AEE6-F52595AC33A1-png_jpg.rf.c211952b63ffeefb25ff32b0a7ce4592.jpg\n",
            "39-E-6716-QR-04-20_jpeg_jpg.rf.4f99585f4883618dd05f420cf5699459.jpg\n",
            "-39F48ED3-07A0-41D7-85B6-474E4ABF17C4-png_jpg.rf.b7fd7c90ea150b4aeda1879460e12c59.jpg\n",
            "39_jpg.rf.86c58d88afc8fc7e554b2679e69276f1.jpg\n",
            "-3AFF5173-8DB5-4DFD-A3AD-3ED85BD289FB-png_jpg.rf.b3288a28ba088998231db3c8fb9bfc00.jpg\n",
            "3asdad_PNG_jpg.rf.ebd21825064b43332508836671dc417a.jpg\n",
            "3asdf1ewq_PNG_jpg.rf.0f9dcc76115929dde47333875482a841.jpg\n",
            "-3B056DBB-3097-4BCB-A38A-F66FA7470A6C-png_jpg.rf.5ecf223dc3f784a5bbd8a8810f5dd405.jpg\n",
            "-3B48CB36-3DE2-4088-B9D1-6F639B60DA9C-png_jpg.rf.e6e5a4cea06eaeae6eac5c2578e8f363.jpg\n",
            "-3B54DE29-3BCA-4191-A23E-003270236E01-png_jpg.rf.9c3d73dace34c3118b7dcf084b60f90d.jpg\n",
            "-3C5B367D-D054-46F4-A427-80D90258A7B3-png_jpg.rf.9913e46290a488dad96ccd6c296f4488.jpg\n",
            "-3CE149A4-29C8-4710-8B76-E45719A9E65F-png_jpg.rf.7c4c337440eedf73591df984ee320f5c.jpg\n",
            "-3D5128F1-30BE-4617-87D6-DBA1B7BF88DF-png_jpg.rf.7e74f90039c83232b410dbfa4e632e21.jpg\n",
            "-3D578705-6794-4049-BF6D-A828FC4F0722-png_jpg.rf.c3e8d59607e773055d20bdfafa2126fc.jpg\n",
            "-3E68E65D-CE4E-4C38-89BA-67A44FF80CC1-png_jpg.rf.1b7558aabb9569afdc9b44cefe4b1aa0.jpg\n",
            "-3ED11401-3001-41F4-8807-7BDA41D24CF3-png_jpg.rf.4f8aa45875f245ebbb989de511ef8d9b.jpg\n",
            "-3F529D18-6BDB-4958-9915-D7913A3AAE05-png_jpg.rf.ded0560cb1c6378622f0f90e9961b2a9.jpg\n",
            "-3FE8B0CD-A85C-45D8-8B05-3565D4F82882-png_jpg.rf.2c06d9546bbe91979dd9e1e10090c695.jpg\n",
            "3_jpeg_jpg.rf.1d81209535bd155e85e04591adde3eb2.jpg\n",
            "3_jpg.rf.19bb0f63e1e0365f30340548ede5b87e.jpg\n",
            "-400E9E90-CD4A-470F-89E2-C9E1D1854AAB-png_jpg.rf.09be3433695bd23fe59166cc57cc8569.jpg\n",
            "401_jpg.rf.56641981f7c694da609113eb0cc271e5.jpg\n",
            "402313_jpg.rf.25d92c48883f9fb07191ceb411bef756.jpg\n",
            "-4023618c44_jpg.rf.41ea9f87519002b1cf26d26febe42b09.jpg\n",
            "4026_a15903860165ecb5d607e7b1_jpg.rf.492062e2d781e434d396d0e67e1ceadc.jpg\n",
            "4026_a15903860165ecb5d607e7b1_jpg.rf.7e03f85975f919443683079e9e9f267f.jpg\n",
            "4026_a15903860165ecb5d607e7b1_jpg.rf.85d47aa391f14bdf23b621cd75b765ea.jpg\n",
            "4026_a15903860165ecb5d607e7b1_jpg.rf.e10f92973d297e49bd14ed1e59a6dbd9.jpg\n",
            "4026_a15903860165ecb5d607e7b1_jpg.rf.fff28da883221cd257ebabbcaded6fab.jpg\n",
            "403_jpg.rf.1f96cb18b21aec7c08c748f3d67056a1.jpg\n",
            "404887_jpg.rf.2069f536c366440a94eb5333a5b6068a.jpg\n",
            "404_jpg.rf.d39281efbe734d6f44bbeaf0cf5f7982.jpg\n",
            "405_jpg.rf.898a565bb07f6aa5d508bf3f22081c6f.jpg\n",
            "406716_fuso2nd_jpg43571b893bc1565318_jpg.rf.04c7565a19f40afdda593f9efd4a0a90.jpg\n",
            "406716_fuso2nd_jpg43571b893bc1565318_jpg.rf.2dad7aa5f877e24ba8452bc66ed04475.jpg\n",
            "406716_fuso2nd_jpg43571b893bc1565318_jpg.rf.e4b5a8ca8c774a6af90fe2eafb121e8a.jpg\n",
            "406716_fuso2nd_jpg43571b893bc1565318_jpg.rf.e7a16e95b147af1e2eacab0ade5a2978.jpg\n",
            "406_jpg.rf.d0ee617aed47d19ca273b37e0ff3ab06.jpg\n",
            "407_jpg.rf.36d9afc8e8a9277dcb701e8b00c99c8a.jpg\n",
            "408218_jpg.rf.d1e70d0986d8798ccd1eb68f6113b408.jpg\n",
            "409_jpg.rf.449488f8b16ad2a68f44800eb2ef5c4a.jpg\n",
            "40-E-2324-OM-09-19_jpg.rf.34213dd61a4d3c6e5c8699e3a69257ab.jpg\n",
            "40_jpg.rf.6ddaa50068f0f804f680afad8dad09b8.jpg\n",
            "410_jpg.rf.3d313c2a3275f8f3a72aabe6e55415ec.jpg\n",
            "411_jpg.rf.c06a132e9ca4422800abbb8f18b92ead.jpg\n",
            "412_jpg.rf.745bec9f6443e6dd9192ab5ab8ba0bbb.jpg\n",
            "-41421EB3-10E7-4E8B-9D22-424751A9FE8A-png_jpg.rf.6fae9284cf4f632f13cb4f7b9109f89a.jpg\n",
            "414_jpg.rf.dda68fba04cb1f19ed575b92fe69b475.jpg\n",
            "415_jpg.rf.41758c4a9da14bd05da576ae5b6337c4.jpg\n",
            "41728_53604_276708_jpg.rf.370eaf6a420adaec8d639574274cd760.jpg\n",
            "41728_53604_276708_jpg.rf.4759a4ec16551e32b1fa33ecb971989e.jpg\n",
            "41728_53604_276708_jpg.rf.7617ee34b5e9ddb9e1d88844c08a91fb.jpg\n",
            "41728_53604_276708_jpg.rf.d13212cde8e95e3a5763d8e28db4d85e.jpg\n",
            "418663_jpg.rf.12cdebadc58b578b338ab16034d8701d.jpg\n",
            "419825_jpg.rf.a403b60337ba72efec3dc22768f4615e.jpg\n",
            "41-E-2648-QI-05-19_jpg.rf.b32c54c7978bd8643b64a7415e72acf7.jpg\n",
            "4209015271_jpg.rf.3196b676e1ca3eea8517032d35edb3b7.jpg\n",
            "4209015271_jpg.rf.442f97322fc4cde4d45aa5919268e1ff.jpg\n",
            "4209015271_jpg.rf.44c8034815aa2277ff1dedc91a1cf8c4.jpg\n",
            "4209015271_jpg.rf.4abd9c64f10a0beaa3fcfb145f0825f7.jpg\n",
            "4209015271_jpg.rf.9c0138a9e75423f9f899991637cf78cd.jpg\n",
            "420924_jpg.rf.51e5e4a86e887f04e2a1562be45c62ec.jpg\n",
            "-420B178A-1068-4C65-B00F-763738FCB982-png_jpg.rf.87cfca033c959e262df0e13adb7895ed.jpg\n",
            "420_jpg.rf.945f586f5496fd0afda5bc5c28da5c36.jpg\n",
            "-422F5744-FC5F-4A43-8DFE-CEF738B5015C-png_jpg.rf.2f51d91a3d76796ac004be3969ccc421.jpg\n",
            "-423FE4FB-F3E1-4E8E-8A40-5A99AEF6C353-png_jpg.rf.cda0e9507f8afe43e0a04358020be15c.jpg\n",
            "4261621862-1_jpg.rf.c638eb9ae3291c53e2c61a43f3de8d41.jpg\n",
            "4261621862_jpg.rf.0e48eb77e6b35fbb4877934ec7f60b4b.jpg\n",
            "4261621862_jpg.rf.4273812fe6c088d3aaf6cedcf9c4e33b.jpg\n",
            "4261621862_jpg.rf.684ef6ecd6dc4212575380a568261c9c.jpg\n",
            "4261621862_jpg.rf.827722c515f09d81f324ada31db28c3e.jpg\n",
            "4261621862_jpg.rf.97837a18e0185c524ba2cfa823995254.jpg\n",
            "4261621862_jpg.rf.b5e13debde2ad4bbcaf1a0450709f4dd.jpg\n",
            "42618_jpg.rf.388ad05daa7c238ac5f587e3b6437526.jpg\n",
            "426822_jpg.rf.80c96fe142fba0ab8522f71f37a191fa.jpg\n",
            "426_jpg.rf.369f47b58329e05004d5a6070278ada2.jpg\n",
            "427_jpg.rf.e728a81b44b66412d15d0d85fa50b41b.jpg\n",
            "428_jpg.rf.29629466e60e14bcab8a4f29d7891ed1.jpg\n",
            "42-E-3690-SE-09-21_jpg.rf.15598866268b41f1a687dfe5c022d73a.jpg\n",
            "42_jpg.rf.896458dbf89e32c3c9e208f8ddae67c5.jpg\n",
            "430_jpg.rf.e04796e810d85637a3d219c8e6eb6af0.jpg\n",
            "-431A51B8-216A-4491-8839-72DCD54029AD-png_jpg.rf.4c4186ccc98c91cbac9609fa4e096d95.jpg\n",
            "431_jpg.rf.2832321f9a83f17e24ea420a1e579526.jpg\n",
            "432_jpg.rf.271bf68aedf1dda64737d3d801959bcb.jpg\n",
            "433_jpg.rf.d1df69364c0a9331cc676f5f85ab6b9f.jpg\n",
            "434586_jpg.rf.b3cac37bbf06dd9c2cf8963a16cc37b7.jpg\n",
            "434_jpg.rf.178be56f47c28f91f20bdeefd7c72e4d.jpg\n",
            "437_jpg.rf.d3cb54c2ea9acae97c92d80d3693d6f9.jpg\n",
            "438154_jpg.rf.69b78cbfd291b30059fde5ed749fc52a.jpg\n",
            "439_jpg.rf.11fdd7b1d453f688987b67864f0fbd98.jpg\n",
            "43-E-5736-PAQ-09-22_jpeg_jpg.rf.743c99a2d444cce83f3601e4f08ddd9e.jpg\n",
            "-43FB8A1A-6BE2-4DF6-AB33-120E54572420-png_jpg.rf.b5825f0135ebcb6a73b0e887d003abdb.jpg\n",
            "-43FD1935-9479-4C6E-9743-BF2673E914F6-png_jpg.rf.4c7833887bc97063e75bf6f5e9e73a4d.jpg\n",
            "440_jpg.rf.d9fe9b2e0fc413fa2d0820fae1c554da.jpg\n",
            "441_jpg.rf.223d93e55b8d1572fa1da6d32420d840.jpg\n",
            "442_jpg.rf.3353cfc1cb906ef8ed585c6589fc4067.jpg\n",
            "443971_jpg.rf.c8790487544d241d2d3e94454d1ba0b4.jpg\n",
            "444238_jpg.rf.499d246b42215a43aad6802e71b3174e.jpg\n",
            "445310_jpg.rf.61beae2755a49a1e8a4faf294e131c71.jpg\n",
            "445_jpg.rf.10cb10b050041585e3710ed8903e0882.jpg\n",
            "446_jpg.rf.247b6748a728101ae35c2acfcdf356fc.jpg\n",
            "448_jpg.rf.8269075acd360166cd3b1077cd0b068e.jpg\n",
            "449_jpg.rf.02e2b6b4b7554a93543bcff6a1c92c8c.jpg\n",
            "-44B6AE6E-3A2E-43B6-8918-65E1F6946480-png_jpg.rf.6774d9c1324ea62c1b0dbb6038447bf9.jpg\n",
            "-44EED5AD-F010-4649-819C-9091185CA9AD-png_jpg.rf.55b3c33690795cc4b090f4397a875884.jpg\n",
            "-44FCC143-4904-46F4-B14E-F3AB715A61C7-png_jpg.rf.5e3ca9a425156be5de5852c336a3dd99.jpg\n",
            "44_jpg.rf.2f65600f682569136d70d41f79d16f69.jpg\n",
            "451_jpg.rf.f75d6d1feb40d402ded03e674577d07f.jpg\n",
            "452_jpg.rf.9f64ef41811649f3e48ed21e38c2e865.jpg\n",
            "453_jpg.rf.934bf18bcc5a9e2d9c6f2ad72e3f956e.jpg\n",
            "45490_57349_308284_jpg.rf.4f53a2aa20d5c20babd18471aad5f665.jpg\n",
            "45490_57349_308284_jpg.rf.5e7d2b8d89c234b57ed1a6fd89d276d5.jpg\n",
            "45490_57349_308284_jpg.rf.a81ec1702c99f89a4d5293699bf815c0.jpg\n",
            "454_jpg.rf.62675a4a8ddd9d7db3d4ced514d77590.jpg\n",
            "455_jpg.rf.d9f1f856ea686c1541283ce807d83adb.jpg\n",
            "4560_jpg.rf.c4493f48849b7e55e598b7d1685d4400.jpg\n",
            "456_jpg.rf.e7aaa6b36a2c38e189373217677c0502.jpg\n",
            "457_jpg.rf.43b25c9e572eed29c648602fc3f3a684.jpg\n",
            "458_jpg.rf.f5c5b72419c1246e0e0411b6e81cca3a.jpg\n",
            "459_jpg.rf.bcc4c84dfedb25e7066c25a6ec0d0899.jpg\n",
            "-45B5DAC8-C6AE-474F-A1A7-E276402C2937-png_jpg.rf.3a8a160eb0576d926ef70fe332f74dee.jpg\n",
            "45-E-4836-QM-10-19_jpeg_jpg.rf.d97ca30605f940f782e45649a2767204.jpg\n",
            "45_jpg.rf.b61a4fdce90fb422273af8dd123c47fc.jpg\n",
            "460_jpg.rf.178b6067a77587d42137e2fc4dc68a73.jpg\n",
            "-46175DA7-1566-414C-8B5E-587BE9339765-png_jpg.rf.705ad813963bf9444265f5ef2dc8e09b.jpg\n",
            "461_jpg.rf.8e35b8cdbd9196be3c93668c258b9f8d.jpg\n",
            "-465396AA-4CB9-4625-A390-70D9E748937A-png_jpg.rf.231cb6c649ff8ecd32f8b162902b151c.jpg\n",
            "465_jpg.rf.cb30a266a68bebcae42b64b458ece7b9.jpg\n",
            "466_jpg.rf.ffe1ebce624dc6a3ef808dbbc62fcbf1.jpg\n",
            "468811_jpg.rf.36141d880310a9ef032855c1834c8553.jpg\n",
            "468_jpg.rf.7d66647152fb49a89927b91a4abb7f4a.jpg\n",
            "-469593C2-4B3A-4A0B-B78A-24B4A79CCC35-png_jpg.rf.563b21e5ff7b80f1f6652b3804112b6b.jpg\n",
            "469775_jpg.rf.5341f187893acb38168903546d20dbbf.jpg\n",
            "46-E-4531-TV-04-18_jpeg_jpg.rf.ccdf9ee4762eae293ab6f11db6d5f9eb.jpg\n",
            "46_jpg.rf.b982306037916550ffb50b0d762a71f1.jpg\n",
            "470_jpg.rf.fefe00c2a36d88d7265952f2caf33765.jpg\n",
            "47133a8d-f-968a_jpg.rf.1a520f5a87a5c5e1583cdaaea84ad010.jpg\n",
            "471_jpg.rf.db6b4c85ec4344175618f5ec65907452.jpg\n",
            "473_jpg.rf.ffdea983bc3d0a3892c31b78ee43c5f2.jpg\n",
            "47585156_303828156906029_21693398286_jpg.rf.09319b90d6a72e23887a061ff21a33b6.jpg\n",
            "47585156_303828156906029_21693398286_jpg.rf.322fd9ed62752bd8e7bf1b85027f658f.jpg\n",
            "47585156_303828156906029_21693398286_jpg.rf.b7ad774ce70145e46449ab3d0e9cc8db.jpg\n",
            "479_jpg.rf.28c592bcb92962345cdf17f045ee8f8d.jpg\n",
            "47-E-4240-RY-06-19_jpeg_jpg.rf.f05ce30b2046bb91643e700a378bdd99.jpg\n",
            "481_jpg.rf.ee7116699359836d5c2202e88fda4c86.jpg\n",
            "482830_jpg.rf.6345be999c0000f361cff78cc777988e.jpg\n",
            "482_jpg.rf.7ac30c316d6e5646aa18a939437ba274.jpg\n",
            "484_jpg.rf.eafe85fb613c9c678bc22703f1e8ea6e.jpg\n",
            "485014_jpg.rf.a7e76ca78f4930a4302c45d6dc070198.jpg\n",
            "488_jpg.rf.cd5869af8e127896f496b0705f84e9db.jpg\n",
            "-48CBF116-BA34-40B7-A379-E91809F98968-png_jpg.rf.c613ba62124855457c2b8a604a9c458e.jpg\n",
            "-48CC7018-725B-4547-B690-F5BE19F7A7B8-png_jpg.rf.1b4c3d4b5629b6917477bf11312d2d6c.jpg\n",
            "48-E-6073-OL-09-19_jpg.rf.1f5dc3cffbb8b9b6be6f117c854528e8.jpg\n",
            "-48F51CDD-4B03-4DBE-86F1-7DEBE87C6B8D-png_jpg.rf.f8c6db994ba8a9f7cc6cc163295fe648.jpg\n",
            "490_jpg.rf.a59fa5110c165e09183ee396e3ae1dfd.jpg\n",
            "492659_jpg.rf.898b470490098b5d2537b24eac297d9c.jpg\n",
            "492_jpg.rf.02f0b3f6196d2f9721f5b25da9a2aa72.jpg\n",
            "494_jpg.rf.b3e0ffa726edaff6096d75887a2a1c44.jpg\n",
            "-496DFB6F-CD96-44F4-8CF4-683733EC79B6-png_jpg.rf.7f9787d247ee7ffd2a6b12ec85604049.jpg\n",
            "496_jpg.rf.baa33a240202466f6be0058d9992cda6.jpg\n",
            "497_jpg.rf.d05a70c7ee1c49ea952274ea3d0fa519.jpg\n",
            "498_jpg.rf.4dece179d9a06cd77a4204f30e73dc5d.jpg\n",
            "499_jpg.rf.d167a34530288db6eb2675a154de71df.jpg\n",
            "-4B472EFE-F5FA-44B6-A214-B41E70E2A0BC-png_jpg.rf.17bbd07121bd4f3277e45e67bc466749.jpg\n",
            "-4B733FC3-CEF8-427E-B4A1-7C1E04168672-png_jpg.rf.bdb53100048ca4522a856139c5be8ec1.jpg\n",
            "-4C1021B6-59C9-4E0F-8736-71D2E2204C54-png_jpg.rf.5a0ea8fcd8239b5268a566a85cf985be.jpg\n",
            "-4C9F05A1-7CD5-458B-B604-60361B491683-png_jpg.rf.17a98530f7d68acfcf74af7032f25dbb.jpg\n",
            "-4CF237D6-DFB7-4129-AEA0-6ED09F00BB88-png_jpg.rf.cc37baa6ec8c723c04b6a355d41adc75.jpg\n",
            "-4D73DEE0-E7DD-47CE-8381-6EB3AC285C0A-png_jpg.rf.5afdc9b06430060b986a1baf7837755e.jpg\n",
            "-4DC13D04-A903-4B83-B0AB-F69731C0DDFB-png_jpg.rf.8e82aae2ec3b5ce79f841c32291eb950.jpg\n",
            "-4DFF09F8-2283-495F-9C84-6A25870884F8-png_jpg.rf.61242e903432e0db0219e6488782c42b.jpg\n",
            "-4E26A992-CA6F-43A4-B40F-D9881EC94176-png_jpg.rf.06f55cb52f047aedcdd8e50b1caa3710.jpg\n",
            "-4F8A1012-5719-437F-9811-1CE117CCBC65-png_jpg.rf.e5bbaae501c37fbd7af9b77c69c2dda0.jpg\n",
            "-4FB14832-DB4E-41E9-B8FC-9D33DEB67AAA-png_jpg.rf.7adf24a480d85adefbb5f8d510afcc87.jpg\n",
            "4_jpeg_jpg.rf.e3a22af099fb324c945ba408f3833bbb.jpg\n",
            "4_jpg.rf.54d59ae63df639b6a5d27bacba01acff.jpg\n",
            "501_jpg.rf.efdde9ce5a938407dd45c7484651153f.jpg\n",
            "503437_jpg.rf.9c86b27889441df83a553eacaf55b1a9.jpg\n",
            "50483_jpg.rf.c0676cf7531afc00bb5bcf1e22f96a97.jpg\n",
            "509950_jpg.rf.af05cb7aebcef014538f11de75955eea.jpg\n",
            "-50F87E85-A506-43B1-A876-756FB9225D0D-png_jpg.rf.b64b8235634612977e2cec7430e55a7e.jpg\n",
            "50_jpg.rf.8c21b9f1719e1c11b4b621066f239f9b.jpg\n",
            "510_jpg.rf.090d40d72432a3a037f9f7c5e089989d.jpg\n",
            "511_jpg.rf.235f759c4e45f74cdcabfee89222c971.jpg\n",
            "515_jpg.rf.3fdd325cd2209ff2c9514cafc3d2d50f.jpg\n",
            "516_jpg.rf.ac8dcedae7a136e36254d0f7566977f0.jpg\n",
            "519_jpg.rf.85f35994b590d3c1472c98f3e5958b00.jpg\n",
            "51-E-3083-PAH-10-21_jpeg_jpg.rf.ced12c85a2db00ed1a07046b84be3438.jpg\n",
            "-51FFF967-684D-4519-8EC0-A9C7CC6F2280-png_jpg.rf.3746929cf9592bd560f99ba02fe54e4c.jpg\n",
            "-52262D73-8B4E-4F06-883D-4C6E2E6ADED2-png_jpg.rf.64cdd16491f14c033eb7180c48e41bfe.jpg\n",
            "522730_jpg.rf.1ae3116e836bc3256d2a698f25fc8906.jpg\n",
            "523324_jpg.rf.8718a3187ed88ddddb4e6f619a48dd06.jpg\n",
            "525392_jpg.rf.e007498e943793f019acf37d9308d1f9.jpg\n",
            "525_jpg.rf.d83ce7d11dda3c01bb5a50650d8314fc.jpg\n",
            "-526B0491-0C42-4F0F-A201-ECFD6ED3DD6E-png_jpg.rf.463ae72876be3ff456a9d66725d83724.jpg\n",
            "526_jpg.rf.a6e36ca2466cefbf8c42ed8a21718584.jpg\n",
            "527214_jpg.rf.89c27b6b8f3c73634ac04ad0cf8e8819.jpg\n",
            "527_jpg.rf.0cfaa469a0034c4f0718b8b4b9019d75.jpg\n",
            "528_jpg.rf.6f6a3ee32b47a95364032e19dec1272c.jpg\n",
            "-52C0EFE4-90C2-473F-9FEE-2E416111A8C7-png_jpg.rf.2372f9a26ea55afb8bba2180c5919848.jpg\n",
            "-52D877A5-D9D5-4B8F-848F-E449684E4869-png_jpg.rf.74add56ce32fd8cdb94847288de8689c.jpg\n",
            "52-E-3765-QO-12-19_jpg.rf.eb19e671e152f5c921ec1f8bec96161a.jpg\n",
            "52_jpg.rf.8dfad20aaeacc130b9d7a2667f22b4dc.jpg\n",
            "530948_jpg.rf.f6153a9c1daf50b86b9ab74357903631.jpg\n",
            "-531F16FE-7468-484D-8B14-D5229D4851B8-png_jpg.rf.f1d05ac99d51917f6fcd15d117781cb4.jpg\n",
            "531_jpg.rf.7f317af4f53a2213747283af68726cee.jpg\n",
            "53241f12843e709981c8804a647fcc41_jpg.rf.5f297c77f94273a18cac8a834cec4e67.jpg\n",
            "532742_jpg.rf.7402dfe047e726564eaf5dde83d337a3.jpg\n",
            "532_jpg.rf.1d9dd841781e0026df6c2c5b3e8e6326.jpg\n",
            "534_jpg.rf.8b9cbb6ad494071709c65c0b63a64028.jpg\n",
            "535_jpg.rf.40880289fa78433df4225405cc398928.jpg\n",
            "537_jpg.rf.81a7d232b772f5b3d02b8dfc18554d47.jpg\n",
            "-5399AA20-C3A4-4841-9CA4-0D18DFCA3806-png_jpg.rf.d4fc2b103b64d92855ba013193c83d1f.jpg\n",
            "539_jpg.rf.eab02ccd1a648288bb94c5299c56f2a8.jpg\n",
            "-53D41263-2FA3-40DF-9556-1EB08D19D5F1-png_jpg.rf.3035a25e6c327aa8807cf22d3a587f97.jpg\n",
            "53-E-3288-QU-06-20_jpg.rf.fea80fa143a3862c3aad8bd432751a73.jpg\n",
            "53_jpg.rf.e5d6496348a4b6ab78de7e22b782bfc1.jpg\n",
            "540709_jpg.rf.ccd9b60e5c4bef2c7db3dd9d1427d542.jpg\n",
            "540_jpg.rf.2e3937d19db3cbc3e64772085dbf8372.jpg\n",
            "-541C6E4C-DEC9-4725-97C0-B773CF5182AB-png_jpg.rf.aa0cc7eb5fbba4bc1c1f2a12cdcf56a4.jpg\n",
            "542108_jpg.rf.0e7d04c7c1d150f13d8f35271b6d23d7.jpg\n",
            "542_jpg.rf.7b51db61a51b380e35ca27d1730b472a.jpg\n",
            "544_jpg.rf.2f48e567b83be76b4c406632f527fed7.jpg\n",
            "545887_jpg.rf.bd9b5baad16358614db93adc5262f5d9.jpg\n",
            "546_jpg.rf.4b50402e195be2efe4babcc9dc3737b4.jpg\n",
            "-5481DCB8-6595-495C-BFEB-5B74B2345808-png_jpg.rf.e1bfecde3c6f7b3689c16578a6a5ea82.jpg\n",
            "549_jpg.rf.2c912fbe4e479a5bad19e8b8d49227cb.jpg\n",
            "54-E-5627-SF-06-19_jpg.rf.e76454e83b1f216c620a143a68b3bc3d.jpg\n",
            "550_jpg.rf.3b416d2c74e94a0b8b074f22976bb36b.jpg\n",
            "552_jpg.rf.8edc5d04e6cbd24a274c344c237fae9e.jpg\n",
            "553_jpg.rf.d7c636317c8981ed3183821f0492231d.jpg\n",
            "55450_jpg.rf.4b5c7e8ea31dcee90ef7a265ee4ae316.jpg\n",
            "554_jpg.rf.830c161de312dec3d70184e14c0f5dd4.jpg\n",
            "556_jpg.rf.29ba14aece70f4e41a232640e4dd3803.jpg\n",
            "557_jpg.rf.3250a1150717a41eac5a257c842446eb.jpg\n",
            "558_jpg.rf.02326be24843c0523601faa5eceb1925.jpg\n",
            "55_jpg.rf.794946242ada7549524d5faecec0c990.jpg\n",
            "-560B3012-6E26-4551-A44C-6F4AB53B707E-png_jpg.rf.8cb47858716cfdfd6a1196ccec1a3600.jpg\n",
            "-560FDA71-D338-4454-BC81-857A74DE813D-png_jpg.rf.4a0e8f7bca7b0869b810e762c3e130c9.jpg\n",
            "560_jpg.rf.a432885e6788e161f8956f32151343cf.jpg\n",
            "562_jpg.rf.67f4fa5bbb702aca11ec2ebe9b8d2fe8.jpg\n",
            "563_jpg.rf.0c8549fcac755e24581cb545836e4522.jpg\n",
            "564579_jpg.rf.4ccaa8686c382382b9eba5081bb206fa.jpg\n",
            "564_jpg.rf.6ed57ce932ebe990ac0b034581bd0ebd.jpg\n",
            "566_jpg.rf.59d845ac479a86ec9b269cde019e0196.jpg\n",
            "567049_jpg.rf.a8f41ec696572916f077c6288152d512.jpg\n",
            "568568_jpg.rf.d98d4d400fb21916f5f9a3d8de0b858e.jpg\n",
            "56-E-5056-QD-12-18_jpeg_jpg.rf.9ae15fa99406d04069e13821a16d77ad.jpg\n",
            "56_jpg.rf.0bc854b4dd41e82eccde484ab210eb88.jpg\n",
            "570761_v3_jpg.rf.685fb0c185162f3f8294d5bd352f2f61.jpg\n",
            "572512_jpg.rf.74949435435717a618e19fdb3577fe74.jpg\n",
            "572_jpg.rf.b9ca91164ddc07177d7d67d1af11568b.jpg\n",
            "57368a_jpg.rf.f64509567a0af17fed0a2a291f07c2ae.jpg\n",
            "573_jpg.rf.1ef7001f811997298de3a1e5142e8f44.jpg\n",
            "575820_jpg.rf.b2fc45b324462dafea5be8b25916a17a.jpg\n",
            "577_jpg.rf.0c990a766fcb825d570f8623bb94eb60.jpg\n",
            "57877d_jpg.rf.6b3d65f0d517d40d5e9b9c56a2e2657c.jpg\n",
            "579_jpg.rf.bdf8f8ad527e7a99e6d8dba3161c77bf.jpg\n",
            "57-E-5893-SH-05-20_jpg.rf.ee12ffc6eee75bfb1ba3995798ef8d7c.jpg\n",
            "580327_jpg.rf.b14f18ad2bdf32f539aae34f34fe5eba.jpg\n",
            "580_jpg.rf.90cbdcbbc2297ce068905d50060917cc.jpg\n",
            "581156_jpg.rf.eadb98d395ed34274a26cd8e30be1fa5.jpg\n",
            "581_jpg.rf.a2b627bba820700dea450b868d9d7700.jpg\n",
            "582171_jpg.rf.060de0ed2277e8888a097ee3bfc69922.jpg\n",
            "583_jpg.rf.bcb245fd4a899623763811ef9e79c9ed.jpg\n",
            "585_jpg.rf.5d2ad9d80fde1c5faaee1daf104b5b84.jpg\n",
            "589_jpg.rf.2a04d7a7e732d1f999c4b8177c2d3076.jpg\n",
            "-58A0B6C6-CAE2-41F9-9A9F-6B6E1A4EE492-png_jpg.rf.7789d36f85603324152bca70439324b0.jpg\n",
            "58-E-5158-TP-09-17_jpg.rf.958c62bc113380037518259b3f2e1aaf.jpg\n",
            "58_jpg.rf.2faa32c04d02f3c63f07339765684942.jpg\n",
            "590_jpg.rf.fa38010a44d98270aa05bec79e61e520.jpg\n",
            "591090_jpg.rf.46e5917680594370446dff85cc334183.jpg\n",
            "592_jpg.rf.39ec46a104b7a3e4e5ec75cb9024fa87.jpg\n",
            "593_jpg.rf.33f1ca2934ef0724296c9c18b2c425d0.jpg\n",
            "594_jpg.rf.b66fe13f272851eb81fa9338b12a803f.jpg\n",
            "595347_jpg.rf.dd7c42aba7cdd100c75dd9787ea8496d.jpg\n",
            "595_jpg.rf.26e3f37fdf208b9b6fedeeb470d6348f.jpg\n",
            "597672_jpg.rf.adaf6229fd04e3f05fa904c385ba034d.jpg\n",
            "-597DE6B4-F29B-4655-A97B-DBFEE2C995F8-png_jpg.rf.fe36a612845f5ae3ebfde81a2c1d01b7.jpg\n",
            "598_jpg.rf.681e49ade8d35467aa1e55409838d13d.jpg\n",
            "599_jpg.rf.e83d8387e5ea349edab3db7a7556ade6.jpg\n",
            "59-E-2153-SP-08-20_jpeg_jpg.rf.b0613871da323fa8757df8fe75404b89.jpg\n",
            "5a1e37db78f66_jpg.rf.3675cf36f7a8e042116a0da69275ea7e.jpg\n",
            "-5AD2C6FA-9814-4CB1-822E-3A617443C49E-png_jpg.rf.6cbbd305f81bdde5ce28912e8de84b7c.jpg\n",
            "-5B95F32A-2281-4DBE-95B0-1B199E9778AF-png_jpg.rf.a64225e7984600b523efcf09fbf4740d.jpg\n",
            "-5BAA1216-71C7-41C4-8494-D0AFE9C52AF5-png_jpg.rf.69d7e3361badc43b0ae869fae96d8daa.jpg\n",
            "-5BB5033D-F96D-4681-808D-9BCBE7C2221E-png_jpg.rf.e14884bd63940d5ed7a9fa4e1cfa2f8c.jpg\n",
            "-5BCD3433-D1A0-436B-B906-4809400FC43E-png_jpg.rf.449cad3452ee39b7f668a07de9ef35b5.jpg\n",
            "-5CEE3337-3AF2-49E4-AE4E-42B9E2E44512-png_jpg.rf.cfe0b5b6f80a13391e97bb68dec1932b.jpg\n",
            "-5D5BA3F7-FDD8-4C19-8DAC-D5384A81B407-png_jpg.rf.da90a3c428f7a6b40024df5f6bc1a26d.jpg\n",
            "-5D890027-73FC-42D9-B3D5-2ED473A73B66-png_jpg.rf.5e425db92878b4b1516557407c0cb45b.jpg\n",
            "-5DB86A4E-D64A-4032-ACF4-957B38D438C9-png_jpg.rf.38de1fb98f36aa6932fd3ed45b24792a.jpg\n",
            "-5E27337A-F8B1-4A0F-BD88-EB390F07131D-png_jpg.rf.306a551a6a759d9892bb1802a8766b4d.jpg\n",
            "-5E492592-1503-4FFB-A59A-7C84C8FB58C8-png_jpg.rf.55be4362c8a14fc9f1939f7dcaed159c.jpg\n",
            "5-E-6862-QT-06-20_jpg.rf.647077fd077e0d353040a5f03faca51e.jpg\n",
            "-5E69D234-D9EE-4A15-ABEB-52BA04828890-png_jpg.rf.67fce3d3c68dd0bc41f48846a599c908.jpg\n",
            "-5E8CB65C-3365-4514-AC80-892C8BF6B0BE-png_jpg.rf.4a08afe3edb918becf204799a001800b.jpg\n",
            "-5F381E05-B9B8-4054-8444-EFE81AA4B78C-png_jpg.rf.2b6c3a5fc274c61c1f3006936fe2ae85.jpg\n",
            "5f630068e794c-jpg_jpg.rf.c990fecc6e5e11ceb5342e5d6329a128.jpg\n",
            "5_jpeg_jpg.rf.bb54e37f2005474b10f3da0ab0d2d6c7.jpg\n",
            "600109_jpg.rf.34402417b3baaf1fd69cefd1e35eec7c.jpg\n",
            "6007931417_jpg.rf.2db4f8596080d7094a8c4cca677501ee.jpg\n",
            "6007931417_jpg.rf.f5561e2e6a475e4fc7ed27c301da0cf6.jpg\n",
            "6007950747_jpg.rf.b31fcaa3d63f092c50f5614ae9ab9cc5.jpg\n",
            "6007950747_jpg.rf.d7183131e8e644f34a74cc51b6738ceb.jpg\n",
            "601054_jpg.rf.7f2c14744f0adddd1dfd85b211c6ec8e.jpg\n",
            "601_jpg.rf.14788cef49597f394ff0cafa48ef53e0.jpg\n",
            "60251_jpg.rf.0a4317453036e11678e7cf590a1ca826.jpg\n",
            "6046f688f6314789_jpg.rf.993a8dfc47c08b2cd31adecd12fa49d7.jpg\n",
            "604996_jpg.rf.3858fd4371c6a779456e86507c81cad2.jpg\n",
            "605_jpg.rf.2563fc3417753e72e0c757edc400f92d.jpg\n",
            "606_jpg.rf.763b11f320d2900371a8a58513075847.jpg\n",
            "609_jpg.rf.df834e57fe681d52d17c618e9c647ab2.jpg\n",
            "60-E-1707-PH-03-15_jpeg_jpg.rf.798a2d47f585835fb6bbedf9b912c81c.jpg\n",
            "60_jpg.rf.86d3705c338aadadb2f56391b35bdc25.jpg\n",
            "610_jpg.rf.8d219bfe3f58bb124dfbda0d3304cac3.jpg\n",
            "-611BF23F-5A2C-45D6-A4DC-033938DD1CA5-png_jpg.rf.057f0c19a913c3fefd56c0579a072914.jpg\n",
            "612_jpg.rf.16b8f702809552efd44618f56f173128.jpg\n",
            "613827_jpg.rf.51cd4906dff98a6008929af5454a5e1e.jpg\n",
            "613_jpg.rf.45639c594d0f39a63f416762448e84ce.jpg\n",
            "614_jpg.rf.b837fa811b9f83cd62e87e3aa8b11347.jpg\n",
            "615_jpg.rf.e302c5125cd98f6820069f8a03b950d7.jpg\n",
            "616269383_jpg.rf.0d8236770ec4068026270e6b537f8504.jpg\n",
            "616269383_jpg.rf.916c94af3e479d1670b304fd53b0cc7c.jpg\n",
            "6171fa966192f1f1_jpg.rf.bba0f0c99f899e8e87b5158f7da22634.jpg\n",
            "618513_jpg.rf.3938182d4d740fdd09564373c7d45f70.jpg\n",
            "-618A0E4F-DFF5-4624-B30C-9F657BE51772-png_jpg.rf.d846ac76e1abbf82842c057adb37eb88.jpg\n",
            "618_jpg.rf.538170d23aa48b11518908c8d5d807ae.jpg\n",
            "619286_jpg.rf.5f60643d938156b109bab2f9b5c2fd01.jpg\n",
            "619_jpg.rf.7390c2ddeb695602ee084136b7161455.jpg\n",
            "-61DB2824-3E4C-44EB-BDA8-91E18B840415-png_jpg.rf.744e604db10e173d733487a95a086916.jpg\n",
            "620_jpg.rf.486fa690af935573062448063577a871.jpg\n",
            "621102_jpg.rf.a64cc3a63e3770f0ab316c2690e8a10a.jpg\n",
            "62134520-mature-lady-on-yellow-scooter-scooter-driver-on-street-background-parking-for-a-few-minutes-near-the__flip_jpg.rf.1c805eb4a0176b1d68a72e2dab274217.jpg\n",
            "62134520-mature-lady-on-yellow-scooter-scooter-driver-on-street-background-parking-for-a-few-minutes-near-the_jpg.rf.831379c3dcc7b41a5bcd934607b54e38.jpg\n",
            "6221ece66a3b3354_jpg.rf.d0eea1e5c85fef3db3b1f17188760232.jpg\n",
            "622_jpg.rf.943420e71404a7a667b13494535cb226.jpg\n",
            "6247ff1c389c8997_jpg.rf.32c04955d41aba5514887eabb87d7eb5.jpg\n",
            "625_jpg.rf.b8083a9b96de5e6e4134739768a5ccb3.jpg\n",
            "627071_jpg.rf.633b7447af2cb4fb6fb3f0c6d45a5a4f.jpg\n",
            "627_jpg.rf.f24aa2bd11011b7603ff8d3c95c0bc4d.jpg\n",
            "628_jpg.rf.21ed3d7179719290e98516691d8f4696.jpg\n",
            "629525_jpg.rf.b32485820241a9a42972a9b6553804ad.jpg\n",
            "629_jpg.rf.9d7ead2c852fdf555699189aa3cdf1a5.jpg\n",
            "-62DA7C7D-C50D-40A7-87D1-DB8633F1F29D-png_jpg.rf.a52d4fdb7f5d4d8cca94817f15330618.jpg\n",
            "62-E-3977-TH-12-18_jpg.rf.92569212f5816254e9f635cd0e960070.jpg\n",
            "62_jpg.rf.9439ba55ae91617209ab6d228edc71cf.jpg\n",
            "630385_jpg.rf.5dda13412f6082ef53597e6e96744812.jpg\n",
            "630_jpg.rf.f436a0e52bf3ccc628eaac2d74a80233.jpg\n",
            "631183_jpg.rf.7747e8cbba80e6afecdd8ab409f9da8d.jpg\n",
            "631_jpg.rf.6a35b8dc87836b7cafa4ba4f3d3ca912.jpg\n",
            "6320646c88aca-generasi-terbaru-dari-_jpg.rf.99ce069568ccb5a25a74b15d6b943f8a.jpg\n",
            "633_jpg.rf.c68a284b6ff66bc8422dd62b44859142.jpg\n",
            "634_jpg.rf.bf2380a50f7e362847c6a34b910f0600.jpg\n",
            "635188_jpg.rf.8ee066f1f08f878f28e047f1a7d41dd0.jpg\n",
            "636308_jpg.rf.6c3d2005ffc88061703c34248bc37d3d.jpg\n",
            "636534_jpg.rf.2af14e7dad428fff98ded681edfa9a64.jpg\n",
            "638_jpg.rf.119a5f688d4e9ca4f1df165c3a4c6ecf.jpg\n",
            "-63A3759B-1595-4A66-BB62-1E7F580BA753-png_jpg.rf.dc63802d8736510f39ac57f023a288ea.jpg\n",
            "63-E-2536-SA-09-18_jpg.rf.5996eff6f99333ca5fcfaa2e51da3594.jpg\n",
            "640699_jpg.rf.5183c2c2268b4cc6811192720e723e2a.jpg\n",
            "640806_jpg.rf.b63bfb33b1a6aab092473ae8a887bce7.jpg\n",
            "642_jpg.rf.d991894ea2b7f85a31ff854843246654.jpg\n",
            "644_jpg.rf.4092d837c7ea9a5fe4b889efe224b12d.jpg\n",
            "645_jpg.rf.b176cffb9a2f1269712d66fd4849f440.jpg\n",
            "646657_jpg.rf.32a9e39d3c723e0ec5985b73da1b01dc.jpg\n",
            "648_jpg.rf.0ba834224c51ebbb0e1a28868c067879.jpg\n",
            "-64FEA10C-1F32-4982-91EE-6FCD11A89A15-png_jpg.rf.c503587579fa991a4c84f9eb4a665268.jpg\n",
            "64_jpg.rf.e000e4d26b4c5447885b5c8fe0410c19.jpg\n",
            "652_jpg.rf.a84d3e1e9ee05f3fbc0966c8bf26459f.jpg\n",
            "654787_jpg.rf.93fba4d39d97e3b516b6148d14096132.jpg\n",
            "65497_jpg.rf.cf358bae7183db199e4693fa485f7096.jpg\n",
            "654_jpg.rf.28bb0ed22efc03612f2258382fefef40.jpg\n",
            "656_jpg.rf.7009a04cd43b12bdc1ee93b3edf846b7.jpg\n",
            "658128_jpg.rf.cc3d2e2a54310ccdcf3d58a93d10f2ac.jpg\n",
            "65-E-4235-PAL-04-22_jpeg_jpg.rf.c3202c0a595ca7b772a9706d02324829.jpg\n",
            "65_jpg.rf.b058831109c1276aeb78ee0b319cafaf.jpg\n",
            "661_jpg.rf.24b028bf06857dabd85cdbce79ac0996.jpg\n",
            "662_jpg.rf.fb99de70902a0a706449aeb4c342e5ff.jpg\n",
            "663_jpg.rf.a2f3cd2198f279210b4b55414c1adb80.jpg\n",
            "667_jpg.rf.bfde60b9ca457819d5750aa13b9c5945.jpg\n",
            "668_jpg.rf.fe55da8448e6f163b63152363e65c533.jpg\n",
            "669_jpg.rf.c2d0cf63000f6cbbcaffb01306e8ca18.jpg\n",
            "66-E-1477-RB-02-21_jpg.rf.db77e6ec051d1e1e71cd24263ecaf475.jpg\n",
            "-66F945A5-3856-4F91-9EDD-6EF4833F57FA-png_jpg.rf.655ba895efb19ca1cbaa00c6479b3bf3.jpg\n",
            "66_jpg.rf.afd716b85514a2e9f121bd230164dead.jpg\n",
            "670_jpg.rf.cd98b65d4c3691f7581af7be608b6f42.jpg\n",
            "671_jpg.rf.0a622a0209d6d8c8a9684f3ef960cd09.jpg\n",
            "67369_jpg.rf.c6ed44b5fa0e1a3c6893f17eaeeca0b8.jpg\n",
            "673838_jpg.rf.7002b2aab7846e34bdf6394b4d6e76a2.jpg\n",
            "67697v_jpg.rf.0c8c81c5840992716b924aef4ff8d27c.jpg\n",
            "67697v_jpg.rf.282749b27b63f2209d43c0446e0714fe.jpg\n",
            "67697v_jpg.rf.6462f81759c1383ff05b929bcdecc21d.jpg\n",
            "677_jpg.rf.1563ba577cf59f64b17f9a10e2ed2062.jpg\n",
            "678_jpg.rf.8901fb0005ed251123c6bcdf18ff4af6.jpg\n",
            "-67F523BC-B8BC-43AB-A499-0F8DD93797EA-png_jpg.rf.34ebbb2c548ed9f2efe2f1eb2558989f.jpg\n",
            "67_jpg.rf.fc805e1a36e90b05b1433b1777bd5c1c.jpg\n",
            "680_jpg.rf.b577c97283181f8fdea28f39b644a556.jpg\n",
            "682403_jpg.rf.ec76dd2d5b112b145a53f4761f341723.jpg\n",
            "682974_jpg.rf.009bc8186bbbf26bffd363c8fec99240.jpg\n",
            "682_jpg.rf.5d29e6950c923863308a10d5f0886b98.jpg\n",
            "6833_jpg.rf.f8bc52e73e34808b3a875625987d2866.jpg\n",
            "686_jpg.rf.8ae0c5cfc29acd57fe4dbe61039cd0f7.jpg\n",
            "688_jpg.rf.70a4204d01cb84a6f5fbe787995c81aa.jpg\n",
            "689402_jpg.rf.cf6b876832b05dd64e348772693160a2.jpg\n",
            "689_jpg.rf.803a28829d2cf139b5fe5239acb565b4.jpg\n",
            "68-E-1267-RB-01-21_jpg.rf.9f16e712476948301072aff67c2f9103.jpg\n",
            "690_jpg.rf.cfc7d74090304c840bda89e13aff0ca9.jpg\n",
            "691077_jpg.rf.9709afa7d703695d36f6957f20aabf8d.jpg\n",
            "691_jpg.rf.575e1f5c39e81b746e7d5c7057167807.jpg\n",
            "692_jpg.rf.f784c569914a789e276eada9d758ca8b.jpg\n",
            "694_jpg.rf.c98621b2cfa5a9eced18f390f15ff802.jpg\n",
            "696278_jpg.rf.d5e5a825580e655803079cf93b74edfc.jpg\n",
            "696_jpg.rf.6aa4de7f394f9ec7225723d7f541c91b.jpg\n",
            "698335_jpg.rf.f47cbec17156b4191eff64c80a1d1752.jpg\n",
            "-6A4AE25F-587B-4392-A93D-C7F5E68AE98F-png_jpg.rf.d4690e10a6bff78066798846edb06a5c.jpg\n",
            "-6B49AF0D-BB75-4309-BC64-B645860395BB-png_jpg.rf.e4b514ff2f3e6e32488a83be72ba5687.jpg\n",
            "-6BD213B4-285C-499C-A703-C20196929F71-png_jpg.rf.66f58d8cee76145003445fa7449bfa7f.jpg\n",
            "-6BD80EF2-8105-4942-9645-FB49CCDACDBF-png_jpg.rf.d781f690b4f90768599b87118c9ee120.jpg\n",
            "-6C03F6AD-22FC-4497-87AF-3A5CAA0C56AE-png_jpg.rf.90e80ab819384f02fe8076ebd24b9433.jpg\n",
            "-6C784C03-FD7A-4D9A-BB13-D3C9E53D8EFC-png_jpg.rf.7ef5ac8ab84a0f3b3c05fd4a932abbeb.jpg\n",
            "-6C8B745B-F55C-4939-A549-004F539643BE-png_jpg.rf.04b004e637512a2216119429acc559da.jpg\n",
            "-6C9D536E-31F3-4D0A-8215-A493ED0CEEFF-png_jpg.rf.4fbf68b1b11243ac05691f7b5cc274ff.jpg\n",
            "-6CFFD6FB-2A39-4815-8F6F-DFAC5E9F5DB8-png_jpg.rf.4d62df98b3748b48fc226e84a9cd7f65.jpg\n",
            "-6DC3CACE-C68D-4C1E-A289-D30BB69C5514-png_jpg.rf.58bfdce95f4189e5b08c65850a7798ad.jpg\n",
            "-6E1F9232-59D2-4C19-94D6-826A8A2049C8-png_jpg.rf.c4439f1a3d0a7a860b4628ba01b04832.jpg\n",
            "-6E572C75-A448-49CF-86E8-9F1364971CB1-png_jpg.rf.62f0d7db341e8bc2e424cf3978015379.jpg\n",
            "6ed4bc32-ec4f-475a-996d-64ad159da3ea_jpg.rf.6d07137e1302d69632e222defa67979c.jpg\n",
            "-6ED52BD9-DBD2-4238-9B1A-8AC83D6ECE73-png_jpg.rf.dcad0f9e8962cff2fb5d5c24c742b6ef.jpg\n",
            "-6EDBF25D-DB21-48EE-85C6-D053CD8F2E69-png_jpg.rf.fb31aff22c9576fbd9510876a50ba51c.jpg\n",
            "-6EDCD451-96F1-4512-A9B4-D8DB41F96E1C-png_jpg.rf.f3ef3d7add80a17c6c8201db031ef67c.jpg\n",
            "-6F232CF8-0FEF-4DAA-8453-5FC09AFC9168-png_jpg.rf.07fac2ae7d3e10cdbf4c00736d2d84ee.jpg\n",
            "6_jpg.rf.68c77d2e8bb855fed7a200e076679417.jpg\n",
            "7002574__flip_jpg.rf.addfa753cade8a98c82031d38b28267a.jpg\n",
            "7002574_jpg.rf.067275215aab8a8a5c26082a0d02bbc3.jpg\n",
            "7003032861_jpg.rf.1f5ad73929c25f498da60840a44cc259.jpg\n",
            "7003032861_jpg.rf.5e0d6e04b9c092a4a585f38602cf7356.jpg\n",
            "7003032861_jpg.rf.8efd2abbbeeaaa43339b8367d8291ab4.jpg\n",
            "700_jpg.rf.bc9e9ad3f74693a27ba9f293dc417edc.jpg\n",
            "701_jpg.rf.923089d591f2c00811636d0dd0bd4292.jpg\n",
            "702_jpg.rf.c864593d2cc24dc6d6e58fd3ccbc7f1f.jpg\n",
            "703_jpg.rf.c7e2094dca9e9af512dee2cb436fff60.jpg\n",
            "706_jpg.rf.ba3b45ceb005f5336da3ec96d924439e.jpg\n",
            "707_jpg.rf.4611171065b755ade654ace40efd524c.jpg\n",
            "709_jpg.rf.6eb27a146616df36caa3cb21fc5840a6.jpg\n",
            "-70B2D8E8-1E31-42B8-8833-99593F1B5600-png_jpg.rf.e8496953938daa5844ccac987070b580.jpg\n",
            "70-E-4310-OR-03-20_jpeg_jpg.rf.22a61505efccc4e55251042eb80b07bc.jpg\n",
            "710_jpg.rf.11ec3ad8d5fe7ec5fe23c8598ca068c1.jpg\n",
            "714_jpg.rf.7fccb087203bc017772ed9d7793456c5.jpg\n",
            "717_jpg.rf.f5f60f9b890ef4a41f636a315335daf1.jpg\n",
            "719_jpg.rf.436be3c98b0a4ae1febbeb80af98fb67.jpg\n",
            "71-E-2478-QK-07-19_jpeg_jpg.rf.7f3b3ffe64bccb8d40310abc91fe8751.jpg\n",
            "720175_jpg.rf.b3922a6c4af1a0aad26dfd37c2cfe5c2.jpg\n",
            "721_jpg.rf.4b87db5b10b05f91cad042a9fbc579b6.jpg\n",
            "722785_jpg.rf.ff398905462cd277101847a9fcf46d60.jpg\n",
            "723_jpg.rf.ec94ea36829c2a6735aeeef23e58d917.jpg\n",
            "724_jpg.rf.b29e161554750f6d709539f7872f63cd.jpg\n",
            "725_jpg.rf.5eabf25636d1478e92104cbfbda269e7.jpg\n",
            "726559_jpg.rf.dd7b9933885b0f2f77ba5619c3fccd66.jpg\n",
            "726_jpg.rf.0f2c65e3c7827a06e988e85329620cf8.jpg\n",
            "727447_jpg.rf.113f064f8252daa9de15ef62c0890743.jpg\n",
            "727_jpg.rf.e279821d412e19b7a2a36bf88ea6b5ef.jpg\n",
            "729_jpg.rf.ffc47209383c4f2351c46e8d501f837e.jpg\n",
            "730_jpg.rf.bf12cad017892a6fda1ea6b60ac6c609.jpg\n",
            "733_jpg.rf.298e1040db866b61acff2aa4077931dc.jpg\n",
            "734_jpg.rf.34b6d8fd1aa14f5fa96b77f7196f68dd.jpg\n",
            "737_jpg.rf.cc8105a18a2a68137a5067d9d0d4dd54.jpg\n",
            "73812_jpg.rf.302fcf6174a9de2a4fcf46b265b21ec1.jpg\n",
            "738_jpg.rf.e53ca71ad8ee576daa49508fd8d1ad98.jpg\n",
            "-73D74CA9-CB84-4A43-91A1-B5688ECD28DB-png_jpg.rf.626129d34f666c3ad81a4d08c85d29fd.jpg\n",
            "73_jpg.rf.ce6cd84b33c1e4a55d1387e91cb31b8c.jpg\n",
            "740_jpg.rf.ea113e9d782366274eabf6e2c012bf61.jpg\n",
            "741_jpg.rf.ba4f6cc752250c325489cf561fc18e2a.jpg\n",
            "742221_jpg.rf.9c702bf9565e49ba380085cabe68a546.jpg\n",
            "743_jpg.rf.da88e9a65c95bf26fd7df1067f735854.jpg\n",
            "745988_jpg.rf.20147691926a94e5159d140e458b0fae.jpg\n",
            "745_jpg.rf.47d620022d1ec838d1f43d691aa5b230.jpg\n",
            "747753_jpg.rf.8f44f81bbec1ec4c135da52a606b673f.jpg\n",
            "748_jpg.rf.b4353c050120f932c1d21fa24b9eaf25.jpg\n",
            "749_jpg.rf.37a006e25e0adf85f93dbf965f7a497b.jpg\n",
            "74-E-2393-TT-01-18_jpg.rf.8b6ef70e014968784ef3a4cc24fa5cf6.jpg\n",
            "750110_jpg.rf.8072354f69345d0ad1b50e7eb6dd1656.jpg\n",
            "750982_jpg.rf.995712c7e10c24e98631b89be38b6f58.jpg\n",
            "754_jpg.rf.ca60114d7fdc8edcfd1cb144f403e817.jpg\n",
            "755_jpg.rf.2bd27ef2874d64f6b7ab3feb024ac261.jpg\n",
            "756_jpg.rf.2be1c0b0c5ec521431e812121c4e3bf9.jpg\n",
            "757_jpg.rf.152d8817352c674c65a4ef9318e2aadb.jpg\n",
            "759821_jpg.rf.142a0b29912706fc307be980fec1fe86.jpg\n",
            "759_jpg.rf.474c60ec580227e22eb4b24c5b4ab8d6.jpg\n",
            "75-E-2956-RP-03-22_jpeg_jpg.rf.8756c9bcdb13b64f32956006448d59be.jpg\n",
            "760_jpg.rf.8e3d35d3bf436aa43768e6caa821b11d.jpg\n",
            "762961_jpg.rf.0761e51848e19cc4f6e272d8a8ece8dd.jpg\n",
            "762_jpg.rf.3318c4770b13d99a34ebe455824afec7.jpg\n",
            "763_jpg.rf.0b43cc2df8124a1002cd642972d5a6f0.jpg\n",
            "764_jpg.rf.1f5cb6a6cb51b8b029e911eda75f781e.jpg\n",
            "765_jpg.rf.cc0bb467b93d05eb3e9d19460b436953.jpg\n",
            "766170_jpg.rf.07f00fe12a0ca8e32b4888da969388a0.jpg\n",
            "768_jpg.rf.2f7d02b1756a0e114f01bcc7008d8237.jpg\n",
            "769_jpg.rf.2de49e45fa517ff2aaea043b7af8d2b0.jpg\n",
            "-76BD94C0-3EF8-4649-A261-EFD9F02C67AA-png_jpg.rf.27eb19fd1cc352d138e38c5d7512532d.jpg\n",
            "-76ED2882-F7AA-49E4-9067-B957B1B55FDE-png_jpg.rf.78d82e4e4ad57d0b420318ce222797cc.jpg\n",
            "770_jpg.rf.9f0e355d669833f5649d30b60979cd2a.jpg\n",
            "771_jpg.rf.7dbc1a6bdfce709b59292d73366c9890.jpg\n",
            "772_jpg.rf.94df66978cec1155491c25de7aaa9e37.jpg\n",
            "773514_jpg.rf.6e6f30cb616075284575a4178551d5eb.jpg\n",
            "773_jpg.rf.6b3eb304953460668e5f778c1f449fbe.jpg\n",
            "774_jpg.rf.92d5f51311cf7a2564a692762d673045.jpg\n",
            "775_jpg.rf.d2d67a93ccd0367783aa601cdf878c3a.jpg\n",
            "778_jpg.rf.496061f83168b118c1d99d245ad728ce.jpg\n",
            "779_jpg.rf.bab8d7b60f755e06c8d91313a72e22ba.jpg\n",
            "77-E-6295-QL-09-19_jpeg_jpg.rf.c08df15ba9620de1917406c35b3f79af.jpg\n",
            "77-E-6295-QL-09-19_jpeg_jpg.rf.e628a4bb5b2d07fb652825206741f4aa.jpg\n",
            "780_jpg.rf.6b4ddc168b6d2edb77be3d359b588c9d.jpg\n",
            "781_jpg.rf.89976aaef2bdb1b695e9577b921feab5.jpg\n",
            "782_jpg.rf.4821002c127d2c09530b9efdab857777.jpg\n",
            "783_jpg.rf.8aad48cf63616a616cdb0290f1e74f98.jpg\n",
            "787982_jpg.rf.fae7cb0791185cf87bd18b711f59367f.jpg\n",
            "788_jpg.rf.2b79173558bc8f32d26c39e050e5f4fc.jpg\n",
            "789_jpg.rf.bae9d2d322a789bc93aeb970761f74d9.jpg\n",
            "78-E-1245-RG-02-20_jpg.rf.336e426d901bd516b18bb5fd2f6dd3c1.jpg\n",
            "-78E89006-062B-436A-B4DC-0C9CCB604A29-png_jpg.rf.789cc1edb7e313c69e4cd7554185681c.jpg\n",
            "78_jpg.rf.68a40f6971c3a1698069663950a5ba60.jpg\n",
            "790_jpg.rf.400820954fa0004354b4071748af209c.jpg\n",
            "792_jpg.rf.038a32d74cbc4ac2ce48e98dfa24ca3b.jpg\n",
            "794_jpg.rf.d910796b5e6a78109d66116dee1be7f2.jpg\n",
            "-79CD8919-65C6-42BE-B5A1-81EF57DAED94-png_jpg.rf.594fca014d433a03f3437d2bbeb8cb2c.jpg\n",
            "79-E-4564-SZ-09-21_jpeg_jpg.rf.7ca124e3c974a4726d2e8386989e7b03.jpg\n",
            "-7A02CEC3-9C8C-4B5A-9B8C-F09F395C2EA7-png_jpg.rf.e3acdc29ebb86e156c17592bbbc12a17.jpg\n",
            "-7A5FF924-9562-4F28-AAEA-937BEE55348E-png_jpg.rf.e757cf45a6fdd44f88b6fad089ecc496.jpg\n",
            "-7A674CAF-64A9-4CAB-81B9-E036F0FB8E02-png_jpg.rf.b08472ef084ef7f6aa80230640417e67.jpg\n",
            "-7B158558-F889-4CA7-847D-10332A467616-png_jpg.rf.ec10d045e0cf18d5f2687a2991cc21a3.jpg\n",
            "-7B2232F0-BE04-4BB5-A476-806409239A4A-png_jpg.rf.2dea50ab1832113ce0fee342344fc4fe.jpg\n",
            "-7B9851BF-C60B-4A0D-8032-76FE903D9312-png_jpg.rf.c79aa857db9bb1567ebf188f2cba8f90.jpg\n",
            "-7BB7C449-A5BF-41D8-B9CE-C083C6E6546E-png_jpg.rf.db67c99839ed2be8e9d984b3cda8d32d.jpg\n",
            "-7C3CD065-1FEF-422A-9845-8975639C2760-png_jpg.rf.0bfccd8d64aacbe198ace62018acd929.jpg\n",
            "-7CB39D5E-230E-4818-8515-710291F3FA50-png_jpg.rf.0b0b0d35ef785f75e75e8457eb601eaa.jpg\n",
            "-7D7FF001-4B2A-4150-BA08-6F1E4C1E2B64-png_jpg.rf.22768ac2edb33e737e11f5510f9fda9e.jpg\n",
            "-7DAAE50C-654B-4094-8350-5C147173C77E-png_jpg.rf.19d04589755e372edc7d431d491dc82c.jpg\n",
            "-7E2BE9C3-F989-4E5F-B605-E250E41C4FFA-png_jpg.rf.8a7ebaf592c394467dad935bdb913371.jpg\n",
            "7-E-4594-Q-08-18_jpeg_jpg.rf.5fd329ea75df7fe4f0a89ab099b68df1.jpg\n",
            "-7E896192-D1B6-4B05-9FC3-AD6802AF0A5A-png_jpg.rf.fdbde54282562ffaefec7a43c08b1469.jpg\n",
            "-7FD32EFB-018E-4523-BF11-D6C6D7EECF1C-png_jpg.rf.2d837770bdd8a0e2b0d241eb4d0b24eb.jpg\n",
            "7_jpg.rf.3c1addcfe0e07f0209f39f4eb96fb3da.jpg\n",
            "800_jpg.rf.5b7e8b84f2080bafcd5960fc5fa1a11e.jpg\n",
            "803054_jpg.rf.33d7c63627a1bb6c37ef41e23383083e.jpg\n",
            "805065_jpg.rf.5d22f3e7817fa7628943a88538ef6667.jpg\n",
            "806114_jpg.rf.618702dbdfe803d40b7cce6eea7ac4f5.jpg\n",
            "80-E-5142-TW-05-18_jpeg_jpg.rf.b5f0241f328a457866e5a90b0a1c35bb.jpg\n",
            "80_jpg.rf.cba45b7c938363c21405a97735fc1510.jpg\n",
            "811212_jpg.rf.0c88a195366060f84cb1a559dde06e88.jpg\n",
            "81-E-3115-SN-06-20_jpg.rf.29e9a731c0f996d3e14232088de2fefa.jpg\n",
            "81_jpg.rf.34b92aa5cc37879f612ff371ccf019ca.jpg\n",
            "821596_jpg.rf.5bbea13bbfa84c1eecd020921579f06d.jpg\n",
            "828179_jpg.rf.f78316e37129226969c892514205f72e.jpg\n",
            "82-E-4993-TI-01-22_jpg.rf.0b4a118045007b12109ff277e6a3f0a9.jpg\n",
            "82_jpg.rf.09ddf7b383f32fc170140abeb39d2f25.jpg\n",
            "830005_1_original_jpg.rf.bd7b6cd12bcfaa793c06a07b76d8e5b8.jpg\n",
            "830005_2_original_jpg.rf.3b9ad6d923726ed1e614e29cd56093d5.jpg\n",
            "830005_2_original_jpg.rf.5bff7f51ae6fdb03d011f6b718be2e4b.jpg\n",
            "83736_jpg.rf.38e65e4a0a1a1647a31eae8443bb3aa9.jpg\n",
            "838467_jpg.rf.c321f44772a2c7e0a68b5f663573e4ba.jpg\n",
            "839402_jpg.rf.97af72f514271d57ea40d48dc9fd3c38.jpg\n",
            "839615_jpg.rf.be4a76f56659ae116629f23e0d1576c9.jpg\n",
            "-83DAC56B-7697-4A8E-B04D-3F5FF6ED3F38-png_jpg.rf.4760ddc3eabc8f3e367d55e4a5605bc5.jpg\n",
            "83-E-4147-QJ-06-19_jpeg_jpg.rf.874d9ffb88dd6e310414596e554d8fd5.jpg\n",
            "-83E8FE19-695B-45C1-9F7F-83ECDED58546-png_jpg.rf.24f6e6e2c536cd1485f5903f7fcf204b.jpg\n",
            "83_jpg.rf.fc34d8153b7b4972901c3e8813d4fa24.jpg\n",
            "840206_jpg.rf.e3d18169149968a5dfd0e326ba389c9b.jpg\n",
            "840255_jpg.rf.0cb55bcbcd06c637625affe865c7b847.jpg\n",
            "847209_jpg.rf.02c52928ec819993c2c1ac816109ca6e.jpg\n",
            "847666-2012-mitsubishi-fuso-super-gr_jpg.rf.21e56d4f9571d169d6ce07e5062d3ec0.jpg\n",
            "847666-2012-mitsubishi-fuso-super-gr_jpg.rf.ee09c1405462f9c01f29a971a51630df.jpg\n",
            "847668-2012-mitsubishi-fuso-super-gr_jpg.rf.702b83eeb634b5c0a89e1513d7f70f44.jpg\n",
            "847668-2012-mitsubishi-fuso-super-gr_jpg.rf.d0254bc230c5cb762bc83dafd759d15f.jpg\n",
            "847673-2012-mitsubishi-fuso-super-gr_jpg.rf.d9fe3d5d17c76899788151a8356158f4.jpg\n",
            "847675-2012-mitsubishi-fuso-super-gr_jpg.rf.5645092fe1ebe2fcca0fa21ed67a330c.jpg\n",
            "848105_jpg.rf.ece60e80c792e4198d283111c274b9eb.jpg\n",
            "84-E-6545-SN-06-21_jpeg_jpg.rf.1325e83ae2e85e98daf01ef7d9a6f3de.jpg\n",
            "84_jpg.rf.63a78efdf39d36e98507047e3f1824a0.jpg\n",
            "850082_jpg.rf.4bc480730ba8c6b882f785c1c6357c92.jpg\n",
            "852641_jpg.rf.a255f35c910a0a0b7e8e412c3d77b459.jpg\n",
            "85267e_jpg.rf.6729413ad0909c0ab80b7f1c64d5476c.jpg\n",
            "85267e_jpg.rf.707a1e812e80b22b60e1fc3dc77ff7cf.jpg\n",
            "85267e_jpg.rf.97be33dba949f2e597681bc73994dc32.jpg\n",
            "854534_SAM_0695_JPG5bb2899218b4c7a1a_jpg.rf.0bf59afb7866f14809dc3149073b8b15.jpg\n",
            "854534_SAM_0695_JPG5bb2899218b4c7a1a_jpg.rf.1635c6d75790a827069a342023e5b7d1.jpg\n",
            "854534_SAM_0695_JPG5bb2899218b4c7a1a_jpg.rf.465751f17830f0861433f5a910046d49.jpg\n",
            "854534_SAM_0695_JPG5bb2899218b4c7a1a_jpg.rf.910e282cf5d8805aa128b53396f6c2d4.jpg\n",
            "854534_SAM_0695_JPG5bb2899218b4c7a1a_jpg.rf.f1d0c6873e677c9e96cb0186f7bae876.jpg\n",
            "854815_jpg.rf.81e1e49479c338b6d57b3bcd4ed5167c.jpg\n",
            "858073_jpg.rf.44cc4c41328ad4c970250c754c62f60c.jpg\n",
            "85-E-2686-QH-04-19_jpeg_jpg.rf.9aa68c366e821b7d9b95b41216774699.jpg\n",
            "865166_jpg.rf.69c1ce6cc466bc076d06f9f4bc7837bf.jpg\n",
            "86_jpg.rf.aa7caeff6c54e93f12f56f1b89c4a551.jpg\n",
            "876470_jpg.rf.04414c47c0616e5d8dd1f72798ca8410.jpg\n",
            "876850_jpg.rf.d05ec6da5e4c868ee3d82fc0d4031e4d.jpg\n",
            "877171_jpg.rf.ceee4634566452f064c6f02bdd247d39.jpg\n",
            "87_jpg.rf.c502499790e37b2cf4cc098f3cf87e3c.jpg\n",
            "880050_jpg.rf.ab5f520cf5bd5d43d67d4842e96ec4dd.jpg\n",
            "884374_jpg.rf.e0ca4ab834594b97bbd53eba28985caf.jpg\n",
            "88-E-3118-QP-01-20_jpeg_jpg.rf.49ae4b919e49e93e7843ff2062e9f8c0.jpg\n",
            "894838_jpg.rf.ae0fdc05a39e771823604b7f8028c2b6.jpg\n",
            "89-E-6099-QS-05-20_jpeg_jpg.rf.665361adb0e503ce5b076c0fb3b4a8fc.jpg\n",
            "89_jpg.rf.1160a7d2563b5a07d6a32bfb294073cb.jpg\n",
            "-8A21E83B-626D-4945-8398-04050BFA2010-png_jpg.rf.e67339407d5704fd1442a889aa1d172c.jpg\n",
            "-8A35D79B-CF9E-4E9D-A3F6-5D9479E17444-png_jpg.rf.8c28aad47502261dc5bf166807d7b6c5.jpg\n",
            "-8A71CD00-04FF-4FB4-BBE1-BCAF7F210055-png_jpg.rf.4aa67844d92e4c0e9b8eb5e9aa2fae3e.jpg\n",
            "-8A73A3B1-5D00-4582-92BD-3112C201466F-png_jpg.rf.7463d719594d4b8b1022f10fd7508c5d.jpg\n",
            "-8B0BA866-F0AB-4C53-8A0C-B98DC7B02DAC-png_jpg.rf.36b318eec83ee7c2452ebf89f21e780b.jpg\n",
            "-8B1E1BDB-65DC-4759-BC91-0D887006C34E-png_jpg.rf.d277bfafe3662b05c20e4fd6f5c6ed52.jpg\n",
            "-8B20CA4D-993F-42FB-8964-4E3850A676B7-png_jpg.rf.7a4eb2ace58fb24ae92763b5206f1542.jpg\n",
            "-8B24C687-2969-4359-A7CC-D702785148AE-png_jpg.rf.134b9c1b5996c8721b56c9f81d593ca0.jpg\n",
            "-8C06617D-11DB-4790-9DCF-007BD3D5A65F-png_jpg.rf.1cd47b6eba48171963c3684d88c2cd4b.jpg\n",
            "8e122b9b28dc5f426486-1296x954_jpg.rf.411cb937ac6629edf302979c197af480.jpg\n",
            "8-E-3396-TO-08-22_jpeg_jpg.rf.ca55a9c63f50d247b775e173532f3d0a.jpg\n",
            "8__flip_jpg.rf.61c9e6045e522caea45e040b5f63460a.jpg\n",
            "8_jpg.rf.7a5790432d87d17865d8562cc62be370.jpg\n",
            "9041_1413578135698_jpg.rf.bf3eef8206a3bd85fa9a5512598a689e.jpg\n",
            "907365_jpg.rf.37acf9fa6f45e3f8c2cacbc275ce4025.jpg\n",
            "908898_jpg.rf.5016d1910309d8a5c3bd549e4e4307c9.jpg\n",
            "90-E-5811-RO-10-18_jpeg_jpg.rf.d0bee9183491546f9b99b7854e822627.jpg\n",
            "90_jpg.rf.e13d8ff62d42c848d4b0be7136c92b3b.jpg\n",
            "910715-725x490_jpg.rf.1a6d5202e4c3bae093a50146f8272dac.jpg\n",
            "912422_jpg.rf.a1599ecc63ebc20d42b6b2fbba08ead6.jpg\n",
            "91247a_jpg.rf.1b1d26c0a16797349ee71a7dd3601252.jpg\n",
            "91247a_jpg.rf.b38060ea432e1877f9ded2e27dc39f3b.jpg\n",
            "91247a_jpg.rf.fc4f125e5524268fe51b4f3868b17239.jpg\n",
            "916007_jpg.rf.19ef6557f414b5b49c0016613bade805.jpg\n",
            "92182b_jpg.rf.71bec081ad9faee7eb92be5555a72212.jpg\n",
            "92-E-3912-P-05-21_jpg.rf.17643a56b039de7fe43a36b70774adb6.jpg\n",
            "93-E-5277-PW-09-18_jpg.rf.1e0221a36beb57509a77a42c93667cad.jpg\n",
            "93_jpg.rf.f7517870ca540e1909700bc1c5af62e3.jpg\n",
            "94-E-2118-ST-01-21_jpeg_jpg.rf.46125dd293c67f3c76cc758fe03903df.jpg\n",
            "94_jpg.rf.f265dbbd8867890b50442ec113e4503f.jpg\n",
            "95945044-man-riding-motorcycle-on-the-road-in-hanoi-vietnam-__flip_jpg.rf.8eaec5c6e146edf29f7964c8af32617d.jpg\n",
            "95945044-man-riding-motorcycle-on-the-road-in-hanoi-vietnam-_jpg.rf.75db8b685b04088246af6b648aad3a0d.jpg\n",
            "95945046-woman-riding-motorcycle-on-the-road-in-hanoi-vietnam-_jpg.rf.eb4e9cdd8bf0e96646ddf5d3eb763ec4.jpg\n",
            "95-E-6686-SK-01-20_jpeg_jpg.rf.ea4f0b3a50dde70068548ea775699982.jpg\n",
            "9688017_201706150418340410_png_jpg.rf.5eec0565081d243a3441da81d4223eff.jpg\n",
            "9688017_201706150418340410_png_jpg.rf.9580a0fd5a6d4ffc530e93d0d1bd6aa7.jpg\n",
            "96-E-5942-TM-06-17_jpeg_jpg.rf.5d50abb39a9a3cbb39b0da9510bbe21c.jpg\n",
            "97_jpg.rf.e1db3adf08493745c0dfb38f9d95fd62.jpg\n",
            "982197058_jpg.rf.b5e1b74f26bef993cc29fd1f9e656488.jpg\n",
            "98-E-2521-RQ-04-19_jpg.rf.c2e757c3facbe204096b2e1eafd7988b.jpg\n",
            "99841576-people-riding-motorcycles-on-the-road-at-hanoi-vietnam-__flip_jpg.rf.282d939bddb1550a09c182929c0baaef.jpg\n",
            "999589157_7_jpg.rf.081f3381788c1f5c4c8964b1a1bed612.jpg\n",
            "999589157_7_jpg.rf.2478997350d40bd2819900d000f80e37.jpg\n",
            "999589157_7_jpg.rf.656cbc3465cb2d995511aa64fc0836d8.jpg\n",
            "999589157_7_jpg.rf.de18faf3c4ba472886623116923f0f74.jpg\n",
            "99_jpg.rf.c899295cf111b16c345e25b19fac0365.jpg\n",
            "9-E-2633-RO-11-16_jpg.rf.a15888bd7dd5773325a3308d342354d2.jpg\n",
            "9_jpeg_jpg.rf.883382a9a1e450405702344d922308ca.jpg\n",
            "9_jpg.rf.06ace4961a07f574c9ef4dde97b5de16.jpg\n",
            "A10_png_jpg.rf.5b0ad0fa6ac653229d5406f765986110.jpg\n",
            "A10_png_jpg.rf.78854230f976acf45a24ed73f1a6f97c.jpg\n",
            "A10_png_jpg.rf.8ec0ae63abbfc9869138377fb381bac3.jpg\n",
            "A11_png_jpg.rf.29d4c57cbfe9ae175d6d8eb49cc23194.jpg\n",
            "A11_png_jpg.rf.6460b3a7f1df9db5eca9ceaed24e2920.jpg\n",
            "A11_png_jpg.rf.a7dc71e8254faba874207c59a88a55b2.jpg\n",
            "A11_png_jpg.rf.ea988067bee8402e99983a746bfafa47.jpg\n",
            "A12_png_jpg.rf.5c34dab72e4e0092d6058801380255dd.jpg\n",
            "A12_png_jpg.rf.683b835876c2e0a0a8fd9053b8984d2e.jpg\n",
            "A12_png_jpg.rf.c55bd2dc5755859387c7352d91465b9d.jpg\n",
            "A14_png_jpg.rf.96b8cb960ab1704fa6c0146f7881cbd5.jpg\n",
            "A15_png_jpg.rf.740d0213ce759fdedaf18bdbaf71268b.jpg\n",
            "A17_png_jpg.rf.6b43e30cea3e537af8f350387764c1d0.jpg\n",
            "A17_png_jpg.rf.834e8eaa37e9dfb934c77f41faf04024.jpg\n",
            "A17_png_jpg.rf.e0d55e58a072a88ef7b75cb167a0aa31.jpg\n",
            "A17_png_jpg.rf.e882abfb02abbf2f62ef877cb816d72f.jpg\n",
            "A17_png_jpg.rf.ea00b06095a5cb0cbdb71974377b7132.jpg\n",
            "A17_png_jpg.rf.eacaab0946873e31522d3e77e5139d82.jpg\n",
            "A18_png_jpg.rf.1d399be0480112822420a579bb4221b7.jpg\n",
            "A18_png_jpg.rf.3853458ebb4e18a51a61761edc77e1ab.jpg\n",
            "A18_png_jpg.rf.483115efc7fbe29d3d21243ed60b78cf.jpg\n",
            "A18_png_jpg.rf.7f32f397ade8a63de498227a9db42095.jpg\n",
            "A18_png_jpg.rf.d32e81f9a9c4e75fe809f3fd4cab9b45.jpg\n",
            "A19_png_jpg.rf.cb2605fe096b8ebd7546322ad635af62.jpg\n",
            "A19_png_jpg.rf.d07fabc678d82136e44538b352ca5be3.jpg\n",
            "A19_png_jpg.rf.dbe9d255434bb6a493934be3b33ba1d6.jpg\n",
            "A19_png_jpg.rf.ea35cba966581476a2e918307fc868ba.jpg\n",
            "A1_png_jpg.rf.28846779b56d3efe3e985daf586ba6d3.jpg\n",
            "A20_png_jpg.rf.0d51fc6be0c66d757d9dd20e9b11d11d.jpg\n",
            "A20_png_jpg.rf.23b6079a9bf39663a510932264f80881.jpg\n",
            "A20_png_jpg.rf.326ba5b160e84a6cfc70a88e1aa49b64.jpg\n",
            "A20_png_jpg.rf.4ea8d84c6d6220f075b0659573e4a688.jpg\n",
            "A20_png_jpg.rf.7d2351232796f6fc2f846625eeab3082.jpg\n",
            "A21_png_jpg.rf.79573c27abe2b0823fd1ad017108dc42.jpg\n",
            "A21_png_jpg.rf.aa02d76f6a8a054aa35e9199bf9e7955.jpg\n",
            "A21_png_jpg.rf.c629e35d7591672570866d267d136654.jpg\n",
            "A21_png_jpg.rf.d7bc320ca8987c8a0833b1c97f2c1c27.jpg\n",
            "A21_png_jpg.rf.ddbe06303b8982d473f67f5607a709c9.jpg\n",
            "A22_png_jpg.rf.238819da6da9baeeb5e12330621e5713.jpg\n",
            "A25_png_jpg.rf.007100f2726c2bbbfbc5df9bf502132c.jpg\n",
            "A25_png_jpg.rf.856fe6280c7019d7e9aac084f800a14c.jpg\n",
            "A25_png_jpg.rf.ba89775c2e259ca7823beb88e5adcd3f.jpg\n",
            "A26_png_jpg.rf.4f430d63d4d3119a8f4842f7a2becd60.jpg\n",
            "A26_png_jpg.rf.dc57a71d3a34aa35aa9ee261e26d3c1b.jpg\n",
            "A27_png_jpg.rf.003f30701756811874fd5253825b7d70.jpg\n",
            "A27_png_jpg.rf.4191f2ca15da7a81695369831d54a5ec.jpg\n",
            "A27_png_jpg.rf.6a747326b33ce6c5972f1c403eef8b5f.jpg\n",
            "A28_png_jpg.rf.dbd951f9a630401093f0274d1bc64316.jpg\n",
            "A2_png_jpg.rf.49189777749b27e8b346fda61d530faf.jpg\n",
            "A2_png_jpg.rf.6a44e7168b142e2e4695db33029c9d5b.jpg\n",
            "A2_png_jpg.rf.97eb34b53dc67fbc95642a76fbc73e00.jpg\n",
            "A2_png_jpg.rf.a1db9efc8d7737bb1cbc0c8a1953a6ad.jpg\n",
            "A2_png_jpg.rf.ebf1083fbf0b17eaeebf3233174b2357.jpg\n",
            "A30_png_jpg.rf.2577688ecc4188bf69af78a511e6b69e.jpg\n",
            "A30_png_jpg.rf.cceea794ac9604766892cd92898f6a53.jpg\n",
            "A31_png_jpg.rf.d174c1b8d5f401d3e8b3e684b3febc9e.jpg\n",
            "A32_png_jpg.rf.ef77531aff7ec7b769743523ca6ce7dc.jpg\n",
            "A33_png_jpg.rf.7dfabc445e94b77b6f1d7cde207886e8.jpg\n",
            "A33_png_jpg.rf.bd273e29d88f013c6360fae511f46b26.jpg\n",
            "A33_png_jpg.rf.d6d29605abddca04a3096f505b0829e0.jpg\n",
            "A34_png_jpg.rf.4318b8333f45145651e88e8453b2879d.jpg\n",
            "A34_png_jpg.rf.ca4739b5150ef93d59ed62db4e90688f.jpg\n",
            "A34_png_jpg.rf.d4bd08d8315157674565e177f6674815.jpg\n",
            "A34_png_jpg.rf.ef5edbb653d5d304ea11a3b4252435f7.jpg\n",
            "A35_png_jpg.rf.2af273bc50605a4ff5909daa90ce8212.jpg\n",
            "A35_png_jpg.rf.452e24941262aa1bf8118943562bca19.jpg\n",
            "A35_png_jpg.rf.5256edf2c7fb06dd1a8756eff4e65036.jpg\n",
            "A36_png_jpg.rf.d31b1f366e2e0836a23e1b84116b9134.jpg\n",
            "A37_png_jpg.rf.7545161c445d4bb25d0209ccb90a3dc7.jpg\n",
            "A38_png_jpg.rf.afc8d286c672447e4fc6362274901c52.jpg\n",
            "A38_png_jpg.rf.c94167c0f91497a15ad612d0aa881706.jpg\n",
            "A39_png_jpg.rf.2816e7f6619ca92284a953649cda3b8d.jpg\n",
            "A3_png_jpg.rf.dcebccb1cbb935a38b9faa3a59e3d18c.jpg\n",
            "A4_png_jpg.rf.221303d45a4194d52fb2fdfdf8ee8599.jpg\n",
            "A4_png_jpg.rf.afa7be7e4efbd1e36d3439a71876a35e.jpg\n",
            "A4_png_jpg.rf.c4b14dfa80965b90a8e8033dc80ebb7b.jpg\n",
            "A5_png_jpg.rf.7a5a7bcac04bedbc9e133f3fdb425d5f.jpg\n",
            "A5_png_jpg.rf.f514e84649845fdf58fc4b2a80a9290b.jpg\n",
            "A6_png_jpg.rf.3d591a621d257556a791e765d46565e9.jpg\n",
            "A6_png_jpg.rf.667b0a5a47d2a7112d9ee336b74eaf8f.jpg\n",
            "A6_png_jpg.rf.a1a4d8c16b037c3842a78ef35fb04910.jpg\n",
            "A6_png_jpg.rf.ab580deadcf3bd4e0b52cd9010e888d2.jpg\n",
            "A7_png_jpg.rf.4be476459a2bdae81accee715aee98aa.jpg\n",
            "A7_png_jpg.rf.aa8fa50fe7571e0c548e04f22dea5c82.jpg\n",
            "A7_png_jpg.rf.e1673afe7c2ddce3b32e0d45923741b8.jpg\n",
            "A8_png_jpg.rf.9e853711805fbb5909e13956461d1f8c.jpg\n",
            "A9_png_jpg.rf.2562c2ad0c4744becd40884edf0213b9.jpg\n",
            "A9_png_jpg.rf.6ef32b12ec82d7da7659e8ca80aaf613.jpg\n",
            "A9_png_jpg.rf.7d9aeab4620eb2576b6bd72479a4a43b.jpg\n",
            "AB1140W_jpg.rf.1af46ccf21368c2543f20ae32335fe0f.jpg\n",
            "AB1291WY_jpg.rf.fa677265105c9e59042f362481e7e710.jpg\n",
            "AB1359EV_jpg.rf.d374625f57b16bea176d770539a40f54.jpg\n",
            "AB1801LY_jpg.rf.ba64a9c188c6795a926abaa9c08db3bc.jpg\n",
            "AB5592EG_jpg.rf.5688a0767d09b17b7a078a2cd02b8376.jpg\n",
            "AD1A_jpg.rf.8742e46f06a09d31dd8d6f1e0e5fd683.jpg\n",
            "AD2914JG_jpg.rf.845fe6fa22be8384f7416fd8194ce59b.jpg\n",
            "AD9501GA_jpg.rf.6c71f00b11ad510faecb1779516f91cc.jpg\n",
            "adad_PNG_jpg.rf.abe8ebbe470e358a3228d26f3b44906a.jpg\n",
            "ad-assets-2F21452-NT129720-2Ffield__jpg.rf.86e35941dcba09a51eba350add6a14e0.jpg\n",
            "afas_PNG_jpg.rf.64c96d7bc1368f11f4c4cbfb0a8cb85a.jpg\n",
            "anggota-linmas-dan-pecalang-melaksanakan-penertiban-penggunaan-masker-ppkm-psbb-jawa-bali_jpg.rf.b6cca758b2e56079e97a2c9a2db5662a.jpg\n",
            "_annotations.coco.json\n",
            "article-2598032-1CE7535A00000578-844_634x426__flip_jpg.rf.393a6a6d553091dcba1581bc8da3328c.jpg\n",
            "asdfasw_PNG_jpg.rf.ecc64af4d6b1b26b8bb00cdac30beebb.jpg\n",
            "asd_PNG_jpg.rf.d67fe734d5dcca00987f9dbf331185ce.jpg\n",
            "asdqwe_PNG_jpg.rf.05223eb45e370788f3f865a47f58f838.jpg\n",
            "asfdasd_PNG_jpg.rf.5f69a6d4f6e8564a6d0d394d577b2230.jpg\n",
            "asian-motorbike-crowd-traffic-street-ho-chi-minh-city-vietnam-people-riding-helmets-62946642__flip_jpg.rf.b50451f701264f12a4a7c03ea30ebc74.jpg\n",
            "asian-motorbike-crowd-traffic-street-ho-chi-minh-city-vietnam-people-riding-helmets-62946642_jpg.rf.d7a5ecd98df53bb9d2a25fe8ff4dbd05.jpg\n",
            "asia-vietnam-hanoi-traffic-traffic-jam-traffic-congestion-motorbikes-C8GFWR__flip_jpg.rf.4177de62a60289dd3b8c6cc195b7aaac.jpg\n",
            "awsfasfqw_PNG_jpg.rf.3943b725e9dac8fbd568846db324bfc1.jpg\n",
            "B1015SEA_jpg.rf.0ba7436295658552f26e09d5e8afbbc6.jpg\n",
            "B1040TYQ_jpg.rf.66b499f70a5ff1438a97b217c2a85dc6.jpg\n",
            "B1044SAJ_jpg.rf.cf9e9a1919de69d7572c5e26078ec616.jpg\n",
            "B1050BIZ_jpg.rf.97c687e25ef12d1f24ad712d3b8ffab9.jpg\n",
            "B1063SJV_jpg.rf.a72aa6bb80acc224f8ddf7f7caedbbd6.jpg\n",
            "B1080UYF_jpg.rf.0f12765e4dbfa59882626a50cc7b75e0.jpg\n",
            "B1114TID_jpg.rf.dbcac12b97ece671bd5ad8bb9b86b53c.jpg\n",
            "B1114TIZ_jpg.rf.84df4e56d407e1a8148002894c47cfae.jpg\n",
            "B1125TZM_jpg.rf.d6fa412fed20a867573db59bd58e6ece.jpg\n",
            "B1134UVL_jpg.rf.c9b196257142432ef3bced416e6b4877.jpg\n",
            "B1145ERE-1-_jpg.rf.5aa8f20752d1f33a42970315df0aa0b5.jpg\n",
            "B1145ERE_jpg.rf.220ff13b153b458acca3b2202a8ff9c2.jpg\n",
            "B1163PU_jpg.rf.50ed950f4b283ad2f52fba47107b5952.jpg\n",
            "B1192FJE_jpg.rf.02bf5ccd2fde4dcb65e81883ef09d256.jpg\n",
            "B1204UIU_jpg.rf.56d16753c79d2122137becf501fa8040.jpg\n",
            "B1215WZE_jpg.rf.779874a0068cd6bba2787418d9c80323.jpg\n",
            "B1269VOE_jpg.rf.1596a64daf8f3e02b0ec93d73f4d67ad.jpg\n",
            "B1302ZMC-1-_jpg.rf.29aaa0720b2bec525c4ce4f4014a277c.jpg\n",
            "B1302ZMC_jpg.rf.caf12e7840d654be77ea163d8d6cdc38.jpg\n",
            "B1335UZH_jpg.rf.4e3352812ea247cc44f90a8d2fdf29d1.jpg\n",
            "B1342PIK_jpg.rf.d2b05587c3a6e379ab83001963eba630.jpg\n",
            "B1400EYL_jpg.rf.c4b019c71d672d9eea314cd879939305.jpg\n",
            "B1410BLQ_jpg.rf.307cc387e126787ba0219592d81a1984.jpg\n",
            "B1422RK_jpg.rf.fe6351012b5a16555f54ed420ea4bd48.jpg\n",
            "B1440BJS_jpg.rf.6625bd79f1fb94b8d8d9d90e61dbca9b.jpg\n",
            "B1491BVB_jpg.rf.acf9a667532fb313e3c2b73eadd79ad9.jpg\n",
            "B1512WFL_jpg.rf.6e756c4abe1bcdddf912d7696e454166.jpg\n",
            "B1518GZ-1-_jpg.rf.8f65cebbfb93412fd92a5a65cd7e37a9.jpg\n",
            "B1518GZ_jpg.rf.d621d0fdbc8239a8d7c42cf8787db345.jpg\n",
            "B1523KBL-1-_jpg.rf.1d79aa8b9a4972803f29cab87b0d2143.jpg\n",
            "B1523KBL-2-_jpg.rf.8900e0cc14d9827a8046b31eb928a4bf.jpg\n",
            "B1528SZC_jpg.rf.11a7fdcc593346e49cc366ff2fe7a122.jpg\n",
            "B1579KML_jpg.rf.b9c4a844e3f9d89478c12151517423db.jpg\n",
            "B1595SGR-2-_jpg.rf.0f945274486fb37ce16324850e164c21.jpg\n",
            "B1595SGR_jpg.rf.e8109f5f156fb839143218ef3aa602c2.jpg\n",
            "B1635NOZ_jpg.rf.cd112a827f8ec59cc54afdd80aaae318.jpg\n",
            "B1636BRW_jpg.rf.71b2dd8b39b7d5542f9d485a919aabee.jpg\n",
            "B1665GKC_jpg.rf.bfc99a33a1a07420640620fc588a9bf2.jpg\n",
            "B1669OG_jpg.rf.ca2508cc24f742fd613daeba2f9b6c59.jpg\n",
            "B1700TYZ_jpg.rf.15324ca514ae371273cdba437298a967.jpg\n",
            "B1767NJ_jpg.rf.bf01c822dff6f46a85b53e8142d4f903.jpg\n",
            "B1864PYH_jpg.rf.5939f6e304a4358178e9e1093d2ea0ab.jpg\n",
            "B1864PYH_jpg.rf.d86cf786cd5f161ca9c78f119bb74b36.jpg\n",
            "B1869ERN_jpg.rf.3602cd831c051184a3185a55a273969b.jpg\n",
            "B1870WZP_jpg.rf.c637d2b1c9e3647225c14ef1757315b3.jpg\n",
            "B1879CMA_jpg.rf.15c5e7bec8de4f0ad617be432db7cf0b.jpg\n",
            "B1879CMA_jpg.rf.9feb7f8eafbde5a337cc3079b2de1395.jpg\n",
            "B1896WOP_jpg.rf.67ff64b35717efa61810b668eca32bd2.jpg\n",
            "B1925BOF-1-_jpg.rf.bb922a87b49b8e75b913587fcc236c96.jpg\n",
            "B1925BOF_jpg.rf.1a86bda07c8dbf806cbc627185f520c9.jpg\n",
            "B1973CFZ_jpg.rf.0418c03997f30721c3a9b080c3847316.jpg\n",
            "B1989KIB_jpg.rf.1e7cd6a6569f8d2d2a0a5f61230f1857.jpg\n",
            "B2113SOY_jpg.rf.48bbd6a58d213fd23009de4a44bd36d0.jpg\n",
            "B2127BKW-1-_jpg.rf.ebed18caa498c2ec2b4ffa46b9ef665a.jpg\n",
            "B2130BOH_jpg.rf.462aeb4ec8b4497adc8e766c2f1b17a2.jpg\n",
            "B2130BOH_jpg.rf.cd61e788f67561d578f7976855421502.jpg\n",
            "B234LOG_jpg.rf.6b2a14dcf10946632becd5579bdbfc3f.jpg\n",
            "B2573SOG_jpg.rf.4ec91990b9f49af7f68f7d2b7631dad6.jpg\n",
            "B2594TYM_jpg.rf.8cf505d7251e84766bc1c4b91ad319f6.jpg\n",
            "B2652SRY_jpg.rf.2ec314a5b3eb8eadf69ae3563260379d.jpg\n",
            "B3023KEZ_jpg.rf.544996420fb0084ea3687e2ee5590916.jpg\n",
            "B7124HG-1-_jpg.rf.ed4a71141aa2e302db4f8f99245a568b.jpg\n",
            "B777DEF_jpg.rf.be8e67b6f77ffe012de463a7aaccfb53.jpg\n",
            "B868DSY_jpg.rf.e518ee836c49fef1d88193c56f43ee3e.jpg\n",
            "B9080SRO_jpg.rf.8de910fb71a3bdecca1f3ad4a417750f.jpg\n",
            "B9507NCG_jpg.rf.4340b942c2c7bef811493469bdab269f.jpg\n",
            "-ba56080033_jpg.rf.430252814628840b8a32d9991975cfb4.jpg\n",
            "Bc9FWNbIQAAldsS_jpg.rf.e4791382f0478536e7cb7b1d212e7ea9.jpg\n",
            "BG1733RP_jpg.rf.0eb01a0a2a19044609d1af6651a42142.jpg\n",
            "BL1439JD-1-_jpg.rf.5cea1d12a4e10d182a514d8f4564bc6e.jpg\n",
            "BM1762VP_jpg.rf.e8270d30ee0e4df307042417980d17c4.jpg\n",
            "Bus-100-_jpg.rf.730fa8f1061e41e7ef68c6a6151ec242.jpg\n",
            "Bus-101-_jpg.rf.8e6434afa146c35b8da35882b20b3b68.jpg\n",
            "Bus-102-_jpg.rf.6e6ccc9dd02fa3a2854fb6ba45ea1553.jpg\n",
            "Bus-103-_jpg.rf.a383f008b3cfa21ec67081c6fcb05860.jpg\n",
            "Bus-104-_jpg.rf.548b966a0999fc83445a90ea34b439ca.jpg\n",
            "Bus-105-_jpg.rf.2d0d755d2522992f872e013dc4ee2d70.jpg\n",
            "Bus-106-_jpg.rf.9b738de34b5f5d44f16db041d5f62535.jpg\n",
            "Bus-109-_jpg.rf.df2c38fc35e6b644b805cb1add951454.jpg\n",
            "Bus-10-_jpg.rf.78edce04b324ed765b7805c4d1c4fe50.jpg\n",
            "Bus-110-_jpg.rf.bff0b0531978c1ebbbaa2c6d598b6fec.jpg\n",
            "Bus-111-_jpg.rf.a73141964b673c9300a11212aa9680b8.jpg\n",
            "Bus-113-_jpg.rf.657962c3ba08a722df33e7b52b63700f.jpg\n",
            "Bus-115-_jpg.rf.189e92bda09ed458b05f5b9e769f60bb.jpg\n",
            "Bus-116-_jpg.rf.d2be0dd7a79d5e66e94f39674122d973.jpg\n",
            "Bus-117-_jpg.rf.f3ba8676716161984ea0061b86ab5bf4.jpg\n",
            "Bus-11-_jpg.rf.d24b244d540a779997e1cc01b3494bbe.jpg\n",
            "Bus-121-_jpg.rf.36c2c02af30f5504caddb179d03c889a.jpg\n",
            "Bus-122-_jpg.rf.0605ca93f14fd56a80806a7c0e4cc43c.jpg\n",
            "Bus-124-_jpg.rf.473c87af003cead6e79e54b1a06aa9e5.jpg\n",
            "Bus-126-_jpg.rf.9064ccc8e8ef1b8fd02f56df61ba0a77.jpg\n",
            "Bus-127-_jpg.rf.50e300fa9d5d38c19fb0e4fc0c30686f.jpg\n",
            "Bus-128-_jpg.rf.9573ee35c777fdf0e32dbf051b85561f.jpg\n",
            "Bus-12-_jpg.rf.0e46f1dcd31d17eb18a484a446f2b58e.jpg\n",
            "Bus-131-_jpg.rf.c59247f179b363568436dee93bf62152.jpg\n",
            "Bus-133-_jpg.rf.b7b76cc445d6bfaabc81a08e7130d915.jpg\n",
            "Bus-134-_jpg.rf.7e744204886032091b24f004accf8257.jpg\n",
            "Bus-135-_jpg.rf.111bb5ca3694cbc148813cb20f7b54e3.jpg\n",
            "Bus-136-_jpg.rf.42b945dd62dad0fc09cdda56e29471c2.jpg\n",
            "Bus-138-_jpg.rf.fd3a79f48868fbbe0078b75fd6bc5cf1.jpg\n",
            "Bus-139-_jpg.rf.51797607e069622f3d6398eac1dba8e7.jpg\n",
            "Bus-141-_jpg.rf.850e87fd8e7b985871c7862329fe761f.jpg\n",
            "Bus-142-_jpg.rf.a4e466713be0c48d8a40dbaeb9433be5.jpg\n",
            "Bus-143-_jpg.rf.27e75b46c5f9f3225acdd7e49e2fe6ad.jpg\n",
            "Bus-145-_jpg.rf.a2d8c7aeee9e5f58c0cc4ffec0345dba.jpg\n",
            "Bus-146-_jpg.rf.fdbdb4d40040343e8bc53efd636cb4b3.jpg\n",
            "Bus-148-_jpg.rf.d77d3fa5e6d93fede5cea9d54c718ad0.jpg\n",
            "Bus-149-_jpg.rf.c9812aacf398480eed72e64b7fc7c944.jpg\n",
            "Bus-14-_jpg.rf.a63f8f88113858964c4d86cd9ff88e60.jpg\n",
            "Bus-150-_jpg.rf.547f24675f7655b1a30067e7a5550f75.jpg\n",
            "Bus-151-_jpg.rf.10bd63fd2c7627bfe1d570b29d544a83.jpg\n",
            "Bus-155-_jpg.rf.4bebfa4e3bfa3d4fb2d7f590d499193e.jpg\n",
            "Bus-156-_jpg.rf.e405312c1bd595963c342660e2941423.jpg\n",
            "Bus-159-_jpg.rf.90509a688455d7bad42cc975250f261d.jpg\n",
            "Bus-15-_jpg.rf.a1ce513998929e33e711dfa3f80e4e42.jpg\n",
            "Bus-160-_jpg.rf.6ae8d53c468a3d58eee000f9436582f1.jpg\n",
            "Bus-161-_jpg.rf.f8eee131b868be3432cc5963a68b4a83.jpg\n",
            "Bus-163-_jpg.rf.444212f11f0f7318d3e4295afbb3921d.jpg\n",
            "Bus-165-_jpg.rf.b045b73184232822863b332baebdea54.jpg\n",
            "Bus-166-_jpg.rf.725337cc1137c448a698510207be2c40.jpg\n",
            "Bus-168-_jpg.rf.e19efe99f2195e8cf8f655ea237d2a21.jpg\n",
            "Bus-169-_jpg.rf.3e8af120008a855e71ec0d0d76e80f56.jpg\n",
            "Bus-16-_jpg.rf.96432c1f2c01c23ee324e492c0f275ab.jpg\n",
            "Bus-170-_jpg.rf.5d4d3b31729eaaab44d11475994cf918.jpg\n",
            "Bus-171-_jpg.rf.ada0fe54e3abda70f40bce8ad2dcb7ea.jpg\n",
            "Bus-172-_jpg.rf.04e247cf0e30a35ecf6776ee08896e22.jpg\n",
            "Bus-173-_jpg.rf.b56d9f3994ee7f7daa40937b596f9e02.jpg\n",
            "Bus-174-_jpg.rf.5f314717f453bfae7c8d9befe335572c.jpg\n",
            "Bus-176-_jpg.rf.e4051097b3151841103727883ff9e5fa.jpg\n",
            "Bus-177-_jpg.rf.77dc429a88c9baf41b351c03932094cf.jpg\n",
            "Bus-178-_jpg.rf.1d608b59dc190d4ce7fd246d76d4bf31.jpg\n",
            "Bus-179-_jpg.rf.0da59790a70c132b1facee48ccfc0e1b.jpg\n",
            "Bus-180-_jpg.rf.347baef9770776e7fd26b8cfa064cf7a.jpg\n",
            "Bus-181-_jpg.rf.3987c63a10f473e45383cf3d70a30a46.jpg\n",
            "Bus-182-_jpg.rf.7578ea8c9281abee646df2353eb412f4.jpg\n",
            "Bus-184-_jpg.rf.ad12a64f70fa5a48fa5af3bde7077236.jpg\n",
            "Bus-185-_jpg.rf.5336f8d8aee76ee00df304eda0b6fde8.jpg\n",
            "Bus-187-_jpg.rf.9a96f30247aec8d921e71e08c6ac4716.jpg\n",
            "Bus-188-_jpg.rf.26777ba096b09316334ce9aa4334663f.jpg\n",
            "Bus-189-_jpg.rf.08b6582d7bf645dc3da958e544767bb8.jpg\n",
            "Bus-18-_jpg.rf.69920a8a81423be9366c6a6090a1c65d.jpg\n",
            "Bus-190-_jpg.rf.bdf3df1f068a3e622b89c34a8dde7c39.jpg\n",
            "Bus-194-_jpg.rf.6d9a8a44670cef693f002ba25a1da431.jpg\n",
            "Bus-195-_jpg.rf.881cbf5cac5eb46e8e9f3eb57a67eac6.jpg\n",
            "Bus-197-_jpg.rf.c2afbc54412941cb58d22185e5626bba.jpg\n",
            "Bus-198-_jpg.rf.7a6f5909a539d784c92f23ce0f531ee3.jpg\n",
            "Bus-19-_jpg.rf.300fa23d110a89ffe55f3b50fdfd6ce8.jpg\n",
            "Bus-200-_jpg.rf.d1920ea28a557a7425b2bb225315df20.jpg\n",
            "Bus-201-_jpg.rf.534d1b76bf58cb4edb30bd98a3357143.jpg\n",
            "Bus-202-_jpg.rf.5cd788ace26dfd824b44de787b0b7433.jpg\n",
            "Bus-203-_jpg.rf.80987226f4d55eb111caec6838c39095.jpg\n",
            "Bus-204-_jpg.rf.29912c5c43c2a4b992de12fe12212c6a.jpg\n",
            "Bus-205-_jpg.rf.91b289a33ac697442240d210600b2425.jpg\n",
            "Bus-206-_jpg.rf.59c575a0aceccd89280b8d44c50b65dd.jpg\n",
            "Bus-208-_jpg.rf.e2be7fe7086f5856f43a2ae65ede4317.jpg\n",
            "Bus-209-_jpg.rf.45bcf0709de7043b92dd56b32b3dfe92.jpg\n",
            "Bus-20-_jpg.rf.e241399b14ed9791b8b1adf051e6daa9.jpg\n",
            "Bus-210-_jpg.rf.f61f21c357f4a962611fa7d611ca4960.jpg\n",
            "Bus-211-_jpg.rf.96f9f6a262b48fd85dfd89f931c19c50.jpg\n",
            "Bus-212-_jpg.rf.5b1a27e12fd28ec2f325b99eac649b3c.jpg\n",
            "Bus-213-_jpg.rf.4a7b8cbf2edc9a5fc6cdad2509bdd3b5.jpg\n",
            "Bus-214-_jpg.rf.9fe081d68d94d0269a2b3ce167571e41.jpg\n",
            "Bus-215-_jpg.rf.26df08941eceff90753713389f4dba3b.jpg\n",
            "Bus-218-_jpg.rf.3a43baac6815d5a965ed0c63cd848a43.jpg\n",
            "Bus-219-_jpg.rf.badf36f730895e6da4f7bf5a150d8001.jpg\n",
            "Bus-220-_jpg.rf.10bd67497c288921369c4683b6417226.jpg\n",
            "Bus-221-_jpg.rf.4e4420a149ef7e3c22fbf9da990cbf5a.jpg\n",
            "Bus-222-_jpg.rf.60c0fc289a816fbd66b070bf07b21576.jpg\n",
            "Bus-223-_jpg.rf.1a73aac2b1c9fce538a23879b909a61d.jpg\n",
            "Bus-224-_jpg.rf.230dd1a4c21c9dc1ddbba1ab14d68a9b.jpg\n",
            "Bus-226-_jpg.rf.91e919794810185e7c982989d36baa73.jpg\n",
            "Bus-227-_jpg.rf.db2fcae2ff1799d78ec79af85fce667e.jpg\n",
            "Bus-228-_jpg.rf.f548ef84a2645c99da021d963564562d.jpg\n",
            "Bus-229-_jpg.rf.8dc58f84019a54fc5fec4768b610d7ea.jpg\n",
            "Bus-22-_jpg.rf.d045223a60720dd17c1938b9b3e00cb7.jpg\n",
            "Bus-230-_jpg.rf.3768ea5d1693a698085082f5056cc42b.jpg\n",
            "Bus-232-_jpg.rf.909d30d999bb0e6064e80c8724f02fe7.jpg\n",
            "Bus-233-_jpg.rf.0b6a656304b9a61b8e267d126713d3ed.jpg\n",
            "Bus-234-_jpg.rf.60f11c53dcb8044df718b01cfc36625d.jpg\n",
            "Bus-236-_jpg.rf.535db95b553a3a94d414c69969980486.jpg\n",
            "Bus-237-_jpg.rf.f6f392e523104ff08d24e7e87ab18b0c.jpg\n",
            "Bus-238-_jpg.rf.c19dd7d31467e00577971f6648876d9a.jpg\n",
            "Bus-23-_jpg.rf.7634ce5e52d333cb8a463f4761619ab4.jpg\n",
            "Bus-240-_jpg.rf.5f576d0be0e591ee25cdfc51e425499a.jpg\n",
            "Bus-241-_jpg.rf.0468687b879fd4d41688cec5c3efcbd9.jpg\n",
            "Bus-242-_jpg.rf.cb5ea2708deb6768f18aa336d53eb9fd.jpg\n",
            "Bus-243-_jpg.rf.f35586fa5f2f68d8b0dae9eadd3ff5eb.jpg\n",
            "Bus-24-_jpg.rf.1c7599068574fe592a62be4ffabda25d.jpg\n",
            "Bus-250-_jpg.rf.92ebaf47f0a48697cb43a69b9d625f8e.jpg\n",
            "Bus-252-_jpg.rf.f30e9b6ecf5db78ed642af4df8a5cbdf.jpg\n",
            "Bus-258-_jpg.rf.7d25d0ce9fe35dc6f8523f6793e8f341.jpg\n",
            "Bus-25-_jpg.rf.07747a5f262133270afb2fba36c7b33a.jpg\n",
            "Bus-260-_jpg.rf.ef2d294af6a1f074d9dbe44426406c94.jpg\n",
            "Bus-261-_jpg.rf.c237522080b699d75bbf92f18f068fcb.jpg\n",
            "Bus-262-_jpg.rf.e48a5bc08108b81630003cccb3731357.jpg\n",
            "Bus-263-_jpg.rf.89cb218139ba5bc176135e98ed8ea8e9.jpg\n",
            "Bus-264-_jpg.rf.d489fd4970a8ef645021801462086a93.jpg\n",
            "Bus-265-_jpg.rf.87147d14894cfd0d1d9e5f1c7e644115.jpg\n",
            "Bus-266-_jpg.rf.20d433542c1c29021320aed6174a9945.jpg\n",
            "Bus-267-_jpg.rf.59c9481cd9e4c6c58f8a178a227499f3.jpg\n",
            "Bus-268-_jpg.rf.a6857f99e47af07f09897db8caf825d7.jpg\n",
            "Bus-26-_jpg.rf.f80673a30d64a82bdee86343a91dc9c1.jpg\n",
            "Bus-270-_jpg.rf.55d086f81e00028c21a4e4f4ebd9e8a8.jpg\n",
            "Bus-271-_jpg.rf.b27b8cb6a9f3d82828c3da025fd86797.jpg\n",
            "Bus-272-_jpg.rf.9b019f80c96f8237c95263a1f075bd15.jpg\n",
            "Bus-273-_jpg.rf.e33d26facda919824582fa7419bbb47b.jpg\n",
            "Bus-274-_jpg.rf.8c781e517481ab41698d1614fada8e1b.jpg\n",
            "Bus-275-_jpg.rf.036b2302cb0a33cec5314bddcfa5873e.jpg\n",
            "Bus-277-_jpg.rf.aed770e946e1c40e16a2039773c7f575.jpg\n",
            "Bus-278-_jpg.rf.5748eb9fff6d8ae1d7995b7bae3a5670.jpg\n",
            "Bus-279-_jpg.rf.1ac726f17c427c8ee2921025d5e28099.jpg\n",
            "Bus-280-_jpg.rf.f1b558aa9c22ee20b5579a22eadaa3df.jpg\n",
            "Bus-281-_jpg.rf.f45826b83defde3d9a59af538f01d9ac.jpg\n",
            "Bus-283-_jpg.rf.ce85df07dec80fb2a1ffbf5a38917796.jpg\n",
            "Bus-284-_jpg.rf.06786f1b8317d849d166671e414c9c71.jpg\n",
            "Bus-286-_jpg.rf.d95691d641009b3e96432d33c3d76518.jpg\n",
            "Bus-287-_jpg.rf.83853dddd9fdf3ca0cd84a55300b1b40.jpg\n",
            "Bus-288-_jpg.rf.34db7f16b47c3b0666eab352f9f206a1.jpg\n",
            "Bus-28-_jpg.rf.2a88d29cbd1fef81f6502260c41add31.jpg\n",
            "Bus-290-_jpg.rf.c3bc82f398b51d52109ae0018b8ff6db.jpg\n",
            "Bus-291-_jpg.rf.9ca350a192494884f61bf9befee7aebe.jpg\n",
            "Bus-292-_jpg.rf.c849b915ee4aca6ac56c59002c5ce7c0.jpg\n",
            "Bus-293-_jpg.rf.890b2353259d64cb89cabdd2841abe2c.jpg\n",
            "Bus-294-_jpg.rf.f5a6976f9b367c8ea2262c2f71b9bb47.jpg\n",
            "Bus-295-_jpg.rf.9b094d5c7287861322bb80319877607b.jpg\n",
            "Bus-298-_jpg.rf.31d1cc3b55b879c2bc8d320c2e8b3613.jpg\n",
            "Bus-299-_jpg.rf.a18551210f7de5aeacebd2d0aa4d493c.jpg\n",
            "Bus-29-_jpg.rf.15307ae8cb27314cfb9d183382004d41.jpg\n",
            "Bus-301-_jpg.rf.e00c6eef0c4cebba98b61c19c5a29701.jpg\n",
            "Bus-302-_jpg.rf.ae7237739d53f199e7fc05b6fb49f2bd.jpg\n",
            "Bus-303-_jpg.rf.c642f286e66e4b67e86197beb90d3a12.jpg\n",
            "Bus-306-_jpg.rf.070273085e767dce6dd50cae1a8cc42b.jpg\n",
            "Bus-307-_jpg.rf.86491c4cb55ffb211a3fca55fb3ef1e2.jpg\n",
            "Bus-30-_jpg.rf.1103fc2fb717e2934e4f8c6b6f4904b4.jpg\n",
            "Bus-317-_jpg.rf.a7452249702772e5d78f827e17634953.jpg\n",
            "Bus-318-_jpg.rf.57f83d6a01b8776cd9a653cf22e7c068.jpg\n",
            "Bus-319-_jpg.rf.b3c7eb21863f5e4437aeaf6478c03d4c.jpg\n",
            "Bus-31-_jpg.rf.efc1679d47ae97d839ef89b28c029f8d.jpg\n",
            "Bus-321-_jpg.rf.27d6c6d19916f92ef1605f1cf3b0dcc9.jpg\n",
            "Bus-322-_jpg.rf.af7e3cdbcbd6543e6dd128dc6bfffde2.jpg\n",
            "Bus-324-_jpg.rf.3d80fe4e13cbec5bcc85013e48e84b6c.jpg\n",
            "Bus-325-_jpg.rf.be46e16fbf0b3bb9aa55f08d1c61cc22.jpg\n",
            "Bus-326-_jpg.rf.2ec91b597ae7716fcba5b0a3a15ae81c.jpg\n",
            "Bus-331-_jpg.rf.1127cfa8710b6925affd72d16cbaa9eb.jpg\n",
            "Bus-337-_jpg.rf.17db8c738d7b4385eac613407f3abdf7.jpg\n",
            "Bus-338-_jpg.rf.c5fe842d692b5309882cfba649715f06.jpg\n",
            "Bus-339-_jpg.rf.5f875a6edb4aebdc0b9439542145678a.jpg\n",
            "Bus-343-_jpg.rf.b8953db667ce808851df3a35ea87ebee.jpg\n",
            "Bus-344-_jpg.rf.1d8b78b902218bd825aa7d4d3f3dd67d.jpg\n",
            "Bus-346-_jpg.rf.bc6a9ab112169ec1483e36e28d63b653.jpg\n",
            "Bus-348-_jpg.rf.284931fae38b1903b6ddd65379d46cab.jpg\n",
            "Bus-350-_jpg.rf.6601ffe38f18e9222cb3370b8eb51aab.jpg\n",
            "Bus-351-_jpg.rf.9a751f975772f809346074738c6431c9.jpg\n",
            "Bus-352-_jpg.rf.b3a8a06fa09eb6b663a155a56e131edd.jpg\n",
            "Bus-353-_jpg.rf.1f9aeb769dbab71f3a5b5868b27723eb.jpg\n",
            "Bus-355-_jpg.rf.8e3330a3a0c4aeda5851dfd3946e3678.jpg\n",
            "Bus-356-_jpg.rf.92138af221760fe34c5c3cb4a325fdec.jpg\n",
            "Bus-357-_jpg.rf.d5430c7052a8939b87a0b9d94843d8d8.jpg\n",
            "Bus-358-_jpg.rf.55eb8d6c4df4bd39255994949cf79ad0.jpg\n",
            "Bus-359-_jpg.rf.6f2624c0190e21476006f7c1a6d35fac.jpg\n",
            "Bus-35-_jpg.rf.19224f764450e735bacaed0416cc3346.jpg\n",
            "Bus-360-_jpg.rf.7f164be67200eb08aaa698ed07c2b103.jpg\n",
            "Bus-361-_jpg.rf.117dc14a242cc0dcd1734e6f2f62ffe4.jpg\n",
            "Bus-363-_jpg.rf.2a3709560a0a02e8ec46c4a062384349.jpg\n",
            "Bus-367-_jpg.rf.d8fea7a3642685effa4f7250f1848e42.jpg\n",
            "Bus-368-_jpg.rf.37286c5dfcb8df013b54bf34cef54223.jpg\n",
            "Bus-36-_jpg.rf.43ac3230a43f308c0496f8f4391192a9.jpg\n",
            "Bus-371-_jpg.rf.289c2e070a09b785e2afdf0b6ca00133.jpg\n",
            "Bus-373-_jpg.rf.3a04fc350d91e8ecfae5974d78aef476.jpg\n",
            "Bus-374-_jpg.rf.f8600de6e51b14de970519762f51afae.jpg\n",
            "Bus-376-_jpg.rf.df04db6ebea152e59e38da524a570cf7.jpg\n",
            "Bus-378-_jpg.rf.3d42a27045cbd6d7a9e6a906f0cfd64e.jpg\n",
            "Bus-37-_jpg.rf.f15453a050e1a4d93128e29e47ff79d4.jpg\n",
            "Bus-380-_jpg.rf.d80883810a094a3303978beede7ebb25.jpg\n",
            "Bus-382-_jpg.rf.90242bf659fbd89c55b95d5c5011e825.jpg\n",
            "Bus-383-_jpg.rf.16fcfbd71ae8a72b53e58ada1ad5b167.jpg\n",
            "Bus-385-_jpg.rf.0b595494a5ea76c9164e1dd87f88ea2e.jpg\n",
            "Bus-387-_jpg.rf.18bfc566f5677f2ddf78b3a9f5687092.jpg\n",
            "Bus-388-_jpg.rf.39fbfe225237eef6de4402f056ce79a3.jpg\n",
            "Bus-389-_jpg.rf.0cf55244362c560726182ae408a18632.jpg\n",
            "Bus-38-_jpg.rf.3f4cedf3ec96e20795573261bbb98115.jpg\n",
            "Bus-390-_jpg.rf.62408e08214b557c2eea91bf6b2c3a06.jpg\n",
            "Bus-393-_jpg.rf.bf5c2c1fd08562025e06888bbba077c6.jpg\n",
            "Bus-395-_jpg.rf.18cf9ae2190fe09804937c56883338a4.jpg\n",
            "Bus-3-_jpg.rf.a33671886a55e830f38606cfc043134f.jpg\n",
            "Bus-40-_jpg.rf.48616d0b69dfc48117ac9c153c1a6fb4.jpg\n",
            "Bus-42-_jpg.rf.664b72ec17c4ebe14b624c439ff3fe53.jpg\n",
            "Bus-43-_jpg.rf.1f36657e9f672888c3fd7243be594434.jpg\n",
            "Bus-44-_jpg.rf.eae11bcf92a7f980587243087ed9cf5c.jpg\n",
            "Bus-45-_jpg.rf.b3b6c5d094a34a06110d85e9a01ac335.jpg\n",
            "Bus-47-_jpg.rf.e4cbbb6a78b3098474e454f31da6d06e.jpg\n",
            "Bus-4-_jpg.rf.d8c730c87e84be4a93c6e6d0030cda23.jpg\n",
            "Bus-50-_jpg.rf.9545e1b387066e7113a258a825f33e2d.jpg\n",
            "Bus-52-_jpg.rf.4a6f8c205af0bca59932a634a2f3dea5.jpg\n",
            "Bus-53-_jpg.rf.993bb0188d76c369efe5256d6a1ae309.jpg\n",
            "Bus-54-_jpg.rf.e2c6671adee99ee56839ce3920f27f39.jpg\n",
            "Bus-55-_jpg.rf.9f4e85c43aac3dba355d99d4a7452a83.jpg\n",
            "Bus-56-_jpg.rf.68ce6a1968f0404fdb690ac552ba2d81.jpg\n",
            "Bus-57-_jpg.rf.48031d14d3f2abb5fc60cdad855a3b88.jpg\n",
            "Bus-58-_jpg.rf.be7347c41d1114ac1deb7f1c91e81597.jpg\n",
            "Bus-59-_jpg.rf.661fd2a985d0720463d387fc297712a3.jpg\n",
            "Bus-5-_jpg.rf.5c76ffdb7483c56596d3653324cf6040.jpg\n",
            "Bus-62-_jpg.rf.67776d8d44205b31eca0cd075608dd2e.jpg\n",
            "Bus-64-_jpg.rf.09fde61a0a46f2a68d967bab03773a34.jpg\n",
            "Bus-67-_jpg.rf.dcfce2ad3d6c3e332c0177135bc4ae0a.jpg\n",
            "Bus-68-_jpg.rf.75abe48ecbb8e30dc07558c21c30c4b7.jpg\n",
            "Bus-69-_jpg.rf.2ae27f4906e30a40c055cbf33175457b.jpg\n",
            "Bus-6-_jpg.rf.3701b19d7bc8a8a4b5bb161259eda70c.jpg\n",
            "Bus-70-_jpg.rf.4d0ecf52e5837b7f736f883d61f1c589.jpg\n",
            "Bus-71-_jpg.rf.2172a4d976bca9bb9f84d44cdca17564.jpg\n",
            "Bus-73-_jpg.rf.066296fbd30c2a9a0900af1098d7dd41.jpg\n",
            "Bus-74-_jpg.rf.ce1bf7588289785bcaccf6c31fd16db6.jpg\n",
            "Bus-76-_jpg.rf.d1fc9cba6031aec3161eada37a8e9c6c.jpg\n",
            "Bus-77-_jpg.rf.cc2cd39555819ab48a41450a118d50b5.jpg\n",
            "Bus-78-_jpg.rf.e78728725a9c5507c76cd2acfa078126.jpg\n",
            "Bus-79-_jpg.rf.6fadb0f92ac25a4957bbf81a2d661f3d.jpg\n",
            "Bus-7-_jpg.rf.7f094b25167cff020cd916716615fa3a.jpg\n",
            "Bus-80-_jpg.rf.3ed843b8c73625a7cd78667be881efd4.jpg\n",
            "Bus-81-_jpg.rf.d1bb22bf6105a2a202c9a7e8d425df70.jpg\n",
            "Bus-83-_jpg.rf.68e901fcc5483b3c0254e5323b3c87b4.jpg\n",
            "Bus-85-_jpg.rf.dcaa5fa7f9c54c31ad28633fa4a85bc6.jpg\n",
            "Bus-86-_jpg.rf.85185571cfaae43860667672437796d4.jpg\n",
            "Bus-88-_jpg.rf.8da141051548f583a8f07208c6b337a0.jpg\n",
            "Bus-89-_jpg.rf.9ef54f097889b84a286c4c188b5b4f5b.jpg\n",
            "Bus-90-_jpg.rf.951540af2ad6f1ae7a546afafa915e4c.jpg\n",
            "Bus-91-_jpg.rf.b734448da9deac94029de1986a216049.jpg\n",
            "Bus-92-_jpg.rf.b6060202600363f453152dbf4f234703.jpg\n",
            "Bus-93-_jpg.rf.348c2fab5f50412f4103282472b68c3a.jpg\n",
            "Bus-95-_jpg.rf.7df84b3f51bd690b9c1e9cb802cf9528.jpg\n",
            "Bus-97-_jpg.rf.a18763f06b037d3e096ff931a9c7321c.jpg\n",
            "Bus-98-_jpg.rf.6b7a09eb8cce8e259e107eb8d000fe19.jpg\n",
            "Bus-99-_jpg.rf.8854c8aeef380ef394e27f6e0e38db6d.jpg\n",
            "Bus-9-_jpg.rf.e0d427a3820ef950f7f788cbe02266d9.jpg\n",
            "-C04C7AD3-AEAC-4250-9856-9D1606800D44-png_jpg.rf.aa78944439d8dbc0765dd4308ad17b68.jpg\n",
            "Cars414_png_jpg.rf.0cc1a8004c82a6aa5a71e44ed1a456c3.jpg\n",
            "Cars417_png_jpg.rf.ea394f282a8807a9ca8f7f6717108c20.jpg\n",
            "Cars420_png_jpg.rf.bd275eb4f413c890409b2f0dbf7d448a.jpg\n",
            "Cars423_png_jpg.rf.9d79417bf563e38e5f0d427be07c6544.jpg\n",
            "Cars425_png_jpg.rf.ebd697e0f12d74cc0e7b962a9d7d007e.jpg\n",
            "cek-pemilik-plat-nomor-kendaraan-online-dari-hp_jpg.rf.45e4fe17879ee7de073803a2ac38a2c9.jpg\n",
            "-CFB928D0-84D7-4021-B542-4F3E73E475AE-png_jpg.rf.3748e85dfe49f0269454e2db956df9c5.jpg\n",
            "Chris-20Truck-20_jpg.rf.2f092fc7fcc60e1ec1ca778b099ac61f.jpg\n",
            "couple-goal-riding-biker-magazine-riding-the-motorcycle__flip_jpg.rf.7bc01ec2e35c911897fb18e650088a12.jpg\n",
            "couple-goal-riding-biker-magazine-riding-the-motorcycle_jpg.rf.a64450edb2192d0fc536dfb4f766c709.jpg\n",
            "Cutting-Sticker-Truck-Canter-Kuning-1_jpg.rf.4ed3f77e4769866a71febf6ba7aa22d9.jpg\n",
            "D1129_17_316_1200__flip_jpg.rf.97118bd12a461bd817c1f980227bba59.jpg\n",
            "D1129_17_316_1200_jpg.rf.165df740f22f5cd42eb296b487a8c59d.jpg\n",
            "D1139WM_jpg.rf.e56031edbd6f7445b66b537b2b9b3d4e.jpg\n",
            "D943_259_758_1200__flip_jpg.rf.28fff1c9fa1e0e8c42c3e1ade31a1091.jpg\n",
            "dasdqwfqw_PNG_jpg.rf.873c1c7abcf7cd03b7074ffee6044cdf.jpg\n",
            "depositphotos_121501430-stock-photo-mature-couple-sitting-on-scooter_jpg.rf.2f46660f8eff88f317cd1356fb9948be.jpg\n",
            "DK27EW_jpg.rf.e046fd9d3db12b05a51a857b1e508f2d.jpg\n",
            "DSC01700_JPG_jpg.rf.5de431a64c283fae3943fd483c05ec12.jpg\n",
            "DSC01700_JPG_jpg.rf.6eb3ac3c6957322a2790cdce6f23ce92.jpg\n",
            "DSC01701_JPG_jpg.rf.96a27a335110c36e96d052ffb1675404.jpg\n",
            "DSC01702_JPG_jpg.rf.6fbabe81b0a439e85f5e3b459fda92fb.jpg\n",
            "DSC01703_JPG_jpg.rf.a3656c49ec06941675cfc1cc48c6893b.jpg\n",
            "DSC01705_JPG_jpg.rf.a2587067e34f9a841227c51267645f1a.jpg\n",
            "DSC01710_JPG_jpg.rf.cba29fe8a76946412c88f314574e6422.jpg\n",
            "DSC01710_JPG_jpg.rf.fe17f62ec172921d1e260da0476fafb9.jpg\n",
            "DSC01711_JPG_jpg.rf.31d79981bfc5196cd6d9cd8007ac172a.jpg\n",
            "DSC01714_JPG_jpg.rf.c9c864968e814a0adbd5cd21fab52fa9.jpg\n",
            "DSC01717_JPG_jpg.rf.5f849c3078fa7f10d913314ea3d3225f.jpg\n",
            "DSC01717_JPG_jpg.rf.d362e1228417fd72b90f04433e61750d.jpg\n",
            "DSC01720_JPG_jpg.rf.3bd7892261dd6f6ae8b63284a601c9b8.jpg\n",
            "DSC01721_JPG_jpg.rf.432eaddda1166530f936cd696c39d9cf.jpg\n",
            "DSC01723_JPG_jpg.rf.8c1701b240f21a96abee60e6d13b486e.jpg\n",
            "DSC01728_JPG_jpg.rf.6c8d1d670cedcd399dbabb387f393b5b.jpg\n",
            "DSC01736_JPG_jpg.rf.ca3a38939a3ecab549d462ce96978524.jpg\n",
            "DSC01739_JPG_jpg.rf.eb493e5fbf94a463e90a33a3e16ad049.jpg\n",
            "DSC01757_JPG_jpg.rf.5e883c2c5b78bb2b35460f5ab404adae.jpg\n",
            "DSC01918_JPG-Copy-Copy_jpg.rf.ae89429e34a5042942e2553c584342f7.jpg\n",
            "DSC01920_JPG_jpg.rf.7967e3bf78ba7b024d2e76be055048c7.jpg\n",
            "DSC01920_JPG_jpg.rf.7991b5d91da03478a662fb2292f4e201.jpg\n",
            "DSC01920_JPG_jpg.rf.ec8fcce5dd2c5203b51aa8f20eea1251.jpg\n",
            "DSC01928_JPG-Copy-Copy_jpg.rf.ebd9881569672a4b922a662f4248a64f.jpg\n",
            "DSC01931_JPG_jpg.rf.0b96f52776069048ff0054b8d8e38f1a.jpg\n",
            "DSC01933_JPG-Copy-Copy_jpg.rf.49830cceefab17f7d488343d83d33468.jpg\n",
            "DSC01933_JPG_jpg.rf.6af1631cc5d8558f1e378b725c74d08b.jpg\n",
            "DSC01939_JPG_jpg.rf.e1e0530fdd16c9873a7de94525a2643b.jpg\n",
            "DSC01940_JPG_jpg.rf.49602b3863d05acbbf7280196bc950dd.jpg\n",
            "DSC01941_JPG_jpg.rf.0a5d9639684c25a7dc9814d786dd0969.jpg\n",
            "DSC01941_JPG_jpg.rf.9db6795d53d54a546396635ec763b32c.jpg\n",
            "DSC01941_JPG_jpg.rf.c44a87eb4be727615678344f0297878c.jpg\n",
            "DSC01943_JPG_jpg.rf.2f1e68e7501eb47bf794925a322fc80c.jpg\n",
            "DSC01943_JPG_jpg.rf.ecc88b7041a49d414b637974faa0396a.jpg\n",
            "DSC01946_JPG_jpg.rf.e0f8076033176fef68c5edd289650de9.jpg\n",
            "DSC01946_JPG_jpg.rf.fadd11b6d9a87317c4cc17e8263aef7a.jpg\n",
            "DSC01947_JPG_jpg.rf.4f5c6271f0651939b963083823226276.jpg\n",
            "DSC01947_JPG_jpg.rf.68e0f86fff3b11ba4f0ad1e40e1a9879.jpg\n",
            "DSC01950_JPG_jpg.rf.053ef98541c1395b0c397330c3e81714.jpg\n",
            "DSC01950_JPG_jpg.rf.434e7f0c1cfb923b845585de088af7ed.jpg\n",
            "DSC01950_JPG_jpg.rf.732e54357d39f8f59996f5878093568c.jpg\n",
            "DSC01951_JPG_jpg.rf.29a0dd8958a1d6650d343791fe7457df.jpg\n",
            "DSC01952_JPG_jpg.rf.489b48275931bf0fc5f9cd7941dcc50f.jpg\n",
            "DSC01952_JPG_jpg.rf.c29c8cc4cae1184ec849f55e5ca4eb49.jpg\n",
            "DSC01954_JPG_jpg.rf.99caa2695437e69173e0c33d915f212f.jpg\n",
            "DSC01954_JPG_jpg.rf.e53ca85a47e0eb58afa4d44dcde88c06.jpg\n",
            "DSC01955_JPG_jpg.rf.34525b2b7d57ef56ae85e845a4301fe8.jpg\n",
            "DSC01955_JPG_jpg.rf.36d8274866999066a9b5b05796eecd1b.jpg\n",
            "DSC01955_JPG_jpg.rf.bd6744a717eb7ac19b7a8a48a5e5191f.jpg\n",
            "DSC01956_JPG_jpg.rf.9c0adb92ebb5789ae6ef9a2ff3aa2733.jpg\n",
            "DSC01959_JPG_jpg.rf.76afe6550d83640f333daf94047b133b.jpg\n",
            "DSC01960_JPG_jpg.rf.25450f02b87e40e7b9a7d0725e846605.jpg\n",
            "DSC01961_JPG_jpg.rf.9b5c6b3d57682d8365b086b64f2b9011.jpg\n",
            "DSC01961_JPG_jpg.rf.df73b3c2b9580b2b73c86cd49622d36c.jpg\n",
            "DSC01963_JPG_jpg.rf.4976277bd3b29c444d0e5d7fbe9b2402.jpg\n",
            "DSC01963_JPG_jpg.rf.bbe6391b1ac49378589241c1a6411e0b.jpg\n",
            "DSC01963_JPG_jpg.rf.e3b5b6058723d667dc3c22335d56e178.jpg\n",
            "DSC01964_JPG_jpg.rf.6648e9b0ad4c9ce28cb54ae16dc4bd79.jpg\n",
            "DSC01964_JPG_jpg.rf.90ce4c10a339639879509b307b341ceb.jpg\n",
            "DSC01965_JPG_jpg.rf.22f0394b00516f59a94c80b029cf1346.jpg\n",
            "DSC01965_JPG_jpg.rf.b7d02c9fdfb99de8d41038afd08afe79.jpg\n",
            "DSC01965_JPG_jpg.rf.e12904a85c53f059e2e3c11c27000494.jpg\n",
            "DSC01966_JPG_jpg.rf.b072249ac19302b96c91ad1e198bc709.jpg\n",
            "DSC01967_JPG_jpg.rf.ddb111754aeec3990af820c419236922.jpg\n",
            "DSC01967_JPG_jpg.rf.edb5f9b2ec4cd3aa9bdcd42f967ab614.jpg\n",
            "DSC01968_JPG_jpg.rf.b61548fc98a084daf77beaceab2a30a7.jpg\n",
            "DSC01968_JPG_jpg.rf.ce0834f080532d843b22391bb81187e1.jpg\n",
            "DSC01970_JPG_jpg.rf.15b3881845144521cb22474845ee0911.jpg\n",
            "DSC01970_JPG_jpg.rf.3acceba9039baf837fb5a05cc06793a3.jpg\n",
            "DSC01970_JPG_jpg.rf.3d692fd52791187815eaf99ebe4be884.jpg\n",
            "DSC01970_JPG_jpg.rf.7d05775cef29e55fc959d12aee8931ea.jpg\n",
            "DSC01972_JPG_jpg.rf.2da7cd896a444f2d6088168bbe9e7885.jpg\n",
            "DSC01972_JPG_jpg.rf.8ff4090c8af5adf3701525d07b97d939.jpg\n",
            "DSC01972_JPG_jpg.rf.d8f2eb25107c7404c467507ab0167c49.jpg\n",
            "DSC01973_JPG_jpg.rf.c96d38a0f483613a042dce81d3e1e192.jpg\n",
            "DSC01973_JPG_jpg.rf.efac0b901bef0eb466edf48d10c7ebea.jpg\n",
            "DSC01975_JPG-Copy-Copy_jpg.rf.6aff362bf5434b7848b363cc11a52108.jpg\n",
            "DSC01975_JPG_jpg.rf.77ef2c616a83f53681ef91039e5677fe.jpg\n",
            "DSC01976_JPG_jpg.rf.86b10b8adf4b316764aa1d16cad1d44b.jpg\n",
            "DSC01976_JPG_jpg.rf.9b9ad7dca542ffa9afbf3edaaa8f7f20.jpg\n",
            "DSC01977_JPG_jpg.rf.8008d5f5def6ce565225e451daa62d45.jpg\n",
            "DSC01977_JPG_jpg.rf.8740b1def711c34b08035a375b26563a.jpg\n",
            "DSC01977_JPG_jpg.rf.a53585c03fa93e3ece7555848ac2abbd.jpg\n",
            "DSC01977_JPG_jpg.rf.ae4321ceec3a31bc50ba57c4e6e95d30.jpg\n",
            "DSC01977_JPG_jpg.rf.b6426b727b52d13fd492239230c569cd.jpg\n",
            "DSC01981_JPG_jpg.rf.208ce25ea6ba990601eab38845cf35c1.jpg\n",
            "DSC01981_JPG_jpg.rf.d94c50e1e4f74298a755e17a1a8ed6cd.jpg\n",
            "DSC01983_JPG_jpg.rf.53d9e1d28df0911818ea74d0ef15ea72.jpg\n",
            "DSC01983_JPG_jpg.rf.922e1de8759a5b077ee61b6783bbb6bf.jpg\n",
            "DSC01983_JPG_jpg.rf.9ebbfaaec254810dc6bc114c4796cd6d.jpg\n",
            "DSC01983_JPG_jpg.rf.afaa3e345bac0affdf0ea1600995cd2a.jpg\n",
            "DSC01984_JPG_jpg.rf.7d8440b12f02c747a5e5ef8dd6fa8b8c.jpg\n",
            "DSC01984_JPG_jpg.rf.e290bbb4b4c5b1ab427b83c1dc244a53.jpg\n",
            "DSC01984_JPG_jpg.rf.e748882989a0ac47211b686d81478607.jpg\n",
            "DSC01985_JPG_jpg.rf.a12cd614487bf54a14d90e2c7a6ba4a5.jpg\n",
            "DSC01986_JPG_jpg.rf.4aa4ceb344f612ad7a03bc3ac5248ab2.jpg\n",
            "DSC01986_JPG_jpg.rf.b378e63133e3212efa913bb483e4924c.jpg\n",
            "DSC01989_JPG_jpg.rf.20e4a3f657d0ee0b4b83af99f05ef3c8.jpg\n",
            "DSC01989_JPG_jpg.rf.6cb90470ed955a299a3de34f1573f254.jpg\n",
            "DSC01989_JPG_jpg.rf.7392e96f11d2863ce8a903d7e9eda8af.jpg\n",
            "DSC01989_JPG_jpg.rf.d35b8aece3a8dbacc9c73093dca2ee6e.jpg\n",
            "DSC01990_JPG_jpg.rf.15ab3e5bf779be8631960a48c655b2ff.jpg\n",
            "DSC01991_JPG_jpg.rf.0c426efc074d4ebeaa4a3bba245920ff.jpg\n",
            "DSC01992_JPG_jpg.rf.5a7b457d75d33b9a74693a275977e514.jpg\n",
            "DSC01992_JPG_jpg.rf.6759ba0aaa4f3f502778d663a6593f14.jpg\n",
            "DSC01993_JPG_jpg.rf.46effce69a5d9e6aecfe26f9efeb616f.jpg\n",
            "DSC01995_JPG_jpg.rf.1d0a345c796fba21d6e4350b7ef2aefc.jpg\n",
            "DSC01995_JPG_jpg.rf.6086580d65052b36c41d1f6fc28999b2.jpg\n",
            "DSC01996_JPG_jpg.rf.225ce415d4529b145345595dbc24e415.jpg\n",
            "DSC01996_JPG_jpg.rf.9aaa7aefc3067dc6fc655e04587e0ee7.jpg\n",
            "DSC01997_JPG_jpg.rf.51785dc3e62f79b42746c8b2b93689c0.jpg\n",
            "DSC01997_JPG_jpg.rf.bece46f613907deca85f5e1576391cb8.jpg\n",
            "DSC01998_JPG_jpg.rf.4607a7f53f329e7f8a3c91e94214b659.jpg\n",
            "DSC01998_JPG_jpg.rf.697a1ae31d7b35015bc46d63e74a54a9.jpg\n",
            "DSC01999_JPG_jpg.rf.90a2f1f60be6ad7afe2c1dec5ca8dbd7.jpg\n",
            "DSC02000_JPG_jpg.rf.1640f5538cb149345d1707f251d3052f.jpg\n",
            "DSC02000_JPG_jpg.rf.56ee0af28cf25904fd8500829313a58a.jpg\n",
            "DSC02000_JPG_jpg.rf.8336ad47f42e7ffdf8bfb5454b96bf46.jpg\n",
            "DSC02000_JPG_jpg.rf.d79e43cc6b5d3e5a571472ce5705e8bf.jpg\n",
            "DSC02001_JPG_jpg.rf.83300c5eba0e7afb6dc08630dcdf88fd.jpg\n",
            "DSC02001_JPG_jpg.rf.dee862ee3190897791fd1260b1d6dba5.jpg\n",
            "DSC02004_JPG_jpg.rf.3fa451e0476272648a355aa606a313af.jpg\n",
            "DSC02004_JPG_jpg.rf.a1950626596a2b117c50f7c47c39d665.jpg\n",
            "DSC02005_JPG_jpg.rf.14300b430a3d3fd4afa6a1b92368cbe6.jpg\n",
            "DSC02005_JPG_jpg.rf.527b6dd0871dd01895bc8021e6a6613d.jpg\n",
            "DSC02005_JPG_jpg.rf.d05db680c2d763a4858135d30fcd5dfb.jpg\n",
            "DSC02006_JPG_jpg.rf.86f5e50334078311e10eff3926563ffd.jpg\n",
            "DSC02006_JPG_jpg.rf.8dab5733176fbcf78e40d00c50404d50.jpg\n",
            "DSC02007_JPG_jpg.rf.067a6ab5d3f10551c2b1c58a2007f2eb.jpg\n",
            "DSC02007_JPG_jpg.rf.a632604bf3e649df3f31fc5de3c3d2e8.jpg\n",
            "DSC02008_JPG_jpg.rf.313b4693d88bf3ea9e4cf447737a86c9.jpg\n",
            "DSC02011_JPG_jpg.rf.68cd97d8ea378854193435288307521a.jpg\n",
            "DSC02012_JPG_jpg.rf.4b3592520fd8ea547c77dbc3dd625e11.jpg\n",
            "DSC02012_JPG_jpg.rf.929617aec7b563637943e11bc37a3b50.jpg\n",
            "DSC02012_JPG_jpg.rf.b1242b409859001fa5150716400037f0.jpg\n",
            "DSC02013_JPG_jpg.rf.b03a346ce728e25e2dae2eb8dec832eb.jpg\n",
            "DSC02013_JPG_jpg.rf.e49adc22d4ab9458014669e2cdb8fc93.jpg\n",
            "DSC02013_JPG_jpg.rf.fc7151546bafd89be7eaffc86af3d63c.jpg\n",
            "DSC02014_JPG_jpg.rf.7d6dd0ec2119b9e739bc5b55e1db0b38.jpg\n",
            "DSC02014_JPG_jpg.rf.9a8ba35139785ecdf5385e8d99e59215.jpg\n",
            "DSC02015_JPG_jpg.rf.8971124dd11d0e118ecce5fb0395ea89.jpg\n",
            "DSC02015_JPG_jpg.rf.bce27d5345cba8e2d9b00b60d4a29be3.jpg\n",
            "DSC02018_JPG_jpg.rf.ae98628c1564408bb812e1cec2bc30f0.jpg\n",
            "DSC02018_JPG_jpg.rf.b17a55c04bcb2159da2db5919bfe435d.jpg\n",
            "DSC02018_JPG_jpg.rf.feee3a0a1b0419e7947dcc4599509b2f.jpg\n",
            "DSC02019_JPG_jpg.rf.4ce1a5730ef0a4bf87d8d66a58b15e71.jpg\n",
            "DSC02019_JPG_jpg.rf.d477350e19757a5c36e9cc2f96cb8232.jpg\n",
            "DSC02020_JPG_jpg.rf.5395e69813e7d67c16aca52e50f4344b.jpg\n",
            "DSC02020_JPG_jpg.rf.75d07ca1f4931f89596d6d5b711f19cb.jpg\n",
            "DSC02022_JPG_jpg.rf.93805fa90b030245811340b8c5463fc0.jpg\n",
            "DSC02023_JPG_jpg.rf.7e9e72e7425150bae2b68d4254f2b60f.jpg\n",
            "DSC02023_JPG_jpg.rf.89abd75181ce073efe29efb3f4f0c401.jpg\n",
            "DSC02024_JPG_jpg.rf.cf4d83e9c87d1bba39f92ae5ceb422ba.jpg\n",
            "DSC02024_JPG_jpg.rf.eb1b56aefdabe2dd71572f4daae56220.jpg\n",
            "DSC02025_JPG_jpg.rf.2dcaef9fb34ed980d0f4292e0c10d048.jpg\n",
            "DSC02025_JPG_jpg.rf.8d48cb2fc3e06986fe9d6e8efe0b4061.jpg\n",
            "DSC02025_JPG_jpg.rf.f4d51b510ae31d785ae7085d2a608b6e.jpg\n",
            "DSC02026_JPG_jpg.rf.2ac56fa5ec8479ac2b3276152d45b925.jpg\n",
            "DSC02026_JPG_jpg.rf.5f907042986f06d836a72a8f0bf68764.jpg\n",
            "DSC02028_JPG_jpg.rf.8ad9754f576f6d515ab5788be1a2fbf9.jpg\n",
            "DSC02028_JPG_jpg.rf.bd366f4aa63479b5d5e3eb6d8f66e77a.jpg\n",
            "DSC02028_JPG_jpg.rf.d2f37aeec98719a08368ec7e2ac9149c.jpg\n",
            "DSC02029_JPG_jpg.rf.6c9cb8678bc590b3686027c887300b4a.jpg\n",
            "DSC02030_JPG_jpg.rf.3caaebb6b3ac03e9bf5be18da1225634.jpg\n",
            "DSC02030_JPG_jpg.rf.425426c4bc7cf79519c5a1c7abf9e0fd.jpg\n",
            "DSC02031_JPG_jpg.rf.57a462f8f8f2ce7cdacafc68300521bf.jpg\n",
            "DSC02032_JPG_jpg.rf.6c6d446d94a244f5a0e829a5235efc9f.jpg\n",
            "DSC02036_JPG_jpg.rf.419534807b18044593687752c2b59a51.jpg\n",
            "DSC02036_JPG_jpg.rf.839f1f83ec1145a748224b7e219f047b.jpg\n",
            "DSC02037_JPG_jpg.rf.345f08de9a9ee15703f85241676b187f.jpg\n",
            "DSC02037_JPG_jpg.rf.78b5e55ccf4c52a0281edb3abf7ae48b.jpg\n",
            "DSC02038_JPG_jpg.rf.35d2d792b2cb4c035b12ee79656068f2.jpg\n",
            "DSC02038_JPG_jpg.rf.cd4a39c97c45e768f779d805e8525bcf.jpg\n",
            "DSC02039_JPG_jpg.rf.23f1e535cca8e345401860c2c45859de.jpg\n",
            "DSC02039_JPG_jpg.rf.cb01e021d776a59eb184389fd69983d4.jpg\n",
            "DSC02042_JPG_jpg.rf.61e3bf1e801702e781f1dbd442b95233.jpg\n",
            "DSC02042_JPG_jpg.rf.8465b8486c458cdac3b2c2f4bec6ec79.jpg\n",
            "DSC02043_JPG_jpg.rf.190b3a6653913926a47cc050baa64200.jpg\n",
            "DSC02043_JPG_jpg.rf.85e606861fb709d54c6fee5eb6421e7c.jpg\n",
            "DSC02043_JPG_jpg.rf.f68de67548a61d8eacf9af153244b5b8.jpg\n",
            "DSC02044_JPG_jpg.rf.a6cc11f9305a4e56ece6a4de68912cec.jpg\n",
            "DSC02044_JPG_jpg.rf.e1b8767d9cfec1ea2ffb03575a42b65a.jpg\n",
            "DSC02045_JPG_jpg.rf.1caad18ddddd97a84b46b7e3a297acfa.jpg\n",
            "DSC02045_JPG_jpg.rf.f710f5257b6333703a1d810d30f89aae.jpg\n",
            "DSC02045_JPG_jpg.rf.fcb6eaa43fc3deafbe33da81d357ba72.jpg\n",
            "DSC02047_JPG_jpg.rf.03592d61a16ac2a17f567091857bf620.jpg\n",
            "DSC02047_JPG_jpg.rf.0d335087423571e27a759c86f2822c5b.jpg\n",
            "DSC02047_JPG_jpg.rf.6c67298ce14beb2fc1c3bbba144aba02.jpg\n",
            "DSC02048_JPG-Copy_jpg.rf.3a522c2dae30a9c9db9b87c2b4c65f6f.jpg\n",
            "DSC02048_JPG-Copy_jpg.rf.9a5e8bcada507cc38eba703296ecb624.jpg\n",
            "DSC02048_JPG-Copy_jpg.rf.f941d7f56cba8a16e983dc8b59dd04b5.jpg\n",
            "DSC02049_JPG_jpg.rf.a05b26c703d6528f9925a6bdf73f7b43.jpg\n",
            "DSC02050_JPG-Copy_jpg.rf.9d3fd077d44e748ae60bf42e41453187.jpg\n",
            "DSC02050_JPG-Copy_jpg.rf.c89734c67cc125d067c8aa7c5e4dfb6a.jpg\n",
            "DSC02051_JPG_jpg.rf.0c20220887d27467781468bdde351770.jpg\n",
            "DSC02051_JPG_jpg.rf.5af420ecf59550c4b7031b5582b48661.jpg\n",
            "DSC02051_JPG_jpg.rf.eb48f2b29a24d83ad11ecf16ee84870a.jpg\n",
            "DSC02052_JPG_jpg.rf.021b77e2bf3cee49101f97c878f728ee.jpg\n",
            "DSC02052_JPG_jpg.rf.0e7731be1ae34d7f3c22f4c36e12ca07.jpg\n",
            "DSC02052_JPG_jpg.rf.b3188a6dee4a73aded0c5d7fc98ba32e.jpg\n",
            "DSC02054_JPG_jpg.rf.0d843b9480cea491e0a2c87748751088.jpg\n",
            "DSC02054_JPG_jpg.rf.22309ad1b5955392f1a061e78f200065.jpg\n",
            "DSC02057_JPG_jpg.rf.e89da745867e85de0e3c0d5f5e1a0aee.jpg\n",
            "DSC02059_JPG_jpg.rf.7e1e7674a045d482b9202a0968a55eb8.jpg\n",
            "DSC02059_JPG_jpg.rf.aef547a5b2e8592518e27b71bcd53538.jpg\n",
            "DSC02060_JPG_jpg.rf.a72d711d3d8e0fa597b030baf24c589c.jpg\n",
            "DSC02060_JPG_jpg.rf.f9d2baf2491050a66c5e7494d906e8e6.jpg\n",
            "DSC02061_JPG_jpg.rf.39effd28b7d0bce05ef8ddfeac92e0f9.jpg\n",
            "DSC02063_JPG_jpg.rf.0ac6d559f45d5959f8fe547d32fbbc5e.jpg\n",
            "DSC02063_JPG_jpg.rf.a2e4041cd67f1778905f90788ffdbe21.jpg\n",
            "DSC02064_JPG_jpg.rf.45f0478b7236622c49f3b4bf6daeb2b6.jpg\n",
            "DSC02064_JPG_jpg.rf.96fb4501dfd2f74ae243df5b62c98a9a.jpg\n",
            "DSC02064_JPG_jpg.rf.9cf18565dd6102b2722f57846116bacd.jpg\n",
            "DSC02065_JPG_jpg.rf.eb6223e07e883f49476ff5a2dff87141.jpg\n",
            "DSC02067_JPG_jpg.rf.1c01541e10df68b7c08058925a8f0b99.jpg\n",
            "DSC02067_JPG_jpg.rf.81eea2665235dcb76f67b66847ae419d.jpg\n",
            "DSC02069_JPG_jpg.rf.da4bf26143ae1a6d719ab4c346961513.jpg\n",
            "DSC02070_JPG_jpg.rf.b976fc488d8ffeab74980b9e79409cb0.jpg\n",
            "DSC02071_JPG_jpg.rf.904e776a38db359df937861bbe9e2352.jpg\n",
            "DSC02072_JPG-Copy_jpg.rf.0176fbb3c1a8bfcc74b61cea319415d0.jpg\n",
            "DSC02072_JPG-Copy_jpg.rf.d3483b12d745b9ec26afc1c47e45f57d.jpg\n",
            "DSC02073_JPG_jpg.rf.0df472399e6e744dc97fe45fa4cafb9a.jpg\n",
            "DSC02075_JPG-Copy_jpg.rf.82b24020fd50b1065053d64eef1f36fa.jpg\n",
            "DSC02075_JPG-Copy_jpg.rf.cb00d6d738a348e0f2497f026e6bbc65.jpg\n",
            "DSC02076_JPG_jpg.rf.022fd8d2a2f3033c2addbfc8a675677a.jpg\n",
            "DSC02076_JPG_jpg.rf.c34bf647c049aa3333caca473f5e5ecb.jpg\n",
            "DSC02076_JPG_jpg.rf.f36a577ef259a6eb27ae3080d818d890.jpg\n",
            "DSC02077_JPG_jpg.rf.03c389bd6a15071eaf89be29ad3021a8.jpg\n",
            "DSC02077_JPG_jpg.rf.0fac8ab6ca9945df4ef43d95442e1f3e.jpg\n",
            "DSC02077_JPG_jpg.rf.a75327024c0aae451a08fa506dc386e3.jpg\n",
            "DSC02078_JPG_jpg.rf.4ef7b9d0df56047c7cad12db0cb0c3dd.jpg\n",
            "DSC02078_JPG_jpg.rf.560926e9c4a1139e6ff005ac48e723b4.jpg\n",
            "DSC02078_JPG_jpg.rf.f1a69d83bd5016d6be84dae47c8771e5.jpg\n",
            "DSC02079_JPG_jpg.rf.5fc97f99749ba169e2eba537013a1c43.jpg\n",
            "DSC02079_JPG_jpg.rf.7e7d18728f5a479b9b39a872aa152b52.jpg\n",
            "DSC02080_JPG_jpg.rf.467955337a4139f30b5cd67ae01132c5.jpg\n",
            "DSC02080_JPG_jpg.rf.b07c71a3f25c5d92c4d3ff820423ced4.jpg\n",
            "DSC02080_JPG_jpg.rf.bffee79923608828f81424c79687573e.jpg\n",
            "DSC02081_JPG_jpg.rf.064dae378b2577f0ac6b34f999bd73c2.jpg\n",
            "DSC02081_JPG_jpg.rf.d209023e44c8404fd58c3918aaac3934.jpg\n",
            "DSC02081_JPG_jpg.rf.ebd77ca45ddae7c3f76ad2e81edb8482.jpg\n",
            "DSC02082_JPG_jpg.rf.7c8f0ed88d2ee7a4292ca30d84f27a0a.jpg\n",
            "DSC02082_JPG_jpg.rf.7eceb15f6fe54477960276605f7a702f.jpg\n",
            "DSC02082_JPG_jpg.rf.9e6d06649ea3cd0175f34c92b2fc8c40.jpg\n",
            "DSC02083_JPG_jpg.rf.4970f1e3cecfb205a6589df1eae4edfa.jpg\n",
            "DSC02083_JPG_jpg.rf.5ef6d197d921c47e2ab5355e2bc8ac0b.jpg\n",
            "DSC02083_JPG_jpg.rf.f67b6c5f0b7a1008d79e296ec67ad36d.jpg\n",
            "DSC02084_JPG_jpg.rf.8a3066a372ef8a7f725e063239e9903a.jpg\n",
            "DSC02084_JPG_jpg.rf.8ec47933f3f63a00c57010dc812eb60f.jpg\n",
            "DSC02084_JPG_jpg.rf.e849e301c0f78c1618821885e5b2be92.jpg\n",
            "DSC02085_JPG_jpg.rf.5d59b142f28f08fc0ac1556959e13017.jpg\n",
            "DSC02085_JPG_jpg.rf.d3f4a69106f088222de62560c4f19677.jpg\n",
            "DSC02085_JPG_jpg.rf.f0eb9bb5bb9d1bdd5c60b6181fd24f31.jpg\n",
            "DSC02086_JPG-Copy_jpg.rf.83fc75d1b057c765d46d5355a98f3736.jpg\n",
            "DSC02086_JPG-Copy_jpg.rf.af8964f921d6aeae769c257b6bc2b643.jpg\n",
            "DSC02087_JPG_jpg.rf.0b4e4356db61515a9ebaa4f3eaa522c6.jpg\n",
            "DSC02087_JPG_jpg.rf.421fd5a532f61ab33012b89d47ae348c.jpg\n",
            "DSC02087_JPG_jpg.rf.f95ff9471171941dbe8e965aa0478ff8.jpg\n",
            "DSC02088_JPG_jpg.rf.3fba4038b5dd87422f7c0e4241b7aee6.jpg\n",
            "DSC02088_JPG_jpg.rf.dcd0346fe78f99c4718ff81b4b9ed614.jpg\n",
            "DSC02089_JPG_jpg.rf.58c3942bbaba105e24f36709d63ac607.jpg\n",
            "DSC02089_JPG_jpg.rf.f5ed068e10e214234f985ade8c0380f0.jpg\n",
            "DSC02092_JPG_jpg.rf.1d2b13ac3289b5f9c2c6f1fbd203c745.jpg\n",
            "DSC02095_JPG_jpg.rf.5198f7838ed1fc4dbe6a96eb744032d3.jpg\n",
            "DSC02095_JPG_jpg.rf.72e2237320898bc74b24937a5eaf0bce.jpg\n",
            "DSC02096_JPG_jpg.rf.38a7548b48d535a97f08250b1199c8b2.jpg\n",
            "DSC02096_JPG_jpg.rf.c33bdf49e6d0c66e58f6f747fd166628.jpg\n",
            "DSC02097_JPG_jpg.rf.1bb60fd177ab3ac483a87d7f9352f214.jpg\n",
            "DSC02097_JPG_jpg.rf.ff0c9d915e4f9bbfe7b8c0f8b36a0f60.jpg\n",
            "DSC02098_JPG_jpg.rf.5cbc2125476ce669cdd04b23e38acf3b.jpg\n",
            "DSC02100_JPG_jpg.rf.03c87b472bd2579dc1cc0a33ed233fc1.jpg\n",
            "DSC02100_JPG_jpg.rf.5e22841b32db0f01aaf50c4cb6b32b7b.jpg\n",
            "DSC02101_JPG_jpg.rf.0795c7280302fa19df04823cf2d649eb.jpg\n",
            "DSC02101_JPG_jpg.rf.d4f00c2101dee2ab8afc1672a9a86f8f.jpg\n",
            "DSC02101_JPG_jpg.rf.e796156abaa2fa83c5ef16cea374d51e.jpg\n",
            "DSC02104_JPG_jpg.rf.27d209d01dde5bbbfac6593e16e9cdb7.jpg\n",
            "DSC02104_JPG_jpg.rf.74cb9c88e8195164fa42aa486c4fa95e.jpg\n",
            "DSC02104_JPG_jpg.rf.9a350279ead9dce33a19d45286d50317.jpg\n",
            "DSC02105_JPG_jpg.rf.178fb4a1c8bb75b34188111b323f1ce0.jpg\n",
            "DSC02105_JPG_jpg.rf.4eda98afbc064bf6bbfa925ec04388ac.jpg\n",
            "DSC02105_JPG_jpg.rf.689447005654f528712aa4880f639cb3.jpg\n",
            "DSC02106_JPG_jpg.rf.86b6c86cbb4c905b3435a185f7f7d81b.jpg\n",
            "DSC02111_JPG_jpg.rf.ab8e2a76a3319a911920106b4e91f47d.jpg\n",
            "DSC02111_JPG_jpg.rf.eb54e9dfa9132b5ebf0327ed2065e689.jpg\n",
            "DSC02111_JPG_jpg.rf.f56d36b092a220eb7022e4955e73df31.jpg\n",
            "DSC02112_JPG_jpg.rf.8f5226da9328cbf7bfcca2f32af8d949.jpg\n",
            "DSC02112_JPG_jpg.rf.b2c68d5c9bbbea12834f65ad40322f51.jpg\n",
            "DSC02113_JPG_jpg.rf.073a965db6910f7c47112195edfcf53d.jpg\n",
            "DSC02113_JPG_jpg.rf.214dab0d3e0c9b42b2b1f890836b7807.jpg\n",
            "DSC02113_JPG_jpg.rf.c448af3beaf09a360581b075a7b7fbd2.jpg\n",
            "DSC02117_JPG_jpg.rf.15cec393cbdc0159ec909f419ee902db.jpg\n",
            "DSC02118_JPG_jpg.rf.148a0721f99c9c4593f946d3bee13d8b.jpg\n",
            "DSC02118_JPG_jpg.rf.d6ea62055c1e33086abe27d48c8a83ea.jpg\n",
            "DSC02120_JPG_jpg.rf.770c8413782dc252862a25221bea61f3.jpg\n",
            "DSC02122_JPG_jpg.rf.2f3b209d749cbbe18349c4d4f06de1c7.jpg\n",
            "DSC02122_JPG_jpg.rf.ca90b91c2bd5e45f5194fca41382dc29.jpg\n",
            "DSC02123_JPG_jpg.rf.2c1ad8c1372796cf5c4d7a4dd0294296.jpg\n",
            "DSC02123_JPG_jpg.rf.84251c42ea77815da425b6282624b609.jpg\n",
            "DSC02124_JPG_jpg.rf.87053534c44eacef654e76d3777f5fc0.jpg\n",
            "DSC02125_JPG_jpg.rf.13659f689851b2fa378cc4781e04ab7e.jpg\n",
            "DSC02125_JPG_jpg.rf.692034252c3bd10607aef3be51021b9a.jpg\n",
            "DSC02125_JPG_jpg.rf.f5a8f74b2e0e7c32b3c9284dc4dd45c0.jpg\n",
            "DSC02126_JPG_jpg.rf.4420d93f93388c5321b38b57040b9e86.jpg\n",
            "DSC02126_JPG_jpg.rf.7a0e3e7b2528b31d36de056df8d4c21a.jpg\n",
            "DSC02126_JPG_jpg.rf.c0947b9d5fd8f9001ab2cd1f4b0ce04d.jpg\n",
            "DSC02127_JPG_jpg.rf.18b04484d16bf2d308d5097dd9c9f243.jpg\n",
            "DSC02128_JPG_jpg.rf.780fd4301b4a8b6680f14364ec75ff42.jpg\n",
            "DSC02129_JPG_jpg.rf.b5abb715cddc67caac29612083b347fc.jpg\n",
            "DSC02129_JPG_jpg.rf.fe8525e7e4f2c506b5e3e0881ffa50e3.jpg\n",
            "DSC02130_JPG_jpg.rf.ad125069f20b618227d30008824ce9f8.jpg\n",
            "DSC02130_JPG_jpg.rf.c3dfd7f10bc5ac1f999365d2d4bcd1d4.jpg\n",
            "DSC02130_JPG_jpg.rf.e49b4ed1c8fa0a33b9ba6aa29953f2e5.jpg\n",
            "DSC02131_JPG_jpg.rf.70abb010ec4cd54b6f0b5c200c32f682.jpg\n",
            "DSC02132_JPG_jpg.rf.58d8d421035f258ade7314832d1de88b.jpg\n",
            "DSC02132_JPG_jpg.rf.7873c3a23966acfabbf1501e346f6586.jpg\n",
            "DSC02133_JPG_jpg.rf.28a1884c17b9bf71ee07618749bcd749.jpg\n",
            "DSC02135_JPG_jpg.rf.3761bfb24f50cb5a8da86215a0a1d82c.jpg\n",
            "DSC02136_JPG_jpg.rf.7cc413329e24f6ccff39d5e400903fee.jpg\n",
            "DSC02136_JPG_jpg.rf.81bf6bfc89d544eee22b798cacaf4fd7.jpg\n",
            "DSC02136_JPG_jpg.rf.8b002e2f7bf275f9880ac5ad9dc41b65.jpg\n",
            "DSC02139_JPG_jpg.rf.137ff8db84d375aff556637ed62c8be8.jpg\n",
            "DSC02139_JPG_jpg.rf.4d2e58d5428d6ff9c7554aed5eeee9a5.jpg\n",
            "DSC02139_JPG_jpg.rf.bec0f9698ae6e093576d703501e5d6d8.jpg\n",
            "DSC02140_JPG_jpg.rf.6a3baaaf69f481c33aea4aff62a27c76.jpg\n",
            "DSC02140_JPG_jpg.rf.de36691fdc62490b4723447ee599391b.jpg\n",
            "DSC02141_JPG_jpg.rf.1d855a940767b3923b3cb0ce50deecea.jpg\n",
            "DSC02141_JPG_jpg.rf.c6e15300de84bcdf3cef64837f210c77.jpg\n",
            "DSC02142_JPG_jpg.rf.1556f0fb8c43b15da14af81d7f73aae6.jpg\n",
            "DSC02144_JPG_jpg.rf.ddbf719720a8494b4f6ea11d1a04e9ad.jpg\n",
            "DSC02145_JPG_jpg.rf.864e441e5b77f8e138feceb6f78a7653.jpg\n",
            "DSC02146_JPG_jpg.rf.1cad3d6b8bf9b078b7473f8ef0fad49d.jpg\n",
            "DSC02146_JPG_jpg.rf.5a5f644cdca1a87345f81f3fd14599a0.jpg\n",
            "DSC02146_JPG_jpg.rf.78f64a29bbbdc012d18735969ff54324.jpg\n",
            "DSC02147_JPG_jpg.rf.3b46ea0f231d63c0d56b439822628269.jpg\n",
            "DSC02147_JPG_jpg.rf.439638145c41eb81e916e544fb05d47f.jpg\n",
            "DSC02147_JPG_jpg.rf.7564befa12bcbf025e3c981ec3435ece.jpg\n",
            "DSC02148_JPG_jpg.rf.0cffc98a6f0b0ae4318f73a85d85802f.jpg\n",
            "DSC02148_JPG_jpg.rf.3e2508b5948b1492ea83f0091d3e7e74.jpg\n",
            "DSC02150_JPG_jpg.rf.518de1f2e3dccc0c8bb345fab403085b.jpg\n",
            "DSC02150_JPG_jpg.rf.8762afd19025f5ef7213ddadfec5ccaa.jpg\n",
            "DSC02151_JPG_jpg.rf.6e4a4f10fbff5fd88cb5bf83230b880c.jpg\n",
            "DSC02151_JPG_jpg.rf.7fe5bdd1ec07a77ebb9623bb8a346151.jpg\n",
            "DSC02152_JPG_jpg.rf.7e80820136b3bdded69bcc86d347960b.jpg\n",
            "DSC02153_JPG_jpg.rf.1a9cc86ca202b1d00c8efa6fc3460a8d.jpg\n",
            "DSC02153_JPG_jpg.rf.90fa3978e90e0513672bcacd28765287.jpg\n",
            "DSC02154_JPG_jpg.rf.00648ca74ffee5da722831027f408289.jpg\n",
            "DSC02154_JPG_jpg.rf.4bc156b6c773a8a94174c02fab25f674.jpg\n",
            "DSC02154_JPG_jpg.rf.621f9273acbd02daf6d3104720ac84a2.jpg\n",
            "DSC02155_JPG_jpg.rf.f5fb7e02bb9c6361dd03907c9b5590d9.jpg\n",
            "DSC02156_JPG_jpg.rf.2166cf1e4d4df14fa2798669bac37445.jpg\n",
            "DSC02156_JPG_jpg.rf.9f5ff8cdb324a619e18fe81857aa5557.jpg\n",
            "DSC02156_JPG_jpg.rf.c34cd44e30cab0bb192927160f240e91.jpg\n",
            "DSC02157_JPG_jpg.rf.aade25b8dfcdff4a9c630ade18dde04d.jpg\n",
            "DSC02157_JPG_jpg.rf.b2f9908d720e5ed1219b508036bf36a1.jpg\n",
            "DSC02159_JPG_jpg.rf.2039b5295b728ec5b9519b9c8db1cbca.jpg\n",
            "DSC02159_JPG_jpg.rf.42ddb266b93d59a96ba8e554e4644a76.jpg\n",
            "DSC02159_JPG_jpg.rf.849ba6c5b5ac85faf2ebfbde544478a5.jpg\n",
            "DSC02160_JPG_jpg.rf.32cd748c093c3b42f07a7503388b0a63.jpg\n",
            "DSC02161_JPG_jpg.rf.0ce9c6407432fe4ffeff21edac698a3c.jpg\n",
            "DSC02163_JPG_jpg.rf.1b7e9da4950cc1b456cfb597bc53c106.jpg\n",
            "DSC02163_JPG_jpg.rf.b9b3a5a2e61f0ede5e3254901bed1e93.jpg\n",
            "DSC02163_JPG_jpg.rf.df534d317d561f0b8555422b2174e6f0.jpg\n",
            "DSC02164_JPG_jpg.rf.a3261969a063eb004936c275145abdea.jpg\n",
            "DSC02164_JPG_jpg.rf.dd92263eda498543786f1af4ff0c907e.jpg\n",
            "DSC02164_JPG_jpg.rf.fdf096f5e34b06169d7ce8e97bb9b5e3.jpg\n",
            "DSC02165_JPG_jpg.rf.2d278f77b144e3f1affd0b0dd95b95c4.jpg\n",
            "DSC02165_JPG_jpg.rf.5e0bcd18b3e42e1dd5add5ef5f72551d.jpg\n",
            "DSC02166_JPG_jpg.rf.151c61ebbed2ecc2f64ea2e262ead1e0.jpg\n",
            "DSC02166_JPG_jpg.rf.447a3b23ccd9cd2d9033e01f82be9f24.jpg\n",
            "DSC02166_JPG_jpg.rf.d8cfa92a57924daf3c8a9b4010523076.jpg\n",
            "DSC02167_JPG_jpg.rf.0c1a9792eeaab3f69809dc8696aa6334.jpg\n",
            "DSC02167_JPG_jpg.rf.48f91192832b905b1a9fb30637ab78d9.jpg\n",
            "DSC02167_JPG_jpg.rf.78c2d1f0f9ae4b89a0871a8198520a07.jpg\n",
            "DSC02168_JPG_jpg.rf.0c54d7f35404de2228ddea14fe8504ee.jpg\n",
            "DSC02168_JPG_jpg.rf.a664af7bd98833284447d6964547ff39.jpg\n",
            "DSC02169_JPG_jpg.rf.c0859b3656e46edbb7f42e44a02de6c2.jpg\n",
            "DSC02169_JPG_jpg.rf.f0792eadabd30b7f9405f48885762a4a.jpg\n",
            "DSC02170_JPG_jpg.rf.468f4ef0014e9a56999f4c59045505ec.jpg\n",
            "DSC02170_JPG_jpg.rf.d9b538d45f56df0e190ea8f97a7cc336.jpg\n",
            "DSC02171_JPG_jpg.rf.ab870d4273470e38f9047bbcab318e8b.jpg\n",
            "DSC02172_JPG_jpg.rf.a72b0a8f0ea66b9a997111c0cb88369c.jpg\n",
            "DSC02173_JPG_jpg.rf.685c8b4b4a6c73d1cc717f4734ecd418.jpg\n",
            "DSC02175_JPG_jpg.rf.21fa2cdb525668f1d9fe39e19cfbbda0.jpg\n",
            "DSC02176_JPG_jpg.rf.132ad3d1af6a607fe6016fd52c1b75ed.jpg\n",
            "DSC02176_JPG_jpg.rf.76362e723919bc02f4b573ce96e42235.jpg\n",
            "DSC02177_JPG_jpg.rf.d1d6dcd788440de4b3ab9c3e2fb6691d.jpg\n",
            "DSC02178_JPG_jpg.rf.bbbbe8c01d635808285b3150543a96dd.jpg\n",
            "DSC02178_JPG_jpg.rf.c59461a774442c5d898e7f45f0a0d8c3.jpg\n",
            "DSC02180_JPG_jpg.rf.7d9efad82ec6f0f3904afcbd87fbb30a.jpg\n",
            "DSC02181_JPG_jpg.rf.93c66c66bfd61827490f4b6a4b416cb9.jpg\n",
            "DSC02183_JPG_jpg.rf.22b99301da1a1716dccda10449c743b6.jpg\n",
            "DSC02183_JPG_jpg.rf.ecdd16c83f2f9f9dabe20e092bf5b15d.jpg\n",
            "DSC02184_JPG_jpg.rf.1204b85331f41fb69646cbacd56f8d28.jpg\n",
            "DSC02184_JPG_jpg.rf.243d4a5e3b22fb5a270f6d1f369bac8a.jpg\n",
            "DSC02185_JPG_jpg.rf.1862aa84912499cab3ac5a4fb7aeeafb.jpg\n",
            "DSC02185_JPG_jpg.rf.f08554f35733f1e28bb1f13f0da06ec4.jpg\n",
            "DSC02187_JPG_jpg.rf.66d3fec37fc52bd0c9d5b3a8f2a65c1d.jpg\n",
            "DSC02187_JPG_jpg.rf.98eec3d3b0766e019f98d5bc767c55c6.jpg\n",
            "DSC02188_JPG_jpg.rf.4218db20a712c0c09b980fe62f38fccc.jpg\n",
            "DSC02188_JPG_jpg.rf.4266ad75cfbc099ffd6d778228819994.jpg\n",
            "DSC02189_JPG_jpg.rf.2afc7968d2c52e3f84967d72011f5239.jpg\n",
            "DSC02189_JPG_jpg.rf.46f47aaa4312400bd2ae2e1a52ca4006.jpg\n",
            "DSC02189_JPG_jpg.rf.859c02acc93c0a09d9f9d4092831bafd.jpg\n",
            "DSC02189_JPG_jpg.rf.f7de8231332f7d9d294e7c000aa89b51.jpg\n",
            "DSC02190_JPG_jpg.rf.8591e1cf9557af4548889c844f15ad8a.jpg\n",
            "DSC02190_JPG_jpg.rf.f9d665998ad18d26d555004384ebf454.jpg\n",
            "DSC02191_JPG_jpg.rf.30f5097c404a9f28d05360c503425769.jpg\n",
            "DSC02191_JPG_jpg.rf.adbc9c9d4ef6ca186e2e5e1b4195b8a1.jpg\n",
            "DSC02191_JPG_jpg.rf.fefcfd4092dc678b4c9843d071227cbb.jpg\n",
            "DSC02192_JPG_jpg.rf.73a1c680f03ecf0a7b12156bba284652.jpg\n",
            "DSC02192_JPG_jpg.rf.dee8f134c733d5c72364ca3de127702b.jpg\n",
            "DSC02194_JPG_jpg.rf.1495536d94cd3a919defb8b0cf173506.jpg\n",
            "DSC02195_JPG_jpg.rf.2387a9d5e4d69e27f6830ec27a98bd38.jpg\n",
            "DSC02195_JPG_jpg.rf.bbb8b907a96029798df05f99d6d1f3cc.jpg\n",
            "DSC02197_JPG_jpg.rf.47b0d905f40934f35241ccc582daab25.jpg\n",
            "DSC02197_JPG_jpg.rf.6b0b3ac16def24a0d059599795c96cd9.jpg\n",
            "DSC02198_JPG_jpg.rf.1ee5d2e395ba4d11ff2b7b8c1f77c645.jpg\n",
            "DSC02198_JPG_jpg.rf.c87e563587142a1f46deed5ac6dca88a.jpg\n",
            "DSC02199_JPG_jpg.rf.1734a2a07826c42d5689f275e033e85b.jpg\n",
            "DSC02199_JPG_jpg.rf.3160657022c5b876e9f0b1bb0f25fdd4.jpg\n",
            "DSC02199_JPG_jpg.rf.ede00433ad14c677af84e3009b54d01f.jpg\n",
            "DSC02200_JPG_jpg.rf.74591d402c0e607a80bfb0cb7c78e198.jpg\n",
            "DSC02200_JPG_jpg.rf.b93166b6f2d430e3178018eda7972ee1.jpg\n",
            "DSC02202_JPG_jpg.rf.c6a8e99760abb7f6f89bd0cd41fc3620.jpg\n",
            "DSC02203_JPG_jpg.rf.55e7b9af4c5dfed49155123c7c86dfd0.jpg\n",
            "DSC02203_JPG_jpg.rf.6127edf1f883c3787ea6775183ebed82.jpg\n",
            "DSC02203_JPG_jpg.rf.7ee7c74dd7ade90d3632eeee15e95229.jpg\n",
            "DSC02205_JPG_jpg.rf.f06bc85b18e8695e23cf3b6c05a35109.jpg\n",
            "DSC02206_JPG_jpg.rf.247ccc60114a3a7a4c30d93eb8169459.jpg\n",
            "DSC02206_JPG_jpg.rf.55ea7c785927692acd984818f2475825.jpg\n",
            "DSC02206_JPG_jpg.rf.c0d879bade8fe77404d70efea1d25671.jpg\n",
            "DSC02208_JPG_jpg.rf.0b71b9c74a1c4eda7496d3169b95ae84.jpg\n",
            "DSC02208_JPG_jpg.rf.62d2b1fa225f57ab18d25aa8460f85fe.jpg\n",
            "DSC02211_JPG_jpg.rf.60cdfe74cc1999e57ff1cba8dc370fd9.jpg\n",
            "DSC02215_JPG_jpg.rf.03acad28109d3b944d1c176b06d8b16b.jpg\n",
            "DSC02222_JPG_jpg.rf.a9c038782acabda7f28ebc83ec2c6be4.jpg\n",
            "DSC02247_JPG_jpg.rf.196ac8c4bcd873cf8f6e1379952d8c47.jpg\n",
            "DSC02249_JPG_jpg.rf.b0d94259f916e8af14ee2af0adf13679.jpg\n",
            "DSC02257_JPG_jpg.rf.4a0304ad0f08084e81355fb14adba8e3.jpg\n",
            "DSC02285_JPG_jpg.rf.d114ab9d4e49df017c1c5aa0c976c351.jpg\n",
            "DSC02289_JPG_jpg.rf.9249e15147b10b152cba92a9e01902ab.jpg\n",
            "DSC02292_JPG_jpg.rf.fc33b03f8ec32915f5b69eaaa0d15303.jpg\n",
            "DSC02781_JPG_jpg.rf.f284d7c3acfb6b151d78a953a75d4a0b.jpg\n",
            "DSC02802_JPG_jpg.rf.f36e73933ba64d9b0ab86eb9dbd27fb2.jpg\n",
            "DSC02835_JPG_jpg.rf.8df0d132c4266ef0e873547ef3bb1824.jpg\n",
            "DSC02860_JPG_jpg.rf.7eff7d17eaa866318b40d24881dbf5fd.jpg\n",
            "DSC02876_JPG_jpg.rf.4080bb37495d13733d9bcf53c1206551.jpg\n",
            "DSC02913_JPG_jpg.rf.8c105daf556880e6d505ef53a4027ffd.jpg\n",
            "DSC02940_JPG_jpg.rf.9251035866df36f86eb8a4c7fcce4260.jpg\n",
            "DSC02941_JPG_jpg.rf.b2e3aa3150d407392bd1e7ea4a2af6e3.jpg\n",
            "DSC02960_JPG_jpg.rf.8339d9c5f92c41abe52f9e9da050c9d8.jpg\n",
            "DSC03002_JPG_jpg.rf.b9868c6b9f71e9afd3243d26c5c897e3.jpg\n",
            "DSC03004_JPG_jpg.rf.b97be95ee07f0407187437bc98602c89.jpg\n",
            "DSC03012_JPG_jpg.rf.606ae393778d513a344b15e9b141595d.jpg\n",
            "DSC03014_JPG_jpg.rf.ddd413c27a0df05e2f41a95d515e76e1.jpg\n",
            "DSC03027_JPG_jpg.rf.83e5f8643655e0fb6c9e978a277955b5.jpg\n",
            "DSC03029_JPG_jpg.rf.29595e72cccecdcf72eeb71f0cc8d42d.jpg\n",
            "DSC03036_JPG_jpg.rf.b508bfa8b381e0be9c675fb2bf44fc55.jpg\n",
            "DSC03047_JPG_jpg.rf.bc42c73d18c0075d8fc1dcb7325070a7.jpg\n",
            "DSC03059_JPG_jpg.rf.87233ce4759349c5f2afc19e2e2232cc.jpg\n",
            "DSC03062_JPG_jpg.rf.52ae3c8b4d75c0812d267f42549ea472.jpg\n",
            "DSC03064_JPG_jpg.rf.57a84616d05f893025ae939c3b6d0c53.jpg\n",
            "DSC03064_JPG_jpg.rf.f6b0c96183b4fc70b9b68cafee811981.jpg\n",
            "DSC03065_JPG_jpg.rf.06c7890e9cb8ebf63fcedb583260fdf3.jpg\n",
            "DSC03066_JPG_jpg.rf.6b222addb18d347c11e83d5bc661f805.jpg\n",
            "DSC03067_JPG_jpg.rf.1e38fe8713a1170fb75fe18571674041.jpg\n",
            "DSC03069_JPG_jpg.rf.b6132c59451dd2f8cc23f03cc1ff4798.jpg\n",
            "DSC03069_JPG_jpg.rf.cc2d97c13011e7c5761d60f09534daf8.jpg\n",
            "DSC03071_JPG_jpg.rf.6e420b885f5fbd4ca0f8a003ef70155e.jpg\n",
            "DSC03077_JPG_jpg.rf.9fa177a20cd70bc9a31e9a5466669755.jpg\n",
            "DSC03077_JPG_jpg.rf.e647ffcfda261e70e9a2de7d2b91a27d.jpg\n",
            "e12ew_PNG_jpg.rf.510f12e271a1036ecb208efe88687d48.jpg\n",
            "e1asdasd_PNG_jpg.rf.6d505ce8fc69bfd6cdf18ddfc3cad874.jpg\n",
            "e1dasda_PNG_jpg.rf.5a158aaafb64c1f1ef2eb09f08d04893.jpg\n",
            "easdasd_PNG_jpg.rf.fb328e8a87382e6668f49744790c711e.jpg\n",
            "eqwasf_PNG_jpg.rf.e09bf527973843195276e476ea87c8f7.jpg\n",
            "eqweqwe_PNG_jpg.rf.e80d19a93a98c3b2f727ac06c3688885.jpg\n",
            "F1883AW_jpg.rf.badb907b1a5fd3a08b9478f7005da71b.jpg\n",
            "fe-120-ps574_jpg.rf.13773623939ebcbc27a057cb829a9904.jpg\n",
            "Foto0008_jpg.rf.0d35728ec6545085dc35b795722b972a.jpg\n",
            "fqqw_PNG_jpg.rf.7824bd36a9d6f74d6532e2f74a9976a4.jpg\n",
            "fuso-34tb_jpg.rf.9e6acd84ed648835f9440923348eefb3.jpg\n",
            "hanoi-vietnam-january-people-riding-motorbikes-busy-street-hanoi-vietnam-people-riding-motorbikes-busy-street-hanoi-120908376_jpg.rf.ef64f616a7f13a05c918c80ac608f133.jpg\n",
            "Hero-Getting-round-SE-Asia-on-a-scooter-Taiwan-Photo-credit-Unsplash-andrew-haimerl-476824-1920x1080__flip_jpg.rf.6323bd88d6d1c045c48d7177b5964844.jpg\n",
            "Hero-Getting-round-SE-Asia-on-a-scooter-Taiwan-Photo-credit-Unsplash-andrew-haimerl-476824-1920x1080_jpg.rf.d333b80a654bccf344f1efd04bfbfbe5.jpg\n",
            "https___s3-ap-northeast-1-amazonaws-com_psh-ex-ftnikkei-3937bb4_images_5_4_8_1_15041845-4-eng-GB_8D8A8513__flip_jpg.rf.27666698dffd18d17b0298d5e748c3d5.jpg\n",
            "Image_013195_jpg.rf.2684e6c399a6e25cbbd0555ee81cb5ad.jpg\n",
            "images230_jpg.rf.b89dd3d746b418663236f6054271df75.jpg\n",
            "images238_jpg.rf.982c6c257bb280be5599afe390da1898.jpg\n",
            "images240_jpg.rf.ada4e830e738fc691c566323d579bb21.jpg\n",
            "images242_jpg.rf.3c278479604852dfdfceaca85657c936.jpg\n",
            "images269_jpg.rf.71e0f6584ba6007779460a5bdd05c9b2.jpg\n",
            "images278_jpg.rf.e6ed82bee13c8bb9dccd6aeeb84dee39.jpg\n",
            "images298_jpg.rf.111485fda1e5330daf45cfca7c4a6399.jpg\n",
            "images318_jpg.rf.9d13ee592a760e38539440986aa0bd5e.jpg\n",
            "images327_jpg.rf.ff53b3eced8d70474fc352fff2367078.jpg\n",
            "images328_jpg.rf.75cb4d3837667c3b4d60a4ba05d82e71.jpg\n",
            "images339_jpg.rf.cf500bebcbb63d6479c61a6fcd29560a.jpg\n",
            "images346_jpg.rf.384962f5a8f879bd7fec509acd876f74.jpg\n",
            "images348_jpg.rf.798c6c250dc53b5aa5a3b8586fb8d498.jpg\n",
            "images350_jpg.rf.6e91b46c65dd58dccbfb0cc93877d295.jpg\n",
            "images351_jpg.rf.1d786dce82b8eeecc72291bee1492f2d.jpg\n",
            "images367_jpg.rf.af3b672bbc527a27b0d831d513f74c7b.jpg\n",
            "images369_jpg.rf.1d85a3ada588d8c99cb9f31e5affc35c.jpg\n",
            "images376_jpg.rf.cc7a23a8d1565e70887c0f7383221996.jpg\n",
            "images377_jpg.rf.461501e55ed1a9352d75582bc971418d.jpg\n",
            "images381_jpg.rf.ae2a868ab39559ac9964435c3f054ee2.jpg\n",
            "images382_jpg.rf.d840eaaa3add9623764b678ec6bbcb12.jpg\n",
            "images383_jpg.rf.55ac4d5f6a150c2dc6b7f533ab7e401a.jpg\n",
            "images385_jpg.rf.bcb9c702e0594c9db7ec26c97117b385.jpg\n",
            "images387_jpg.rf.ad827a4bdc1f6152952df2b78c79b85d.jpg\n",
            "images391_jpg.rf.058ce59e8d6ecfa5c795974d0335b99b.jpg\n",
            "images400_jpg.rf.bf6c31bdffd49b8cd4807e40dffdd130.jpg\n",
            "images44_jpg.rf.ee46073cbb65e223b7386aabe41c8978.jpg\n",
            "images47_jpg.rf.74db1ee00c5ba98ef5d68fa7b2734b35.jpg\n",
            "images52_jpg.rf.496fa4e1378738e2fea9f8299a29df8e.jpg\n",
            "images54_jpg.rf.f7b85baf743c2fc303acebe6bcaab91f.jpg\n",
            "images56_jpg.rf.00b0fd75dc4dd82c667795de121a961e.jpg\n",
            "images58_jpg.rf.cf02e3f092920628ae4e28bcfdb4c462.jpg\n",
            "images5_jpg.rf.715c92efa61062ac0fd4d101210b21d5.jpg\n",
            "images60_jpg.rf.9972e2453ea2ab14002c1a0a8dbe69fa.jpg\n",
            "images66_jpg.rf.b652d9db174a2da3d89b26fb34c8870f.jpg\n",
            "images67_jpg.rf.deb4c6464b99131a0dd283fb3ba12e15.jpg\n",
            "images6_jpg.rf.8b51f8e1f517248d99e2721d0036a578.jpg\n",
            "images6_jpg.rf.c270508dc9788ba03ee01163d3d66d1e.jpg\n",
            "images74_jpg.rf.fea625f4c1341466fc9795ab110311a1.jpg\n",
            "images85_jpg.rf.a6a2e46886fbf6cba08eb3cede6ecb95.jpg\n",
            "images90_jpg.rf.7fb81feac48f41d564a31b751669c992.jpg\n",
            "images91_jpg.rf.21e15111b2cc030b517ea07ef2f8bd41.jpg\n",
            "images92_jpg.rf.216517b79820f4fd7d77371456940857.jpg\n",
            "images94_jpg.rf.04e3c484dde0adb74a2e419b29618254.jpg\n",
            "IMG-20180108-WA0017_jpg.rf.7a78f60b760844d1a189e6738e8a62f5.jpg\n",
            "IMG-20180108-WA0018_jpg.rf.030755011de1bf0317f673c58fa8e9dd.jpg\n",
            "IMG-20180108-WA0020_jpg.rf.1cf6fb10da2f35ec16bfb3b9f1eefb92.jpg\n",
            "IMG-20180108-WA0022_jpg.rf.552de2b175973a185b52934488ba0510.jpg\n",
            "IMG-20180108-WA0023_jpg.rf.5a3426937735a8d31783d3ebb13483b1.jpg\n",
            "IMG-20180108-WA0024_jpg.rf.318d46fea3ba9e10247210fbe5cce87a.jpg\n",
            "IMG-20180108-WA0026_jpg.rf.b783d55a0b23607d1ad9fd539d8e4ca4.jpg\n",
            "IMG-20180108-WA0028_jpg.rf.d63e32ca1b2a4ebfcf4114d8b13e1278.jpg\n",
            "IMG-20180108-WA0030_jpg.rf.ce57405c48f044084c09fcbd5a06f641.jpg\n",
            "IMG-20180108-WA0031_jpg.rf.772b26d372688bc1609353b640431d89.jpg\n",
            "IMG-20180108-WA0032_jpg.rf.8abdf60c25fd9eb6fbbb9c78d6bf7318.jpg\n",
            "IMG-20180108-WA0033_jpg.rf.a38eac22071f15884e21826fb4c72778.jpg\n",
            "IMG-20180108-WA0034_jpg.rf.c49f6fd261eb4121aa8d30a382c6ebde.jpg\n",
            "IMG-20180108-WA0037_jpg.rf.b53a0fe776ccb7510180418193d6053d.jpg\n",
            "IMG-20180108-WA0041_jpg.rf.cf33f2e6675b7f8adb52b21e0d5043c2.jpg\n",
            "IMG-20180108-WA0046_jpg.rf.21045f648dfe496b95e4f5ad1bf4f9f0.jpg\n",
            "IMG-20180108-WA0048_jpg.rf.ffa3b428fd7ac9b27d8f00df6554c1cf.jpg\n",
            "IMG-20180108-WA0050_jpg.rf.3f738dcea924d543bd2b55d49d90b568.jpg\n",
            "IMG-20180108-WA0051_jpg.rf.bd9fa77892e892ed3a59edfa6f8dcf79.jpg\n",
            "IMG-20180108-WA0054_jpg.rf.74408966fa3fb768aba89dec453b3ce4.jpg\n",
            "IMG-20180108-WA0055_jpg.rf.ed878a87f14ca9582cd3cb1c0504d44c.jpg\n",
            "IMG-20180108-WA0056_jpg.rf.94ff59fd3f73f83168deacc12eff0455.jpg\n",
            "IMG-20180108-WA0057_jpg.rf.62390d18cf751d44b326b6a26692cde6.jpg\n",
            "IMG-20180108-WA0059_jpg.rf.b35a9997f320659316183b4406913ed1.jpg\n",
            "IMG-20180108-WA0060_jpg.rf.f4ffff395b64c173796c94855760c23c.jpg\n",
            "IMG-20180108-WA0062_jpg.rf.7bef2f42ad07b8ba61dfdf44f33cdb5b.jpg\n",
            "IMG-20180108-WA0064_jpg.rf.41d435d89daf5e26f018ff74729cd025.jpg\n",
            "IMG-20180108-WA0066_jpg.rf.7e9a06bff7876f62ec0cf522ead54c5b.jpg\n",
            "IMG-20180108-WA0068_jpg.rf.c9de76f667ba0b7389dba617a8f75a71.jpg\n",
            "IMG-20180108-WA0069_jpg.rf.e49d71cf5a811761308e19a412947960.jpg\n",
            "IMG-20180108-WA0070_jpg.rf.4f68ddc3e4f0714acd24475c641e6608.jpg\n",
            "IMG-20180108-WA0072_jpg.rf.7d971ffeb49d59452491b6b9e8b85f93.jpg\n",
            "IMG-20180108-WA0073_jpg.rf.8ff0cc5283704cfa725625a7e8fbcb88.jpg\n",
            "IMG-20180108-WA0074_jpg.rf.359437c99a878ae15b6cd51a2dd31fbc.jpg\n",
            "IMG-20180108-WA0075_jpg.rf.fb94a2e067827144f78cf7be42db25cc.jpg\n",
            "IMG-20180108-WA0076_jpg.rf.1dce6f416aad46039f6f5ca4d8b44969.jpg\n",
            "IMG-20180108-WA0077_jpg.rf.8be0cc994d91d73c4c61f5d80c4e8e31.jpg\n",
            "IMG-20180108-WA0079_jpg.rf.7a5fdbe014d282da8b5e5b63915ebb7c.jpg\n",
            "IMG-20180108-WA0080_jpg.rf.3fee84a4e53cb84120c2d2d09a7837b6.jpg\n",
            "IMG-20180108-WA0081_jpg.rf.7c25e9c7f19061d73576e4c9707b8a87.jpg\n",
            "IMG-20180108-WA0083_jpg.rf.c64454b495766cf9fbd281a364472753.jpg\n",
            "IMG-20180108-WA0086_jpg.rf.cf9d06806c4d7417b6694e0adc68edd2.jpg\n",
            "IMG-20180108-WA0087_jpg.rf.d06cdeccc353a03c928818248d3a555b.jpg\n",
            "IMG-20180108-WA0090_jpg.rf.4e6c6278d7709301317ecb1c83abf703.jpg\n",
            "IMG-20180108-WA0092_jpg.rf.fdb5766229953a4ff025d20654df5729.jpg\n",
            "IMG-20180108-WA0093_jpg.rf.fad4605fb8445ea51c9b428f0e4cada7.jpg\n",
            "IMG-20180108-WA0094_jpg.rf.8edfdee098fd80a84b621c48d0a0c772.jpg\n",
            "IMG-20180108-WA0095_jpg.rf.a170403bba3df88e4ccb1b98b7ed4a9c.jpg\n",
            "IMG-20180108-WA0096_jpg.rf.f8136b56160072be36b9a1e36133fde5.jpg\n",
            "IMG-20180108-WA0097_jpg.rf.19e74655f9bc348d283c6184ebf45e0d.jpg\n",
            "IMG-20180108-WA0099_jpg.rf.1266aaae400c891df5e7ba5de54e36eb.jpg\n",
            "IMG-20180108-WA0100_jpg.rf.853b1e064e881baaca17bfb19cec2b1e.jpg\n",
            "IMG-20180108-WA0101_jpg.rf.da03c97e1cc17002d46ef1eeb1322e6a.jpg\n",
            "IMG-20180108-WA0103_jpg.rf.55c2e8bc5c463cc1bdc242722a3e67a6.jpg\n",
            "IMG-20180108-WA0106_jpg.rf.f47af757bc5e5e79bf64c5b18b6f7d8e.jpg\n",
            "IMG-20180108-WA0108_jpg.rf.ee0061de23a91a8986a2b23ec387e24c.jpg\n",
            "IMG-20180108-WA0109_jpg.rf.5fca97c9e64be57f94f8ec4a741e6057.jpg\n",
            "IMG-20180108-WA0110_jpg.rf.8c6d62000b32c0164f9c85a32f8a11da.jpg\n",
            "IMG-20180108-WA0112_jpg.rf.ff62583880de58edde4efa24d6a5d807.jpg\n",
            "IMG-20180108-WA0114_jpg.rf.30534e1ca0d3160bfc92977ab4b70447.jpg\n",
            "IMG-20180108-WA0116_jpg.rf.913013f102d7ede3b7f67af3d5bba190.jpg\n",
            "IMG-20180108-WA0117_jpg.rf.fc6dcb6e2ff60ce877507ed2fa2a73db.jpg\n",
            "IMG-20180108-WA0118_jpg.rf.e681dc6cb690c41d58b91449d41eafa3.jpg\n",
            "IMG-20180108-WA0120_jpg.rf.620469e4416b208aa0e81f55cc723dfd.jpg\n",
            "IMG-20180108-WA0121_jpg.rf.62ceb3fb201616285ea391df0e9dc68a.jpg\n",
            "IMG-20211122-WA0006_jpg.rf.fbdd2474022d4c74bb97ee8e6bb3d57e.jpg\n",
            "IMG-20211122-WA0007_jpg.rf.146a5801ccfa56fdab7f04219ae9f6a4.jpg\n",
            "IMG-20211122-WA0008_jpg.rf.26b7c8375a43e7a339cac16acea92e51.jpg\n",
            "IMG-20211122-WA0009_jpg.rf.2a963e88e1f5271539e13e0311cabb53.jpg\n",
            "IMG-20211122-WA0010_jpg.rf.b8538880756e04159eb86f00e14c33b1.jpg\n",
            "IMG-20211122-WA0011_jpg.rf.c8f648eec3ef1af652dd7482bbaf3863.jpg\n",
            "IMG-20211122-WA0012_jpg.rf.6ced5a023b1e8d08eea9655c2e73381c.jpg\n",
            "IMG-20211122-WA0013_jpg.rf.18692e89d84543c99ee900fdbd447285.jpg\n",
            "IMG-20211122-WA0015_jpg.rf.d719acc7a4c8794128232a87abf7ac04.jpg\n",
            "IMG-20211122-WA0017_jpg.rf.d00a9aee5728851152c606a4fa094d86.jpg\n",
            "IMG-20211122-WA0018_jpg.rf.9532f1a73ec32143d8c92b97abd2870d.jpg\n",
            "IMG-20211122-WA0019_jpg.rf.dbcbb91283e0e976861b67bfafc998e3.jpg\n",
            "IMG-20211122-WA0020_jpg.rf.0899704ecb675e9730cab23f31b9f0d4.jpg\n",
            "IMG-20211122-WA0022_jpg.rf.6d5ad74df2459eb13c4de42fda1203c0.jpg\n",
            "IMG-20211122-WA0035_jpg.rf.b1ea24b8d0ca176f829b0d5242e75d75.jpg\n",
            "IMG-20211122-WA0036_jpg.rf.0983d298929f3266d7af30ed63d52f27.jpg\n",
            "IMG-20211122-WA0039_jpg.rf.2cd8fc849d4693a9ff848ff84abdf8c9.jpg\n",
            "IMG-20211122-WA0040_jpg.rf.390ff680dbf171231b6bd8c4d3174c0f.jpg\n",
            "IMG-20211122-WA0041_jpg.rf.a35e52eeaf9c52e3f90d99d8ce4fbbcf.jpg\n",
            "IMG-20211122-WA0042_jpg.rf.995626adae6d9918d629cab64758b77b.jpg\n",
            "IMG-20211122-WA0043_jpg.rf.abc219b455fade7d04960deab1744230.jpg\n",
            "IMG-20211122-WA0044_jpg.rf.061358d688c696305e11e6384d8db4e9.jpg\n",
            "IMG-20211122-WA0046_jpg.rf.d52f541834542dace442a9dcb19e111c.jpg\n",
            "IMG-20211122-WA0047_jpg.rf.f9ef3082530024c06755aa345f18ada9.jpg\n",
            "IMG-20211122-WA0048_jpg.rf.b27264facce411ff04d8d4f9c5b5988c.jpg\n",
            "IMG-20211123-WA0020_jpg.rf.269c12e9e8a7980d9a02a4004acf2861.jpg\n",
            "IMG-20220515-WA0055_jpg.rf.02ed39db26e180334c9d6682b91c4f5c.jpg\n",
            "IMG-20220515-WA0055_jpg.rf.1265f878c2738a05afb44bd484c7ca61.jpg\n",
            "IMG-20220517-WA0021_jpg.rf.4e37f5388a944da9d7a2d62579abfe6a.jpg\n",
            "IMG-20220517-WA0021_jpg.rf.61779b23b52b131ba04b7f0cd0fae9e9.jpg\n",
            "IMG_20220518_203051_jpg.rf.7a9f7a545d9e16f5df0e944fcbf4eb37.jpg\n",
            "IMG_20220518_203105_jpg.rf.2a56a4f6e3f581fd9dfb315c0dd6cc80.jpg\n",
            "IMG_20220518_203148_jpg.rf.c9eaa57699e9571531942cf1459e628d.jpg\n",
            "IMG_20220518_203336_jpg.rf.cb7a449fc9a6cff1dae1ff06ce9017d5.jpg\n",
            "IMG_20220518_203633_jpg.rf.12930935e7f00063efacbf805ea8d478.jpg\n",
            "IMG_5890__flip_jpg.rf.ecc1f5d9a4719d4000fc5270e8a9c901.jpg\n",
            "IMG_5892_jpg.rf.fef98f018a50e6b471b64e5ec2890cf7.jpg\n",
            "IMG_5894_jpg.rf.92ce157568c8b78cb37e4f30b89c9cf7.jpg\n",
            "IMG_5895_jpg.rf.c823ad55045c16edc5a5d672b8287c31.jpg\n",
            "IMG_5898__flip_jpg.rf.0afdb3bb8b48f716aa5f2460088f6b7b.jpg\n",
            "IMG_5899_jpg.rf.56d4df1ea98e8da23de6a1b9e45e992d.jpg\n",
            "IMG_8354_jpg.rf.7b2afd1806bc88297bc43cfb8c6029b1.jpg\n",
            "IMG_8372_jpg.rf.b5fbfceb88465bf197869d98b24d1096.jpg\n",
            "IMG_8388_jpg.rf.02ebe5ebc0f4810952defb577df33370.jpg\n",
            "IMG_8401_jpg.rf.43acbd3344363719c8e519270e42cbad.jpg\n",
            "IMG_8409_jpg.rf.f3e275c3ff25958afa627666129cd37c.jpg\n",
            "IMG_8417_jpg.rf.3d95c018bdc69f3d98e3c270c966a68f.jpg\n",
            "IMG_8467_jpg.rf.385c02259f6425da605f3db6f05c8b23.jpg\n",
            "IMG_8469_jpg.rf.8b44875d0320b280cbaa0eebbd040356.jpg\n",
            "img-p1651820217548-2_haxe3b_jpg.rf.2f854e7598a4977e8872bdde91e9153d.jpg\n",
            "img-p1652107308949-1_xwovs6_jpg.rf.7391ce1c696093b437ced6bf951f6af8.jpg\n",
            "img-p1652107308949-2_acmddq_jpg.rf.64d29a4861693d4a20e6cbad5ea2fc6f.jpg\n",
            "img-p1652158769921-1_bzzoyi_jpg.rf.4ef1e493b81a2eefbaaefc1498e7f12e.jpg\n",
            "img-p1652158769921-1_bzzoyi_jpg.rf.b3f4862f89b25411d16a0f689dd7f346.jpg\n",
            "img-p1652159099741-1_yrdmem_jpg.rf.3c0030b2a831ab6dbea33bd3210a347d.jpg\n",
            "img-p1652159099741-2_kct1x8_jpg.rf.9fc367c1739d727acbd9de479a3e1037.jpg\n",
            "img-p1652159099741-2_kct1x8_jpg.rf.c88222fdec995a7c52893f5e55508445.jpg\n",
            "img-p1652170725870-1_wvshgl_jpg.rf.6dbac6e2e0330348759f982d4eb185a8.jpg\n",
            "img-p1652170725870-1_wvshgl_jpg.rf.9dcf0035528d1ecb39444cca370bb4b7.jpg\n",
            "img-p1652234792788-1_rgesaj_jpg.rf.5fce5a1ceb2b222be33a8e7d7ee219ff.jpg\n",
            "img-p1652234792788-1_rgesaj_jpg.rf.795325a482aa4c6574899c3215a51d7e.jpg\n",
            "img-p1652234792788-2_x2ivdk_jpg.rf.fde906728aa9595d61976553ff2f23f2.jpg\n",
            "img-p1652263017285-1_fli5yi_jpg.rf.d6c0266da90ab7be5ea3f3ddf636dc7a.jpg\n",
            "img-p1652320270036-1_qdbazn_jpg.rf.c0a7d698ded770dfd98cdf4f77adb9c6.jpg\n",
            "img-p1652320270036-2_k8tanl_jpg.rf.c0aa750fbc2eed4ac94ec23db7595850.jpg\n",
            "img-p1652329424223-1_hjomi7_jpg.rf.be09fdb9b93f44651b11b2d3a9d8a0d9.jpg\n",
            "img-p1652331040084-1_rdmc94_jpg.rf.7d621d026e48ae28a981a1b1e46bcf34.jpg\n",
            "img-p1652331040084-2_hrr7bj_jpg.rf.18d1326c44e380a7b84c05ce759e6b0b.jpg\n",
            "img-p1652333486992-2_gxnw20_jpg.rf.ad5ddcfe0e2a6d22cd34402e7d645792.jpg\n",
            "img-p1652339531515-1_zvybsy_jpg.rf.d9190103931804c13fc60bc988906cc3.jpg\n",
            "img-p1652342497571-1_pbcwh9_jpg.rf.b036c98df53f6de09c4ba1fd83ecf88c.jpg\n",
            "img-p1652342497571-2_lahfkd_jpg.rf.9c2a8d5a06c95811a931dee75cc09bf9.jpg\n",
            "img-p1652354746041-2_bz3rmj_jpg.rf.d0b11cd7c791f2fe768da7fd7974ad67.jpg\n",
            "img-p1652354746041-2_bz3rmj_jpg.rf.f8ea84779badfe33a0c0b9807b55147e.jpg\n",
            "img-p1652445794492-1_iyrvf7_jpg.rf.171702a30dbf3ed38e88323c16394c7a.jpg\n",
            "img-p1652446607682-1_vhyo46_jpg.rf.792eaeca08a01d060c28268ad1afa8cc.jpg\n",
            "img-p1652446607682-2_idxdcx_jpg.rf.e19a07219dd42f38121441408c544406.jpg\n",
            "img-p1652454297915-1_htjzsx_jpg.rf.6a61eff0dab431907894b79266d7a4e8.jpg\n",
            "img-p1652454297915-1_htjzsx_jpg.rf.d7ddc586a269131bc5d253d8c49f800f.jpg\n",
            "img-p1652454297915-2_phw14k_jpg.rf.15e50d5b1825b60b5f6b1c6e16f97ffe.jpg\n",
            "img-p1652545847960-2_qebtrh_jpg.rf.196fce1b9946d1939019c11b3f428e04.jpg\n",
            "img-p1652706727912-2_binchc_jpg.rf.87b47f359d78da440f2df37edb148b02.jpg\n",
            "img-p1652706727912-2_binchc_jpg.rf.ecaa043827b8bc1eb680218047bbe9f6.jpg\n",
            "img-p1652713533367-2_gdciz7_jpg.rf.08ca0b28bca247580ea4845a7bcfcbc6.jpg\n",
            "img-p1652713533367-2_gdciz7_jpg.rf.ef3cf98acba2b3a4851e377ca278533f.jpg\n",
            "img-p1652773434128-2_nguqqm_jpg.rf.4cbdedfd41fa9e0bff63446a726a8a6a.jpg\n",
            "img-p1652773434128-2_nguqqm_jpg.rf.71c03d4f4cf383edaa895b77988e4c3e.jpg\n",
            "img-p1652775611668-1_hydn6i_jpg.rf.2eb8fafb40b5993fff051106a78b1d49.jpg\n",
            "img-p1652857474976-1_nvwznb_jpg.rf.05faa05d603af0ead9a4b3e4c2d9cb32.jpg\n",
            "img-p1652857474976-2_t9akoc_jpg.rf.5741c21d712ede3a7fbeb97ae6a199b2.jpg\n",
            "img-p1652857474976-2_t9akoc_jpg.rf.5869fc156c4b13c6a694d4cc6a2eccec.jpg\n",
            "img-p1652857847718-1_icriyb_jpg.rf.622fdb49da48d898f1a9a24d7ac4fe75.jpg\n",
            "img-p1652857847718-2_jmjvel_jpg.rf.677dc7afacfda44f94ec71306e756f8a.jpg\n",
            "img-p1652857847718-2_jmjvel_jpg.rf.98150414a7f849f4d4495fa994808071.jpg\n",
            "img-p1652875748731-1_k64hdi_jpg.rf.b8589ea43372a452d68e4c0bd929bcc9.jpg\n",
            "img-p1652875748731-2_mhqg1n_jpg.rf.5dabc5f4e57c0f18cb82bbc0c79b75fc.jpg\n",
            "img-p1652885548798-1_bbhow8_jpg.rf.00c8d7073807c25aba112444049a0bee.jpg\n",
            "img-p1652885548798-1_bbhow8_jpg.rf.73507eed510c8362a2772bf5a2ab7ec3.jpg\n",
            "img-p1652889006582-2_cy7uno_jpg.rf.0448ae2953e38c978a2afafb2b1bf887.jpg\n",
            "img-p1652889006582-2_cy7uno_jpg.rf.b9262a9a0784ff2f8f2b9fe9af123a8b.jpg\n",
            "img-p1652889315521-2_hmgx0d_jpg.rf.2033d4a329d4e5c2cf88aaa52b2d0897.jpg\n",
            "img-p1652889315521-2_hmgx0d_jpg.rf.98f06ab1082e52b2570f9e996e7f989b.jpg\n",
            "KB1081ON_jpg.rf.3f48d25d8fb3254c38f2bc9c8ea3f5f1.jpg\n",
            "KB1081ON_jpg.rf.7c3e58545213457850f068b3fb29e942.jpg\n",
            "L1072AAN-1-_jpg.rf.7e320d261e55cf55e034c63bb4049b19.jpg\n",
            "L1090LY_jpg.rf.156c6d1833d988f2ae0581043f7c85df.jpg\n",
            "L12UL_jpg.rf.10fb6228dad6274dfdaf9b469389b9c2.jpg\n",
            "L12UL_jpg.rf.d26b4387a7f63b1788d3fb9a0bcd3d66.jpg\n",
            "L1564CZ-1-_jpg.rf.1db8901c6e2014de5ad7014c87aed139.jpg\n",
            "L1564CZ-1-_jpg.rf.653f29ebb43feaec08d1e26dabec81c2.jpg\n",
            "L1604AE_jpg.rf.72a7d466a65487da199ec26c8fa3e3d6.jpg\n",
            "L9069GJ_jpg.rf.ec35f76c88b5194e4f0fc865b5702b3a.jpg\n",
            "maxresdefault-990x556-1_jpg.rf.b251eb1f6858ff4600c295dcc7316bd5.jpg\n",
            "maxresdefault_jpg.rf.62f864297a3b1697f0b8cc6f5708987f.jpg\n",
            "mini-tesla-model-s-for-kids-inset-license-plate-model-910_jpg.rf.655555a9e45cc984fa4d36f7d1d8b089.jpg\n",
            "Mobil-102-_jpg.rf.a037b7077d7e78bcd2a1a63c2ccc6519.jpg\n",
            "Mobil-103-_jpg.rf.78a9bbd33001832161f38029dcde5784.jpg\n",
            "Mobil-105-_jpg.rf.ac61ee38698de30357f2e4bcb273ad06.jpg\n",
            "Mobil-106-_jpg.rf.7b812fb8cc42591a7046d550607d1d6f.jpg\n",
            "Mobil-107-_jpg.rf.0c06ab460bbcaf7148ce0140ba4f53db.jpg\n",
            "Mobil-108-_jpg.rf.d776796e38ce6b35f5fd47be97698b87.jpg\n",
            "Mobil-10-_jpg.rf.b436e5f612c34c415f778ea28a82c62f.jpg\n",
            "Mobil-110-_jpg.rf.58a8ca667909340ad3f69d3f2e3109d9.jpg\n",
            "Mobil-111-_jpg.rf.13149f74e2d2cbfd9c4324896e1e318e.jpg\n",
            "Mobil-112-_jpg.rf.057a19da9ddbb41ee17488653ee315cb.jpg\n",
            "Mobil-113-_jpg.rf.cd53871c2d22d5108623ab5954873f81.jpg\n",
            "Mobil-114-_jpg.rf.9ebc39ade0f94a8d997554ff67fddc9d.jpg\n",
            "Mobil-115-_jpg.rf.585eecee4edd26c6114f589b83aee207.jpg\n",
            "Mobil-116-_jpg.rf.7e5c1f8f68403c0f6a02c5b2360d5d6c.jpg\n",
            "Mobil-117-_jpg.rf.edce1ff9c9b83a84a580c482d9e2a259.jpg\n",
            "Mobil-118-_jpg.rf.0be3b05521ce5667da3a30436871923c.jpg\n",
            "Mobil-119-_jpg.rf.5e02ac58d53abae62382610da2873be2.jpg\n",
            "Mobil-11-_jpg.rf.d805c754d37be05f191865d539d7b2a1.jpg\n",
            "Mobil-120-_jpg.rf.3e066ed03eca34719937fc5dbbeacec9.jpg\n",
            "Mobil-124-_jpg.rf.c0cf7de9b73fe3d6169fd701aafe096d.jpg\n",
            "Mobil-125-_jpg.rf.511e594f18beb270637a976dbe2864cd.jpg\n",
            "Mobil-127-_jpg.rf.a987536b66ecc8869398e209b58397af.jpg\n",
            "Mobil-128-_jpg.rf.3298b87456d5c69e7891adb6896eea1d.jpg\n",
            "Mobil-131-_jpg.rf.751ce1133321aa53efd3bd09c32ffdbd.jpg\n",
            "Mobil-132-_jpg.rf.fa518cd5a264429098b0dcf68ba4d634.jpg\n",
            "Mobil-133-_jpg.rf.3f95d9dd6dc081322c5c8096ef15742c.jpg\n",
            "Mobil-134-_jpg.rf.ab0db4abf1e448f55d9abdbd010993cf.jpg\n",
            "Mobil-135-_jpg.rf.465ca150d4a669ca936ff73ca9a1b7ae.jpg\n",
            "Mobil-136-_jpg.rf.abe980c433ec6720c340a9d7c3535781.jpg\n",
            "Mobil-138-_jpg.rf.04998c6c2d3f7c82ddd4f4622d680e8a.jpg\n",
            "Mobil-139-_jpg.rf.98e082322ad7b5db806a0170745f2582.jpg\n",
            "Mobil-13-_jpg.rf.f9b89bb1be444cbf979c08c08cdc4803.jpg\n",
            "Mobil-140-_jpg.rf.65701d0a0b1627caf3ac57bf037cc9d5.jpg\n",
            "Mobil-141-_jpg.rf.c389dadc10afd64c5ee5f71337641aef.jpg\n",
            "Mobil-142-_jpg.rf.6d9f8425aed5c97cfa43140c9a0e2773.jpg\n",
            "Mobil-144-_jpg.rf.2ca2037d08c8d870db3fcf3a70e3c584.jpg\n",
            "Mobil-145-_jpg.rf.03b5b701268d2f38757c61d8217a032b.jpg\n",
            "Mobil-149-_jpg.rf.a17b9e232531a332f2a3d86ba64bfbb9.jpg\n",
            "Mobil-150-_jpg.rf.953631d3a4f93bb1ee641a561f910b4e.jpg\n",
            "Mobil-151-_jpg.rf.eba11b69900edec56f9b060ace7790d7.jpg\n",
            "Mobil-152-_jpg.rf.8ef5b6058bedd305b1c60bc10605b16a.jpg\n",
            "Mobil-154-_jpg.rf.c0ac0bd74fbbead80e16cc040c7ddd90.jpg\n",
            "Mobil-155-_jpg.rf.8884aec304f28100d337bc9f7062a56e.jpg\n",
            "Mobil-156-_jpg.rf.981e5859b8b05fab53cd2eee5494fad2.jpg\n",
            "Mobil-157-_jpg.rf.007d0c555d5834f07c1a3fad2f0451ad.jpg\n",
            "Mobil-159-_jpg.rf.13eab0d8fc206f6a02d60bfefcb4d4f4.jpg\n",
            "Mobil-160-_jpg.rf.11b398a685b288d5d16fc3fdf2a93c5a.jpg\n",
            "Mobil-162-_jpg.rf.f8ccaef8e25ccdb4261ed22bb81df36d.jpg\n",
            "Mobil-163-_jpg.rf.8c7600e83cf0085210d7e7a86bff79ce.jpg\n",
            "Mobil-164-_jpg.rf.f730dbd1b10413b24afc30fc3d15db57.jpg\n",
            "Mobil-165-_jpg.rf.502d00d24953e3cf06da98567cfab3dd.jpg\n",
            "Mobil-166-_jpg.rf.576bc44e3fb94708debfc17328ea9d30.jpg\n",
            "Mobil-169-_jpg.rf.696c138d7b16916db7003ba0ecbbdaef.jpg\n",
            "Mobil-16-_jpg.rf.c2507bb76450d0a66d8a4f46a1cbce18.jpg\n",
            "Mobil-170-_jpg.rf.a3d12be26696275ca298791c83486123.jpg\n",
            "Mobil-171-_jpg.rf.ce7af88601da3aa5c5097bda69f941e3.jpg\n",
            "Mobil-175-_jpg.rf.e1297c9ca3bc3df713394dd1f26fc2c0.jpg\n",
            "Mobil-176-_jpg.rf.130ec9cd4647a429b764bf55f51daa26.jpg\n",
            "Mobil-177-_jpg.rf.7def497ad1ee68a8a192d99dca9f5e46.jpg\n",
            "Mobil-178-_jpg.rf.d4bc8bb5deeb9d779259076dbc652c9e.jpg\n",
            "Mobil-179-_jpg.rf.0f911406fe71d1304e5a09e09c26ff83.jpg\n",
            "Mobil-17-_jpg.rf.051e1b68d47e623bca27cbfbc96fb9e2.jpg\n",
            "Mobil-180-_jpg.rf.12fa7304b090988a780838703d75187b.jpg\n",
            "Mobil-181-_jpg.rf.f7b565449813e0a589f14ce9dd16da59.jpg\n",
            "Mobil-182-_jpg.rf.4e2dc681b11c6ee684b5e28177632094.jpg\n",
            "Mobil-183-_jpg.rf.46b96c1deab13ea48bd8b2c888c44c67.jpg\n",
            "Mobil-185-_jpg.rf.45a29bb13dad37d9f2c07930b7184ee5.jpg\n",
            "Mobil-186-_jpg.rf.8a13f9d5015b4e6dfd63aa1df3102a52.jpg\n",
            "Mobil-18-_jpg.rf.20d5e3d0ec0ea3c6ef7999b27d81f174.jpg\n",
            "Mobil-191-_jpg.rf.bc8de7ff32f0bf334dc86554a5f0e7a4.jpg\n",
            "Mobil-192-_jpg.rf.e7d9bdef4f789683c8692b44ac8dfa0a.jpg\n",
            "Mobil-193-_jpg.rf.51e8868abb53022b6eb514ed1543e011.jpg\n",
            "Mobil-196-_jpg.rf.867cb65989e4e0c78ed9b41e2a1f67a0.jpg\n",
            "Mobil-197-_jpg.rf.59dca7305fb6eb13eeffb8f3887a0db5.jpg\n",
            "Mobil-198-_jpg.rf.2a88710a8de00e52549b3baab075f47f.jpg\n",
            "Mobil-199-_jpg.rf.d1a79c3be8ba19bd39fb11d63a6f7eba.jpg\n",
            "Mobil-19-_jpg.rf.f54d657d8115becd689f2a67a5a3a58f.jpg\n",
            "Mobil-201-_jpg.rf.7aeb3c7b74e9da70163ea87f2aa96ac0.jpg\n",
            "Mobil-202-_jpg.rf.9b29b24c8487c1b90d7ae4c8ac15e963.jpg\n",
            "Mobil-203-_jpg.rf.084a37c78837b2f04eb435a3e1ad0709.jpg\n",
            "Mobil-204-_jpg.rf.3d67c8562c72f27b19a0d034df6e182f.jpg\n",
            "Mobil-205-_jpg.rf.36689dc0cfd886b098190d11bf482526.jpg\n",
            "Mobil-206-_jpg.rf.d08fdb32852c77ef081d55da8a68ac3f.jpg\n",
            "Mobil-207-_jpg.rf.299e1ec00ed9b36f5335f5ef2b3b5186.jpg\n",
            "Mobil-209-_jpg.rf.36dd3e2eac6395cab4b0fb4de1b925ca.jpg\n",
            "Mobil-20-_jpg.rf.64d77de76e5fcbfb7ef3213d7abccddb.jpg\n",
            "Mobil-210-_jpg.rf.78e67f8a8f711861b1da7362028c4df5.jpg\n",
            "Mobil-211-_jpg.rf.5b5fa137241d2c792d84edafa9cd7172.jpg\n",
            "Mobil-212-_jpg.rf.e76021d1e44a557ff01e5d69d857e721.jpg\n",
            "Mobil-214-_jpg.rf.48669d5bc3ed1ebfa806838ee6680a2c.jpg\n",
            "Mobil-215-_jpg.rf.f92e4b952cbfe4c601d3494e36e49313.jpg\n",
            "Mobil-216-_jpg.rf.165429663924694caa707d3840668e3b.jpg\n",
            "Mobil-217-_jpg.rf.d6a26076cbe40c80ae4efd726318b584.jpg\n",
            "Mobil-219-_jpg.rf.d4ef94c1c2d4bec48f263b4962fcfae0.jpg\n",
            "Mobil-21-_jpg.rf.4ede8639273ee8261df6bdfe65aeb2e9.jpg\n",
            "Mobil-220-_jpg.rf.4cfdfa739b9b96c51fe2cd8f13a3a7d4.jpg\n",
            "Mobil-221-_jpg.rf.113e11eac40b8a6b51d1c22f40110590.jpg\n",
            "Mobil-222-_jpg.rf.3596ac33e8893321246f597812d7cf4a.jpg\n",
            "Mobil-223-_jpg.rf.4d50bd7f556ae4d73033aa0a0b9e5178.jpg\n",
            "Mobil-225-_jpg.rf.4c4c721ed97a70f88bec25aaee0f3134.jpg\n",
            "Mobil-227-_jpg.rf.f72c5fdf1f1b7a972a5b15cb06bba0b4.jpg\n",
            "Mobil-228-_jpg.rf.8a379ad7fb8ebfe11fc1d8a77e12fb14.jpg\n",
            "Mobil-229-_jpg.rf.581085b941f72e4340dd1b99bac624a4.jpg\n",
            "Mobil-230-_jpg.rf.d55c9ff4ae7eb6b81ef7a98544ae87f8.jpg\n",
            "Mobil-232-_jpg.rf.28ad1b989e8d4a1dc37c71252a63edde.jpg\n",
            "Mobil-234-_jpg.rf.3ac9bad197b615fed19cc8d3b8435d11.jpg\n",
            "Mobil-235-_jpg.rf.92050fe571a5d8d603b00f1a0a1d4e62.jpg\n",
            "Mobil-236-_jpg.rf.d00bbfc8fa87a57a4092c4f70fcb99f5.jpg\n",
            "Mobil-237-_jpg.rf.9121e3ac6ebc4488f995aaed11562b8e.jpg\n",
            "Mobil-239-_jpg.rf.aeb882cdff46652c1709fe3c925416bb.jpg\n",
            "Mobil-240-_jpg.rf.933c020db5203e7a79fa59db10e04ddd.jpg\n",
            "Mobil-241-_jpg.rf.2e4d012b91a77bbcb1382bcc8dd50287.jpg\n",
            "Mobil-242-_jpg.rf.66f549afd2ddb75fa51c96637b136057.jpg\n",
            "Mobil-243-_jpg.rf.975c580d1aeba92c84084112cd9bbec8.jpg\n",
            "Mobil-244-_jpg.rf.b2f779031a669416fb387e396b632621.jpg\n",
            "Mobil-248-_jpg.rf.57ce99d6c92aacb2984e52eb0dc006c8.jpg\n",
            "Mobil-249-_jpg.rf.82be795f440fc9be8f925e274d2bfad0.jpg\n",
            "Mobil-250-_jpg.rf.824d5ee974d876ada1f597e5d6715a1f.jpg\n",
            "Mobil-254-_jpg.rf.f3bf6d8846127be5507ae789aa618079.jpg\n",
            "Mobil-256-_jpg.rf.0abd4ef543bdb51f2f0c2a15b41b1436.jpg\n",
            "Mobil-258-_jpg.rf.99a7a32d05529f29bb9140a3b7132266.jpg\n",
            "Mobil-25-_jpg.rf.49cfd55dba33fe96c08840500a8da65f.jpg\n",
            "Mobil-260-_jpg.rf.3b9080ee3fc0eee185490dcb06569f08.jpg\n",
            "Mobil-261-_jpg.rf.78fa6aa4dc0c0f9e0667670a94e58f2d.jpg\n",
            "Mobil-262-_jpg.rf.1dc106f80e44f37566f237abe7a5bd27.jpg\n",
            "Mobil-263-_jpg.rf.936f98b7570d6e5de4db0cbd5e5cff17.jpg\n",
            "Mobil-264-_jpg.rf.28da753c7ce01de8cc71d442a8024354.jpg\n",
            "Mobil-267-_jpg.rf.5f5aa6b07a7443262443abfc6626bf14.jpg\n",
            "Mobil-269-_jpg.rf.91cfc563081cfa653d2ffa127c79d749.jpg\n",
            "Mobil-26-_jpg.rf.7961ae5894306109f5f91c71d77019b6.jpg\n",
            "Mobil-270-_jpg.rf.eb95f928a7d6b258ce7fa779c07f1fa2.jpg\n",
            "Mobil-271-_jpg.rf.4da0fcd54420aee29a2cf13346576702.jpg\n",
            "Mobil-272-_jpg.rf.e3f697f2e6dec71e0e27d4b278716844.jpg\n",
            "Mobil-273-_jpg.rf.60525c85b9b11b044bdd9e3f62309292.jpg\n",
            "Mobil-274-_jpg.rf.39a83e0252ae0e57e179f55f493d403b.jpg\n",
            "Mobil-276-_jpg.rf.2d550e6f798cbebeb402fe09a3ddcd2f.jpg\n",
            "Mobil-277-_jpg.rf.41b58672611944ecd2f58fd6ef9d2f80.jpg\n",
            "Mobil-278-_jpg.rf.1d369aa73d713950ef1b9fa3f6cd452b.jpg\n",
            "Mobil-279-_jpg.rf.c437892641bb4452c444a2889af0be6d.jpg\n",
            "Mobil-27-_jpg.rf.9c651acd6a4a485e67148327985996d4.jpg\n",
            "Mobil-281-_jpg.rf.160c0952b54d24e1378c492b403f9e2c.jpg\n",
            "Mobil-283-_jpg.rf.9b65c969476644eb9ffb61bcced695b5.jpg\n",
            "Mobil-284-_jpg.rf.3f9ba9c807eeee0a761f26633b5a274c.jpg\n",
            "Mobil-285-_jpg.rf.c229e950e998e243348e2fbfb900e287.jpg\n",
            "Mobil-286-_jpg.rf.fd134ddd0025b610eb16923043cbd6a3.jpg\n",
            "Mobil-287-_jpg.rf.0c9defc4fc8c6e3f4eb6a3eaacc5d0db.jpg\n",
            "Mobil-289-_jpg.rf.29ec01758b1a6aee01687dac083826a6.jpg\n",
            "Mobil-291-_jpg.rf.76d09359e0eb249dfa9f0fb56340f0a5.jpg\n",
            "Mobil-292-_jpg.rf.7166e5e0042c41d7a0e3841a76d29176.jpg\n",
            "Mobil-293-_jpg.rf.d10ce6192bcc0f2f57f0707fa3f1c187.jpg\n",
            "Mobil-294-_jpg.rf.e6edbbb0ded8898a852d7d935945dfc7.jpg\n",
            "Mobil-295-_jpg.rf.9a8c84d11f135c3f525244473a64d035.jpg\n",
            "Mobil-296-_jpg.rf.2fcae7e93dbb92d3bd13d501ca5e1bcd.jpg\n",
            "Mobil-297-_jpg.rf.654f4ed4ccd33d5e63a22800e6266752.jpg\n",
            "Mobil-298-_jpg.rf.ea882be608e1448a737e14c3277baadc.jpg\n",
            "Mobil-29-_jpg.rf.36d03433818a108ed340ab0f9dbcc7e4.jpg\n",
            "Mobil-2-_jpg.rf.0c3377b04db30e0e1b1896a3737dcad1.jpg\n",
            "Mobil-301-_jpg.rf.aebae25d6d44bb5f347048bb769fb69e.jpg\n",
            "Mobil-302-_jpg.rf.d312745495ff49c63920e21610f6698c.jpg\n",
            "Mobil-304-_jpg.rf.ffe7ea961ba08909d3946776055dd8bc.jpg\n",
            "Mobil-306-_jpg.rf.fef77a12d15f55008bbcaa96fcbe747b.jpg\n",
            "Mobil-307-_jpg.rf.271bddc3c63bab49b5a031828f567389.jpg\n",
            "Mobil-308-_jpg.rf.07cd7ed40b87bc2266090012bce3f880.jpg\n",
            "Mobil-310-_jpg.rf.0af8dc80f36a671033124e7f478c7cf9.jpg\n",
            "Mobil-311-_jpg.rf.258a8c5c9fd03e03bb25c736ddf74fe1.jpg\n",
            "Mobil-314-_jpg.rf.3ce685755b221289f7c9e7529888a51f.jpg\n",
            "Mobil-315-_jpg.rf.6a820e91c353db05f1e5cb85b0598477.jpg\n",
            "Mobil-316-_jpg.rf.1f34fa4402542c328a863a685a69a7af.jpg\n",
            "Mobil-317-_jpg.rf.243f9d47fdf245a0e559b4e0140cee1f.jpg\n",
            "Mobil-318-_jpg.rf.7879130b5fc8b5c37ca0665e6913aee8.jpg\n",
            "Mobil-319-_jpg.rf.ac10b4e36e732830423d3101cc756896.jpg\n",
            "Mobil-31-_jpg.rf.2adc32c078d445310ab8a6a16eff90d6.jpg\n",
            "Mobil-320-_jpg.rf.4c2658d1d49f6019195cde725db2974d.jpg\n",
            "Mobil-321-_jpg.rf.e1f6fb656fa5fb7e09cadcb27e041660.jpg\n",
            "Mobil-322-_jpg.rf.e368c2344acae70b2052329452077a86.jpg\n",
            "Mobil-323-_jpg.rf.bce973b5c75321d070b019caa102b241.jpg\n",
            "Mobil-324-_jpg.rf.a618de464b94ccb39f8a59a44fe24d03.jpg\n",
            "Mobil-325-_jpg.rf.72735bc8180abcf4ea34bd971c795ae8.jpg\n",
            "Mobil-326-_jpg.rf.7a3e08631f02c772f0bc2af09d8c74c9.jpg\n",
            "Mobil-327-_jpg.rf.61fbc8ea89dfd989fce3733d671e999d.jpg\n",
            "Mobil-330-_jpg.rf.fcc915c06489589a631aa22ca49786a6.jpg\n",
            "Mobil-331-_jpg.rf.724ee7865ae9adb274d54c03caa64385.jpg\n",
            "Mobil-332-_jpg.rf.6855c3e9e8f3ed49b2defd34d8360894.jpg\n",
            "Mobil-333-_jpg.rf.327a709d25840da7af1dd84cca04d8a2.jpg\n",
            "Mobil-335-_jpg.rf.b334ceaaaf9c90785a1791d04d9a1cc5.jpg\n",
            "Mobil-338-_jpg.rf.1bde9cc69ed2664f2174a77898b53fb8.jpg\n",
            "Mobil-339-_jpg.rf.5b441bc6cfaa1c97b11c1c4e27932cd8.jpg\n",
            "Mobil-340-_jpg.rf.8368e9deeadf6d6c9f91ae8542bdd20e.jpg\n",
            "Mobil-342-_jpg.rf.c9eb3e6e05afd63eef5b6fcaf0216be1.jpg\n",
            "Mobil-343-_jpg.rf.6c776ea34cef5324d48d74a386cf3a55.jpg\n",
            "Mobil-345-_jpg.rf.430f4939626308d730ddf440e146ecfc.jpg\n",
            "Mobil-347-_jpg.rf.3af04eb89e6668560f973ce4c3c3bd25.jpg\n",
            "Mobil-348-_jpg.rf.6117ba52869fc1196ca395993986f41e.jpg\n",
            "Mobil-34-_jpg.rf.389f2d6037637d8e837c43a7fa867200.jpg\n",
            "Mobil-350-_jpg.rf.3d475edae6ebbbc64f8473a03334ff4a.jpg\n",
            "Mobil-351-_jpg.rf.e2f32f0963275ce1b6669d1bb4048f1e.jpg\n",
            "Mobil-353-_jpg.rf.026359150e8b2d4902d5565a325d0a49.jpg\n",
            "Mobil-354-_jpg.rf.cd9133028194897fbbead4407673105b.jpg\n",
            "Mobil-356-_jpg.rf.7093ddc03116a174da9843b44df4d292.jpg\n",
            "Mobil-357-_jpg.rf.c2791ed044bcc76f735d0a1fda45dd25.jpg\n",
            "Mobil-358-_jpg.rf.3233ddf29c6ad9001c83a105140ab249.jpg\n",
            "Mobil-359-_jpg.rf.fbf6c76523c787b93b9078c88d01992d.jpg\n",
            "Mobil-361-_jpg.rf.55eb200a48fa5704113f456b489c2410.jpg\n",
            "Mobil-362-_jpg.rf.5c7a159d1649f56f65e64d6ce7b30c67.jpg\n",
            "Mobil-363-_jpg.rf.b7645ea4bb168445eb81e9a9a25bd34c.jpg\n",
            "Mobil-365-_jpg.rf.a70d41f3f3c16bd1842e4788a4f7410a.jpg\n",
            "Mobil-366-_jpg.rf.6f1830c77fab8690c26128b902c779c3.jpg\n",
            "Mobil-367-_jpg.rf.621d1bae0314efd4b84c493528e8b925.jpg\n",
            "Mobil-368-_jpg.rf.a23ba7bb160e47ac61ace1b234600afc.jpg\n",
            "Mobil-369-_jpg.rf.3966a8543f80df7b5989f13c863afb70.jpg\n",
            "Mobil-36-_jpg.rf.e319d7e68c6847c8ffc63056626c1267.jpg\n",
            "Mobil-370-_jpg.rf.ab46f3e008813baf82dcb9e80ba21621.jpg\n",
            "Mobil-372-_jpg.rf.aae61b7d441b326dd924579f35d848a7.jpg\n",
            "Mobil-374-_jpg.rf.a05999a805f6cb9a811ed2dddaf79774.jpg\n",
            "Mobil-375-_jpg.rf.43ad4d8e438beb8073e812562d93ab2a.jpg\n",
            "Mobil-37-_jpg.rf.e5ec30b50ab8a41b8d28772f8395bc3d.jpg\n",
            "Mobil-38-_jpg.rf.995b271729886446b17d26eacef13520.jpg\n",
            "Mobil-39-_jpg.rf.cbd224191a3d618c9ad8bc69f9b5ebed.jpg\n",
            "Mobil-40-_jpg.rf.99246ea303b885637cf7104362ad4ee0.jpg\n",
            "Mobil-41-_jpg.rf.760554dfd99766ab653ce520da780899.jpg\n",
            "Mobil-42-_jpg.rf.85d0427eb4a3b8f415f3d5c9124bbb95.jpg\n",
            "Mobil-44-_jpg.rf.91dea2a121723e19c2ddfdafc28ff3f7.jpg\n",
            "Mobil-47-_jpg.rf.60c17d12d31a6cdbba1ed1cff906da45.jpg\n",
            "Mobil-48-_jpg.rf.d50bfcdc24fabfcd613243843adea722.jpg\n",
            "Mobil-49-_jpg.rf.f5c0ab8250416b22a69ad6b0e9c4a43d.jpg\n",
            "Mobil-4-_jpg.rf.e309e1f3b22a7cb6157147113b0564a1.jpg\n",
            "Mobil-50-_jpg.rf.33ca56af79530b69fd672be2028da0bb.jpg\n",
            "Mobil-51-_jpg.rf.6f13676dacefaa73b1935e61b1d991c6.jpg\n",
            "Mobil-52-_jpg.rf.6b9c095c52d31fabbbb39537d57a4a02.jpg\n",
            "Mobil-53-_jpg.rf.4a21ac90a4e74cc794da3d5b1fceeafb.jpg\n",
            "Mobil-54-_jpg.rf.61797ba01375609f100fea8755384da0.jpg\n",
            "Mobil-56-_jpg.rf.5da73adb6b00445d70af6d9b117bc933.jpg\n",
            "Mobil-57-_jpg.rf.6ec3512f9cc91efd959b5f34ff0e6ac5.jpg\n",
            "Mobil-5-_jpg.rf.a7612efd0f91b87fc105fb66bf36d1aa.jpg\n",
            "Mobil-60-_jpg.rf.32778285bd15deb345f28dd5a3b2b891.jpg\n",
            "Mobil-62-_jpg.rf.b201c88e858ffbce534569da4c58f1fc.jpg\n",
            "Mobil-63-_jpg.rf.1bd907908705583555a029d904cc3418.jpg\n",
            "Mobil-65-_jpg.rf.bffdbaaf1d600581e606bfe90e74e1cb.jpg\n",
            "Mobil-68-_jpg.rf.f01b46a2c1bf3fd06bb76155a95e7b7b.jpg\n",
            "Mobil-69-_jpg.rf.f2f5129e2d85259085bd4be096da04e4.jpg\n",
            "Mobil-71-_jpg.rf.1c022b0e57cad8c0d3fc1d340cf88c03.jpg\n",
            "Mobil-74-_jpg.rf.d5c788ea98e32ba7f5f890d258ff6054.jpg\n",
            "Mobil-75-_jpg.rf.99bbe93feb69fc862f26cd46c29e802b.jpg\n",
            "Mobil-77-_jpg.rf.71e10f962859fbb76c41073e663ea03d.jpg\n",
            "Mobil-78-_jpg.rf.314b8b0290cd539c55c821dc09975fa6.jpg\n",
            "Mobil-79-_jpg.rf.e80b634901e1bc2c384f87681c556f6a.jpg\n",
            "Mobil-7-_jpg.rf.b5fbf56d35f945e2afa11611e4e489b7.jpg\n",
            "Mobil-80-_jpg.rf.e15ce11ff1b24c89778d65507efaa329.jpg\n",
            "Mobil-81-_jpg.rf.be99d6dbeb8cad9572545a3a8f27dea4.jpg\n",
            "Mobil-82-_jpg.rf.9bcb96168a4758d9bf0b00c9a0483b0e.jpg\n",
            "Mobil-84-_jpg.rf.bc3a0a0a244f0a034ab4a32db7b80fd5.jpg\n",
            "Mobil-85-_jpg.rf.443da989601575da1de66dee3db35cda.jpg\n",
            "Mobil-86-_jpg.rf.b41f3a8b2da4ede547487658cd0bc1c3.jpg\n",
            "Mobil-89-_jpg.rf.17aa8c5c11b41da9f93074fa65206da4.jpg\n",
            "Mobil-8-_jpg.rf.db26347fb6b9d052aa9bbe167747b284.jpg\n",
            "Mobil-91-_jpg.rf.e4d8dea1320ec6fe2acd50c3f28f14e1.jpg\n",
            "Mobil-92-_jpg.rf.daa8be8c23c8f0e32baf1ed9b5c5d137.jpg\n",
            "Mobil-94-_jpg.rf.6cddd0779a36897f1b0538acdff4a04b.jpg\n",
            "Mobil-96-_jpg.rf.fb31818ceb497a8579270bd1008c6fd5.jpg\n",
            "Mobil-97-_jpg.rf.4d0d61c08fdd86a3f7d1cf3b3c34f961.jpg\n",
            "Mobil-98-_jpg.rf.11b13af99bf406a384a6389691aeccdb.jpg\n",
            "Mobil-9-_jpg.rf.0796c48d940b8333cd016218153a8bb9.jpg\n",
            "mobil-bekas-city-car-di-olx-dengan-jarak-tempuh-40000-45000-km-3_43_jpg.rf.4afbf5900a18bb7fa9368312553568b4.jpg\n",
            "mobil_honda_jazz_rs_2013_matic_putih_plat_b_4231645_1502692175_jpg.rf.87265719244505e146dfe8af79779252.jpg\n",
            "Motor-101-_jpg.rf.e2081c7c0ea6fe05e78ac03e044e5e2f.jpg\n",
            "Motor-102-_jpg.rf.f3d43856f9b084a4189c0245b4aef979.jpg\n",
            "Motor-104-_jpg.rf.73833cac6d761089e254157c745d252b.jpg\n",
            "Motor-105-_jpg.rf.4bc4b562e49927e6f14aacd4671b8180.jpg\n",
            "Motor-106-_jpg.rf.501d890610bd69e5fa19f0880f87cc3c.jpg\n",
            "Motor-107-_jpg.rf.231b7861b9a9cca3143cf60211da9117.jpg\n",
            "Motor-108-_jpg.rf.14fffad03ef9b3cafd751288ba97e6c7.jpg\n",
            "Motor-109-_jpg.rf.43af6f05830933f73c3f1d683e3eea7e.jpg\n",
            "Motor-110-_jpg.rf.2809a2f2c961513ce440f98812e30944.jpg\n",
            "Motor-111-_jpg.rf.9a4cb37c1575ae4cbe527aa30871fda2.jpg\n",
            "Motor-113-_jpg.rf.0ad0e0b7db784befb857d20226e9ed32.jpg\n",
            "Motor-114-_jpg.rf.a7afdea2c06a7f018955d6f4a1343731.jpg\n",
            "Motor-115-_jpg.rf.dec3eb6944a874bb5648dc38a6729879.jpg\n",
            "Motor-119-_jpg.rf.896555c28720c9543e775afc341427d7.jpg\n",
            "Motor-120-_jpg.rf.2882b11580e876af49c07bb7cb582549.jpg\n",
            "Motor-122-_jpg.rf.d9519d01fd49c51e8ecad21fab47df14.jpg\n",
            "Motor-123-_jpg.rf.72fe10be11e6dc2a2c4c868e4e09cbbe.jpg\n",
            "Motor-125-_jpg.rf.28b1a5dcc52e606449de39d8a3c28928.jpg\n",
            "Motor-126-_jpg.rf.ec949fa1a423d3eed5921a958278c230.jpg\n",
            "Motor-127-_jpg.rf.101302c02fc79629a6a6682a14ddcf19.jpg\n",
            "Motor-12-_jpg.rf.dc3f6458731177b10db0792f0bd69585.jpg\n",
            "Motor-132-_jpg.rf.d42454ad7aac855561427e7e35a5595c.jpg\n",
            "Motor-133-_jpg.rf.58d3b6eebd671a573952f0ee1779dc93.jpg\n",
            "Motor-136-_jpg.rf.3fed4358abfdf5f5a3e3c0e45f6defdf.jpg\n",
            "Motor-137-_jpg.rf.5ca711d645f48e472c9eb03f5c8d3e86.jpg\n",
            "Motor-138-_jpg.rf.ed0c1972e55f7c6af697a87bd051659c.jpg\n",
            "Motor-139-_jpg.rf.382296318edf0dd7b9e00c6837abcb79.jpg\n",
            "Motor-13-_jpg.rf.ba884e697e8b1807a65274827c86a1ed.jpg\n",
            "Motor-140-_jpg.rf.f13522818b6d07e1ded34e8a5834d5ec.jpg\n",
            "Motor-143-_jpg.rf.17cd5e9d0c7326ae9c2ff08c38caa7a3.jpg\n",
            "Motor-145-_jpg.rf.9b0b94f71d0f70262177f32f3cf8c477.jpg\n",
            "Motor-146-_jpg.rf.f8ed14be6c023b5bccf6ab5c71dfec58.jpg\n",
            "Motor-148-_jpg.rf.856746158289caffd7685fbbd2cf1f8b.jpg\n",
            "Motor-149-_jpg.rf.d9eb52b8398f6cba9788df9f4162ed3f.jpg\n",
            "Motor-150-_jpg.rf.234d2b44636a36bea24296cbceb9d5bd.jpg\n",
            "Motor-151-_jpg.rf.a7129273bc43181547f5b4ed5a321ffd.jpg\n",
            "Motor-152-_jpg.rf.b5cacdc3c632ee4e8623cd6eddb0e5cb.jpg\n",
            "Motor-154-_jpg.rf.5207346a952c40877b04319df127f71c.jpg\n",
            "Motor-156-_jpg.rf.557a549ad4f34c83ee709c0358f61116.jpg\n",
            "Motor-157-_jpg.rf.acb5f2f21ce332c4407f59a288d5deff.jpg\n",
            "Motor-158-_jpg.rf.3e603b141f8eefc513b01d114d798cf5.jpg\n",
            "Motor-159-_jpg.rf.0bb095b87dff40ee0bb9f2dedd5c6608.jpg\n",
            "Motor-15-_jpg.rf.a1192ea6fd764baf7158ab0230e00b0f.jpg\n",
            "Motor-160-_jpg.rf.30a99d55facbfac42df1885c675ebed5.jpg\n",
            "Motor-162-_jpg.rf.84a3cd89d86eee97a4d6ec126913754f.jpg\n",
            "Motor-164-_jpg.rf.0c4b896bb925dfb0107b0e24921b6896.jpg\n",
            "Motor-165-_jpg.rf.b5e95e64bdd35474f92d47c3f48a1340.jpg\n",
            "Motor-166-_jpg.rf.adc05f6607a8ef085a0cac4ad8495bb0.jpg\n",
            "Motor-167-_jpg.rf.caa8249175213a9fcfb6cf855b9ebdcc.jpg\n",
            "Motor-168-_jpg.rf.158d65c88a735fc10f957880bd674e66.jpg\n",
            "Motor-16-_jpg.rf.b1d2ab3ab599e46b855e45249d2ebeb4.jpg\n",
            "Motor-170-_jpg.rf.d5c3df240472dcc5c7799e5e522d3206.jpg\n",
            "Motor-171-_jpg.rf.9ee186c181508fcc0bd72a471eca75fc.jpg\n",
            "Motor-172-_jpg.rf.dbc817d76478eea2bd1b450bf253ee08.jpg\n",
            "Motor-173-_jpg.rf.89c31279501645eb73d50a873db837a8.jpg\n",
            "Motor-174-_jpg.rf.e11cb5ae0c1653cafd2e1b037ab45ba0.jpg\n",
            "Motor-175-_jpg.rf.12388c248eb89d171230b6a576d30b0c.jpg\n",
            "Motor-176-_jpg.rf.819b1e81265336a23f5ef2c753320778.jpg\n",
            "Motor-177-_jpg.rf.9203284522b0f395621abb6843995e35.jpg\n",
            "Motor-178-_jpg.rf.f471cd55809b00f04e77cb2ca62aed7f.jpg\n",
            "Motor-179-_jpg.rf.15467014ddd7203fc1630e59b8026959.jpg\n",
            "Motor-17-_jpg.rf.bbd14d6d57125f1fc31d7b0574b68aa2.jpg\n",
            "Motor-182-_jpg.rf.359ec7b745d5ac14d9bbc1d5dfdae629.jpg\n",
            "Motor-183-_jpg.rf.e72a387cbad7fdd6e8e3a70b22055331.jpg\n",
            "Motor-184-_jpg.rf.b81599c8d290ecf034c1c915d480093b.jpg\n",
            "Motor-185-_jpg.rf.95ab23c64fc5f2466326cd7a6e52e0d7.jpg\n",
            "Motor-186-_jpg.rf.1fcd4306589ad5efa2066477eaff512c.jpg\n",
            "Motor-187-_jpg.rf.280e9fa8b715e025cdbc8318c8a3355c.jpg\n",
            "Motor-188-_jpg.rf.1115f70438b2e341d4b3d9c49ced0c84.jpg\n",
            "Motor-18-_jpg.rf.3188ffc79ca9f85d31fd75116a0c4a07.jpg\n",
            "Motor-190-_jpg.rf.3a0a7f8be0d0c023c112584a0afcafb4.jpg\n",
            "Motor-192-_jpg.rf.07dd594fd8416403be7ba18a1cc3bf4a.jpg\n",
            "Motor-193-_jpg.rf.524b8b7a792489a9b2445b061e22539a.jpg\n",
            "Motor-195-_jpg.rf.6b4efed4bbb632aaf73208c876c456c5.jpg\n",
            "Motor-196-_jpg.rf.1c2441f915808c24928dd40286a9b41e.jpg\n",
            "Motor-197-_jpg.rf.904117bb733d5c22054bd3f6591c2e16.jpg\n",
            "Motor-198-_jpg.rf.cf09bf528f2a72e7c8cf3e4d920ea136.jpg\n",
            "Motor-199-_jpg.rf.91f13a0b07bda85d579d79238345905d.jpg\n",
            "Motor-19-_jpg.rf.6ea51cb72ffa40e26b2f96cb8e404a80.jpg\n",
            "Motor-1-_jpg.rf.1168991bfb8fe9dc63d59b27de93f0de.jpg\n",
            "Motor-200-_jpg.rf.f2183ffd759f09424cd0381cbcf2993a.jpg\n",
            "Motor-201-_jpg.rf.6e3210e27712a64d7e0a7a120cf4753b.jpg\n",
            "Motor-202-_jpg.rf.6b5e5b0a99cc32394d0fcf1c17a5edea.jpg\n",
            "Motor-205-_jpg.rf.a9607afd66f409a729182f18162621ab.jpg\n",
            "Motor-206-_jpg.rf.4aa6ecdfe5a0817f4567c114d4edeb7f.jpg\n",
            "Motor-208-_jpg.rf.95580d81f3675c956b08102d54e1ec4b.jpg\n",
            "Motor-209-_jpg.rf.93dd8fb221e39906a62c5eced8f701f2.jpg\n",
            "Motor-20-_jpg.rf.404b7c0d220bf1f9bdc402671ceba04f.jpg\n",
            "Motor-210-_jpg.rf.c42cb05241d006da34c2b8c3ba099333.jpg\n",
            "Motor-212-_jpg.rf.d88b8c729fba8d908adb29954bbeed06.jpg\n",
            "Motor-213-_jpg.rf.f6ec1826b004b037474f7c4b6d4315d5.jpg\n",
            "Motor-215-_jpg.rf.a3422005aabd05937072166b761b1960.jpg\n",
            "Motor-216-_jpg.rf.cb0d71e411f874c3fe20c172a7a9eef5.jpg\n",
            "Motor-218-_jpg.rf.48fdb603c48cf4c62fe80811f55fb57e.jpg\n",
            "Motor-219-_jpg.rf.de6a0ec534e04110489b9a1865211d70.jpg\n",
            "Motor-21-_jpg.rf.7f3ac7b699c27b03d2bea8645a96266d.jpg\n",
            "Motor-220-_jpg.rf.d2685b3aa46eb7cfffd4ecb08c92ddbc.jpg\n",
            "Motor-221-_jpg.rf.3fd4c03acbaf41458c53392cf3e02e81.jpg\n",
            "Motor-222-_jpg.rf.1c7a8c36722b5eca997d0a85a3368457.jpg\n",
            "Motor-223-_jpg.rf.b14636b95282403e0b61bbbdef4cf400.jpg\n",
            "Motor-224-_jpg.rf.3c2b673fb201d53529b476f08cb8f0e1.jpg\n",
            "Motor-225-_jpg.rf.3f63402ae87e107082e6b19d095247be.jpg\n",
            "Motor-227-_jpg.rf.09044fb8be5e5a5a8c3b89a8d19ba447.jpg\n",
            "Motor-228-_jpg.rf.87b86fef449b9c0875c1a24668e07b86.jpg\n",
            "Motor-229-_jpg.rf.1dab5087378ce41431ce5873b843359f.jpg\n",
            "Motor-22-_jpg.rf.67eea9fe751a418313521b7955318a8e.jpg\n",
            "Motor-230-_jpg.rf.586eaa4193641286804f9aebca16afe1.jpg\n",
            "Motor-231-_jpg.rf.f652ce6983243ebc630f1534e5e6750d.jpg\n",
            "Motor-232-_jpg.rf.1b0810265c3de7bd39a486076425bcca.jpg\n",
            "Motor-235-_jpg.rf.9214cecae1b6fa2222be0801bb6183cb.jpg\n",
            "Motor-236-_jpg.rf.e43ebe0a0b356151f06ee7af7c229a24.jpg\n",
            "Motor-237-_jpg.rf.f3ebb391d78c0e0579e960e08ff073a8.jpg\n",
            "Motor-238-_jpg.rf.a47e17c53dc06f9064d47a54f1a1ab5b.jpg\n",
            "Motor-239-_jpg.rf.786388b31657f00fc26e268150fe5b2b.jpg\n",
            "Motor-23-_jpg.rf.3ef68b50b19762bdc87868b9ae5942ac.jpg\n",
            "Motor-240-_jpg.rf.7c65a91552cdd31a22458a674d080ca0.jpg\n",
            "Motor-241-_jpg.rf.d8c7feb2a884dde8a1f57cbd767744e4.jpg\n",
            "Motor-242-_jpg.rf.b031ad0e3027003886232cec31c11f3b.jpg\n",
            "Motor-243-_jpg.rf.449020bed7b157d43adc4a9cbae6cb29.jpg\n",
            "Motor-246-_jpg.rf.a8f27c419474cf31f70355026f39ac65.jpg\n",
            "Motor-247-_jpg.rf.3fdae1f714a0c9060fcdbcf29a979264.jpg\n",
            "Motor-248-_jpg.rf.fd6fb31ce74372dd3e5de4dc21c27031.jpg\n",
            "Motor-249-_jpg.rf.691fecd1f0dbbfae23b1b2c6942ba612.jpg\n",
            "Motor-24-_jpg.rf.d1c34b542589bad3838840156f139c28.jpg\n",
            "Motor-250-_jpg.rf.093f3e6df2782a4ca4bd0b5ffcf565e3.jpg\n",
            "Motor-251-_jpg.rf.944ebbd7f525705448bacd7aae12a5f1.jpg\n",
            "Motor-253-_jpg.rf.0c9ea329c2e1006066dac458b24512b3.jpg\n",
            "Motor-254-_jpg.rf.c367de1ab4b45882630626c7c497b4f3.jpg\n",
            "Motor-256-_jpg.rf.61801852470bb86cda68795520ae5110.jpg\n",
            "Motor-259-_jpg.rf.1d6296ab8536c2a67c1f5511c2dc98f7.jpg\n",
            "Motor-25-_jpg.rf.654e18723122f033750c98b97fa4cc5c.jpg\n",
            "Motor-260-_jpg.rf.0b3104091ffaedc17fa6337c43bf4fe5.jpg\n",
            "Motor-261-_jpg.rf.ec017eac1f5d58a714379682fefac1e5.jpg\n",
            "Motor-263-_jpg.rf.6f94f79d6f275139978d293bd691e649.jpg\n",
            "Motor-264-_jpg.rf.ebbef0e9c6bdda0470790bc441df083f.jpg\n",
            "Motor-265-_jpg.rf.6c24de45975380cc80e6a118dcff79b9.jpg\n",
            "Motor-266-_jpg.rf.ec94eac5ebcfd402258870c26113f272.jpg\n",
            "Motor-267-_jpg.rf.2a0eb5476faf2487c09583ea24a18931.jpg\n",
            "Motor-268-_jpg.rf.a50464198e02c9be53d251fe57dbcc8b.jpg\n",
            "Motor-270-_jpg.rf.8ca9cd0147a6c0cf50fd9bc61cdd5e4c.jpg\n",
            "Motor-272-_jpg.rf.b6726aeaf1944190d80d7c1eff8a4ad2.jpg\n",
            "Motor-273-_jpg.rf.5a79ebab31f8b64a42a64587a98c8573.jpg\n",
            "Motor-274-_jpg.rf.db4e65a6d911d7abdf33196fbaf1e18c.jpg\n",
            "Motor-275-_jpg.rf.d86c69ed5c6f77cc4104aef3e10c8aa7.jpg\n",
            "Motor-277-_jpg.rf.b520b267117f4488039ea7055099ce3e.jpg\n",
            "Motor-278-_jpg.rf.007d90ea5f308d143fd574a29c45ca3d.jpg\n",
            "Motor-279-_jpg.rf.9b40387c3e1880dd7dbfc82f2f4a557f.jpg\n",
            "Motor-27-_jpg.rf.70add4d37075fdf1ea27e341cc7d6574.jpg\n",
            "Motor-281-_jpg.rf.5d2d20e0f5df5df99f0afdf8fde342a5.jpg\n",
            "Motor-282-_jpg.rf.34f10af578b5e7c2348e752ec0522d86.jpg\n",
            "Motor-283-_jpg.rf.09a7e70ab7fd72063df47842c29a4f74.jpg\n",
            "Motor-284-_jpg.rf.e766447e77301e539eca448a2075c830.jpg\n",
            "Motor-285-_jpg.rf.b77967c20fd41f6a15c9345a7c1eced6.jpg\n",
            "Motor-287-_jpg.rf.2cbe9f4a84bca326461d9d8167be3186.jpg\n",
            "Motor-288-_jpg.rf.4904b2153ff92eab2d340ac621c08257.jpg\n",
            "Motor-289-_jpg.rf.7fdf1d567eb5f3978989c0520399208a.jpg\n",
            "Motor-28-_jpg.rf.24ef066c2bb279f1dd8816a960e3da74.jpg\n",
            "Motor-292-_jpg.rf.9292c6f2438bc80941c64b3d721ef6f0.jpg\n",
            "Motor-293-_jpg.rf.9e12c7c0f0b0c87e2fcb4ebabf8b7980.jpg\n",
            "Motor-294-_jpg.rf.e15661ccc71cb7d758e8809391d7cea4.jpg\n",
            "Motor-295-_jpg.rf.7cc23ea39e224193b24a47ff4e65fa23.jpg\n",
            "Motor-296-_jpg.rf.b903299e3bc503e67077616651939c90.jpg\n",
            "Motor-298-_jpg.rf.77eb718fca6653609f463aa5d320fc9a.jpg\n",
            "Motor-299-_jpg.rf.081741742a7b77bc790db1b9b483d2a6.jpg\n",
            "Motor-301-_jpg.rf.431a6373c0f8ca40254333eb128f2f17.jpg\n",
            "Motor-302-_jpg.rf.5f8334aface1455dfc36f780b628d769.jpg\n",
            "Motor-303-_jpg.rf.fc785442bdf1209ee514d92b4ef0fca1.jpg\n",
            "Motor-308-_jpg.rf.8664e14a92cf991d78f72bc32480b8de.jpg\n",
            "Motor-309-_jpg.rf.28bebf32859be06a67208439c6faafd1.jpg\n",
            "Motor-311-_jpg.rf.70d13cb086d44ecf92e6929543755f0d.jpg\n",
            "Motor-312-_jpg.rf.9867144ef038cef0abe071015f7d8e36.jpg\n",
            "Motor-313-_jpg.rf.29e150b14f9fe98e1856729db0121cfc.jpg\n",
            "Motor-314-_jpg.rf.e776c30ddc3b8e06e6538c817390ae86.jpg\n",
            "Motor-315-_jpg.rf.cd5df8bbac0279a1b97194fbc299d316.jpg\n",
            "Motor-316-_jpg.rf.01e49db9b257b9cfca07c1b8724c26a4.jpg\n",
            "Motor-317-_jpg.rf.d4ea1fd51b5f8629ab51dd48f1d15c12.jpg\n",
            "Motor-31-_jpg.rf.faadfcb2412a07d50a98ca7cdd307e76.jpg\n",
            "Motor-321-_jpg.rf.613f3cdb65d4eb6071fe47a02d5daeeb.jpg\n",
            "Motor-322-_jpg.rf.917b2ee6e5bbfff71f3f6a1b14b0603d.jpg\n",
            "Motor-324-_jpg.rf.3019447048d514de68a461c0de1d5015.jpg\n",
            "Motor-328-_jpg.rf.55c827c2c2c7c3fcca5386834d67bfff.jpg\n",
            "Motor-32-_jpg.rf.7917421727364dcf38f9225ac35518ef.jpg\n",
            "Motor-331-_jpg.rf.323746fd3b0e56a039c4f984efe8beae.jpg\n",
            "Motor-334-_jpg.rf.6b2574c86d3de8bec814e755cf523654.jpg\n",
            "Motor-335-_jpg.rf.0ce7cbc143faad19c45989aef7b93b94.jpg\n",
            "Motor-339-_jpg.rf.93e95e77a93daa40e156b1b1d8319e84.jpg\n",
            "Motor-33-_jpg.rf.b677c17f68cbee08cc4165e190556c9a.jpg\n",
            "Motor-341-_jpg.rf.ebd588fde61b2049f4fb64e5797ccebc.jpg\n",
            "Motor-342-_jpg.rf.135f9cb8120405912cad858247c5c93f.jpg\n",
            "Motor-343-_jpg.rf.2c942d9e3429ed1c7815c3d0c6492cef.jpg\n",
            "Motor-345-_jpg.rf.508dd29341f9bf43a00fec368143693a.jpg\n",
            "Motor-346-_jpg.rf.473fe47a31ccc356c580d371f5d8628c.jpg\n",
            "Motor-348-_jpg.rf.033dfcfde6fc61e10ada89f43fcc59c1.jpg\n",
            "Motor-349-_jpg.rf.62327ce00bb7a05425703f768f1d6d05.jpg\n",
            "Motor-34-_jpg.rf.01312e96f1ab2a521cc6d4c1c74dac54.jpg\n",
            "Motor-351-_jpg.rf.75948006db6b5347c8b60648fa601599.jpg\n",
            "Motor-352-_jpg.rf.1bea5ab0bda6ff91e3867d22f07478a3.jpg\n",
            "Motor-353-_jpg.rf.55a00111429cf7336c6e3743096b8774.jpg\n",
            "Motor-354-_jpg.rf.7e61cfcc9d7c66f6ed93e751a10283fe.jpg\n",
            "Motor-355-_jpg.rf.b122602a24ea056c78fb4c927fe39ab0.jpg\n",
            "Motor-356-_jpg.rf.526d21c52d2d19a2739cc58babefd0bd.jpg\n",
            "Motor-357-_jpg.rf.7330ef31d5a1b3c56f2fb17bafd052c9.jpg\n",
            "Motor-359-_jpg.rf.cf833e0f3c680c27c5b5ce959b9a82ab.jpg\n",
            "Motor-360-_jpg.rf.5efbbcc6f40c785744c1f08171731e14.jpg\n",
            "Motor-361-_jpg.rf.7abd97bc232e21c5495b35db2bca311a.jpg\n",
            "Motor-362-_jpg.rf.3b9d6da35b2eaa9092e04f8c0b9e5534.jpg\n",
            "Motor-364-_jpg.rf.1314694cde7c7f1eb66ef15d9717de5e.jpg\n",
            "Motor-365-_jpg.rf.3124ac96f307fc6fe6c167a73f5de419.jpg\n",
            "Motor-366-_jpg.rf.f0d3679cf4cce0c346d9c70764ff219c.jpg\n",
            "Motor-367-_jpg.rf.f46fa0b30f250a30b76681c2d2722f4c.jpg\n",
            "Motor-368-_jpg.rf.307edfde7d598a23cec785455fa9dbae.jpg\n",
            "Motor-369-_jpg.rf.8f7e80c42a594b855196670d690051e8.jpg\n",
            "Motor-36-_jpg.rf.cbe6f295f7cd8147aa64c5525ed5ef39.jpg\n",
            "Motor-370-_jpg.rf.7b2c56fef12ca27659457eb387cf7bf2.jpg\n",
            "Motor-375-_jpg.rf.3807347bf706263dc7538d662288d99d.jpg\n",
            "Motor-37-_jpg.rf.4b8081a0795bb42893c8921fe2221afc.jpg\n",
            "Motor-39-_jpg.rf.57028bb3525a5cb0ec2b766c859dd691.jpg\n",
            "Motor-3-_jpg.rf.fa5d3246bbc01481453847a83130022b.jpg\n",
            "Motor-40-_jpg.rf.69d0feeb0d8d5aa02472e94536f9862a.jpg\n",
            "Motor-42-_jpg.rf.87f6bdaee5c5d3601bbaaf110de17e17.jpg\n",
            "Motor-43-_jpg.rf.15268bc8685172080ed7b15ca62fe204.jpg\n",
            "Motor-44-_jpg.rf.74a205bf35c022413f8a8fe82a29da46.jpg\n",
            "Motor-47-_jpg.rf.84568093afcba32ae71bfe3dc57e5f53.jpg\n",
            "Motor-48-_jpg.rf.5c9906196cff3681b2b4c3f1addc62d5.jpg\n",
            "Motor-49-_jpg.rf.f455383d87ae34d5d0b89da8bf763056.jpg\n",
            "Motor-4-_jpg.rf.35839b0cd2eee7449f3af3792893ae0c.jpg\n",
            "Motor-50-_jpg.rf.c856baedd961d132e4b3915bc23d1b4c.jpg\n",
            "Motor-51-_jpg.rf.866964f88cc825a170020bcc7f92cae1.jpg\n",
            "Motor-52-_jpg.rf.3e625886a0dd557dc920a1715c1b9e80.jpg\n",
            "Motor-53-_jpg.rf.dc8cf9101182918a3505f300e9b513a6.jpg\n",
            "Motor-54-_jpg.rf.9ec9b80fc3ad219f4c460e6dac2ddf4b.jpg\n",
            "Motor-56-_jpg.rf.779f08b44965759590db912405de4764.jpg\n",
            "Motor-58-_jpg.rf.8c0f8872aa810c51d0a484144d7af25b.jpg\n",
            "Motor-59-_jpg.rf.1a32326e4b338b74c0393b7740e287c9.jpg\n",
            "Motor-5-_jpg.rf.7e8149b5cd59eeac694146c36622cfc5.jpg\n",
            "Motor-60-_jpg.rf.72e4c046b75759edfab6fee53ec4d266.jpg\n",
            "Motor-62-_jpg.rf.cf892dc2b24918320ab76354fc0bccb9.jpg\n",
            "Motor-63-_jpg.rf.44ba6a832b59828f9d125dddc078c05f.jpg\n",
            "Motor-66-_jpg.rf.93ed202aaf8f2fd1055310bed45cfeab.jpg\n",
            "Motor-67-_jpg.rf.a38018d86f8ba9844395ba7f5d283480.jpg\n",
            "Motor-68-_jpg.rf.1b31a3270c47d29f1a7b2ca59aaaa23f.jpg\n",
            "Motor-69-_jpg.rf.ea869c18caa9917b2cdc99a5882b4c40.jpg\n",
            "Motor-71-_jpg.rf.69e22b183cb87097de7690d6e059f14b.jpg\n",
            "Motor-72-_jpg.rf.d71f98c57b303027086953a405f2b551.jpg\n",
            "Motor-76-_jpg.rf.76b91b7d5e891e0502a4356ad02e9cf6.jpg\n",
            "Motor-78-_jpg.rf.af193fa5997c9d3cf04c07db2efaaade.jpg\n",
            "Motor-79-_jpg.rf.4d18508294ed852f20551c0604642eb4.jpg\n",
            "Motor-80-_jpg.rf.b065545b99857f542f121ac9bf226041.jpg\n",
            "Motor-83-_jpg.rf.431eea61323a45bca90b7a58a97c4e70.jpg\n",
            "Motor-84-_jpg.rf.dafcdc6b19f87403bb34c17d843ebda5.jpg\n",
            "Motor-86-_jpg.rf.5eab661427e69c23961c12f9f6b5132e.jpg\n",
            "Motor-87-_jpg.rf.59348816e140334537d205a24066cb8d.jpg\n",
            "Motor-88-_jpg.rf.130ae8cda82119f0a4d5b091a71c42fc.jpg\n",
            "Motor-89-_jpg.rf.0be9b9a5d72bd114349b820ea7f41358.jpg\n",
            "Motor-8-_jpg.rf.a6dd79f884c4bc522eecc7f3db10938f.jpg\n",
            "Motor-90-_jpg.rf.6cf96eb7a0fb4a0287629dca53a1cf1c.jpg\n",
            "Motor-93-_jpg.rf.202f557eaf824fc64e280d67e1aa7b6b.jpg\n",
            "Motor-94-_jpg.rf.fd87f71dbc5c8d0d8349355bddc06340.jpg\n",
            "Motor-95-_jpg.rf.9e833e6d7d6c04154cd21243abcbb3f0.jpg\n",
            "Motor-96-_jpg.rf.ed7ffd63761aa858acfae1acf7a10e5a.jpg\n",
            "Motor-97-_jpg.rf.4c41151284687b8f280f461f819e2fef.jpg\n",
            "Motor-98-_jpg.rf.d7804ecea6551cd15d83fdd88b09c0f5.jpg\n",
            "N1824KJ_jpg.rf.9eee994cc30b59f884d08473a7704c9d.jpg\n",
            "N731CS_jpg.rf.0c1ddfc829c7d0c59955a4487046bb6b.jpg\n",
            "N731CS_jpg.rf.d52df717869eb849fba94300d96ef2aa.jpg\n",
            "P_20211122_114537_jpg.rf.f3ee20cc26d40d98a1e869f4eda76353.jpg\n",
            "P_20211122_114545_jpg.rf.4af47633c0625eff25da001922f0da5e.jpg\n",
            "P_20211122_114606_jpg.rf.e9e1799e0d25f67ebf15f4c99f28010f.jpg\n",
            "P_20211122_114618_jpg.rf.b61e55a87072d922add2fe6af1be94bc.jpg\n",
            "Pelat-100-_jpg.rf.b8284ef3eefa3eeac4d1355d1427b525.jpg\n",
            "Pelat-101-_jpg.rf.23331b703c4592731dd630785bfa8b4f.jpg\n",
            "Pelat-103-_jpg.rf.e1fdd84c55cf180198c84f84df5965c2.jpg\n",
            "Pelat-105-_jpg.rf.63d237020af70beffd3ccd5aed26bef2.jpg\n",
            "Pelat-106-_jpg.rf.266cf9605e8b5fd10e64ee5c87162aaa.jpg\n",
            "Pelat-107-_jpg.rf.ef59c10752c9a7a49cf5f540deaa57c4.jpg\n",
            "Pelat-108-_jpg.rf.01d07d83044b59f73ae36830082b82c2.jpg\n",
            "Pelat-10-_jpg.rf.bf2c06bec35540c6c49b4598be21a2c2.jpg\n",
            "Pelat-110-_jpg.rf.1afa86e9e3e1956146d251fd9cde747f.jpg\n",
            "Pelat-111-_jpg.rf.ff66a2baea145abae4355854a4e4be08.jpg\n",
            "Pelat-112-_jpg.rf.a0ede8b94cf13aaab83674f4f74aec6d.jpg\n",
            "Pelat-113-_jpg.rf.0f8f9d41ed5d1254858a017bfeeb1a4d.jpg\n",
            "Pelat-115-_jpg.rf.0c82a4fba9c11e20433efa67ce084af6.jpg\n",
            "Pelat-116-_jpg.rf.1641963784386665021bd66667031ad0.jpg\n",
            "Pelat-117-_jpg.rf.3868bd5f5ff7c5afc040ab6b6766bec4.jpg\n",
            "Pelat-118-_jpg.rf.16eaedf64031ed3ab1d1d152df64f6d5.jpg\n",
            "Pelat-11-_jpg.rf.5b62450da40a318b8a23d8cf49a5a137.jpg\n",
            "Pelat-121-_jpg.rf.c77542fddc852c46872f80aba1ba6826.jpg\n",
            "Pelat-122-_jpg.rf.b6d3ee296b3bed748d892c33c170a324.jpg\n",
            "Pelat-123-_jpg.rf.192588c239c4905b7e581f107a1e40f5.jpg\n",
            "Pelat-125-_jpg.rf.15c8c226aedafb2d0cecf0b2673533ea.jpg\n",
            "Pelat-126-_jpg.rf.1dd901f13063c3e669982629ac5c2353.jpg\n",
            "Pelat-128-_jpg.rf.09b56b0dc09a088afb3b94d4f387bae0.jpg\n",
            "Pelat-129-_jpg.rf.50f115fb2e2fb88bfc36667a7e7e35b7.jpg\n",
            "Pelat-12-_jpg.rf.e031c3e5ae8b236397344d1ed6d269aa.jpg\n",
            "Pelat-131-_jpg.rf.511980e0d9763212a137c68b8ac697a8.jpg\n",
            "Pelat-132-_jpg.rf.2ce7800dbbb5b6431a769ee95a267968.jpg\n",
            "Pelat-133-_jpg.rf.b7d70899ecb26324fd17be8c7e725a86.jpg\n",
            "Pelat-134-_jpg.rf.9bbcdb83ee144d61a2f1c3eb6f5bce61.jpg\n",
            "Pelat-135-_jpg.rf.d650888f120284035e28f4fbe9111e69.jpg\n",
            "Pelat-136-_jpg.rf.08118a61460cdae7c23275512a4602cc.jpg\n",
            "Pelat-137-_jpg.rf.0eb36b1b54e9c6a7ca69f694b0f60df4.jpg\n",
            "Pelat-139-_jpg.rf.aa0cfa2e6bcd1bee09368d7e70768058.jpg\n",
            "Pelat-13-_jpg.rf.a0e3027a2ce4849cf27de1ca4190909d.jpg\n",
            "Pelat-140-_jpg.rf.54ff115d53a4e2ec09bf1e055a5c49a2.jpg\n",
            "Pelat-141-_jpg.rf.644dd44b704a0c60faa1d14d8908cc35.jpg\n",
            "Pelat-142-_jpg.rf.4bb7e1e65486e0b2dd15c48087b45ecb.jpg\n",
            "Pelat-143-_jpg.rf.f9df45dcea393067cf51093c98c41371.jpg\n",
            "Pelat-144-_jpg.rf.8ecd08ebff28a64f9063ae6a26b91d87.jpg\n",
            "Pelat-146-_jpg.rf.0bb980799653ae38f90226cfe4abea4d.jpg\n",
            "Pelat-147-_jpg.rf.4f445740bd93ea0594fe9320020758c7.jpg\n",
            "Pelat-148-_jpg.rf.412b9945868136871392e1d4b1c4e56d.jpg\n",
            "Pelat-149-_jpg.rf.2b3f7db717052de58cac33734b6f6ded.jpg\n",
            "Pelat-155-_jpg.rf.f536bcc2c883a67f2619b87b5d73650b.jpg\n",
            "Pelat-156-_jpg.rf.6cd019f4715694054bd207e022c32173.jpg\n",
            "Pelat-158-_jpg.rf.a152e9e1a3ba539cce553bafc0f6fd03.jpg\n",
            "Pelat-159-_jpg.rf.fc0a11ebbd88a3e4c447fb3333b9b536.jpg\n",
            "Pelat-15-_jpg.rf.7ecd95d00511816dc2ee6344bfce378b.jpg\n",
            "Pelat-161-_jpg.rf.0f4b63d9a3a4e93f1a42da14a739005e.jpg\n",
            "Pelat-162-_jpg.rf.6397c7adfbda49778271fc0c98c96ff8.jpg\n",
            "Pelat-163-_jpg.rf.f858052119abe235f818a01f7a00cacf.jpg\n",
            "Pelat-164-_jpg.rf.f965c7c2df79304a98756a647961d7c0.jpg\n",
            "Pelat-166-_jpg.rf.7f13d9959e0d31fe12d882b1be9e2c12.jpg\n",
            "Pelat-167-_jpg.rf.76fd6321888ea4a5f3aa14544cfe0cd8.jpg\n",
            "Pelat-168-_jpg.rf.f962728ff7bcbc5afca6cf5095b7811b.jpg\n",
            "Pelat-169-_jpg.rf.635dd732f7bbb58b3c7ef64ec7a736cf.jpg\n",
            "Pelat-16-_jpg.rf.e8b643f705162c42da284d8dae6b9a3e.jpg\n",
            "Pelat-170-_jpg.rf.4befb2aff1aa4747e925edf2dd59961b.jpg\n",
            "Pelat-171-_jpg.rf.57c71fb1683f8f05ff73b00d97046814.jpg\n",
            "Pelat-172-_jpg.rf.7e084cec27d93ceab4189c7945636abb.jpg\n",
            "Pelat-173-_jpg.rf.69e59e96c842f42bd7fe737f2096acb8.jpg\n",
            "Pelat-174-_jpg.rf.381caa45c58ffa121252c9d74739ad21.jpg\n",
            "Pelat-176-_jpg.rf.4e09e0b7b180dc18490dca9d15a5df0e.jpg\n",
            "Pelat-177-_jpg.rf.f114fbaf23755fd9bbdf6e39895b6e68.jpg\n",
            "Pelat-178-_jpg.rf.3263cd20c31ca83d9719e616fe387e78.jpg\n",
            "Pelat-179-_jpg.rf.70f3b7fd20881cba7954750da267c25a.jpg\n",
            "Pelat-17-_jpg.rf.1a25c291227d98e9e7fac6f5cd47d436.jpg\n",
            "Pelat-180-_jpg.rf.5e0941b2dd053e6c3be2f5d9f693f91d.jpg\n",
            "Pelat-181-_jpg.rf.02c5a6dbdc21ccdb493a9a7d9e9d6f36.jpg\n",
            "Pelat-182-_jpg.rf.9c2018fe5d2df6533e349ecc48ec43b4.jpg\n",
            "Pelat-184-_jpg.rf.eecd7e2a510b850a98bda9e59e041b56.jpg\n",
            "Pelat-185-_jpg.rf.017ed028d7c988c36a0f4cd302152e8f.jpg\n",
            "Pelat-189-_jpg.rf.f6ed344db05f5c28ccc019ea92327543.jpg\n",
            "Pelat-190-_jpg.rf.099c83d0b3faae734070dfffd67af61d.jpg\n",
            "Pelat-191-_jpg.rf.d4f18e9a9d27513cb90123d7649f0d0c.jpg\n",
            "Pelat-193-_jpg.rf.65eb48305dbd521df4e90ca4c340ecf6.jpg\n",
            "Pelat-195-_jpg.rf.537991279a6b585d65e824c1e0a58914.jpg\n",
            "Pelat-196-_jpg.rf.6c2b909dc23094159e0e208eb022ee41.jpg\n",
            "Pelat-197-_jpg.rf.394989bcfbad8d2b6a636c5efeb45c08.jpg\n",
            "Pelat-199-_jpg.rf.20567787eede4fbe3af6003d742db960.jpg\n",
            "Pelat-200-_jpg.rf.c625cffbbe102af45e1c7c425882a5e9.jpg\n",
            "Pelat-202-_jpg.rf.cb4e01e8a2ef63c4d6c6dbcd673ba438.jpg\n",
            "Pelat-204-_jpg.rf.f3b2b56abd0b5c4f16ad25b2690ac91b.jpg\n",
            "Pelat-205-_jpg.rf.7def0948fbd97f4c05f009db4620fbea.jpg\n",
            "Pelat-206-_jpg.rf.2d3c8b5997423dd7599bb9ae4d2c30de.jpg\n",
            "Pelat-207-_jpg.rf.e204ce6a60b3c7a2ce5bcf93e4100dc4.jpg\n",
            "Pelat-209-_jpg.rf.774fc10a7bd17f3f7cb3ff89f77a9230.jpg\n",
            "Pelat-210-_jpg.rf.82df709a5f0817e3a709c09e402d9a9a.jpg\n",
            "Pelat-211-_jpg.rf.96415751969e21263a7bc41e0a3e61e2.jpg\n",
            "Pelat-212-_jpg.rf.d5b1338bc9b3b3cd6fa782ee2d9a24bc.jpg\n",
            "Pelat-213-_jpg.rf.a322014d90f5e92666962a55595e253a.jpg\n",
            "Pelat-214-_jpg.rf.84d1a2505949a5850296a9d9da4bac02.jpg\n",
            "Pelat-215-_jpg.rf.1449fd39d1e15fc2b85bafcd82ab3554.jpg\n",
            "Pelat-218-_jpg.rf.cd3dd5c599f1f0859a6b109ea5aa0be2.jpg\n",
            "Pelat-220-_jpg.rf.e1873ada1ca8877ac1a883e21bbb364b.jpg\n",
            "Pelat-221-_jpg.rf.963df1275202b985182c2dcca44dc9a0.jpg\n",
            "Pelat-222-_jpg.rf.dee4d6c3f9774631d2598e63c27ea08a.jpg\n",
            "Pelat-223-_jpg.rf.acedcdef76a7df87e06f76929068a2ba.jpg\n",
            "Pelat-224-_jpg.rf.fe68f19d9e6dc977d5ea3d576273202f.jpg\n",
            "Pelat-225-_jpg.rf.736f24f75f3a1ce33c1303eaaf01ff09.jpg\n",
            "Pelat-227-_jpg.rf.a12d072f2a8abca9b3fa1c9dda0e3e71.jpg\n",
            "Pelat-228-_jpg.rf.292521aa53695dc41a7bc3085f5592b0.jpg\n",
            "Pelat-229-_jpg.rf.b286de7912d0058637256284afc00b18.jpg\n",
            "Pelat-22-_jpg.rf.f3574f53689341ae939b2cdc1d03eb8a.jpg\n",
            "Pelat-230-_jpg.rf.6b6941bfdae6b5065147f1b99b127ae9.jpg\n",
            "Pelat-231-_jpg.rf.860535b85d0b0e5fbb21df36a6668a2d.jpg\n",
            "Pelat-232-_jpg.rf.a1dbfd801b3732f1a45ed7f1f72c358b.jpg\n",
            "Pelat-233-_jpg.rf.63f11b799ca9d9fe19cadeb229b6827b.jpg\n",
            "Pelat-234-_jpg.rf.ce574a65df1c8c4d4f05d626513fe947.jpg\n",
            "Pelat-238-_jpg.rf.6592a100a96678835f7dfa2930b19d64.jpg\n",
            "Pelat-23-_jpg.rf.c91d68722e502e3cea2873e814cce659.jpg\n",
            "Pelat-240-_jpg.rf.1c3edd50507e5bbb2b1d6a498ca2e396.jpg\n",
            "Pelat-242-_jpg.rf.5615afd75c485b27d3d2740c1f7d443a.jpg\n",
            "Pelat-243-_jpg.rf.d88b96129bf8e4e11a93d1d96757fa68.jpg\n",
            "Pelat-244-_jpg.rf.56ec3c69daffa49e99785e2eda118a1f.jpg\n",
            "Pelat-245-_jpg.rf.6b4b8627f75166d666faad9a5c2b703a.jpg\n",
            "Pelat-246-_jpg.rf.c67ff602af7e6dd5a930e30a82815fd1.jpg\n",
            "Pelat-247-_jpg.rf.2a0f3803ff460447c9858facb538c792.jpg\n",
            "Pelat-248-_jpg.rf.bcca87e95c3544a09d30940750b96288.jpg\n",
            "Pelat-249-_jpg.rf.a92bb2301f097447a01e33eae8215edc.jpg\n",
            "Pelat-252-_jpg.rf.060c951541ef2e69ac73ca1645704592.jpg\n",
            "Pelat-253-_jpg.rf.57da33dc991d33d3c9796a50ee930fe0.jpg\n",
            "Pelat-254-_jpg.rf.658701026591c5678f6ac4ce436209b4.jpg\n",
            "Pelat-257-_jpg.rf.3f11d5f62ce30266fedd672970440f1a.jpg\n",
            "Pelat-260-_jpg.rf.2e27362c1a37e005759bdce0ac3677f7.jpg\n",
            "Pelat-261-_jpg.rf.dadc60e963d949c7585d35bd423d6684.jpg\n",
            "Pelat-263-_jpg.rf.2114c323b333ee0ecaba292603fc3055.jpg\n",
            "Pelat-264-_jpg.rf.c1c7186e17600fb2facf4c86e2c5f6d7.jpg\n",
            "Pelat-266-_jpg.rf.fbc3a978e3c7c215b370e9fbf16d5643.jpg\n",
            "Pelat-267-_jpg.rf.4481fd017dab76aa37f76415f4df6de2.jpg\n",
            "Pelat-269-_jpg.rf.793a0a68bd314368bfa9ac8ad8411d22.jpg\n",
            "Pelat-26-_jpg.rf.d62b084ba8e3f4614d87a60e56454b67.jpg\n",
            "Pelat-270-_jpg.rf.ecb11599d47b49d49bf2e6bd4649fe2d.jpg\n",
            "Pelat-272-_jpg.rf.64fbaeb84d30285d3bcdb3dd880de2a1.jpg\n",
            "Pelat-273-_jpg.rf.9172b54a29f9c55296bf27ec23038346.jpg\n",
            "Pelat-274-_jpg.rf.a03c8950e7784c2a9e1e4848378559b7.jpg\n",
            "Pelat-275-_jpg.rf.e4bc47763d7810d88e3eabb25ed9b9dd.jpg\n",
            "Pelat-276-_jpg.rf.ae1f9ba7c6f1f2db781e1856f4fe8968.jpg\n",
            "Pelat-277-_jpg.rf.433e203565080565a47adbcb0b6061ab.jpg\n",
            "Pelat-279-_jpg.rf.e4bf7bd616d7e2407f4d3dd68eb69e4f.jpg\n",
            "Pelat-27-_jpg.rf.b2fadbb3af5a475b2f6668c11151a502.jpg\n",
            "Pelat-280-_jpg.rf.eb1a68511ca2fbcb6ae249bfc8bbabe1.jpg\n",
            "Pelat-282-_jpg.rf.391747f834d254e6cce0aa200d10402a.jpg\n",
            "Pelat-284-_jpg.rf.2eebec9b312050feaf57200ef23fe478.jpg\n",
            "Pelat-285-_jpg.rf.87f421074388f6de4b908494392ef5dc.jpg\n",
            "Pelat-286-_jpg.rf.22559a46a1a68a846cbfae2391163a31.jpg\n",
            "Pelat-287-_jpg.rf.1fa7adae056c6158fd2debd6d1778677.jpg\n",
            "Pelat-288-_jpg.rf.63c3b478614b5cacfb64100d9b430c69.jpg\n",
            "Pelat-289-_jpg.rf.c4d7b82f48a056325131edb916ec5b90.jpg\n",
            "Pelat-290-_jpg.rf.17853fac2a0dfe968407440fa3c7179e.jpg\n",
            "Pelat-291-_jpg.rf.624dee3ee7f33e708943f33396237ba8.jpg\n",
            "Pelat-293-_jpg.rf.bda95c8b39a2b9a2a5a2dcfb4860cdbd.jpg\n",
            "Pelat-294-_jpg.rf.4cdb72ef4dc79077057ffc7e775e6b08.jpg\n",
            "Pelat-295-_jpg.rf.e6dd290968333aa101d003fcf3179f71.jpg\n",
            "Pelat-298-_jpg.rf.b806035c9ee0ef41f942aa02daacc2ab.jpg\n",
            "Pelat-299-_jpg.rf.3d8855ec6a1c6c8e352b16a526bc802b.jpg\n",
            "Pelat-2-_jpg.rf.eaf3fd1158408b0980998bd3cdcf4fef.jpg\n",
            "Pelat-301-_jpg.rf.6d70316cb6f8c68a394fde120bdfab37.jpg\n",
            "Pelat-302-_jpg.rf.7b60e93477b9afaea6ab11a09b176232.jpg\n",
            "Pelat-303-_jpg.rf.d66d205fec63566921ad1ff2edff961f.jpg\n",
            "Pelat-304-_jpg.rf.55c358aa1a3e1b138a58dfc8f5ab959c.jpg\n",
            "Pelat-306-_jpg.rf.044138511e655284d6856911fe90ab76.jpg\n",
            "Pelat-307-_jpg.rf.c6bbe230ed4d6e3fd319cec570b2f065.jpg\n",
            "Pelat-308-_jpg.rf.16af2cee3b03a7c5192cec53602b44b0.jpg\n",
            "Pelat-309-_jpg.rf.d833e39d8a1a7709cc54f36778826b41.jpg\n",
            "Pelat-310-_jpg.rf.44c1e70714c485f893342129f9c73e5e.jpg\n",
            "Pelat-311-_jpg.rf.d4392d14aaee67c53de03a24b9f7db02.jpg\n",
            "Pelat-313-_jpg.rf.57974ebe9820b4104f841b67cc7aa8a7.jpg\n",
            "Pelat-314-_jpg.rf.08a6f62d808da1a81ddacf14f20ef7a3.jpg\n",
            "Pelat-315-_jpg.rf.df2fb2b6e91594a30822d77ec8f511c0.jpg\n",
            "Pelat-318-_jpg.rf.99ec3d8e7b9b6430d927c75ea3c99dbf.jpg\n",
            "Pelat-31-_jpg.rf.bef993547a44583e3fea522c2e79799a.jpg\n",
            "Pelat-320-_jpg.rf.b5cf4f24c9f23e76c8efa8010d43a397.jpg\n",
            "Pelat-321-_jpg.rf.59757dac665ed5a9d15a4b037b162c52.jpg\n",
            "Pelat-325-_jpg.rf.d2aab9171a554b05673d38fe36c49834.jpg\n",
            "Pelat-328-_jpg.rf.1efb70bb543d2c9a86862d4785c413c0.jpg\n",
            "Pelat-329-_jpg.rf.9c88a6f655de3cf2f705f32a75f21671.jpg\n",
            "Pelat-32-_jpg.rf.925a281fafc888d4844d07b030e627c9.jpg\n",
            "Pelat-331-_jpg.rf.d86f460eedc9a3ed5d52f531b9452912.jpg\n",
            "Pelat-332-_jpg.rf.6c182c1d5f3fa472625ace7c4cbc2fe8.jpg\n",
            "Pelat-333-_jpg.rf.bd4305bba68b6a15b3e43292c5df8818.jpg\n",
            "Pelat-337-_jpg.rf.1fd9a0b2352ea63ab7269b6835fb24fe.jpg\n",
            "Pelat-339-_jpg.rf.d8deb8a77a3cd9a7f3039f4d72046e8d.jpg\n",
            "Pelat-33-_jpg.rf.69fbbedd83c1f75209a26d79c8dd73d2.jpg\n",
            "Pelat-340-_jpg.rf.f23c59f7eeb2fd3f807778300e8f10be.jpg\n",
            "Pelat-341-_jpg.rf.8865a7f8acf46d55e5d87af0fb68aca7.jpg\n",
            "Pelat-342-_jpg.rf.bcbf86dce3037784c1268110fcc366cc.jpg\n",
            "Pelat-343-_jpg.rf.84fe74d1b6dd18013ded379b6a4624a5.jpg\n",
            "Pelat-344-_jpg.rf.8ea4502826a1c658832a8369d853607e.jpg\n",
            "Pelat-349-_jpg.rf.e40ff7c1fe498b11b27018d71c704ba9.jpg\n",
            "Pelat-34-_jpg.rf.457a010fa974d5b6f32928c8d063ee39.jpg\n",
            "Pelat-350-_jpg.rf.d7591c03ed3a5e51bafd46dc46b221d6.jpg\n",
            "Pelat-355-_jpg.rf.c8625cedb6e63f7b4c00d2f30c0af5bb.jpg\n",
            "Pelat-356-_jpg.rf.cea32a319369a945195a283919c73686.jpg\n",
            "Pelat-357-_jpg.rf.2cbbf7c62d3c7833936196627378735f.jpg\n",
            "Pelat-358-_jpg.rf.03d2d19d4587acdd1e0a9b8a22eedcb5.jpg\n",
            "Pelat-359-_jpg.rf.bacf8e6d2b175224e45caf814fb11a06.jpg\n",
            "Pelat-360-_jpg.rf.c95cc8d3b51a72c93f2e4681b4682596.jpg\n",
            "Pelat-361-_jpg.rf.eaed7072584f0059d65c31835012ac74.jpg\n",
            "Pelat-362-_jpg.rf.f47dfe1c2d99560c46f308bdab6a3cb1.jpg\n",
            "Pelat-363-_jpg.rf.819147f59b1dc15e82376c01ca6a9a93.jpg\n",
            "Pelat-364-_jpg.rf.810a3ecb5ef0ee05ccfc33315836734a.jpg\n",
            "Pelat-365-_jpg.rf.32b1de9195358377846e98751e6b5ff5.jpg\n",
            "Pelat-366-_jpg.rf.793e1fd4ec746b813322526ca1fd8e8f.jpg\n",
            "Pelat-367-_jpg.rf.cd60fc33c7e870af8c14310214d0b9ea.jpg\n",
            "Pelat-368-_jpg.rf.7a28b271e8944b753343df8e3f4bce56.jpg\n",
            "Pelat-369-_jpg.rf.6bdf0050368b19bb4f665e3fea6f75ca.jpg\n",
            "Pelat-36-_jpg.rf.6e4f01e60e3b64e049dc56c96355905a.jpg\n",
            "Pelat-370-_jpg.rf.baa76d4680af32f6e40eda186cbd6039.jpg\n",
            "Pelat-371-_jpg.rf.b4ceacecd5c34d6d47debb592c87b40c.jpg\n",
            "Pelat-373-_jpg.rf.aabe471aa10752e2fc1b41516514a042.jpg\n",
            "Pelat-374-_jpg.rf.901ba6aeff06c75223f97ed864837bc2.jpg\n",
            "Pelat-38-_jpg.rf.a582e81b5d13c826cf0aebb8dcbe9891.jpg\n",
            "Pelat-39-_jpg.rf.98b0282db107dcf8b97b58a78b9c08ba.jpg\n",
            "Pelat-3-_jpg.rf.a255f97226ed9e9424969a27438034d9.jpg\n",
            "Pelat-40-_jpg.rf.c5b9ee3d28d8ebbdacb577ce08c6f0cb.jpg\n",
            "Pelat-41-_jpg.rf.12784f6ebf1b53f0c7720dbbb203963f.jpg\n",
            "Pelat-43-_jpg.rf.c9c1db33868f3b56107ec3eb520362d4.jpg\n",
            "Pelat-44-_jpg.rf.effb500ae8898aec7f0273f5427f203b.jpg\n",
            "Pelat-45-_jpg.rf.bb376b819ac837ef588a09ec0f966833.jpg\n",
            "Pelat-46-_jpg.rf.15d683d27a7d938c040ca32ce242a237.jpg\n",
            "Pelat-47-_jpg.rf.fab9922cf7f78f97a00a5b71691a6a2b.jpg\n",
            "Pelat-48-_jpg.rf.347188918b6a73a21ecb832116f773bf.jpg\n",
            "Pelat-4-_jpg.rf.7b5d1559d0b629dde013102576bf8348.jpg\n",
            "Pelat-50-_jpg.rf.6201d1f64ebd2be10a5824d58f0385a0.jpg\n",
            "Pelat-51-_jpg.rf.d10ba144d781e7815f431360662ad089.jpg\n",
            "Pelat-52-_jpg.rf.cad1a900e5a47863a2c37f9d3f2de32b.jpg\n",
            "Pelat-54-_jpg.rf.6b081ad55ea88a38b7ab5a5fef577d74.jpg\n",
            "Pelat-55-_jpg.rf.6b22c77f924d144ff2c6ff557bd82051.jpg\n",
            "Pelat-56-_jpg.rf.8aaa153b9f5ef9bc4e2102569502245a.jpg\n",
            "Pelat-59-_jpg.rf.5345fc13a1c9497e5f10a364668fef41.jpg\n",
            "Pelat-5-_jpg.rf.3436292dac140cd64efae7b55f225248.jpg\n",
            "Pelat-61-_jpg.rf.b0f4a31f19de864e1bfa801a2332227c.jpg\n",
            "Pelat-62-_jpg.rf.bc7ee52e3110a4aa7ea3452b474af1e9.jpg\n",
            "Pelat-63-_jpg.rf.18ef75f043921ea4ba25762c8688638e.jpg\n",
            "Pelat-64-_jpg.rf.ac6eb6d083c6a83951ab48be5a194ceb.jpg\n",
            "Pelat-65-_jpg.rf.49bd074b251ec52a9b44755c44223900.jpg\n",
            "Pelat-66-_jpg.rf.a2ffc220c5880129258bd57644a0e385.jpg\n",
            "Pelat-68-_jpg.rf.16368ea71e4246c2e8e488af4f3def6a.jpg\n",
            "Pelat-6-_jpg.rf.1df1a84ab3ddc822ecae36d8bb9527c1.jpg\n",
            "Pelat-70-_jpg.rf.35c15121f51815074dab40591491d298.jpg\n",
            "Pelat-71-_jpg.rf.7008f96051ed16d63b2cdb228f22138f.jpg\n",
            "Pelat-72-_jpg.rf.c02f983349ce64f3d8bbf376af842bc0.jpg\n",
            "Pelat-73-_jpg.rf.c3dd207c9e783b1fb6da42b4b31676a6.jpg\n",
            "Pelat-74-_jpg.rf.c33c4d9ae5ec34df6c8417c335e77989.jpg\n",
            "Pelat-76-_jpg.rf.f40cc11e965667c15d88394645a62a0a.jpg\n",
            "Pelat-77-_jpg.rf.a515a777fc8cba714c2104019262cf40.jpg\n",
            "Pelat-78-_jpg.rf.8ce6ba70847c8c470f5812d257d14a92.jpg\n",
            "Pelat-79-_jpg.rf.9e073b65dee5a1fe921bbe3184394d7c.jpg\n",
            "Pelat-81-_jpg.rf.717a162b26b2af8159a60b1d3562cbc2.jpg\n",
            "Pelat-82-_jpg.rf.be7007ba6187f672de4a369d5ab8aeda.jpg\n",
            "Pelat-83-_jpg.rf.f9b86626856b55bfb1b37ac90ae858b8.jpg\n",
            "Pelat-85-_jpg.rf.4e12d6ed5b174526ec9c0a6d492593fc.jpg\n",
            "Pelat-87-_jpg.rf.925503e1a207bebfc6052dc3e18b1f9b.jpg\n",
            "Pelat-88-_jpg.rf.05a07608cc3bdd27157650f8ed129d27.jpg\n",
            "Pelat-89-_jpg.rf.eb7c88b811e7e46ac39f77f39d8c6857.jpg\n",
            "Pelat-90-_jpg.rf.ef2af0aff887ca7db12cc50d3e78ef25.jpg\n",
            "Pelat-92-_jpg.rf.ad6d68c43ff4cb9d45002261fd12e84d.jpg\n",
            "Pelat-93-_jpg.rf.3274ca5a53ed028716188e2b44f5b532.jpg\n",
            "Pelat-95-_jpg.rf.31a3afe5046f76bb87001df0996d6c2a.jpg\n",
            "Pelat-96-_jpg.rf.163f495c87c6dc002a114876b2682b02.jpg\n",
            "Pelat-9-_jpg.rf.d7d6af7d27ac9eda237cf12ae9c503e0.jpg\n",
            "pelat-nomor-kendaraan-putih-1_169_jpeg_jpg.rf.efe38fdd3ef8fec944cce290d36bd931.jpg\n",
            "pelat-nomor-khusus-motor-listrik3499_jpg.rf.7ea27b5a1a34645fb712f4263202d882.jpg\n",
            "PHOTO-2022-05-17-13-12-23_jpg.rf.19bf3959e2a05f5ba34c701f805ba85a.jpg\n",
            "PHOTO-2022-05-17-13-12-23_jpg.rf.7fb15603cbfaf39e26da830022f5f459.jpg\n",
            "PHOTO-2022-05-17-13-12-24_jpg.rf.2f2c3837ca6c6579fbc26d0ffa7ffccc.jpg\n",
            "PHOTO-2022-05-17-13-12-24_jpg.rf.3bca7106f6e73e68e2b914955da1d900.jpg\n",
            "PHOTO-2022-05-17-13-12-25_jpg.rf.ca4feb48035813b7857ddad7a5dc7866.jpg\n",
            "PHOTO-2022-05-17-13-12-26_jpg.rf.147ff9f5ebe5b13a8e149cac7f9c0566.jpg\n",
            "PHOTO-2022-05-17-13-12-26_jpg.rf.9185ce7c4ac41feeee02f50124f25675.jpg\n",
            "PHOTO-2022-05-17-13-12-28_jpg.rf.9f4e804cd3482f180c10600be6c1c458.jpg\n",
            "PHOTO-2022-05-17-13-12-29_jpg.rf.695665ee832f2c194e63c68650e9d1b9.jpg\n",
            "PHOTO-2022-05-17-13-12-29_jpg.rf.ab8f7dab12af59fa1a2f9f63b25259ac.jpg\n",
            "PHOTO-2022-05-17-13-12-30_jpg.rf.ee1207f1115457bad15451455c7027ad.jpg\n",
            "PHOTO-2022-05-17-13-12-31-1-_jpg.rf.726d89c365ad9d047366bc9a29c1fc38.jpg\n",
            "PHOTO-2022-05-17-13-12-31_jpg.rf.61dca21bf9546a4109bcea361337507d.jpg\n",
            "PHOTO-2022-05-17-13-12-31_jpg.rf.678ca03815f527978c7b153b7ed1ce13.jpg\n",
            "PHOTO-2022-05-17-13-12-32-1-_jpg.rf.26864c60a88e7d3f44d145d136ec02b0.jpg\n",
            "PHOTO-2022-05-17-13-12-33-1-_jpg.rf.185c4a57dbf08850f62fc9498afa0553.jpg\n",
            "PHOTO-2022-05-17-13-12-33_jpg.rf.2e0e23146b0df3201d5b9065cac2208c.jpg\n",
            "PHOTO-2022-05-17-13-12-33_jpg.rf.be3b3a59384f48a7dba30a59a64a6a11.jpg\n",
            "PHOTO-2022-05-17-13-12-34-1-_jpg.rf.b166e6ed971e1d4b3e4988ff65413079.jpg\n",
            "PHOTO-2022-05-17-13-12-34-1-_jpg.rf.cb8fbb80c539b384d89f7b70d9420e1f.jpg\n",
            "PHOTO-2022-05-17-13-12-34_jpg.rf.e7d2df815b245a9af29254efbcbf6583.jpg\n",
            "PHOTO-2022-05-17-13-12-35-1-_jpg.rf.747a4383c3b5f705a5503d4231d16ab9.jpg\n",
            "PHOTO-2022-05-17-13-12-35_jpg.rf.5dbdf636000e69e960c2ce0e37154c84.jpg\n",
            "PHOTO-2022-05-17-16-44-18_jpg.rf.d21e50e17edd377964587b8e400efe22.jpg\n",
            "PHOTO-2022-05-17-16-44-19_jpg.rf.908e2e56cea00b795d862cd20d2dc591.jpg\n",
            "PHOTO-2022-05-17-16-44-19_jpg.rf.a061be84d781b4c6198a4464c1780d78.jpg\n",
            "PHOTO-2022-05-17-16-44-21_jpg.rf.0c670634d326ccd622ccdc5c2a5b3303.jpg\n",
            "PHOTO-2022-05-17-16-44-23_jpg.rf.b1eec47574558583cb6677792a236a82.jpg\n",
            "PHOTO-2022-05-17-16-44-23_jpg.rf.f0872165ae77974e1ccc87398ae0d180.jpg\n",
            "PHOTO-2022-05-17-16-44-24_jpg.rf.4a27237aff5d4238026a2cad6ff7a940.jpg\n",
            "PHOTO-2022-05-17-16-44-24_jpg.rf.efcecf763ed69c0472107e6204d04bf1.jpg\n",
            "PHOTO-2022-05-17-16-44-25_jpg.rf.76075966673c1ae3f23c97c851ed564d.jpg\n",
            "PHOTO-2022-05-17-16-44-25_jpg.rf.85355c6c0104094a17767581be0d1943.jpg\n",
            "PHOTO-2022-05-17-16-44-26_jpg.rf.86b693245cf476754f217edcc3bfc97a.jpg\n",
            "PHOTO-2022-05-17-16-44-27-1-_jpg.rf.3781a50ba3abf758f63e32f7b0136077.jpg\n",
            "PHOTO-2022-05-17-16-44-27-1-_jpg.rf.c7ede84b94a5d054bd1fba0a84799546.jpg\n",
            "PHOTO-2022-05-17-16-44-27_jpg.rf.944fbe17cf3d6c2e24c7684c4997eb27.jpg\n",
            "PHOTO-2022-05-17-16-44-28-1-_jpg.rf.3a02a0f9fe8c4cb44eae6a5e7cecad2e.jpg\n",
            "PHOTO-2022-05-17-16-44-30-1-_jpg.rf.e883c8e918e657a10f7f14e0a0576cdf.jpg\n",
            "PHOTO-2022-05-17-16-44-30_jpg.rf.1b13e1ba8c04849613dba20722f3e7dc.jpg\n",
            "PHOTO-2022-05-17-16-44-30_jpg.rf.c43d64acf05dc01ef71c41d4f5bd3be9.jpg\n",
            "PHOTO-2022-05-17-16-44-50_jpg.rf.1095ad791946bb8c444c87f7652cf2e2.jpg\n",
            "PHOTO-2022-05-17-16-44-50_jpg.rf.c72d93d51315e36233691318b3cdfee6.jpg\n",
            "PHOTO-2022-05-17-16-44-51-1-_jpg.rf.6a38e86d8210c474acfe170b900fa70b.jpg\n",
            "PHOTO-2022-05-17-16-44-51-1-_jpg.rf.df9431d2d4242c0a8af9dcd3fb3b46b6.jpg\n",
            "PHOTO-2022-05-17-16-44-51_jpg.rf.5bf76bcf84f2cabda13e7feb51abd392.jpg\n",
            "plat2_jpg.rf.86a7dedb2ea6700181247e2a02db0e2d.jpg\n",
            "plat-kendaraan-unik-liputantimes-com-thumbnail-1-660x330_png_jpg.rf.4d22ebe78bdcdd7f7c9b22bf2bca319c.jpg\n",
            "plat-nomor-putih-728x404_jpg.rf.cc7c944f50c9b4409d9f25491f04f758.jpg\n",
            "removelicenseplatewhensellingcar_jpg.rf.d18e7c08655b8c2c256fd0b4e8f7ac9b.jpg\n",
            "Screenshot_20220517-140026_Gallery_jpg.rf.ce52c841e3c9778abf2d457c457be61e.jpg\n",
            "Screenshot_20220517-140053_Gallery_jpg.rf.ca811d66caf2c1929bac8e640b297ea1.jpg\n",
            "Screenshot_20220517-140144_Gallery_jpg.rf.44377b102b5132ff4a3404ef254da205.jpg\n",
            "Screenshot_20220517-140154_Gallery_jpg.rf.61b34b0571cdd442a95564ab36885b83.jpg\n",
            "Screenshot_20220517-140206_Gallery_jpg.rf.5476a42001f598881116494bc3bbadd6.jpg\n",
            "Screenshot_20220517-140216_Gallery_jpg.rf.fedb2f75ff6c3d9e345e75ef78a422a6.jpg\n",
            "Screenshot_20220517-140228_Gallery_jpg.rf.76fa6496accf1864d4c93038525d4a6b.jpg\n",
            "Screenshot_20220517-140245_Gallery_jpg.rf.86054edafbc9dc652c21c74b111c9d48.jpg\n",
            "Screenshot_20220517-140317_Gallery_jpg.rf.6346479cafb955dc8d3e0ca5601980f3.jpg\n",
            "Screenshot_20220517-140329_Gallery_jpg.rf.b00eac5540a2671a6d41d72edc88d45b.jpg\n",
            "Screenshot_20220517-140338_Gallery_jpg.rf.42d6695d715c4f8d88bb951bc01a9f70.jpg\n",
            "Screenshot_20220517-140449_Gallery_jpg.rf.ea2cf4789bce4807030f23a24c7a49de.jpg\n",
            "Screenshot_20220517-140507_Gallery_jpg.rf.b87149730a6b99cac061fc4541d0689c.jpg\n",
            "Screenshot_20220517-140531_Gallery_jpg.rf.0bdf06a0ceaf4d2d6291dc93b18488b9.jpg\n",
            "Screenshot_20220517-140544_Gallery_jpg.rf.7beefe66ff4b180e3a4f82dd61f22da7.jpg\n",
            "Screenshot_20220517-140555_Gallery_jpg.rf.49e77925a2e6cbba0880989505a10111.jpg\n",
            "Screenshot_20220517-140604_Gallery_jpg.rf.5fae0f2365ebfc0e3994c1d01bc304b1.jpg\n",
            "Screenshot_20220517-140616_Gallery_jpg.rf.84d5813d46bf1f9a7b6849270a646017.jpg\n",
            "Screenshot_20220517-140624_Gallery_jpg.rf.a23ab6b18844601115bc3e7799a6cfe0.jpg\n",
            "Screenshot_20220517-140632_Gallery_jpg.rf.3eef284634b139d96a6dd721164e1b8b.jpg\n",
            "Truk-100-_jpg.rf.4916efc5895c013af5fc8c6ebc64e4a4.jpg\n",
            "Truk-102-_jpg.rf.04ea3d5026e8bb88c89cdb36b9156f0f.jpg\n",
            "Truk-103-_jpg.rf.99c037bed22498b348210524c60a703e.jpg\n",
            "Truk-105-_jpg.rf.91a3b68fbd2cbab07f05b94a9e47dd5c.jpg\n",
            "Truk-106-_jpg.rf.2a99d19db535c5f0489eeb6c4f177d74.jpg\n",
            "Truk-107-_jpg.rf.8adb625f06a38c9566f1f3e7708bf249.jpg\n",
            "Truk-108-_jpg.rf.3e14bfcb686aff3b1d7a3f92a386c206.jpg\n",
            "Truk-110-_jpg.rf.9317e89bfe48a68abffc3b3c6d879f9a.jpg\n",
            "Truk-113-_jpg.rf.87152a82743b85a6ff6c7d611c6c88a6.jpg\n",
            "Truk-114-_jpg.rf.f15e1f32743b61c44be3b708a1685bee.jpg\n",
            "Truk-117-_jpg.rf.ff7f3dbfbdcb8e0a1170850dec226049.jpg\n",
            "Truk-11-_jpg.rf.a8b9d705ba04a8fe5c3b592a13fe664c.jpg\n",
            "Truk-120-_jpg.rf.5457112cd1bffb7030cba5db1ebcc091.jpg\n",
            "Truk-124-_jpg.rf.12f8fd227bf886b24b349c43fee6f3e9.jpg\n",
            "Truk-126-_jpg.rf.5e9cf095ca2a1a6f68cdb4aed64e73e6.jpg\n",
            "Truk-128-_jpg.rf.ca20c7ec04eb910944605d373b60c1dc.jpg\n",
            "Truk-129-_jpg.rf.11eddd804cf01a692b22f5fb22472bf9.jpg\n",
            "Truk-12-_jpg.rf.179d1efe4b12bf6b616166843c2d6fb4.jpg\n",
            "Truk-130-_jpg.rf.e2f4ccd4fa6443628ebe8fb913e8b8b7.jpg\n",
            "Truk-132-_jpg.rf.f7d4d1a7e78882a67fe9c4a7bdfd88be.jpg\n",
            "Truk-134-_jpg.rf.29414da5b8b40e8e94f368ef62d6b901.jpg\n",
            "Truk-135-_jpg.rf.353ee131621d776a1077ba7361b186d8.jpg\n",
            "Truk-137-_jpg.rf.eddc3ed4c0c677a7d5d4fc7babcb3cfa.jpg\n",
            "Truk-138-_jpg.rf.337795a5352da0f471e248bb0ed1689f.jpg\n",
            "Truk-13-_jpg.rf.580c6e722aa8ecc59ef046af41a079f4.jpg\n",
            "Truk-140-_jpg.rf.c8921df37fac47128ba652a8a5911481.jpg\n",
            "Truk-142-_jpg.rf.86835567188328aae0775ab205928551.jpg\n",
            "Truk-143-_jpg.rf.236fd4619cb77366ca6f5084c12e3c1c.jpg\n",
            "Truk-144-_jpg.rf.07f14e7cf2c23977e8608636e36f2763.jpg\n",
            "Truk-145-_jpg.rf.c369c17bff139f97067832177294c575.jpg\n",
            "Truk-146-_jpg.rf.1b7e2d8f4fd98f2feb1667097fa16b6c.jpg\n",
            "Truk-147-_jpg.rf.cb81829b04b73388cf8e2964d6cd8c33.jpg\n",
            "Truk-148-_jpg.rf.cb9c3750d7550755aa69daa878ff41b5.jpg\n",
            "Truk-149-_jpg.rf.c07baae9df4229e3f639ad90a7ca88ed.jpg\n",
            "Truk-14-_jpg.rf.8dd4e615c358fad868541df362e57b26.jpg\n",
            "Truk-150-_jpg.rf.fc7a94a0c32d5f5e0c78acace11363ca.jpg\n",
            "Truk-151-_jpg.rf.68a0e590287c4fae05372eff6820cca2.jpg\n",
            "Truk-152-_jpg.rf.f38e24278abc188f03f5ca72ffc35343.jpg\n",
            "Truk-153-_jpg.rf.46c527cabdc6dcc2102277644c2cb390.jpg\n",
            "Truk-154-_jpg.rf.83b717616e2e49502f58a01de6eb4fc8.jpg\n",
            "Truk-155-_jpg.rf.17525b14d844d5c848a6e307c4de91a9.jpg\n",
            "Truk-156-_jpg.rf.1bd1e3aa950eecc9e2c2c0115a92fe9a.jpg\n",
            "Truk-157-_jpg.rf.4fd9f79f699fee333defa32dc4325416.jpg\n",
            "Truk-158-_jpg.rf.341993c861da3afc403a19396bff2094.jpg\n",
            "Truk-160-_jpg.rf.acd43ce3a04a925429b0c74095f4f830.jpg\n",
            "Truk-161-_jpg.rf.a3c89e9f0aada0f132b2c13d54eef592.jpg\n",
            "Truk-162-_jpg.rf.d971288a039ac0d773e1e2dc6a144f59.jpg\n",
            "Truk-163-_jpg.rf.3ab46c111f245d81ca9eb91d81880e03.jpg\n",
            "Truk-165-_jpg.rf.7f593eb1767fefc05ef033f60ff22d54.jpg\n",
            "Truk-166-_jpg.rf.9316fafd1955f4cd1fd13182bcd282c8.jpg\n",
            "Truk-169-_jpg.rf.186c04f711b829b78f2f7ccfb1748476.jpg\n",
            "Truk-170-_jpg.rf.e741fa30aa46f8d2147fe8c43d16d6b5.jpg\n",
            "Truk-171-_jpg.rf.5d9fc351504268fd64ca96c5ac237d0d.jpg\n",
            "Truk-172-_jpg.rf.abbde9c53b0d15315e10702985a94ae0.jpg\n",
            "Truk-173-_jpg.rf.9572ec755020836ab4c5c17103289f3f.jpg\n",
            "Truk-174-_jpg.rf.0f315d9ee6b504b2f77aaa32db1ae19d.jpg\n",
            "Truk-175-_jpg.rf.693e5353e4083754a64dead7628c439c.jpg\n",
            "Truk-176-_jpg.rf.96c8822c94dd7d68b1e726458db332ec.jpg\n",
            "Truk-177-_jpg.rf.299bab2523cc72ff6a026eafc95758e6.jpg\n",
            "Truk-178-_jpg.rf.1bc6bbc54277e83c5f2a3c2c4af93989.jpg\n",
            "Truk-179-_jpg.rf.e1b6f3fc61cd06396885d06e4b010288.jpg\n",
            "Truk-17-_jpg.rf.2c5e4f182f85fbc9be8a2944bb20dd91.jpg\n",
            "Truk-181-_jpg.rf.4ef971bb6ccac359ac0510a70550fc26.jpg\n",
            "Truk-182-_jpg.rf.32a1f86063098a75a77ef7995ce48cc5.jpg\n",
            "Truk-183-_jpg.rf.ed1f94f5b0d06c938067ded0646034fe.jpg\n",
            "Truk-185-_jpg.rf.51da50e51d255839c71ae8803f593e5f.jpg\n",
            "Truk-186-_jpg.rf.75d3591a6ea1fd805bac315714720ecb.jpg\n",
            "Truk-188-_jpg.rf.58c840405a220757dde9d08c5149ed24.jpg\n",
            "Truk-18-_jpg.rf.82b7ed20fc1b7ff4781c32476a5e73a0.jpg\n",
            "Truk-190-_jpg.rf.965111d3160d341fccf6d58164d46592.jpg\n",
            "Truk-191-_jpg.rf.d1e6bdf0af0e0528dff964d2980369ad.jpg\n",
            "Truk-192-_jpg.rf.30e2c0280299fbca1f4030c47eecab9e.jpg\n",
            "Truk-194-_jpg.rf.b30d71eae6079199b350d3f284f31675.jpg\n",
            "Truk-195-_jpg.rf.f126971c9e4937aa9e9a8e2f11899d33.jpg\n",
            "Truk-196-_jpg.rf.1685a94abeeccf7da2082f196ef0aa55.jpg\n",
            "Truk-197-_jpg.rf.fa040c31bb746b7d3d50f7c203057626.jpg\n",
            "Truk-198-_jpg.rf.afa6c60b1472ae1b2e36e01e61d9bf49.jpg\n",
            "Truk-19-_jpg.rf.2fd8b38778235d1ada5c13498cce6cfc.jpg\n",
            "Truk-201-_jpg.rf.8b42f2c561a1258268c4b7ee9a5d1272.jpg\n",
            "Truk-203-_jpg.rf.efe944042181c4a644dd80691e40f210.jpg\n",
            "Truk-205-_jpg.rf.05239894e5b2ec624146f4196ece6718.jpg\n",
            "Truk-206-_jpg.rf.efb3929995f303106eed229195dfe9e5.jpg\n",
            "Truk-207-_jpg.rf.01f6dcc4b1eb768b65a9bb25f4a2f594.jpg\n",
            "Truk-208-_jpg.rf.3b490a084efb098f77cc74d523232563.jpg\n",
            "Truk-209-_jpg.rf.5788ae4a89ae57df560a7f161c3dc0b9.jpg\n",
            "Truk-20-_jpg.rf.7cfcf12c8ba07bba73cb6d1dbde687d8.jpg\n",
            "Truk-211-_jpg.rf.3aacb01a431518036bb31b42e93717d7.jpg\n",
            "Truk-212-_jpg.rf.24fa772ae71a9d79ba89dff7bf03fe3f.jpg\n",
            "Truk-213-_jpg.rf.7f885d31d950c9446bde6ab4b8b1e030.jpg\n",
            "Truk-214-_jpg.rf.dd0f8eed2b02299cedb9cce49cea13be.jpg\n",
            "Truk-215-_jpg.rf.57397670ad658dfdadbf26612661f19c.jpg\n",
            "Truk-217-_jpg.rf.ce4728d5f522ef8d8d3a783c89d77ae2.jpg\n",
            "Truk-218-_jpg.rf.7bd1e19221f2f06c0ffedbf3ba33bd55.jpg\n",
            "Truk-219-_jpg.rf.d9808bb224cbd5e30d48bc54bcf4be53.jpg\n",
            "Truk-21-_jpg.rf.2825ebe626bbb86c6b8e21846d359878.jpg\n",
            "Truk-220-_jpg.rf.d74d82886edfaa0ac42e9040a9cac21a.jpg\n",
            "Truk-222-_jpg.rf.9afdbdf2e94ba032204b21d94a553a15.jpg\n",
            "Truk-224-_jpg.rf.d105001eb76698225d223696660aca5f.jpg\n",
            "Truk-225-_jpg.rf.9415fc0e67461f588e77911f6dea20d9.jpg\n",
            "Truk-226-_jpg.rf.e11bd28cf7935156dafcbf64f98f9497.jpg\n",
            "Truk-229-_jpg.rf.baacdbf8a1d51f8ad575c5c3658354cc.jpg\n",
            "Truk-22-_jpg.rf.5b9a16c4e80e95edde7559c1b0e2e20f.jpg\n",
            "Truk-230-_jpg.rf.2638730526592faec6bbb9b69cb9c08c.jpg\n",
            "Truk-234-_jpg.rf.c4e5c79ab9628f4466365e6bad1db049.jpg\n",
            "Truk-235-_jpg.rf.71bfc273242b6d2923c3cb3b006d07bc.jpg\n",
            "Truk-238-_jpg.rf.e9d81e178e8e4ef18f6cacaa881df586.jpg\n",
            "Truk-239-_jpg.rf.3c3396f90b12f30217e9a69db9867d1b.jpg\n",
            "Truk-241-_jpg.rf.40f4a8497bf05c1d46761fea21d1096c.jpg\n",
            "Truk-242-_jpg.rf.7d3514a50c92c916a406d66245da8800.jpg\n",
            "Truk-243-_jpg.rf.b9fe1e8486563b317140f3bcb700cada.jpg\n",
            "Truk-244-_jpg.rf.1291b6d6a7bfaabc42deff993af49481.jpg\n",
            "Truk-247-_jpg.rf.be3a3ba289b09d422cd2d32ae4cf0728.jpg\n",
            "Truk-248-_jpg.rf.d0e3b2911c19cdcf3bd429a92ceaeb11.jpg\n",
            "Truk-249-_jpg.rf.501fba477c460284955396a2961c0b38.jpg\n",
            "Truk-251-_jpg.rf.a06fd5dbfe08b387e6b732c2a1e17bac.jpg\n",
            "Truk-252-_jpg.rf.cb7b05919e76a8521d2564f4d9f5dac0.jpg\n",
            "Truk-253-_jpg.rf.e716ce1ebebf2e6eb47b3165e8954079.jpg\n",
            "Truk-254-_jpg.rf.6069c5a2bbd9edadab01371a240d046d.jpg\n",
            "Truk-255-_jpg.rf.90ff5c9bafbb1a927641318d286d99be.jpg\n",
            "Truk-257-_jpg.rf.d59cf165ed33cc0690cdac9c555bdcfd.jpg\n",
            "Truk-259-_jpg.rf.342b929941669ce2cc43f66730d8c9b8.jpg\n",
            "Truk-25-_jpg.rf.7d0e518134987b154af55b4bda1eeddd.jpg\n",
            "Truk-260-_jpg.rf.3b79c43124897de2b627389aee66f4ec.jpg\n",
            "Truk-261-_jpg.rf.4b6584b663c498e134d414ad72020d16.jpg\n",
            "Truk-262-_jpg.rf.3e79afe23b92d92ce789dc2ff89ca9da.jpg\n",
            "Truk-263-_jpg.rf.804fb8712a3f50ee96b4577d86ec7f6b.jpg\n",
            "Truk-264-_jpg.rf.f8639b653ec169ddd35185f562815710.jpg\n",
            "Truk-265-_jpg.rf.0724bdfe21cb8d5967b5a43c11a285a4.jpg\n",
            "Truk-266-_jpg.rf.22ce39d40b7a2918bd27e43d96008357.jpg\n",
            "Truk-268-_jpg.rf.bd76efd42cf94f86b9c6b87aebfee0ef.jpg\n",
            "Truk-26-_jpg.rf.c0682382334e9607481da791ce95da57.jpg\n",
            "Truk-270-_jpg.rf.7037a466b5b5132bd5f76ce84961e2cf.jpg\n",
            "Truk-271-_jpg.rf.d4f6033646ff3e63976350b526d2fb61.jpg\n",
            "Truk-272-_jpg.rf.b6e16852ddc335c3596cf27035e30b2a.jpg\n",
            "Truk-275-_jpg.rf.b9ab4826dd8e0d04f698fd690a4cd444.jpg\n",
            "Truk-276-_jpg.rf.eab41b61092d82557de2159cacd6ac23.jpg\n",
            "Truk-277-_jpg.rf.c441cb3f0f211ace5ce9da3d1c16ad4a.jpg\n",
            "Truk-278-_jpg.rf.340a230745fd980a30b9571453f68998.jpg\n",
            "Truk-27-_jpg.rf.59ba3c43b0cdceefbe22e915de04d408.jpg\n",
            "Truk-280-_jpg.rf.850a7d251793361e5fbf6e4a5e89e27a.jpg\n",
            "Truk-283-_jpg.rf.8b7273529c91bb37aa0169671cd5d9c9.jpg\n",
            "Truk-284-_jpg.rf.b904f1437e0209409b4757197f4710cc.jpg\n",
            "Truk-285-_jpg.rf.9ecc7554c0235d9895e9e5d66c635417.jpg\n",
            "Truk-286-_jpg.rf.0188bb9272b826afe50948e9f7aee365.jpg\n",
            "Truk-287-_jpg.rf.16f416506d3890aaf732b3c307ff344c.jpg\n",
            "Truk-288-_jpg.rf.a22de5ce6df0d32908ae837a08b7aebf.jpg\n",
            "Truk-289-_jpg.rf.a81c6fff9bb98b14ed836aa893fcc8a2.jpg\n",
            "Truk-291-_jpg.rf.81e7610bfbd2f226725c1c07c04490ed.jpg\n",
            "Truk-292-_jpg.rf.b2502d3386b18f7c80fbc6091c87c87a.jpg\n",
            "Truk-293-_jpg.rf.81d4fc9f7ee2ea20473198d2efa898a8.jpg\n",
            "Truk-294-_jpg.rf.8180dfb5be90de59907dc264702b72d9.jpg\n",
            "Truk-295-_jpg.rf.b91571b52a7e2bcedddca9f03e1f7b55.jpg\n",
            "Truk-298-_jpg.rf.4590f16b6b97a083891256ac00ae3bea.jpg\n",
            "Truk-299-_jpg.rf.67aa04827e13e9d53c545fe3b420ee07.jpg\n",
            "Truk-2-_jpg.rf.9826bf8b4906062d0a2563c908c207a0.jpg\n",
            "Truk-300-_jpg.rf.dfc2f2538183739de37d0a8ce1a71006.jpg\n",
            "Truk-301-_jpg.rf.4f00a92ec234746494f0d3ee7d778731.jpg\n",
            "Truk-302-_jpg.rf.b2ebe031b892b8f2836c671442d4ad35.jpg\n",
            "Truk-303-_jpg.rf.38e2c274eb3d56abae528d64d10da808.jpg\n",
            "Truk-304-_jpg.rf.43b635f7514ec0722ea6e5a0d7b44a61.jpg\n",
            "Truk-305-_jpg.rf.ba446a8430c2b6265c1df9af9117d73a.jpg\n",
            "Truk-306-_jpg.rf.4906e87af49d53746136d15370a93fb3.jpg\n",
            "Truk-307-_jpg.rf.140ec1dab10039f90e66e04d415bcf41.jpg\n",
            "Truk-308-_jpg.rf.f7f206974d7027bb2142295d6981ef5e.jpg\n",
            "Truk-310-_jpg.rf.c93d5e97c4badaacf54ea39e9ca9f5c4.jpg\n",
            "Truk-311-_jpg.rf.0c8796e931fd74e267801d5767064c80.jpg\n",
            "Truk-312-_jpg.rf.c1876967e43ad81083a3cb808607a526.jpg\n",
            "Truk-314-_jpg.rf.ea9e65ced26893ab7c56431b733e0948.jpg\n",
            "Truk-315-_jpg.rf.4c5f453e2ee496ebe38b55bc72eec761.jpg\n",
            "Truk-317-_jpg.rf.20753a86207a6f4eda201138a91502db.jpg\n",
            "Truk-318-_jpg.rf.6f1f4a7094ea4fce2dab0f69025e7b6c.jpg\n",
            "Truk-319-_jpg.rf.274043e880e7a15cc3f82fb92498faff.jpg\n",
            "Truk-31-_jpg.rf.e8ecca6a429c6bf4a6e3dc268352f602.jpg\n",
            "Truk-320-_jpg.rf.234b7dfce9b758718e5d8035ff8c06a4.jpg\n",
            "Truk-321-_jpg.rf.ebd2fb81faac4c8cf9a5f0660acaa944.jpg\n",
            "Truk-322-_jpg.rf.effbf0047a7c0bebc2490da49d060bf6.jpg\n",
            "Truk-325-_jpg.rf.8689656bb01dc97b31af87450ad48745.jpg\n",
            "Truk-326-_jpg.rf.9e0c5d26c074596bd2ef4211d5b5eca2.jpg\n",
            "Truk-327-_jpg.rf.f90ee2daf9c7a7bc1e1d93289b0d884e.jpg\n",
            "Truk-328-_jpg.rf.765c87c52aeede425c31284089cf8188.jpg\n",
            "Truk-329-_jpg.rf.cb59901b21ae0124c1084cf2f6b11b31.jpg\n",
            "Truk-32-_jpg.rf.87145755a6e253f5a1db0a170442dad2.jpg\n",
            "Truk-330-_jpg.rf.8146821e9b6f645ad3cc692d39ddd1cd.jpg\n",
            "Truk-332-_jpg.rf.85983cb315639a088168c8ae5bb82dd8.jpg\n",
            "Truk-333-_jpg.rf.61a71f5e1b32eb5d9ad8768fab8cf074.jpg\n",
            "Truk-334-_jpg.rf.6b124371498439ddf18015e2db39973e.jpg\n",
            "Truk-335-_jpg.rf.7b38435e1024b9d1754e12e3b50d184f.jpg\n",
            "Truk-338-_jpg.rf.fa6a58fc2869972f3a0e6279b2c00510.jpg\n",
            "Truk-340-_jpg.rf.196e33d018624f9efce9306e7bc79e14.jpg\n",
            "Truk-342-_jpg.rf.086d6a60f35d86dd00f0e528d92fbd01.jpg\n",
            "Truk-343-_jpg.rf.1066e03cadaad969dfd4853f79179844.jpg\n",
            "Truk-344-_jpg.rf.674928cf2c453947a9a19de72313d844.jpg\n",
            "Truk-347-_jpg.rf.ab8868600247267d0e7ca808e9f7c24d.jpg\n",
            "Truk-349-_jpg.rf.4b0a7e6fa272c142cb11375851a7f7d1.jpg\n",
            "Truk-351-_jpg.rf.79141d647b9f32b3d772c2fd61620e38.jpg\n",
            "Truk-352-_jpg.rf.cdec6039dbadfcab02c8bf285cda8326.jpg\n",
            "Truk-353-_jpg.rf.51b3d48c09518245b428b272d4cf1e5f.jpg\n",
            "Truk-355-_jpg.rf.fc51eb981ebb158ced85ba0e926dabb5.jpg\n",
            "Truk-356-_jpg.rf.593574e485c34bc05e37277197af8081.jpg\n",
            "Truk-357-_jpg.rf.50e35cbd2779c85d835d93019a4c98e2.jpg\n",
            "Truk-358-_jpg.rf.f4e3fba57e3edec1f3ddd689eccc1ba9.jpg\n",
            "Truk-359-_jpg.rf.9732616f55a04669ad695d6b2f443466.jpg\n",
            "Truk-360-_jpg.rf.154862536ea2963f11c1e731b3d35c19.jpg\n",
            "Truk-363-_jpg.rf.967db248e89014445f22d41ad56b67ad.jpg\n",
            "Truk-364-_jpg.rf.429909c105b1f128a3e7fbbacac9c472.jpg\n",
            "Truk-367-_jpg.rf.3199544232a38efcdab13b704372c275.jpg\n",
            "Truk-369-_jpg.rf.37bcba8b7c364d5d97827cb534b398b0.jpg\n",
            "Truk-370-_jpg.rf.b69de8d98f8dd60e36ce0dcbedf47992.jpg\n",
            "Truk-373-_jpg.rf.30d2984bbf72a755c84c7eddced2fe69.jpg\n",
            "Truk-374-_jpg.rf.67b9d16300671747aa24336b10765bd4.jpg\n",
            "Truk-38-_jpg.rf.84a2b34c931321fc3dad97a4f1738de1.jpg\n",
            "Truk-39-_jpg.rf.d8108c89b435d50cacc1de47360385d4.jpg\n",
            "Truk-40-_jpg.rf.be2aa2737797bd335db5bbedcef73b74.jpg\n",
            "Truk-41-_jpg.rf.61b76fd2be31f0394af3ad934adc99c5.jpg\n",
            "Truk-43-_jpg.rf.cd220adf29386f0b3416093a4d01af9f.jpg\n",
            "Truk-44-_jpg.rf.b4fabcf1f9749e8e3f42fe39b0c0e3f6.jpg\n",
            "Truk-45-_jpg.rf.a7fdf406628c55c1aca41023522aa3a1.jpg\n",
            "Truk-46-_jpg.rf.89f6c4913dccf18f0ff4d81dc2fd9333.jpg\n",
            "Truk-47-_jpg.rf.336b829042e0fde5194bb903b99e47f6.jpg\n",
            "Truk-48-_jpg.rf.b638387007c2372c58db8e1d6c2400c1.jpg\n",
            "Truk-50-_jpg.rf.51b18ba8529fdbd4fa71caa48cbc1d09.jpg\n",
            "Truk-51-_jpg.rf.d50dccbab71aedb87939e366e90d170e.jpg\n",
            "Truk-52-_jpg.rf.35a3ad197a9b00dec5734a06d929f432.jpg\n",
            "Truk-53-_jpg.rf.b23dc747cc0e8c5c4477382a72002b74.jpg\n",
            "Truk-54-_jpg.rf.8b9e96fd42a2dc168811582209ac9da7.jpg\n",
            "Truk-57-_jpg.rf.aec580574b266dc1b606852a165c145f.jpg\n",
            "Truk-58-_jpg.rf.725c1bb67488d4265de06ae1d26cccb9.jpg\n",
            "Truk-59-_jpg.rf.b564146c8c65135c9a7f7e1a04508968.jpg\n",
            "Truk-5-_jpg.rf.782755fc6f79c5431f2ce4d26b0a0f50.jpg\n",
            "Truk-60-_jpg.rf.6e4b9297bbf790f3bc1ccdeb88df40d2.jpg\n",
            "Truk-61-_jpg.rf.6ad6144be72077f5091091c72ae54c13.jpg\n",
            "Truk-63-_jpg.rf.2b601955f29ef965e85f2a7f71c64427.jpg\n",
            "Truk-64-_jpg.rf.a7bae8a50cd87ce069ac4803bdc39b61.jpg\n",
            "Truk-65-_jpg.rf.b4694b92d16f951ed3b3a195036a86c9.jpg\n",
            "Truk-67-_jpg.rf.d735c0ffad25da2d227796b5e8fa1640.jpg\n",
            "Truk-68-_jpg.rf.760094bb5a6e23638bebf5239da9f400.jpg\n",
            "Truk-69-_jpg.rf.73d665f38009702d37211bc674bb399e.jpg\n",
            "Truk-6-_jpg.rf.2d2292b234c52bd2e430a8e8a57e0858.jpg\n",
            "Truk-73-_jpg.rf.1fc8bebb29beee9105d5c013cc056434.jpg\n",
            "Truk-74-_jpg.rf.94d0ced95fb66d672fc2d672393f9010.jpg\n",
            "Truk-75-_jpg.rf.3546ff0559e325dfaae3496b9b1c5cc1.jpg\n",
            "Truk-76-_jpg.rf.371b7a738a4aacd9e2517badb10422dc.jpg\n",
            "Truk-77-_jpg.rf.c7596821e4ff1a4b61dd09f81e9cbe88.jpg\n",
            "Truk-78-_jpg.rf.a797122fbbb3631f6af5f076d63b0c5a.jpg\n",
            "Truk-79-_jpg.rf.19c6e77bed5d7f188fe30e6b77740e43.jpg\n",
            "Truk-80-_jpg.rf.e32cc2ab2c9148f37df2b9240963e092.jpg\n",
            "Truk-81-_jpg.rf.7d68a8645c2a911db0614ec225df4665.jpg\n",
            "Truk-83-_jpg.rf.eee63b53312a605f6bd185b721c824b4.jpg\n",
            "Truk-84-_jpg.rf.783b2e15b3e09f36af7c33751afe70c0.jpg\n",
            "Truk-85-_jpg.rf.0d4b7fd839a68b524c95ad21693b9f1f.jpg\n",
            "Truk-86-_jpg.rf.4fcb892b1f594d50992626fb81ddebdb.jpg\n",
            "Truk-88-_jpg.rf.99a1943265db1b364eeeb02e210ecef7.jpg\n",
            "Truk-89-_jpg.rf.5b29108fd1c11701e24a761bfc186ff1.jpg\n",
            "Truk-8-_jpg.rf.b8ffa31288481cd4e2a65899ac7367f1.jpg\n",
            "Truk-90-_jpg.rf.1a8a17216e3d93b3c766a0ac47e1f6cb.jpg\n",
            "Truk-91-_jpg.rf.4fb403547af2dddbab9345f1d8d36d05.jpg\n",
            "Truk-92-_jpg.rf.e27fcb71b84cf46f0c50b4ec14e5a012.jpg\n",
            "Truk-94-_jpg.rf.cef469976024291787b6b9c3d288cfca.jpg\n",
            "Truk-95-_jpg.rf.fb4a4445c5d7ee42c4e7236015259fd7.jpg\n",
            "Truk-99-_jpg.rf.a75573b1420973fca7c920f2758be45b.jpg\n",
            "Truk-9-_jpg.rf.671969df248f6631eb48e328adff751b.jpg\n",
            "viar_q1_jpg.rf.579d1f7377c184a79a962fafa165d540.jpg\n",
            "W1588TE-1-_jpg.rf.e396d7e4a520419e98159b52f2118472.jpg\n",
            "W1588TE_jpg.rf.38fc37c23514f8ebd69fcac09eb8a658.jpg\n",
            "Z1859LD_jpg.rf.aa7859e6595f5764b6140ed36c9d68da.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DtDu-7Hlk_O"
      },
      "source": [
        "#in the next three cells, we move the data into a structure that the image detection library will be expecting\n",
        "#but no file data manipulation is necessary\n",
        "#images can also be segmented into class folders, but we combine all classes here\n",
        "!mkdir Chess\n",
        "!mkdir Chess/annotations\n",
        "!mkdir Chess/Annotations\n",
        "!mkdir Chess/Images"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir Kendaraan\n",
        "!mkdir Kendaraan/annotations\n",
        "!mkdir Kendaraan/Annotations\n",
        "!mkdir Kendaraan/Images"
      ],
      "metadata": {
        "id": "r0UBPT6lKye_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uZzGiw_mrRI"
      },
      "source": [
        "%cp train/_annotations.coco.json Chess/annotations/instances_Images.json"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLzZXkkhrvx4"
      },
      "source": [
        "%cp train/*.jpg Chess/Images/"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBi3RS1_fd4N"
      },
      "source": [
        "# Training\n",
        "\n",
        "In this section we set up the efficientDet-d0 model from backbone and train to our custom case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fvfo6x7Vdw6i"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append(\"Monk_Object_Detection/4_efficientdet/lib/\");"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21o9flNqfP-8"
      },
      "source": [
        "from train_detector import Detector"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c35tC0dCfoky"
      },
      "source": [
        "gtf = Detector();"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYKeGqpqgvN4"
      },
      "source": [
        "#directs the model towards file structure\n",
        "root_dir = \"./\";\n",
        "coco_dir = \"Chess\";\n",
        "img_dir = \"./\";\n",
        "set_dir = \"Images\";"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6epk9-HkBwJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c51bb83-b5f5-485a-809f-c0786395e251"
      },
      "source": [
        "#smells like some free compute from Colab, nice\n",
        "gtf.Train_Dataset(root_dir, coco_dir, img_dir, set_dir, batch_size=8, image_size=640, use_gpu=True)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.03s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0-xLOmisU9P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c81c8b1-cded-4d54-d5b8-aa20c1042083"
      },
      "source": [
        "gtf.Model();"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3XsPHdxsXsH"
      },
      "source": [
        "gtf.Set_Hyperparams(lr=0.0001, val_interval=1, es_min_delta=0.0, es_patience=0)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7vtQ28fsc9K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "67886d48-c077-48e9-cba4-1827f51b8bce"
      },
      "source": [
        "%%time\n",
        "gtf.Train(num_epochs=26, model_output_dir=\"trained/\");"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ],
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 1/26. Iteration: 646/646. Cls loss: 0.25539. Reg loss: 0.35904. Batch loss: 0.61442 Total loss: 0.68934</span><progress style='margin:2px 4px;description_width:initial;' max='646' value='646'></progress>100% 646/646 [05:19&lt;00:00,  2.15it/s]</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "faild onnx export\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ],
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 2/26. Iteration: 646/646. Cls loss: 0.20194. Reg loss: 0.30017. Batch loss: 0.50211 Total loss: 0.57071</span><progress style='margin:2px 4px;description_width:initial;' max='646' value='646'></progress>100% 646/646 [05:18&lt;00:00,  2.26it/s]</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "faild onnx export\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ],
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 3/26. Iteration: 646/646. Cls loss: 0.17162. Reg loss: 0.33956. Batch loss: 0.51118 Total loss: 0.49972</span><progress style='margin:2px 4px;description_width:initial;' max='646' value='646'></progress>100% 646/646 [05:21&lt;00:00,  2.27it/s]</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "faild onnx export\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ],
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 4/26. Iteration: 646/646. Cls loss: 0.17930. Reg loss: 0.32729. Batch loss: 0.50659 Total loss: 0.44990</span><progress style='margin:2px 4px;description_width:initial;' max='646' value='646'></progress>100% 646/646 [05:19&lt;00:00,  2.29it/s]</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "faild onnx export\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ],
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 5/26. Iteration: 646/646. Cls loss: 0.14161. Reg loss: 0.31354. Batch loss: 0.45515 Total loss: 0.40930</span><progress style='margin:2px 4px;description_width:initial;' max='646' value='646'></progress>100% 646/646 [05:20&lt;00:00,  2.30it/s]</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "faild onnx export\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ],
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 6/26. Iteration: 646/646. Cls loss: 0.13012. Reg loss: 0.28339. Batch loss: 0.41350 Total loss: 0.38092</span><progress style='margin:2px 4px;description_width:initial;' max='646' value='646'></progress>100% 646/646 [05:22&lt;00:00,  2.27it/s]</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "faild onnx export\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ],
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 7/26. Iteration: 646/646. Cls loss: 0.06222. Reg loss: 0.21498. Batch loss: 0.27721 Total loss: 0.35044</span><progress style='margin:2px 4px;description_width:initial;' max='646' value='646'></progress>100% 646/646 [05:22&lt;00:00,  2.23it/s]</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "faild onnx export\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ],
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 8/26. Iteration: 646/646. Cls loss: 0.03777. Reg loss: 0.17181. Batch loss: 0.20958 Total loss: 0.32959</span><progress style='margin:2px 4px;description_width:initial;' max='646' value='646'></progress>100% 646/646 [05:24&lt;00:00,  2.20it/s]</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "faild onnx export\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ],
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 9/26. Iteration: 646/646. Cls loss: 0.10509. Reg loss: 0.16914. Batch loss: 0.27423 Total loss: 0.30882</span><progress style='margin:2px 4px;description_width:initial;' max='646' value='646'></progress>100% 646/646 [05:20&lt;00:00,  2.20it/s]</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "faild onnx export\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ],
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 10/26. Iteration: 646/646. Cls loss: 0.06370. Reg loss: 0.18379. Batch loss: 0.24749 Total loss: 0.29141</span><progress style='margin:2px 4px;description_width:initial;' max='646' value='646'></progress>100% 646/646 [05:23&lt;00:00,  2.20it/s]</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "faild onnx export\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ],
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 11/26. Iteration: 646/646. Cls loss: 0.11605. Reg loss: 0.23871. Batch loss: 0.35476 Total loss: 0.27459</span><progress style='margin:2px 4px;description_width:initial;' max='646' value='646'></progress>100% 646/646 [05:22&lt;00:00,  2.26it/s]</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "faild onnx export\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ],
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 12/26. Iteration: 646/646. Cls loss: 0.03193. Reg loss: 0.12416. Batch loss: 0.15609 Total loss: 0.25952</span><progress style='margin:2px 4px;description_width:initial;' max='646' value='646'></progress>100% 646/646 [05:24&lt;00:00,  2.26it/s]</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "faild onnx export\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ],
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 13/26. Iteration: 646/646. Cls loss: 0.06896. Reg loss: 0.14583. Batch loss: 0.21479 Total loss: 0.24546</span><progress style='margin:2px 4px;description_width:initial;' max='646' value='646'></progress>100% 646/646 [05:21&lt;00:00,  2.30it/s]</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "faild onnx export\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ],
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 14/26. Iteration: 646/646. Cls loss: 0.05103. Reg loss: 0.14873. Batch loss: 0.19977 Total loss: 0.23511</span><progress style='margin:2px 4px;description_width:initial;' max='646' value='646'></progress>100% 646/646 [05:24&lt;00:00,  2.18it/s]</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "faild onnx export\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ],
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 15/26. Iteration: 646/646. Cls loss: 0.05487. Reg loss: 0.25060. Batch loss: 0.30547 Total loss: 0.22540</span><progress style='margin:2px 4px;description_width:initial;' max='646' value='646'></progress>100% 646/646 [05:22&lt;00:00,  2.17it/s]</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "faild onnx export\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ],
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span></span><progress style='margin:2px 4px;' max='646' value='646'></progress>100% 646/646 [02:54&lt;00:00,  6.93it/s]</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.58 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.59 GiB already allocated; 8.81 MiB free; 13.68 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "faild onnx export\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ],
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span></span><progress style='margin:2px 4px;' max='646' value='646'></progress>100% 646/646 [02:55&lt;00:00,  4.41it/s]</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 14.75 GiB total capacity; 13.53 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 14.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 14.75 GiB total capacity; 13.49 GiB already allocated; 10.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "faild onnx export\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ],
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span></span><progress style='margin:2px 4px;' max='646' value='646'></progress>100% 646/646 [02:52&lt;00:00,  3.75it/s]</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 30.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.13 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "faild onnx export\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ],
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span></span><progress style='margin:2px 4px;' max='646' value='646'></progress>100% 646/646 [02:54&lt;00:00,  3.70it/s]</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.48 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.25 GiB already allocated; 48.81 MiB free; 13.64 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "Epoch 00020: reducing learning rate of group 0 to 1.0000e-05.\n",
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "faild onnx export\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ],
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span></span><progress style='margin:2px 4px;' max='646' value='646'></progress>100% 646/646 [02:58&lt;00:00,  3.62it/s]</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 72.00 MiB (GPU 0; 14.75 GiB total capacity; 13.46 GiB already allocated; 12.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "faild onnx export\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ],
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span></span><progress style='margin:2px 4px;' max='646' value='646'></progress>100% 646/646 [02:58&lt;00:00,  3.63it/s]</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 194.00 MiB (GPU 0; 14.75 GiB total capacity; 13.53 GiB already allocated; 36.81 MiB free; 13.65 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.34 GiB already allocated; 102.81 MiB free; 13.58 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "faild onnx export\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ],
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span></span><progress style='margin:2px 4px;' max='646' value='646'></progress>100% 646/646 [03:05&lt;00:00,  5.61it/s]</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 14.75 GiB total capacity; 13.39 GiB already allocated; 62.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "faild onnx export\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ],
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span></span><progress style='margin:2px 4px;' max='646' value='646'></progress>100% 646/646 [03:06&lt;00:00,  5.31it/s]</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "Epoch 00024: reducing learning rate of group 0 to 1.0000e-06.\n",
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "faild onnx export\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ],
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span></span><progress style='margin:2px 4px;' max='646' value='646'></progress>100% 646/646 [03:12&lt;00:00,  3.35it/s]</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "faild onnx export\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ],
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span></span><progress style='margin:2px 4px;' max='646' value='646'></progress>100% 646/646 [03:15&lt;00:00,  3.30it/s]</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "faild onnx export\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ],
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span></span><progress style='margin:2px 4px;' max='646' value='646'></progress>100% 646/646 [03:18&lt;00:00,  5.10it/s]</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "CUDA out of memory. Tried to allocate 66.00 MiB (GPU 0; 14.75 GiB total capacity; 13.50 GiB already allocated; 22.81 MiB free; 13.66 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n",
            "faild onnx export\n",
            "CPU times: user 1h 12min 39s, sys: 5min 5s, total: 1h 17min 45s\n",
            "Wall time: 1h 54min 24s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cj9gst-hRDg"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZC263x69sfai"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append(\"Monk_Object_Detection/4_efficientdet/lib/\");"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsxWRWL8tcgP"
      },
      "source": [
        "from infer_detector import Infer"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEuuSjWYte5-"
      },
      "source": [
        "gtf = Infer();"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWbOZk-rthzW"
      },
      "source": [
        "#our trained model weights are in here in onxx format\n",
        "gtf.Model(model_dir=\"trained/\")"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CH2Tv7gstkP_"
      },
      "source": [
        "#extract class list from our annotations\n",
        "import json\n",
        "with open('train/_annotations.coco.json') as json_file:\n",
        "    data = json.load(json_file)\n",
        "class_list = []\n",
        "for category in data['categories']:\n",
        "  class_list.append(category['name'])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMLy8LIcuRQS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47472fed-694c-4fd0-9a7b-40460499746c"
      },
      "source": [
        "class_list"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Deteksi', 'Bus', 'car', 'motorcycle', 'plat', 'truck']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oc87-3NPummz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "outputId": "d0043a47-b4ae-4a05-f397-443b2f917b33"
      },
      "source": [
        "%%time\n",
        "test_images = [f for f in os.listdir('test') if f.endswith('.jpg')]\n",
        "import random\n",
        "img_path = \"test/\" + random.choice(test_images);\n",
        "duration, scores, labels, boxes = gtf.Predict(img_path, class_list, vis_threshold=0.2);"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done. (0.168s)\n",
            "NO Object Detected\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbJbgLggvGM_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "0fccb86d-8269-49d8-e5a3-6d678768fae2"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(filename='output.jpg') "
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-a1459c468b64>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'output.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m   1229\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretina\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1231\u001b[0;31m         super(Image, self).__init__(data=data, url=url, filename=filename, \n\u001b[0m\u001b[1;32m   1232\u001b[0m                 metadata=metadata)\n\u001b[1;32m   1233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1261\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1264\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfyWosXWrbWN"
      },
      "source": [
        "# Export Trained Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwDS9qqBbMQa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "456c40a0-b451-4586-9d6b-7c80f0a6d625"
      },
      "source": [
        "#export trained model\n",
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSqXvZhlbfCc"
      },
      "source": [
        "%mkdir trained_export\n",
        "%cp ./trained/signatrix_efficientdet_coco.onnx ./trained_export/signatrix_efficientdet_coco_$(date +%F-%H:%M).onnx\n",
        "%cp ./trained/signatrix_efficientdet_coco.pth ./trained_export/signatrix_efficientdet_coco_$(date +%F-%H:%M).pth\n",
        "%mv ./trained_export/* /content/drive/My\\ Drive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ieAIXwm11CO"
      },
      "source": [
        "# Reloading Trained Weights after Export\n",
        "\n",
        "Imagine you have exported your trained model and would like to reaccess it later. This portion of the notebook picks up the trained model and starts at inference\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ5__F0haiqP"
      },
      "source": [
        "#export trained model\n",
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhyNJ7GsatcD"
      },
      "source": [
        "#our fork of the Tessellate-Imaging image detection library\n",
        "#!rm -rf Monk_Object_Detection\n",
        "! git clone https://github.com/roboflow-ai/Monk_Object_Detection.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTVWQohaa2WU"
      },
      "source": [
        "# For colab use the command below\n",
        "# Set up library requirments\n",
        "! cd Monk_Object_Detection/3_mxrcnn/installation && cat requirements_colab.txt | xargs -n 1 -L 1 pip install\n",
        "\n",
        "#fixed version of tqdm output for Colab\n",
        "!pip install --force https://github.com/chengs/tqdm/archive/colab.zip\n",
        "#IGNORE restart runtime warning, it is indeed installed\n",
        "#missing a few extra packages that we will need later! \n",
        "!pip install efficientnet_pytorch\n",
        "!pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rKXFWlLbZlf"
      },
      "source": [
        "#recover trained weights\n",
        "!mkdir '/trained'\n",
        "!cp '/content/drive/MyDrive/signatrix_efficientdet_coco_2021-03-22-02:02.onnx' '/trained/signatrix_efficientdet_coco.onnx'\n",
        "!cp '/content/drive/MyDrive/signatrix_efficientdet_coco_2021-03-22-02:02.pth' '/trained/signatrix_efficientdet_coco.pth'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maetU4VddJNC"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append(\"Monk_Object_Detection/4_efficientdet/lib/\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3Jrco_TdkhU"
      },
      "source": [
        "from infer_detector import Infer\n",
        "gtf = Infer();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgZKzmI1egUa"
      },
      "source": [
        "#our trained model weights are in here in onxx format\n",
        "gtf.Model(model_dir=\"/trained\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEksZQC5fMQ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12b1122c-a820-4243-cc10-f58d27a20448"
      },
      "source": [
        "#download some test data\n",
        "!curl -L [YOUR LINK HERE] | jar -x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "curl: (3) [globbing] bad range in column 2\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (6) Could not resolve host: LINK\n",
            "curl: (3) [globbing] unmatched close brace/bracket in column 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOOGlzad1Kln",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6befb8f8-0b39-44d7-ea4b-1dd61a458054"
      },
      "source": [
        "!ls test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0b47311f426ff926578c9d738d683e76_jpg.rf.0b55f43ac16aa65c889558d8ea757072.jpg\n",
            "1c0060ef868bdc326ce5e6389cb6732f_jpg.rf.9ce88078ea356949f4ab7ad9cfdfc62d.jpg\n",
            "2f6fb003bb89cd401322a535acb42f65_jpg.rf.91ad9df05bd1f86bab67c8368ae5e4ad.jpg\n",
            "410993714e325a1de3e394ffe860df3a_jpg.rf.519bf0fdbd5e38cd44cae1cfebc98536.jpg\n",
            "4e3117459d759798537eb52cf5bf534d_jpg.rf.5b99421bf416463a8c75cfd07f8a68d1.jpg\n",
            "5a35ba2ec3e0d0b2b12b1758a8ac29aa_jpg.rf.a907af85301c729635d6ab1c31eb31b2.jpg\n",
            "654bb8835258b26c466b1c19893df451_jpg.rf.95aad22d4dd31ab256cb2bcff02a34dd.jpg\n",
            "685b860d412b91f5d4f7f9e643b84452_jpg.rf.5ba8dc0b5d2585d01b28089debd42cd6.jpg\n",
            "73a38a5c8f8f1b09f093f304660d5326_jpg.rf.2d2fa2f4b419d9f2a57fb82d38d8bc6b.jpg\n",
            "749e9074a77f8d34d86e2218f26cdab4_jpg.rf.8079f8abd9f24ec16e76fcbf18489f46.jpg\n",
            "7a34d8620235048917b28bcfd3b5572b_jpg.rf.71653deb6fe88ad472dabea12353373d.jpg\n",
            "8ff752f9ed443e6e49d495abfceb2032_jpg.rf.c3e91277eea99c26328e39a6f0285189.jpg\n",
            "a3863d0be6002c21b20ac88817b2c56f_jpg.rf.e421134b139d57e02e7df9468a35c1fb.jpg\n",
            "_annotations.coco.json\n",
            "b4ff4132c8c85da97d8bf9a2a4ed3e3d_jpg.rf.51d1d3e2f2ae5b116c7daf5a304e75ad.jpg\n",
            "b526b661a33ff481231d1342aff2a266_jpg.rf.b63c85ea45c4e3a665915fddee8c76f9.jpg\n",
            "b9402881fa580d0eb8b9b98845417550_jpg.rf.087d716cdfdd9cf2cb65b437af716d4d.jpg\n",
            "c4943d83c06a12ad5e0399d19514a4ca_jpg.rf.8b0040b3b68009f6f700ea28fb1aa491.jpg\n",
            "c5a012dfa72816098d23fc8baee67834_jpg.rf.e3f72193f30138545bf762265f30083f.jpg\n",
            "cf4769d0586df6b3fb0dc618d9f8abe6_jpg.rf.326565beb891e3656f7083109897a48b.jpg\n",
            "cfc306bf86176b92ffc1afbb98d7896f_jpg.rf.a3779da7c72dfa583f9fffa23c231beb.jpg\n",
            "d7887071e972604ddf5940d8eb2702e7_jpg.rf.9e1760bfa031e0f1b9ec48b6c0448994.jpg\n",
            "e0d38d159ad3a801d0304d7e275812cc_jpg.rf.fa0bb8160816a373df824349a24a11e7.jpg\n",
            "e4147f3d8819fc5d67a9f72596bd9e47_jpg.rf.ff3718b0109da4fea85bf6ff5631104c.jpg\n",
            "e4583d082076b2b549b3736ad1b193c9_jpg.rf.be7ed36bb2bee36cf4edad46fdd4ec75.jpg\n",
            "f1a24b6bb778ee11ba33687415aa84f2_jpg.rf.6e35192bbbb13f887540067e07d5d660.jpg\n",
            "fdcd6ada676799da8a870f58fdf548db_jpg.rf.54abced68347da874d25c5d3886d3c4a.jpg\n",
            "IMG_0159_JPG.rf.1cf4f243b5072d63e492711720df35f7.jpg\n",
            "IMG_0169_JPG.rf.b1530b71278953ad465d06863135c71e.jpg\n",
            "IMG_0170_JPG.rf.6e336797b63833d78997207d352a44fc.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0qOyjPh1MOs"
      },
      "source": [
        "#extract class list from our annotations\n",
        "#in your application you will probably already have this saved\n",
        "import json\n",
        "with open('train/_annotations.coco.json') as json_file:\n",
        "    data = json.load(json_file)\n",
        "class_list = []\n",
        "for category in data['categories']:\n",
        "  class_list.append(category['name'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xW8EEb111csu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08c78b1b-fca2-45ec-a44b-8cd35f5aa2e8"
      },
      "source": [
        "class_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pieces',\n",
              " 'bishop',\n",
              " 'black-bishop',\n",
              " 'black-king',\n",
              " 'black-knight',\n",
              " 'black-pawn',\n",
              " 'black-queen',\n",
              " 'black-rook',\n",
              " 'white-bishop',\n",
              " 'white-king',\n",
              " 'white-knight',\n",
              " 'white-pawn',\n",
              " 'white-queen',\n",
              " 'white-rook']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObmqK4EI1ga0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f05ec5d9-ac3e-47cb-e750-b34ee8b99756"
      },
      "source": [
        "%%time\n",
        "#bang!\n",
        "img_path = \"/content/test/c4943d83c06a12ad5e0399d19514a4ca_jpg.rf.8b0040b3b68009f6f700ea28fb1aa491.jpg\";\n",
        "duration, scores, labels, boxes = gtf.Predict(img_path, class_list, vis_threshold=0.2);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done. (0.044s)\n",
            "CPU times: user 258 ms, sys: 24.1 ms, total: 283 ms\n",
            "Wall time: 279 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AINktQgG1kmc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "outputId": "b6d8a8f1-3515-4ddf-fba6-ac5e447013a5"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(filename='output.jpg') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    }
  ]
}